{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca33fb7c",
   "metadata": {},
   "source": [
    "# 1. Import Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e2d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,recall_score\n",
    "\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import pickle\n",
    "import random\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import lyricsgenius as lg\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2aa3a",
   "metadata": {},
   "source": [
    "# 2. Load Preprocessing Functions and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d29e5e",
   "metadata": {},
   "source": [
    "#### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b8b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('  ',' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cff4beb",
   "metadata": {},
   "source": [
    "#### Label Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e1187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_maps = {'Spanish': 0,'Portuguese': 1,'English': 2,'Kinyarwanda': 3,'Italian': 4,'French': 5,'German': 6,\n",
    " 'Other': 7,'Finnish': 8,'Swedish': 9,'Romanian': 10}\n",
    "label_to_language = {}\n",
    "for key,value in label_maps.items():\n",
    "    label_to_language[value] = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a1efb",
   "metadata": {},
   "source": [
    "#### Class Recall + Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a3b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_recall(y_true,y_pred):\n",
    "    #true labels\n",
    "    true = y_true.numpy()\n",
    "    #predicted prob of each class for each sample\n",
    "    pred = y_pred.numpy()\n",
    "    #prob to class based off max predicted prob\n",
    "    pred = np.array([x.argmax() for x in pred])\n",
    "    #confusion matrix\n",
    "    confuse = confusion_matrix(true,pred)\n",
    "    confuse_sum = confuse.sum(axis=1)\n",
    "    score = 0\n",
    "    for num in range(len(confuse_sum)):\n",
    "        if confuse_sum[num]!=0:\n",
    "            score = score + confuse[num][num]/confuse_sum[num]\n",
    "    \n",
    "    return score/len(confuse_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b86c4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_language_detection_model(filepath):\n",
    "    def class_recall(y_true,y_pred):\n",
    "        #true labels\n",
    "        true = y_true.numpy()\n",
    "        #predicted prob of each class for each sample\n",
    "        pred = y_pred.numpy()\n",
    "        #prob to class based off max predicted prob\n",
    "        pred = np.array([x.argmax() for x in pred])\n",
    "        #confusion matrix\n",
    "        confuse = confusion_matrix(true,pred)\n",
    "        confuse_sum = confuse.sum(axis=1)\n",
    "        score = 0\n",
    "        for num in range(len(confuse_sum)):\n",
    "            if confuse_sum[num]!=0:\n",
    "                score = score + confuse[num][num]/confuse_sum[num]\n",
    "\n",
    "        return score/len(confuse_sum)\n",
    "    \n",
    "    model = load_model(filepath,custom_objects={'class_recall':class_recall})\n",
    "    return model\n",
    "\n",
    "language_detection_model = load_language_detection_model('language_detection_ff_tf.h5')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae752b38",
   "metadata": {},
   "source": [
    "#### Word Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c93207",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open('word_vectorizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c016cb9",
   "metadata": {},
   "source": [
    "#### Function to pull song lyrics, around Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6551b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "genius_api = lg.Genius(os.getenv('genius_token'))\n",
    "genius_api.verbose = False\n",
    "\n",
    "def get_song_lyrics(song_name,artist_name,genius_api):\n",
    "    try:\n",
    "        lyrics = genius_api.search_song(song_name,artist_name).lyrics\n",
    "    except:\n",
    "        lyrics = ''\n",
    "    \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cda3a",
   "metadata": {},
   "source": [
    "#### Text to Term Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a126cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lyrics = ['hello my name is Amit and I am going to the store',\n",
    " 'hola mi nombre es Amit y voy a la tienda',\n",
    " \"bonjour je m'appelle Amit et je vais au magasin\",\n",
    " \"Olá meu nome é Amit e estou indo para a loja\",\n",
    " \"ciao mi chiamo Amit e vado al negozio\",\n",
    " \"Halō nā pēru amit mariyu nēnu dukāṇāniki veḷtunnānu\",\n",
    " \"me gustan los pepinillos\"]\n",
    "\n",
    "def lyrics_to_term_density(lyrics,vectorizer):\n",
    "    bag_of_words = vectorizer.transform(lyrics).todense()\n",
    "    word_counts = bag_of_words.sum(axis=1).repeat(len(vectorizer.get_feature_names())).reshape(bag_of_words.shape)\n",
    "    term_density = bag_of_words/word_counts\n",
    "    term_density = np.nan_to_num(term_density)\n",
    "    return term_density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23278456",
   "metadata": {},
   "source": [
    "#### Lyrics to Language Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b995794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_prediction(lyrics,vectorizer,model,label_to_language):\n",
    "    \n",
    "    #Lyrics to Term Density\n",
    "    def lyrics_to_term_density(lyrics,vectorizer):\n",
    "        bag_of_words = vectorizer.transform(lyrics).todense()\n",
    "        word_counts = bag_of_words.sum(axis=1).repeat(len(vectorizer.get_feature_names())).reshape(bag_of_words.shape)\n",
    "        term_density = bag_of_words/word_counts\n",
    "        term_density = np.nan_to_num(term_density)\n",
    "        return term_density\n",
    "    \n",
    "    term_density_lyrics = lyrics_to_term_density(lyrics,vectorizer)\n",
    "    preds = [pred.argmax() for pred in model.predict(term_density_lyrics,verbose=0)]\n",
    "    preds_language = [label_to_language[label] for label in preds]\n",
    "    return preds, preds_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4c83563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2, 0, 5, 1, 4, 7, 0],\n",
       " ['English', 'Spanish', 'French', 'Portuguese', 'Italian', 'Other', 'Spanish'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_prediction(sample_lyrics,vectorizer,language_detection_model,label_to_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c0897",
   "metadata": {},
   "source": [
    "#### Lyrics to Language Prediction w/ Song From Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53a4a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_prediction_genius(song_name,artist_name,genius_api,vectorizer,model,label_to_language):\n",
    "    # get song lyrics\n",
    "    def get_song_lyrics(song_name,artist_name,genius_api):\n",
    "        try:\n",
    "            lyrics = genius_api.search_song(song_name,artist_name).lyrics\n",
    "        except:\n",
    "            lyrics = ''\n",
    "\n",
    "        return lyrics\n",
    "    \n",
    "    # return prediction for lyrics\n",
    "    def language_prediction(lyrics,vectorizer,model,label_to_language):\n",
    "    \n",
    "        #Lyrics to Term Density\n",
    "        def lyrics_to_term_density(lyrics,vectorizer):\n",
    "            bag_of_words = vectorizer.transform(lyrics).todense()\n",
    "            word_counts = bag_of_words.sum(axis=1).repeat(len(vectorizer.get_feature_names())).reshape(bag_of_words.shape)\n",
    "            term_density = bag_of_words/word_counts\n",
    "            term_density = np.nan_to_num(term_density)\n",
    "            return term_density\n",
    "\n",
    "        term_density_lyrics = lyrics_to_term_density(lyrics,vectorizer)\n",
    "        preds = [pred.argmax() for pred in model.predict(term_density_lyrics,verbose=0)]\n",
    "        preds_language = [label_to_language[label] for label in preds]\n",
    "        return preds, preds_language\n",
    "    \n",
    "    lyrics = [get_song_lyrics(song_name,artist_name,genius_api)]\n",
    "    preds,preds_language = language_prediction(lyrics,vectorizer,model,label_to_language)\n",
    "    return preds,preds_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "534a4b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0], ['Spanish'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_prediction_genius('Gasolina','Daddy Yankee',genius_api,vectorizer,language_detection_model,label_to_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd41a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
