{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47218b40",
   "metadata": {},
   "source": [
    "# 1. Import Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0327700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,recall_score\n",
    "\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "import matplotlib.pyplot as plt\n",
    "#import shap\n",
    "\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import pickle\n",
    "import random\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07bcff",
   "metadata": {},
   "source": [
    "# 2. Read in Train/Val/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c5e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open('Train_Test_Data/genre_sub_genre_train.pkl','rb'))[['danceability', 'energy',\n",
    "                                                                                 'loudness', \n",
    "                                                                                 'speechiness', 'acousticness',\n",
    "                                                                                 'instrumentalness', 'liveness', \n",
    "                                                                                 'valence', 'tempo', \n",
    "                                                                                 'duration_ms',\n",
    "                                                                                 'Lyrics','Major Genre']]\n",
    "\n",
    "val = pickle.load(open('Train_Test_Data/genre_sub_genre_test.pkl','rb'))[['danceability', 'energy',\n",
    "                                                                                 'loudness',\n",
    "                                                                                 'speechiness', 'acousticness',\n",
    "                                                                                 'instrumentalness', 'liveness', \n",
    "                                                                                 'valence', 'tempo',\n",
    "                                                                                 'duration_ms', \n",
    "                                                                                 'Lyrics','Major Genre']].iloc[:1437]\n",
    "test = pickle.load(open('Train_Test_Data/genre_sub_genre_test.pkl','rb'))[['danceability', 'energy',\n",
    "                                                                                 'loudness', \n",
    "                                                                                 'speechiness', 'acousticness',\n",
    "                                                                                 'instrumentalness', 'liveness', \n",
    "                                                                                 'valence', 'tempo',\n",
    "                                                                                 'duration_ms', \n",
    "                                                                                 'Lyrics','Major Genre']].iloc[1437:]\n",
    "\n",
    "np.random.seed(50)\n",
    "all_data = pd.concat([train,val,test],ignore_index=True)\n",
    "#all_data['Major Genre'] = all_data['Major Genre'].apply(lambda x:'Rock' if x == 'Metal' else x)\n",
    "all_data = all_data.iloc[np.random.choice(all_data.index,len(all_data))]\n",
    "train = all_data.iloc[:len(train)]\n",
    "val = all_data.iloc[len(train):len(train) + len(val)]\n",
    "test = all_data.iloc[len(train) + len(val):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e109956",
   "metadata": {},
   "source": [
    "# 3. Clean Lyric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6956d",
   "metadata": {
    "id": "e2d6956d"
   },
   "source": [
    "#### Genius API Generated Text at the beginning of lyrics, typically of the form Track Name or Album Name + ' ' + Lyrics, remove from input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025e9703",
   "metadata": {
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1658335703748,
     "user": {
      "displayName": "Amit Gattadahalli",
      "userId": "12177286346576981509"
     },
     "user_tz": 240
    },
    "id": "025e9703"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/_wnqfx9n7674x_jkw4jm41xw0000gn/T/ipykernel_12378/217011968.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Lyrics'] = train['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())\n",
      "/var/folders/w2/_wnqfx9n7674x_jkw4jm41xw0000gn/T/ipykernel_12378/217011968.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val['Lyrics'] = val['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())\n",
      "/var/folders/w2/_wnqfx9n7674x_jkw4jm41xw0000gn/T/ipykernel_12378/217011968.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Lyrics'] = test['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())\n"
     ]
    }
   ],
   "source": [
    "train['Lyrics'] = train['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())\n",
    "val['Lyrics'] = val['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())\n",
    "test['Lyrics'] = test['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7f4d3",
   "metadata": {
    "id": "2bd7f4d3"
   },
   "source": [
    "#### Drop examples with over 1000 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724a610a",
   "metadata": {
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1658335704874,
     "user": {
      "displayName": "Amit Gattadahalli",
      "userId": "12177286346576981509"
     },
     "user_tz": 240
    },
    "id": "724a610a"
   },
   "outputs": [],
   "source": [
    "token_thresh = 1000\n",
    "\n",
    "train_bool = train['Lyrics'].apply(lambda x:True if len(str(x).split()) <= token_thresh else False)\n",
    "train = train[train_bool]\n",
    "\n",
    "val_bool = val['Lyrics'].apply(lambda x:True if len(str(x).split()) <= token_thresh else False)\n",
    "val = val[val_bool]\n",
    "\n",
    "test_bool = test['Lyrics'].apply(lambda x:True if len(str(x).split()) <= token_thresh else False)\n",
    "test = test[test_bool]\n",
    "\n",
    "train.index = np.arange(0,len(train))\n",
    "val.index = np.arange(0,len(val))\n",
    "test.index = np.arange(0,len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95cd70f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_bool,val_bool,test_bool\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00f93a",
   "metadata": {
    "id": "9b00f93a"
   },
   "source": [
    "#### Get Language Indicators Marking Natural Split Points Between Songs, shown by genius API with language between brackets to serve as potential text splitting criteria later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a2b504",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1658335704875,
     "user": {
      "displayName": "Amit Gattadahalli",
      "userId": "12177286346576981509"
     },
     "user_tz": 240
    },
    "id": "d9a2b504"
   },
   "outputs": [],
   "source": [
    "def split_text_into_regions(text):\n",
    "    string = text\n",
    "    \n",
    "    #mark line breaks\n",
    "    string = string.replace('\\n','[]')\n",
    "    string = string.replace('embed','')\n",
    "    #find language indicators of song sections\n",
    "    splits = re.findall('\\[.*?\\]',string)\n",
    "    #find ad libs to remove\n",
    "    ad_libs = re.findall('\\(.*?\\)',string)\n",
    "    \n",
    "    #remove ad libs\n",
    "    if len(ad_libs) > 0:\n",
    "        for ad_lib in ad_libs:\n",
    "            string = string.replace(ad_lib,'')\n",
    "        string = string.replace('  ',' ')\n",
    "    \n",
    "    #If there is no splitting criteria, single string is entire song without any additional groupings\n",
    "    if len(splits) == 0:\n",
    "        string = [string]\n",
    "    else:\n",
    "        #replace split criteria with makers for splitting\n",
    "        for delim in splits:\n",
    "            string = string.replace(delim,'[]')\n",
    "        string = string.split('[]')\n",
    "    \n",
    "    #Identify sections of song, made up of groups of lyrics\n",
    "    sections = []\n",
    "    section = []\n",
    "    last_part = ''\n",
    "    for part in string:\n",
    "        if part == '' and last_part != '':\n",
    "            sections.append(section)\n",
    "            section = []\n",
    "        elif part != '':\n",
    "            section.append(part)\n",
    "        \n",
    "        last_part = part\n",
    "    \n",
    "    try:\n",
    "        if section != sections[-1]:\n",
    "            sections.append(section)\n",
    "    except:\n",
    "        sections.append(section)\n",
    "    \n",
    "    return sections    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be688571",
   "metadata": {
    "id": "be688571"
   },
   "source": [
    "#### Cleaner version of lyrics by joining the lyric groups above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0610488",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1658335704875,
     "user": {
      "displayName": "Amit Gattadahalli",
      "userId": "12177286346576981509"
     },
     "user_tz": 240
    },
    "id": "c0610488"
   },
   "outputs": [],
   "source": [
    "def single_text_lyrics(group_of_lyrics):\n",
    "    lyrics = ''\n",
    "    for group in group_of_lyrics:\n",
    "        lyrics = lyrics + ' ' + ' '.join(group)\n",
    "    return lyrics.strip() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99abee49",
   "metadata": {
    "id": "99abee49"
   },
   "source": [
    "#### Create Modified Versions of Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff11e2d",
   "metadata": {
    "executionInfo": {
     "elapsed": 2835,
     "status": "ok",
     "timestamp": 1658335707707,
     "user": {
      "displayName": "Amit Gattadahalli",
      "userId": "12177286346576981509"
     },
     "user_tz": 240
    },
    "id": "9ff11e2d"
   },
   "outputs": [],
   "source": [
    "# Lyric Groups\n",
    "train['Lyric Group'] = train['Lyrics'].apply(lambda x:split_text_into_regions(x))\n",
    "val['Lyric Group'] = val['Lyrics'].apply(lambda x:split_text_into_regions(x))\n",
    "test['Lyric Group'] = test['Lyrics'].apply(lambda x:split_text_into_regions(x))\n",
    "\n",
    "# Cleaner Lyrics\n",
    "train['Cleaner Lyrics'] = train['Lyric Group'].apply(lambda x:single_text_lyrics(x))\n",
    "val['Cleaner Lyrics'] = val['Lyric Group'].apply(lambda x:single_text_lyrics(x))\n",
    "test['Cleaner Lyrics'] = test['Lyric Group'].apply(lambda x:single_text_lyrics(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37653a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Cleaner Lyrics'] != '']\n",
    "val = val[val['Cleaner Lyrics'] != '']\n",
    "test = test[test['Cleaner Lyrics'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0dc5de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock           0.321368\n",
       "Indie          0.157749\n",
       "Pop            0.142096\n",
       "Metal          0.120842\n",
       "Hip Hop        0.100600\n",
       "Alternative    0.096822\n",
       "Blues          0.060522\n",
       "Name: Major Genre, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Rock           0.316679\n",
       "Indie          0.164489\n",
       "Pop            0.146810\n",
       "Metal          0.126826\n",
       "Hip Hop        0.094543\n",
       "Alternative    0.086856\n",
       "Blues          0.063797\n",
       "Name: Major Genre, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Rock           0.310185\n",
       "Indie          0.172068\n",
       "Pop            0.153549\n",
       "Alternative    0.105710\n",
       "Metal          0.105710\n",
       "Hip Hop        0.095679\n",
       "Blues          0.057099\n",
       "Name: Major Genre, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train['Major Genre'].value_counts()/len(train))\n",
    "display(val['Major Genre'].value_counts()/len(val))\n",
    "display(test['Major Genre'].value_counts()/len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2d7bb",
   "metadata": {},
   "source": [
    "# 4. Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339cd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_weights = train['Major Genre'].value_counts().max()/train['Major Genre'].value_counts()\n",
    "class_weights = {}\n",
    "label_mapping = {}\n",
    "weights = {}\n",
    "\n",
    "for num in range(len(label_weights)):\n",
    "    class_weights[label_weights.index[num]] = label_weights.iloc[num]\n",
    "    label_mapping[label_weights.index[num]] = num\n",
    "    weights[num] = label_weights.iloc[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab129bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rock': 1.0,\n",
       " 'Indie': 2.0372112917023095,\n",
       " 'Pop': 2.261633428300095,\n",
       " 'Metal': 2.6594081518704633,\n",
       " 'Hip Hop': 3.194500335345406,\n",
       " 'Alternative': 3.3191637630662023,\n",
       " 'Blues': 5.309921962095875}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Rock': 0,\n",
       " 'Indie': 1,\n",
       " 'Pop': 2,\n",
       " 'Metal': 3,\n",
       " 'Hip Hop': 4,\n",
       " 'Alternative': 5,\n",
       " 'Blues': 6}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.0,\n",
       " 1: 2.0372112917023095,\n",
       " 2: 2.261633428300095,\n",
       " 3: 2.6594081518704633,\n",
       " 4: 3.194500335345406,\n",
       " 5: 3.3191637630662023,\n",
       " 6: 5.309921962095875}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(class_weights)\n",
    "display(label_mapping)\n",
    "display(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece443c7",
   "metadata": {},
   "source": [
    "# 5. Separate Audio and Lyric Features, labels, Standardize Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "769ae78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train.iloc[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c160183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Audio + Lyrics\n",
    "train_audio = scaler.transform(train.iloc[:,:10])\n",
    "train_lyrics = train.iloc[:,-1]\n",
    "\n",
    "# Val Audio + Lyrics\n",
    "val_audio = scaler.transform(val.iloc[:,:10])\n",
    "val_lyrics = val.iloc[:,-1]\n",
    "\n",
    "# Test Audio + Lyrics\n",
    "test_audio = scaler.transform(test.iloc[:,:10])\n",
    "test_lyrics = test.iloc[:,-1]\n",
    "\n",
    "#Train/Val/Test Labels\n",
    "train_labels = train.iloc[:,-3].map(label_mapping)\n",
    "val_labels = val.iloc[:,-3].map(label_mapping)\n",
    "test_labels = test.iloc[:,-3].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc26c66",
   "metadata": {},
   "source": [
    "# 6. Feed Forward Network w/ Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce62fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_recall(y_true,y_pred):\n",
    "    #true labels\n",
    "    true = y_true.numpy()\n",
    "    #predicted prob of each class for each sample\n",
    "    pred = y_pred.numpy()\n",
    "    #prob to class based off max predicted prob\n",
    "    pred = np.array([x.argmax() for x in pred])\n",
    "    #confusion matrix\n",
    "    confuse = confusion_matrix(true,pred)\n",
    "    confuse_sum = confuse.sum(axis=1)\n",
    "    score = 0\n",
    "    for num in range(len(confuse_sum)):\n",
    "        if confuse_sum[num]!=0:\n",
    "            score = score + confuse[num][num]/confuse_sum[num]\n",
    "    \n",
    "    return score/len(confuse_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8b46329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ff(hidden_layers = [100,100],hidden_layer_activation = 'relu',dropout_rate = 0.3,shape=(10,),\n",
    "             output_layer_size = 7, output_layer_activation = 'softmax',learning_rate = 0.001,epochs = 10):\n",
    "    \n",
    "    #input layer\n",
    "    input_layer = tf.keras.layers.Input(shape=shape)\n",
    "    \n",
    "    x = input_layer\n",
    "    for layer in hidden_layers:\n",
    "        #hidden layer\n",
    "        hidden = tf.keras.layers.Dense(layer,activation=hidden_layer_activation)(x)\n",
    "        dropout = tf.keras.layers.Dropout(rate=dropout_rate)(hidden)\n",
    "        x = dropout\n",
    "    \n",
    "    #classification\n",
    "    classification = tf.keras.layers.Dense(output_layer_size,activation= output_layer_activation)(x)\n",
    "    \n",
    "    #model\n",
    "    model = tf.keras.models.Model(inputs = [input_layer], outputs = [classification])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,decay=learning_rate/epochs),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                            metrics=['accuracy',class_recall],\n",
    "                 run_eagerly=True)\n",
    "    \n",
    "    display(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab1459d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               1100      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,907\n",
      "Trainable params: 11,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 00:34:54.537953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 66s 35ms/step - loss: 3.9960 - accuracy: 0.2577 - class_recall: 0.2217 - val_loss: 1.6325 - val_accuracy: 0.3566 - val_class_recall: 0.3110\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 65s 35ms/step - loss: 3.5048 - accuracy: 0.3442 - class_recall: 0.2912 - val_loss: 1.5454 - val_accuracy: 0.3797 - val_class_recall: 0.3165\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 65s 35ms/step - loss: 3.4117 - accuracy: 0.3660 - class_recall: 0.3077 - val_loss: 1.5353 - val_accuracy: 0.3782 - val_class_recall: 0.3250\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 65s 35ms/step - loss: 3.3593 - accuracy: 0.3748 - class_recall: 0.3142 - val_loss: 1.5120 - val_accuracy: 0.3897 - val_class_recall: 0.3371\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 65s 35ms/step - loss: 3.3404 - accuracy: 0.3829 - class_recall: 0.3199 - val_loss: 1.5099 - val_accuracy: 0.3966 - val_class_recall: 0.3438\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 65s 35ms/step - loss: 3.3172 - accuracy: 0.3810 - class_recall: 0.3212 - val_loss: 1.5019 - val_accuracy: 0.4035 - val_class_recall: 0.3483\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - 65s 35ms/step - loss: 3.2892 - accuracy: 0.3888 - class_recall: 0.3309 - val_loss: 1.5098 - val_accuracy: 0.3989 - val_class_recall: 0.3458\n",
      "Epoch 8/30\n",
      "1853/1853 [==============================] - 64s 34ms/step - loss: 3.2785 - accuracy: 0.3859 - class_recall: 0.3290 - val_loss: 1.5088 - val_accuracy: 0.3989 - val_class_recall: 0.3480\n",
      "Epoch 9/30\n",
      "1853/1853 [==============================] - 63s 34ms/step - loss: 3.2607 - accuracy: 0.3907 - class_recall: 0.3322 - val_loss: 1.4957 - val_accuracy: 0.4043 - val_class_recall: 0.3537\n",
      "Epoch 10/30\n",
      "1853/1853 [==============================] - 63s 34ms/step - loss: 3.2573 - accuracy: 0.3950 - class_recall: 0.3325 - val_loss: 1.4978 - val_accuracy: 0.4005 - val_class_recall: 0.3509\n",
      "Epoch 11/30\n",
      "1853/1853 [==============================] - 63s 34ms/step - loss: 3.2575 - accuracy: 0.3905 - class_recall: 0.3286 - val_loss: 1.5066 - val_accuracy: 0.4028 - val_class_recall: 0.3514\n",
      "Epoch 12/30\n",
      "1853/1853 [==============================] - 63s 34ms/step - loss: 3.2486 - accuracy: 0.3911 - class_recall: 0.3286 - val_loss: 1.5009 - val_accuracy: 0.3966 - val_class_recall: 0.3473\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8a44b0250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30\n",
    "model = create_ff(shape=(train_audio.shape[1],),epochs = epochs)\n",
    "stoppage = keras.callbacks.EarlyStopping(monitor = 'val_class_recall',verbose=1,patience=3,mode='max')\n",
    "model.fit(np.array(train_audio),np.array(train_labels),\n",
    "         validation_data=(np.array(val_audio),np.array(val_labels)),\n",
    "         epochs = epochs,\n",
    "         batch_size=8,\n",
    "         class_weight = weights,\n",
    "         shuffle=True,\n",
    "         callbacks = [stoppage])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9462123",
   "metadata": {},
   "source": [
    "# 7. Standardized Term Density Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c570f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train['Cleaner Lyrics'])\n",
    "\n",
    "train_lyrics = pd.DataFrame(vectorizer.transform(train['Cleaner Lyrics']).todense(),columns = vectorizer.get_feature_names())\n",
    "train_lyrics = (train_lyrics/np.array(train_lyrics).sum(axis = 1).repeat(len(vectorizer.get_feature_names())).reshape(train_lyrics.shape)).astype('float32')\n",
    "\n",
    "val_lyrics = pd.DataFrame(vectorizer.transform(val['Cleaner Lyrics']).todense(),columns = vectorizer.get_feature_names())\n",
    "val_lyrics = (val_lyrics/np.array(val_lyrics).sum(axis = 1).repeat(len(vectorizer.get_feature_names())).reshape(val_lyrics.shape)).astype('float32')\n",
    "\n",
    "test_lyrics = pd.DataFrame(vectorizer.transform(test['Cleaner Lyrics']).todense(),columns = vectorizer.get_feature_names())\n",
    "test_lyrics = (test_lyrics/np.array(test_lyrics).sum(axis = 1).repeat(len(vectorizer.get_feature_names())).reshape(test_lyrics.shape)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62bd5595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Term Density Features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_lyrics)\n",
    "\n",
    "train_lyrics = scaler.transform(train_lyrics)\n",
    "val_lyrics = scaler.transform(val_lyrics)\n",
    "test_lyrics = scaler.transform(test_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0e38daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 83372)]           0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               8337300   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,348,107\n",
      "Trainable params: 8,348,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 123s 67ms/step - loss: 16.1509 - accuracy: 0.2432 - class_recall: 0.1901 - val_loss: nan - val_accuracy: 0.4650 - val_class_recall: 0.3770\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 123s 66ms/step - loss: 14.4001 - accuracy: 0.4176 - class_recall: 0.3439 - val_loss: nan - val_accuracy: 0.4950 - val_class_recall: 0.4241\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 120s 65ms/step - loss: 10.5123 - accuracy: 0.5623 - class_recall: 0.4802 - val_loss: nan - val_accuracy: 0.5880 - val_class_recall: 0.5041\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 119s 64ms/step - loss: 8.0101 - accuracy: 0.6545 - class_recall: 0.5710 - val_loss: nan - val_accuracy: 0.6018 - val_class_recall: 0.5250\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 119s 64ms/step - loss: 5.9729 - accuracy: 0.7159 - class_recall: 0.6397 - val_loss: nan - val_accuracy: 0.6141 - val_class_recall: 0.5380\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 118s 64ms/step - loss: 4.2827 - accuracy: 0.7614 - class_recall: 0.6898 - val_loss: nan - val_accuracy: 0.6257 - val_class_recall: 0.5421\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - 120s 65ms/step - loss: 4.2000 - accuracy: 0.7865 - class_recall: 0.7206 - val_loss: nan - val_accuracy: 0.6195 - val_class_recall: 0.5422\n",
      "Epoch 8/30\n",
      "1853/1853 [==============================] - 120s 65ms/step - loss: 3.3193 - accuracy: 0.8068 - class_recall: 0.7431 - val_loss: nan - val_accuracy: 0.6287 - val_class_recall: 0.5560\n",
      "Epoch 9/30\n",
      "1853/1853 [==============================] - 120s 65ms/step - loss: 3.0199 - accuracy: 0.8192 - class_recall: 0.7586 - val_loss: nan - val_accuracy: 0.6372 - val_class_recall: 0.5585\n",
      "Epoch 10/30\n",
      "1853/1853 [==============================] - 118s 64ms/step - loss: 2.6130 - accuracy: 0.8317 - class_recall: 0.7726 - val_loss: nan - val_accuracy: 0.6380 - val_class_recall: 0.5627\n",
      "Epoch 11/30\n",
      "1853/1853 [==============================] - 118s 64ms/step - loss: 2.4144 - accuracy: 0.8365 - class_recall: 0.7797 - val_loss: nan - val_accuracy: 0.6334 - val_class_recall: 0.5544\n",
      "Epoch 12/30\n",
      "1853/1853 [==============================] - 118s 64ms/step - loss: 2.7658 - accuracy: 0.8421 - class_recall: 0.7862 - val_loss: nan - val_accuracy: 0.6357 - val_class_recall: 0.5576\n",
      "Epoch 13/30\n",
      "1853/1853 [==============================] - 118s 64ms/step - loss: 2.1293 - accuracy: 0.8497 - class_recall: 0.7961 - val_loss: nan - val_accuracy: 0.6311 - val_class_recall: 0.5563\n",
      "Epoch 13: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb941c01a90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30\n",
    "model = create_ff(shape=(train_lyrics.shape[1]),dropout_rate=0.3,hidden_layers=[100,100],epochs = epochs)\n",
    "stoppage = keras.callbacks.EarlyStopping(monitor = 'val_class_recall',verbose=1,patience=3,mode='max')\n",
    "model.fit(train_lyrics,np.array(train_labels),\n",
    "         validation_data=(val_lyrics,np.array(val_labels)),\n",
    "         epochs = epochs,\n",
    "         batch_size=8,\n",
    "         class_weight = weights,\n",
    "         shuffle=True,\n",
    "         callbacks=[stoppage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b9d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 83382)]           0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               8338300   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,349,107\n",
      "Trainable params: 8,349,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 123s 66ms/step - loss: 17.9347 - accuracy: 0.2319 - class_recall: 0.1905 - val_loss: nan - val_accuracy: 0.3759 - val_class_recall: 0.3281\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 14.2402 - accuracy: 0.4202 - class_recall: 0.3531 - val_loss: nan - val_accuracy: 0.5111 - val_class_recall: 0.4360\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 11.0513 - accuracy: 0.5508 - class_recall: 0.4728 - val_loss: nan - val_accuracy: 0.5965 - val_class_recall: 0.5151\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 8.2038 - accuracy: 0.6444 - class_recall: 0.5685 - val_loss: nan - val_accuracy: 0.6126 - val_class_recall: 0.5378\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 6.0602 - accuracy: 0.7020 - class_recall: 0.6278 - val_loss: nan - val_accuracy: 0.6080 - val_class_recall: 0.5379\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 4.8763 - accuracy: 0.7405 - class_recall: 0.6696 - val_loss: nan - val_accuracy: 0.6280 - val_class_recall: 0.5517\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 4.3223 - accuracy: 0.7677 - class_recall: 0.6969 - val_loss: nan - val_accuracy: 0.6372 - val_class_recall: 0.5614\n",
      "Epoch 8/30\n",
      "1853/1853 [==============================] - 124s 67ms/step - loss: 3.7471 - accuracy: 0.7858 - class_recall: 0.7196 - val_loss: nan - val_accuracy: 0.6526 - val_class_recall: 0.5766\n",
      "Epoch 9/30\n",
      "1853/1853 [==============================] - 123s 67ms/step - loss: 3.1364 - accuracy: 0.8039 - class_recall: 0.7422 - val_loss: nan - val_accuracy: 0.6518 - val_class_recall: 0.5769\n",
      "Epoch 10/30\n",
      "1853/1853 [==============================] - 123s 66ms/step - loss: 2.8432 - accuracy: 0.8191 - class_recall: 0.7605 - val_loss: nan - val_accuracy: 0.6549 - val_class_recall: 0.5770\n",
      "Epoch 11/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 2.4475 - accuracy: 0.8260 - class_recall: 0.7661 - val_loss: nan - val_accuracy: 0.6387 - val_class_recall: 0.5655\n",
      "Epoch 12/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 2.2707 - accuracy: 0.8325 - class_recall: 0.7748 - val_loss: nan - val_accuracy: 0.6487 - val_class_recall: 0.5680\n",
      "Epoch 13/30\n",
      "1853/1853 [==============================] - 122s 66ms/step - loss: 2.2583 - accuracy: 0.8365 - class_recall: 0.7811 - val_loss: nan - val_accuracy: 0.6487 - val_class_recall: 0.5695\n",
      "Epoch 13: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8a44e4d00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30\n",
    "model = create_ff(shape=(train_lyrics.shape[1] + train_audio.shape[1]),epochs = epochs)\n",
    "stoppage = keras.callbacks.EarlyStopping(monitor = 'val_class_recall',verbose=1,patience=3,mode='max')\n",
    "model.fit(np.hstack((train_lyrics,train_audio)),np.array(train_labels),\n",
    "         validation_data=(np.hstack((val_lyrics,val_audio)),np.array(val_labels)),\n",
    "         epochs = epochs,\n",
    "         batch_size=8,\n",
    "         class_weight = weights,\n",
    "         shuffle=True,\n",
    "         callbacks=[stoppage])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1a6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
