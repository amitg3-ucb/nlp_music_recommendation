{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibI44CbFPvC3",
    "outputId": "1c71485e-a302-4542-9f4e-b680582234f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading word2vec_sample: <urlopen error [Errno 60]\n",
      "[nltk_data]     Operation timed out>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 60]\n",
      "[nltk_data]     Operation timed out>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,recall_score\n",
    "\n",
    "#!pip install transformers\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import string\n",
    "import multiprocessing\n",
    "import unicodedata\n",
    "import re\n",
    "import gc\n",
    "import sklearn\n",
    "\n",
    "#!pip install gensim==4.2.0 \n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "nltk.download('word2vec_sample')\n",
    "from nltk.data import find\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gG2aCR59PvC5",
    "outputId": "e061aa65-2f82-425a-e43e-146894c655fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trespimentel/Desktop/w266_final_project/Genre_Classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6hIOBUdovYQ",
    "outputId": "40e8e3ff-76b1-4123-87e9-bba79f910cfb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scikit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-5aabad044985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscikit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'scikit' is not defined"
     ]
    }
   ],
   "source": [
    "print(scikit-learn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement sklearn==0.24.2 (from versions: 0.0)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for sklearn==0.24.2\u001b[0m\n",
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "#!pip uninstall sklearn\n",
    "!pip install sklearn==0.24.2\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRhYLs2tPvC6"
   },
   "source": [
    "# 1. Import data, filter out problematic data, create normalized feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "G-jwOWUgPvC7"
   },
   "outputs": [],
   "source": [
    "# import train and test data\n",
    "#df_test = pkl.load(open('Train_Test_Data/genre_sub_genre_test.pkl', 'rb'))\n",
    "#df_train = pkl.load(open('Train_Test_Data/genre_sub_genre_train.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "avpabnZ5gV3w"
   },
   "outputs": [],
   "source": [
    "#df_all = pd.concat([df_train, df_test], ignore_index=True)\n",
    "#print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ynJABDGugV3x"
   },
   "outputs": [],
   "source": [
    "#df_all = df_all.sample(frac=1)\n",
    "#print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g1TajdBEgV3y"
   },
   "outputs": [],
   "source": [
    "#df_train = df_all[:15375]\n",
    "#df_val = df_all[15375:17375]\n",
    "#df_test = df_all[17375:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y5ALf19_gV3z"
   },
   "outputs": [],
   "source": [
    "#pkl.dump(df_train,open('Train_Test_Data/genre_train.pkl','wb'))\n",
    "#pkl.dump(df_val,open('Train_Test_Data/genre_val.pkl','wb'))\n",
    "#pkl.dump(df_test,open('Train_Test_Data/genre_test.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FRCOe3T6gV3z"
   },
   "outputs": [],
   "source": [
    "train = pkl.load(open('Train_Test_Data/genre_train_final.pkl', 'rb'))\n",
    "val = pkl.load(open('Train_Test_Data/genre_val_final.pkl', 'rb'))\n",
    "test = pkl.load(open('Train_Test_Data/genre_test_final.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Lyrics'] = train['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())\n",
    "val['Lyrics'] = val['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())\n",
    "test['Lyrics'] = test['Lyrics'].apply(lambda x: ' '.join(x.split(' Lyrics')[1:]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_thresh = 1000\n",
    "\n",
    "train_bool = train['Lyrics'].apply(lambda x:True if len(str(x).split()) <= token_thresh else False)\n",
    "train = train[train_bool]\n",
    "\n",
    "val_bool = val['Lyrics'].apply(lambda x:True if len(str(x).split()) <= token_thresh else False)\n",
    "val = val[val_bool]\n",
    "\n",
    "test_bool = test['Lyrics'].apply(lambda x:True if len(str(x).split()) <= token_thresh else False)\n",
    "test = test[test_bool]\n",
    "\n",
    "train.index = np.arange(0,len(train))\n",
    "val.index = np.arange(0,len(val))\n",
    "test.index = np.arange(0,len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_bool,val_bool,test_bool\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_regions(text):\n",
    "    string = text\n",
    "    \n",
    "    #mark line breaks\n",
    "    string = string.replace('\\n','[]')\n",
    "    string = string.replace('embed','')\n",
    "    #find language indicators of song sections\n",
    "    splits = re.findall('\\[.*?\\]',string)\n",
    "    #find ad libs to remove\n",
    "    ad_libs = re.findall('\\(.*?\\)',string)\n",
    "    \n",
    "    #remove ad libs\n",
    "    if len(ad_libs) > 0:\n",
    "        for ad_lib in ad_libs:\n",
    "            string = string.replace(ad_lib,'')\n",
    "        string = string.replace('  ',' ')\n",
    "    \n",
    "    #If there is no splitting criteria, single string is entire song without any additional groupings\n",
    "    if len(splits) == 0:\n",
    "        string = [string]\n",
    "    else:\n",
    "        #replace split criteria with makers for splitting\n",
    "        for delim in splits:\n",
    "            string = string.replace(delim,'[]')\n",
    "        string = string.split('[]')\n",
    "    \n",
    "    #Identify sections of song, made up of groups of lyrics\n",
    "    sections = []\n",
    "    section = []\n",
    "    last_part = ''\n",
    "    for part in string:\n",
    "        if part == '' and last_part != '':\n",
    "            sections.append(section)\n",
    "            section = []\n",
    "        elif part != '':\n",
    "            section.append(part)\n",
    "        \n",
    "        last_part = part\n",
    "    \n",
    "    try:\n",
    "        if section != sections[-1]:\n",
    "            sections.append(section)\n",
    "    except:\n",
    "        sections.append(section)\n",
    "    \n",
    "    return sections    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_text_lyrics(group_of_lyrics):\n",
    "    lyrics = ''\n",
    "    for group in group_of_lyrics:\n",
    "        lyrics = lyrics + ' ' + ' '.join(group)\n",
    "    return lyrics.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lyric Groups\n",
    "train['Lyric Group'] = train['Lyrics'].apply(lambda x:split_text_into_regions(x))\n",
    "val['Lyric Group'] = val['Lyrics'].apply(lambda x:split_text_into_regions(x))\n",
    "test['Lyric Group'] = test['Lyrics'].apply(lambda x:split_text_into_regions(x))\n",
    "\n",
    "# Cleaner Lyrics\n",
    "train['Cleaner Lyrics'] = train['Lyric Group'].apply(lambda x:single_text_lyrics(x))\n",
    "val['Cleaner Lyrics'] = val['Lyric Group'].apply(lambda x:single_text_lyrics(x))\n",
    "test['Cleaner Lyrics'] = test['Lyric Group'].apply(lambda x:single_text_lyrics(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Cleaner Lyrics'] != '']\n",
    "val = val[val['Cleaner Lyrics'] != '']\n",
    "test = test[test['Cleaner Lyrics'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock           0.321368\n",
       "Indie          0.157749\n",
       "Pop            0.142096\n",
       "Metal          0.120842\n",
       "Hip Hop        0.100600\n",
       "Alternative    0.096822\n",
       "Blues          0.060522\n",
       "Name: Major Genre, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Rock           0.316679\n",
       "Indie          0.164489\n",
       "Pop            0.146810\n",
       "Metal          0.126826\n",
       "Hip Hop        0.094543\n",
       "Alternative    0.086856\n",
       "Blues          0.063797\n",
       "Name: Major Genre, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Rock           0.310185\n",
       "Indie          0.172068\n",
       "Pop            0.153549\n",
       "Alternative    0.105710\n",
       "Metal          0.105710\n",
       "Hip Hop        0.095679\n",
       "Blues          0.057099\n",
       "Name: Major Genre, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train['Major Genre'].value_counts()/len(train))\n",
    "display(val['Major Genre'].value_counts()/len(val))\n",
    "display(test['Major Genre'].value_counts()/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_weights = train['Major Genre'].value_counts().max()/train['Major Genre'].value_counts()\n",
    "class_weights = {}\n",
    "label_mapping = {}\n",
    "weights = {}\n",
    "\n",
    "for num in range(len(label_weights)):\n",
    "    class_weights[label_weights.index[num]] = label_weights.iloc[num]\n",
    "    label_mapping[label_weights.index[num]] = num\n",
    "    weights[num] = label_weights.iloc[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rock': 1.0,\n",
       " 'Indie': 2.0372112917023095,\n",
       " 'Pop': 2.261633428300095,\n",
       " 'Metal': 2.6594081518704633,\n",
       " 'Hip Hop': 3.194500335345406,\n",
       " 'Alternative': 3.3191637630662023,\n",
       " 'Blues': 5.309921962095875}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Rock': 0,\n",
       " 'Indie': 1,\n",
       " 'Pop': 2,\n",
       " 'Metal': 3,\n",
       " 'Hip Hop': 4,\n",
       " 'Alternative': 5,\n",
       " 'Blues': 6}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.0,\n",
       " 1: 2.0372112917023095,\n",
       " 2: 2.261633428300095,\n",
       " 3: 2.6594081518704633,\n",
       " 4: 3.194500335345406,\n",
       " 5: 3.3191637630662023,\n",
       " 6: 5.309921962095875}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(class_weights)\n",
    "display(label_mapping)\n",
    "display(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALER STARTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train.iloc[:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Audio + Lyrics\n",
    "train_audio = scaler.transform(train.iloc[:,:10])\n",
    "train_lyrics = train.iloc[:,-1]\n",
    "\n",
    "# Val Audio + Lyrics\n",
    "val_audio = scaler.transform(val.iloc[:,:10])\n",
    "val_lyrics = val.iloc[:,-1]\n",
    "\n",
    "# Test Audio + Lyrics\n",
    "test_audio = scaler.transform(test.iloc[:,:10])\n",
    "test_lyrics = test.iloc[:,-1]\n",
    "\n",
    "#Train/Val/Test Labels\n",
    "train_labels = train.iloc[:,-3].map(label_mapping)\n",
    "val_labels = val.iloc[:,-3].map(label_mapping)\n",
    "test_labels = test.iloc[:,-3].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_recall(y_true,y_pred):\n",
    "    #true labels\n",
    "    true = y_true.numpy()\n",
    "    #predicted prob of each class for each sample\n",
    "    pred = y_pred.numpy()\n",
    "    #prob to class based off max predicted prob\n",
    "    pred = np.array([x.argmax() for x in pred])\n",
    "    #confusion matrix\n",
    "    confuse = confusion_matrix(true,pred)\n",
    "    confuse_sum = confuse.sum(axis=1)\n",
    "    score = 0\n",
    "    for num in range(len(confuse_sum)):\n",
    "        if confuse_sum[num]!=0:\n",
    "            score = score + confuse[num][num]/confuse_sum[num]\n",
    "    \n",
    "    return score/len(confuse_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ff(hidden_layers = [100,100],hidden_layer_activation = 'relu',dropout_rate = 0.3,shape=(10,),\n",
    "             output_layer_size = 7, output_layer_activation = 'softmax',learning_rate = 0.001,epochs = 10):\n",
    "    \n",
    "    #input layer\n",
    "    input_layer = tf.keras.layers.Input(shape=shape)\n",
    "    \n",
    "    x = input_layer\n",
    "    for layer in hidden_layers:\n",
    "        #hidden layer\n",
    "        hidden = tf.keras.layers.Dense(layer,activation=hidden_layer_activation)(x)\n",
    "        dropout = tf.keras.layers.Dropout(rate=dropout_rate)(hidden)\n",
    "        x = dropout\n",
    "    \n",
    "    #classification\n",
    "    classification = tf.keras.layers.Dense(output_layer_size,activation= output_layer_activation)(x)\n",
    "    \n",
    "    #model\n",
    "    model = tf.keras.models.Model(inputs = [input_layer], outputs = [classification])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,decay=learning_rate/epochs),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                            metrics=['accuracy',class_recall],\n",
    "                 run_eagerly=True)\n",
    "    \n",
    "    display(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clean after here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    deep dive slithering height of the skyline blu...\n",
       "1    and how does it feel like to wake up in the su...\n",
       "2    well, i don't want to be useless neutered and ...\n",
       "3    i'm just trying to make you see oh i'm just tr...\n",
       "4    december 31st, i grabbed a beer threw it up, s...\n",
       "Name: Cleaner Lyrics, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cleaner Lyrics'].iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3vEwxhEPvC8",
    "outputId": "599bd4b2-1850-48e1-b595-aab8b30520c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000    Witching Hour Lyrics[Verse 1]\\nDeep dive\\nSlit...\n",
       "5600     Let Forever Be Lyrics[Instrumental Intro]\\n\\n[...\n",
       "10123    Gold Lyrics[Verse 1]\\nWell, I don't want to be...\n",
       "15649    Bruise Cruise LyricsI'm just trying to make yo...\n",
       "14565    F2020 Lyrics[Verse 1]\\nDecember 31st, I grabbe...\n",
       "Name: Lyrics, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train['Lyrics'].iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeS--6ecPvC8"
   },
   "source": [
    "data cleanliness issue: it seems that a few things were causing us to get incorrect lyrics from genius:\n",
    "\n",
    "1. our dataset contains versions of songs e.g. xyz remastered, xyz live version, etc. which genius thinks is a different song than the actual \"base\" song\n",
    "\n",
    "2. genius saves songs/artists in \"unaccented\" characters (e.g. cafe vs café) - our dataset has these accents which is causing us to get incorrect results\n",
    "\n",
    "we can solve these problems in 2 ways - cleaning pre-genius query or filtering post-query.  for now, i have filtered them post-query but we can always re-run the query if we want.\n",
    "\n",
    "based on exploration of this error, it appears that the incorrect data we are getting are all very long documents - there exists a risk that we are getting incorrect lyric data that is the same size as the correct results, but i have no way of checking this other than spot-checking (which i have done).  the only additional errors i found using this method had to do with a special case of (2) above - i believe filtering out any rows where the song or artist contains accented characters will be enough to solve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Jp_XXhFXPvDF"
   },
   "outputs": [],
   "source": [
    "# in case we want to clean pre-query, here are variables we can use to find problem words/chars\n",
    "#problem_words = ['acoustic', 'version', 'remastered', 'anniversary', 'remaster']\n",
    "#accented_characters = \"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "id": "93TWoqahPvDF",
    "outputId": "89baac14-113e-446d-a064-a947f487c983"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub-Genre: modern alternative rock</th>\n",
       "      <th>Sub-Genre: southern hip hop</th>\n",
       "      <th>Sub-Genre: nu metal</th>\n",
       "      <th>Sub-Genre: israeli mediterranean</th>\n",
       "      <th>Sub-Genre: thrash metal</th>\n",
       "      <th>Sub-Genre: pop rock</th>\n",
       "      <th>Sub-Genre: chicago blues</th>\n",
       "      <th>Sub-Genre: indie pop</th>\n",
       "      <th>Sub-Genre: classic rock</th>\n",
       "      <th>Sub-Genre: hardcore hip hop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>CKY</td>\n",
       "      <td>Disengage the Simulator</td>\n",
       "      <td>43</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.846</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>Ace Hood</td>\n",
       "      <td>Hustle Hard Remix</td>\n",
       "      <td>46</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.740</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.723</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>ENVYYOU</td>\n",
       "      <td>New Friends</td>\n",
       "      <td>46</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.651</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.966</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14674</th>\n",
       "      <td>Freya Ridings</td>\n",
       "      <td>Unconditional</td>\n",
       "      <td>2</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.213</td>\n",
       "      <td>2</td>\n",
       "      <td>-7.731</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9573</th>\n",
       "      <td>Zoe Wees</td>\n",
       "      <td>Hold Me Like You Used To</td>\n",
       "      <td>31</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13322</th>\n",
       "      <td>The Flaming Lips</td>\n",
       "      <td>She Don't Use Jelly</td>\n",
       "      <td>60</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.556</td>\n",
       "      <td>7</td>\n",
       "      <td>-11.494</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12057</th>\n",
       "      <td>Heart</td>\n",
       "      <td>These Dreams</td>\n",
       "      <td>61</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.532</td>\n",
       "      <td>11</td>\n",
       "      <td>-9.865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>Hole</td>\n",
       "      <td>Celebrity Skin</td>\n",
       "      <td>67</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.905</td>\n",
       "      <td>9</td>\n",
       "      <td>-6.161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14702</th>\n",
       "      <td>Dudu Faruk</td>\n",
       "      <td>מלך הקיץ</td>\n",
       "      <td>29</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.645</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.233</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>The Lumineers</td>\n",
       "      <td>Gloria</td>\n",
       "      <td>28</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.638</td>\n",
       "      <td>11</td>\n",
       "      <td>-10.154</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0823</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1799 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Artist Name                Track Name  Popularity  danceability  \\\n",
       "1649                CKY   Disengage the Simulator          43         0.324   \n",
       "5377           Ace Hood         Hustle Hard Remix          46         0.831   \n",
       "4514            ENVYYOU               New Friends          46         0.545   \n",
       "14674     Freya Ridings             Unconditional           2         0.403   \n",
       "9573           Zoe Wees  Hold Me Like You Used To          31         0.573   \n",
       "...                 ...                       ...         ...           ...   \n",
       "13322  The Flaming Lips       She Don't Use Jelly          60         0.330   \n",
       "12057             Heart              These Dreams          61         0.535   \n",
       "2704               Hole            Celebrity Skin          67         0.438   \n",
       "14702        Dudu Faruk                  מלך הקיץ          29         0.820   \n",
       "4172      The Lumineers                    Gloria          28         0.379   \n",
       "\n",
       "       energy  key  loudness  mode  speechiness  acousticness  ...  \\\n",
       "1649    0.846    4    -8.883     1       0.0596      0.000187  ...   \n",
       "5377    0.740    1    -3.723     1       0.1520      0.005570  ...   \n",
       "4514    0.651   11    -5.966     0       0.0440      0.000792  ...   \n",
       "14674   0.213    2    -7.731     1       0.0366      0.923000  ...   \n",
       "9573    0.590    0    -6.308     0       0.0352      0.528000  ...   \n",
       "...       ...  ...       ...   ...          ...           ...  ...   \n",
       "13322   0.556    7   -11.494     1       0.0796      0.207000  ...   \n",
       "12057   0.532   11    -9.865     1       0.0291      0.508000  ...   \n",
       "2704    0.905    9    -6.161     1       0.0419      0.000009  ...   \n",
       "14702   0.645    9    -7.233     0       0.1800      0.145000  ...   \n",
       "4172    0.638   11   -10.154     1       0.0823      0.577000  ...   \n",
       "\n",
       "       Sub-Genre: modern alternative rock  Sub-Genre: southern hip hop  \\\n",
       "1649                                    0                            0   \n",
       "5377                                    0                            1   \n",
       "4514                                    0                            0   \n",
       "14674                                   0                            0   \n",
       "9573                                    0                            0   \n",
       "...                                   ...                          ...   \n",
       "13322                                   0                            0   \n",
       "12057                                   0                            0   \n",
       "2704                                    0                            0   \n",
       "14702                                   0                            0   \n",
       "4172                                    0                            0   \n",
       "\n",
       "       Sub-Genre: nu metal  Sub-Genre: israeli mediterranean  \\\n",
       "1649                     1                                 0   \n",
       "5377                     0                                 0   \n",
       "4514                     0                                 0   \n",
       "14674                    0                                 0   \n",
       "9573                     0                                 0   \n",
       "...                    ...                               ...   \n",
       "13322                    0                                 0   \n",
       "12057                    0                                 0   \n",
       "2704                     0                                 0   \n",
       "14702                    0                                 0   \n",
       "4172                     0                                 0   \n",
       "\n",
       "      Sub-Genre: thrash metal Sub-Genre: pop rock Sub-Genre: chicago blues  \\\n",
       "1649                        0                   0                        0   \n",
       "5377                        0                   0                        0   \n",
       "4514                        0                   0                        0   \n",
       "14674                       0                   0                        0   \n",
       "9573                        0                   0                        0   \n",
       "...                       ...                 ...                      ...   \n",
       "13322                       0                   0                        0   \n",
       "12057                       0                   1                        0   \n",
       "2704                        0                   1                        0   \n",
       "14702                       0                   0                        0   \n",
       "4172                        0                   0                        0   \n",
       "\n",
       "      Sub-Genre: indie pop  Sub-Genre: classic rock  \\\n",
       "1649                     0                        0   \n",
       "5377                     0                        0   \n",
       "4514                     0                        0   \n",
       "14674                    0                        0   \n",
       "9573                     0                        0   \n",
       "...                    ...                      ...   \n",
       "13322                    1                        0   \n",
       "12057                    0                        1   \n",
       "2704                     0                        0   \n",
       "14702                    0                        0   \n",
       "4172                     0                        0   \n",
       "\n",
       "       Sub-Genre: hardcore hip hop  \n",
       "1649                             0  \n",
       "5377                             0  \n",
       "4514                             0  \n",
       "14674                            0  \n",
       "9573                             0  \n",
       "...                            ...  \n",
       "13322                            0  \n",
       "12057                            0  \n",
       "2704                             0  \n",
       "14702                            0  \n",
       "4172                             0  \n",
       "\n",
       "[1799 rows x 72 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out results\n",
    "df_train.drop(df_train[df_train['Lyrics'].str.len() > 5000].index, inplace=True)\n",
    "df_train[df_train['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
    "df_train[df_train['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
    "\n",
    "df_val.drop(df_val[df_val['Lyrics'].str.len() > 5000].index, inplace=True)\n",
    "df_val[df_val['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
    "df_val[df_val['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
    "\n",
    "df_test.drop(df_test[df_test['Lyrics'].str.len() > 5000].index, inplace=True)\n",
    "df_test[df_test['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
    "df_test[df_test['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlktVKpFPvDG",
    "outputId": "ee4ea353-64f5-4e78-dd71-c3b524346855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13768\n",
      "1792\n",
      "1799\n"
     ]
    }
   ],
   "source": [
    "# this removes ~10% of both train/test data\n",
    "print(len(df_train))\n",
    "print(len(df_val))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WYFJiw9PvDG"
   },
   "source": [
    "below cells are related to the tensorflow issue involving lyric + audio data.  leaving until resolved (do not run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "F1M0SetEPvDG"
   },
   "outputs": [],
   "source": [
    "#test = df_train_audio_normalized.iloc[:5,:-1].copy()\n",
    "#test1 = [np.array(x) for x in train_tokens_prebuilt[0:5]]\n",
    "#test1 = train_tokens_prebuilt[0:5]\n",
    "#print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dZfKU0bTPvDH"
   },
   "outputs": [],
   "source": [
    "#ls = list([list(test.iloc[num]) for num in range(len(test))])\n",
    "\n",
    "#print(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9TAixcPEPvDH"
   },
   "outputs": [],
   "source": [
    "#final_array = list([list(x) for x in zip(ls, test1)])\n",
    "#print(final_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1jZO9lQPvDH"
   },
   "source": [
    "end issue section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "r_Sm1do1PvDI"
   },
   "outputs": [],
   "source": [
    "# let's create a df that is all of the normalized audio features we want to use\n",
    "#df_train_audio_normalized = df_train[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "#df_train_audio_normalized = (df_train_audio_normalized-df_train_audio_normalized.mean())/df_train_audio_normalized.std()\n",
    "\n",
    "#df_val_audio_normalized = df_val[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "#df_val_audio_normalized = (df_val_audio_normalized-df_val_audio_normalized.mean())/df_val_audio_normalized.std()\n",
    "\n",
    "#df_test_audio_normalized = df_test[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "#df_test_audio_normalized = (df_test_audio_normalized-df_test_audio_normalized.mean())/df_test_audio_normalized.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "U9or6vVbPvDI",
    "outputId": "dd096f59-0942-47f2-e409-ffd511a32d0c"
   },
   "outputs": [],
   "source": [
    "# looks good\n",
    "#df_train_audio_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FCoicSGPvDI"
   },
   "source": [
    "# 2. Embedding Creation, get token and label data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hPHrBp7NPvDJ"
   },
   "outputs": [],
   "source": [
    "# get word2vec model\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaojUbp7PvDJ",
    "outputId": "f46e0c80-37e9-4f3b-d6aa-1cebd2450183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43981\n"
     ]
    }
   ],
   "source": [
    "# how big does our embedding matrix need to be\n",
    "print(len(model.key_to_index.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "o88SBWR-PvDJ"
   },
   "outputs": [],
   "source": [
    "#construct embedding matrix w/ prebuilt embedding\n",
    "vocab_dict = model.key_to_index.copy()\n",
    "embedding_matrix = np.zeros((43982,300))\n",
    "for word,index in model.key_to_index.items():\n",
    "    embedding_matrix[index] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Dq-9iw14gV39"
   },
   "outputs": [],
   "source": [
    "def split_text_into_regions(text):\n",
    "    string = text\n",
    "   \n",
    "    #mark line breaks\n",
    "    string = string.replace('\\n','[]')\n",
    "    string = string.replace('embed','')\n",
    "    #find language indicators of song sections\n",
    "    splits = re.findall('\\[.*?\\]',string)\n",
    "    #find ad libs to remove\n",
    "    ad_libs = re.findall('\\(.*?\\)',string)\n",
    "   \n",
    "    #remove ad libs\n",
    "    if len(ad_libs) > 0:\n",
    "        for ad_lib in ad_libs:\n",
    "            string = string.replace(ad_lib,'')\n",
    "        string = string.replace('  ',' ')\n",
    "   \n",
    "    #If there is no splitting criteria, single string is entire song without any additional groupings\n",
    "    if len(splits) == 0:\n",
    "        string = [string]\n",
    "    else:\n",
    "        #replace split criteria with makers for splitting\n",
    "        for delim in splits:\n",
    "            string = string.replace(delim,'[]')\n",
    "        string = string.split('[]')\n",
    "   \n",
    "    #Identify sections of song, made up of groups of lyrics\n",
    "    sections = []\n",
    "    section = []\n",
    "    last_part = ''\n",
    "    for part in string:\n",
    "        if part == '' and last_part != '':\n",
    "            sections.append(section)\n",
    "            section = []\n",
    "        elif part != '':\n",
    "            section.append(part)\n",
    "       \n",
    "        last_part = part\n",
    "   \n",
    "    try:\n",
    "        if section != sections[-1]:\n",
    "            sections.append(section)\n",
    "    except:\n",
    "        sections.append(section)\n",
    "   \n",
    "    return sections    \n",
    "\n",
    "\n",
    "def single_text_lyrics(group_of_lyrics):\n",
    "    lyrics = ''\n",
    "    for group in group_of_lyrics:\n",
    "        lyrics = lyrics + ' ' + ' '.join(group)\n",
    "    return lyrics.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8et5usJlgV3-"
   },
   "outputs": [],
   "source": [
    "df_train['modified_lyrics'] = df_train['Lyrics'].apply(lambda x: ' '.join(str(x).split('Lyrics')[1:]).lower())\n",
    "df_val['modified_lyrics'] = df_val['Lyrics'].apply(lambda x: ' '.join(str(x).split('Lyrics')[1:]).lower())\n",
    "df_test['modified_lyrics'] = df_test['Lyrics'].apply(lambda x: ' '.join(str(x).split('Lyrics')[1:]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6tMSeYopgV3-"
   },
   "outputs": [],
   "source": [
    "df_train['modified_lyrics'] = df_train['modified_lyrics'].apply(lambda x: split_text_into_regions(x))\n",
    "df_val['modified_lyrics'] = df_val['modified_lyrics'].apply(lambda x: split_text_into_regions(x))\n",
    "df_test['modified_lyrics'] = df_test['modified_lyrics'].apply(lambda x: split_text_into_regions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "3mQMeg-ogV3-"
   },
   "outputs": [],
   "source": [
    "df_train['final_modified_lyrics'] = df_train['modified_lyrics'].apply(lambda x: single_text_lyrics(x))\n",
    "df_val['final_modified_lyrics'] = df_val['modified_lyrics'].apply(lambda x: single_text_lyrics(x))\n",
    "df_test['final_modified_lyrics'] = df_test['modified_lyrics'].apply(lambda x: single_text_lyrics(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "pg9fq9z5phaf",
    "outputId": "48358061-1842-4e3f-b482-2b356323888a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"born of the frozen wastes peasant with an arctic gaze blessed with such piety blighted by the gift of prophecy clairvoyant, seer beyond through the wilds on and on siberian lupine appetite grows as the gates fall\\u205finto\\u205fsight dark\\u205fforces rise as\\u205fthe scythe descends gold\\u205fspires reflect the coming fires in the white night city it'll be a hot time in the town tonight lurker in the palace holy fool, mystifier mourning wind, songs of sorrow our mother is bleeding guide the hand that stabs hеr heart holy devil, mystifier sеt a place beside the throne oh, sisters of the crow sin be the path to salvation be not afraid of damnation warnings of the coming storm silenced by the waters of neva infinite misery crumbling of the dynasty dark forces rise as the scythe descends gold spires reflect the coming fires in the white night city it'll be a hot time in the town tonight lurker in the palace holy fool, mystifier mourning wind, songs of sorrow our mother is bleeding guide the hand that stabs her heart holy devil, mystifier dark forces rise as the scythe descends gold spires reflect the coming fires in the white night city it'll be a hot time in the town tonight lurker in the palace holy fool, mystifier mourning wind, songs of sorrow our mother is bleeding guide the hand that stabs her heart holy devil, mystifier\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train['final_modified_lyrics']\n",
    "df_train.iloc[3]['final_modified_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GGDzZZFTgV3-",
    "outputId": "542d118a-de55-4916-f803-5bf751ea5eb4"
   },
   "outputs": [],
   "source": [
    "#exclude = set(string.punctuation)\n",
    "\n",
    "#experiment = df_train['final_modified_lyrics'].tolist()\n",
    "#new_ex_list = []\n",
    "#for ex in experiment:\n",
    "#    new_ex = ''.join(ch for ch in experiment if ch not in exclude)\n",
    "#    new_ex_list.append(new_ex)\n",
    "#print(new_ex_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dGzIL_y0gV3_"
   },
   "outputs": [],
   "source": [
    "#train_lyrics = df_train['final_modified_lyrics'].tolist()\n",
    "#val_lyrics = df_val['final_modified_lyrics'].tolist()\n",
    "#test_lyrics = df_test['final_modified_lyrics'].tolist()\n",
    "\n",
    "train_lang_clean = train['Cleaner Lyrics'].tolist()\n",
    "val_lang_clean = val['Cleaner Lyrics'].tolist()\n",
    "test_lang_clean = test['Cleaner Lyrics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lNxMJjvRgV3_"
   },
   "outputs": [],
   "source": [
    "#train_lyrics = [x.split() for x in train_lyrics]\n",
    "#df_train['final_modified_lyrics_list'] = train_lang_clean\n",
    "#df_val['final_modified_lyrics_list'] = val_lang_clean\n",
    "#df_test['final_modified_lyrics_list'] = test_lang_clean\n",
    "\n",
    "train['final_modified_lyrics_list'] = train_lang_clean\n",
    "val['final_modified_lyrics_list'] = val_lang_clean\n",
    "test['final_modified_lyrics_list'] = test_lang_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "ZMPeYsFpgV3_",
    "outputId": "d57d60a1-53bf-43f8-9db3-de107c7f7aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'millie tried to talk the pleasure back into being alive reminiscing \\'bout the apricots and blunts on peckham rye won\\'t call her friends \\'cause she\\'s ashamed of being locked into bed can\\'t feel her legs and feeling like a liar at best you\\'re not alone like you think you are you\\'re not alone like you think you are we all have scars, i know it\\'s hard you\\'re not alone, you\\'re not alone you\\'re not alone like you think you are you\\'re not alonе like you think you are we all havе scars, i know it\\'s hard you\\'re not alone, you\\'re not alone you\\'re not alone, you\\'re not alone started sweating bullets when her dad asked, \"how d\\'you really feel?\" she said, \"i\\'ve been feeling like something inside me wants to scream\" won\\'t call my friends, i\\'m persuaded that they\\'ll leave in the end can\\'t feel my legs, i\\'m feeling like a liar at best you\\'re not alone like you think you are you\\'re not alone like you think you are we all have scars, i know it\\'s hard you\\'re not alone, you\\'re not alone you\\'re not alone like you think you are you\\'re not alone like you think you are we all have scars, i know it\\'s hard you\\'re not alone, you\\'re not alone i\\'ve often felt like i was born under a bad sign wearing suffering like a silk garment or a spot of blue ink looking for light and finding a hole where there shouldn\\'t be one i cannot communicate the depth of the feeling truth is i\\'m still learning to be open about this but know that i know and you\\'re not alone yeah, know that i know and you\\'re not alone you\\'re not alone like you think you are you\\'re not alone like you think you are we all have scars, i know it\\'s hard you\\'re not alone, you\\'re not alone you\\'re not alone like you think you are you\\'re not alone like you think you are we all have scars, i know it\\'s hard you\\'re not alone, you\\'re not alone'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['final_modified_lyrics_list'].iloc[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "tHT-pe7TPvDK"
   },
   "outputs": [],
   "source": [
    "# text cleaning function - this is just part 1\n",
    "bad_punctuation = str(\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\")\n",
    "\n",
    "def text_cleaner(text_data):\n",
    "    return_data = []\n",
    "    for text in text_data:\n",
    "        final_text = []\n",
    "        new_text = text.lower()\n",
    "        new_text = new_text.replace('\\n',' ')\n",
    "        new_text = new_text.translate(str.maketrans('', '', bad_punctuation))\n",
    "        new_text = re.sub(r\"[,.;@#?!&$]+\\/ *\", \" \", new_text)\n",
    "        new_text = new_text.replace('   ',' ')\n",
    "        new_text = new_text.replace('  ',' ')\n",
    "        new_text = new_text.split()\n",
    "        for word in new_text:\n",
    "            if word not in stopWords:\n",
    "                final_text.append(word)\n",
    "        return_data.append(final_text)\n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80e0fIV_gV4A",
    "outputId": "32ee29af-534a-4dcb-e3b3-f7c7535c7896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hel?,;lo'.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "id": "UYQq3O62gV4A",
    "outputId": "b53009e2-5c9e-486d-f852-8bd397ccda57"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-f4cc5f0bca88>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-f4cc5f0bca88>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    bad_punctuation = str(!\"#$%&'()*+,-./:;<=>?@\\^_`{|}~)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "\n",
    "bad_punctuation = str(!\"#$%&'()*+,-./:;<=>?@\\^_`{|}~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "S0gH5zl7PvDK"
   },
   "outputs": [],
   "source": [
    "#train_lang_clean = text_cleaner(df_train['final_modified_lyrics_list'])\n",
    "#val_lang_clean = text_cleaner(df_val['final_modified_lyrics_list'])\n",
    "#test_lang_clean = text_cleaner(df_test['final_modified_lyrics_list'])\n",
    "\n",
    "train_lang_clean = text_cleaner(train['final_modified_lyrics_list'])\n",
    "val_lang_clean = text_cleaner(val['final_modified_lyrics_list'])\n",
    "test_lang_clean = text_cleaner(test['final_modified_lyrics_list'])\n",
    "#train_lang_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep',\n",
       " 'dive',\n",
       " 'slithering',\n",
       " 'height',\n",
       " 'skyline',\n",
       " 'blue',\n",
       " 'skies',\n",
       " 'another',\n",
       " 'flight',\n",
       " 'eye',\n",
       " 'prize',\n",
       " 'highlighted',\n",
       " 'hair',\n",
       " 'eyeline',\n",
       " 'emphasize',\n",
       " 'women',\n",
       " 'side',\n",
       " 'string',\n",
       " 'along',\n",
       " 'pearls',\n",
       " 'around',\n",
       " 'neck',\n",
       " 'serpent',\n",
       " 'theyve',\n",
       " 'become',\n",
       " 'choking',\n",
       " 'every',\n",
       " 'breath',\n",
       " 'bite',\n",
       " 'tongue',\n",
       " 'dont',\n",
       " 'remember',\n",
       " 'im',\n",
       " 'running',\n",
       " 'twenty',\n",
       " 'years',\n",
       " 'millennium',\n",
       " 'dream',\n",
       " 'tomorrow',\n",
       " 'come',\n",
       " 'werent',\n",
       " 'im',\n",
       " 'missing',\n",
       " 'something',\n",
       " 'im',\n",
       " 'arms',\n",
       " 'good',\n",
       " 'nothing',\n",
       " 'wont',\n",
       " 'long',\n",
       " 'witching',\n",
       " 'hour',\n",
       " 'dawn',\n",
       " 'witching',\n",
       " 'hour',\n",
       " 'dawn',\n",
       " 'boys',\n",
       " 'pride',\n",
       " 'vanishing',\n",
       " 'spotlight',\n",
       " 'many',\n",
       " 'sides',\n",
       " 'surface',\n",
       " 'ignite',\n",
       " 'swallow',\n",
       " 'tears',\n",
       " 'wind',\n",
       " 'swept',\n",
       " 'pressure',\n",
       " 'become',\n",
       " 'til',\n",
       " 'theres',\n",
       " 'nothing',\n",
       " 'left',\n",
       " 'bite',\n",
       " 'tongue',\n",
       " 'dont',\n",
       " 'remember',\n",
       " 'im',\n",
       " 'running',\n",
       " 'twenty',\n",
       " 'years',\n",
       " 'millennium',\n",
       " 'dream',\n",
       " 'tomorrow',\n",
       " 'come',\n",
       " 'werent',\n",
       " 'im',\n",
       " 'missing',\n",
       " 'something',\n",
       " 'im',\n",
       " 'arms',\n",
       " 'good',\n",
       " 'nothing',\n",
       " 'wont',\n",
       " 'long',\n",
       " 'witching',\n",
       " 'hour',\n",
       " 'dawn',\n",
       " 'witching',\n",
       " 'hour',\n",
       " 'dawn',\n",
       " 'witching',\n",
       " 'hour',\n",
       " 'dawn',\n",
       " 'witching',\n",
       " 'hour',\n",
       " 'dawn',\n",
       " 'eye',\n",
       " 'prize',\n",
       " 'highlighted',\n",
       " 'hair',\n",
       " 'eyeline',\n",
       " 'emphasize',\n",
       " 'women',\n",
       " 'side']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lang_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "AtL7Hh-UPvDL"
   },
   "outputs": [],
   "source": [
    "# DONT USE\n",
    "# this is a messy implementation, but this basically is a step 2 text cleaner that is slightly different based off the format of the text\n",
    "# if i have time, i will combine into a single function, but for now this runs and does what it intends to do\n",
    "\n",
    "def more_cleaning_if_brackets(song):\n",
    "    include_word = False\n",
    "    clean_song = []\n",
    "    final_song_counter = 0\n",
    "    \n",
    "    for word in song:\n",
    "        final_song_counter += 1\n",
    "        if ']' in word and '[' in word:\n",
    "            include_word = True\n",
    "            continue\n",
    "        \n",
    "        if include_word == False:\n",
    "            if ']' in word:\n",
    "                    include_word = True\n",
    "                    continue\n",
    "                    \n",
    "        else: # if include_word == True\n",
    "            if '[' in word:\n",
    "                    include_word = False\n",
    "                    \n",
    "        if include_word == True and final_song_counter != len(song):\n",
    "            new_word = word.replace('(','').replace(')','')\n",
    "            new_word = new_word.lower()\n",
    "            clean_song.append(new_word)\n",
    "        elif include_word == True and final_song_counter == len(song):\n",
    "            try:\n",
    "                r = re.compile(\"([a-zA-Z]+)([0-9]+)\")\n",
    "                clean_song.append(r.match(word).groups()[0])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return(clean_song)\n",
    "\n",
    "def more_cleaning_if_no_brackets(song):\n",
    "    include_word = False\n",
    "    clean_song = []\n",
    "    final_song_counter = 0\n",
    "    \n",
    "    for word in song:\n",
    "        final_song_counter += 1\n",
    "        if ']' in word and '[' in word:\n",
    "            continue\n",
    "        \n",
    "        if include_word == False:\n",
    "            if 'lyrics' in word:\n",
    "                    include_word = True\n",
    "                    continue\n",
    "                    \n",
    "        else: # if include_word == True\n",
    "            if '[' in word:\n",
    "                    include_word = False\n",
    "                    \n",
    "        if include_word == True and final_song_counter != len(song):\n",
    "            new_word = word.replace('(','').replace(')','')\n",
    "            new_word = new_word.lower()\n",
    "            clean_song.append(new_word)\n",
    "        elif include_word == True and final_song_counter == len(song):\n",
    "            try:\n",
    "                r = re.compile(\"([a-zA-Z]+)([0-9]+)\")\n",
    "                clean_song.append(r.match(word).groups()[0])\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return(clean_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "k6qirREQPvDL"
   },
   "outputs": [],
   "source": [
    "# DONT USE\n",
    "train_lang_clean_post_function = []\n",
    "for song in train_lang_clean:\n",
    "    if '[' in ''.join(song):\n",
    "        new_song = more_cleaning_if_brackets(song)\n",
    "        #if new_song[0] == '1':\n",
    "         #   new_song.pop(0)\n",
    "        train_lang_clean_post_function.append(new_song)\n",
    "    else:\n",
    "        new_song = more_cleaning_if_no_brackets(song)\n",
    "        #if new_song[0] == '1':\n",
    "         #   new_song.pop(0)\n",
    "        train_lang_clean_post_function.append(new_song)\n",
    "        \n",
    "        \n",
    "val_lang_clean_post_function = []\n",
    "for song in val_lang_clean:\n",
    "    if '[' in ''.join(song):\n",
    "        new_song = more_cleaning_if_brackets(song)\n",
    "        val_lang_clean_post_function.append(new_song)\n",
    "    else:\n",
    "        new_song = more_cleaning_if_no_brackets(song)\n",
    "        val_lang_clean_post_function.append(new_song)\n",
    "        \n",
    "        \n",
    "test_lang_clean_post_function = []\n",
    "for song in test_lang_clean:\n",
    "    if '[' in ''.join(song):\n",
    "        new_song = more_cleaning_if_brackets(song)\n",
    "        test_lang_clean_post_function.append(new_song)\n",
    "    else:\n",
    "        new_song = more_cleaning_if_no_brackets(song)\n",
    "        test_lang_clean_post_function.append(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdB-PHYxgV4B",
    "outputId": "00683078-a882-4f67-a186-e4bc28cff8ac"
   },
   "outputs": [],
   "source": [
    "#print(train_lang_clean[1])\n",
    "#print(df_train.iloc[1]['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9lT9GXOvPvDM",
    "outputId": "884c247b-bca6-4071-f856-26be83a8b142"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nights',\n",
       " 'stay',\n",
       " 'cashing',\n",
       " 'bad',\n",
       " 'luck',\n",
       " 'nights',\n",
       " 'call',\n",
       " 'draw',\n",
       " 'nights',\n",
       " 'wish',\n",
       " 'lips',\n",
       " 'could',\n",
       " 'build',\n",
       " 'castle',\n",
       " 'nights',\n",
       " 'wish',\n",
       " 'theyd',\n",
       " 'fall',\n",
       " 'still',\n",
       " 'wake',\n",
       " 'still',\n",
       " 'see',\n",
       " 'ghost',\n",
       " 'oh',\n",
       " 'lord',\n",
       " 'im',\n",
       " 'still',\n",
       " 'sure',\n",
       " 'stand',\n",
       " 'oh',\n",
       " 'stand',\n",
       " 'stand',\n",
       " 'nights',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'anymore',\n",
       " 'ohwoah',\n",
       " 'ohoohwoahoh',\n",
       " 'ohoohwoahoh',\n",
       " 'ohoh',\n",
       " 'ohwoah',\n",
       " 'ohoohwoahoh',\n",
       " 'ohoohwoahoh',\n",
       " 'ohoh',\n",
       " 'boys',\n",
       " 'war',\n",
       " 'waiting',\n",
       " 'dont',\n",
       " 'break',\n",
       " 'rules',\n",
       " 'already',\n",
       " 'never',\n",
       " 'one',\n",
       " 'believe',\n",
       " 'hype',\n",
       " 'save',\n",
       " 'black',\n",
       " 'white',\n",
       " 'try',\n",
       " 'twice',\n",
       " 'hard',\n",
       " 'im',\n",
       " 'half',\n",
       " 'liked',\n",
       " 'come',\n",
       " 'jack',\n",
       " 'style',\n",
       " 'thats',\n",
       " 'alright',\n",
       " 'found',\n",
       " 'martyr',\n",
       " 'bed',\n",
       " 'tonight',\n",
       " 'stops',\n",
       " 'bones',\n",
       " 'wondering',\n",
       " 'oh',\n",
       " 'mmm',\n",
       " 'mmm',\n",
       " 'well',\n",
       " 'nights',\n",
       " 'wish',\n",
       " 'would',\n",
       " 'end',\n",
       " 'cause',\n",
       " 'could',\n",
       " 'use',\n",
       " 'friends',\n",
       " 'change',\n",
       " 'nights',\n",
       " 'im',\n",
       " 'scared',\n",
       " 'youll',\n",
       " 'forget',\n",
       " 'nights',\n",
       " 'always',\n",
       " 'win',\n",
       " 'still',\n",
       " 'wake',\n",
       " 'still',\n",
       " 'see',\n",
       " 'ghost',\n",
       " 'oh',\n",
       " 'lord',\n",
       " 'im',\n",
       " 'still',\n",
       " 'sure',\n",
       " 'stand',\n",
       " 'oh',\n",
       " 'stand',\n",
       " 'stand',\n",
       " 'nights',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'sold',\n",
       " 'soul',\n",
       " 'washed',\n",
       " 'hands',\n",
       " 'miss',\n",
       " 'mom',\n",
       " 'dad',\n",
       " 'see',\n",
       " 'stars',\n",
       " 'see',\n",
       " 'stars',\n",
       " 'thats',\n",
       " 'hear',\n",
       " 'songs',\n",
       " 'sound',\n",
       " 'like',\n",
       " 'swan',\n",
       " 'come',\n",
       " 'oh',\n",
       " 'come',\n",
       " 'oh',\n",
       " 'come',\n",
       " 'oh',\n",
       " 'come',\n",
       " 'well',\n",
       " 'guys',\n",
       " 'five',\n",
       " 'minutes',\n",
       " 'im',\n",
       " 'bored',\n",
       " 'ten',\n",
       " 'years',\n",
       " 'im',\n",
       " 'sure',\n",
       " 'anybody',\n",
       " 'understands',\n",
       " 'one',\n",
       " 'folks',\n",
       " 'home',\n",
       " 'sorry',\n",
       " 'leave',\n",
       " 'mom',\n",
       " 'go',\n",
       " 'fuck',\n",
       " 'wants',\n",
       " 'die',\n",
       " 'alone',\n",
       " 'dried',\n",
       " 'desert',\n",
       " 'sun',\n",
       " 'heart',\n",
       " 'breaking',\n",
       " 'sister',\n",
       " 'con',\n",
       " 'called',\n",
       " '\"love\"',\n",
       " 'look',\n",
       " 'nephews',\n",
       " 'eyes',\n",
       " 'man',\n",
       " 'wouldnt',\n",
       " 'believe',\n",
       " 'amazing',\n",
       " 'things',\n",
       " 'come',\n",
       " 'terrible',\n",
       " 'nights',\n",
       " 'ohwoah',\n",
       " 'ohoohwoahoh',\n",
       " 'ohoohwoahoh',\n",
       " 'ohoh',\n",
       " 'ohwoah',\n",
       " 'ohoohwoahoh',\n",
       " 'ohoohwoahoh',\n",
       " 'ohoh',\n",
       " 'night',\n",
       " 'wouldnt',\n",
       " 'believe',\n",
       " 'dream',\n",
       " 'id',\n",
       " 'called',\n",
       " 'agreed',\n",
       " 'best',\n",
       " 'didnt',\n",
       " 'listen',\n",
       " 'best',\n",
       " 'gave',\n",
       " 'distance',\n",
       " 'oh',\n",
       " 'best',\n",
       " 'didnt',\n",
       " 'listen',\n",
       " 'best',\n",
       " 'get',\n",
       " 'distance',\n",
       " 'oh86']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks\n",
    "#print(len(test_lang_clean_post_function))\n",
    "#train_lang_clean_post_function[11]\n",
    "train_lang_clean[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Bf2OxcKWgV4B"
   },
   "outputs": [],
   "source": [
    "# DONT RUN\n",
    "train_lang_no_punct = []\n",
    "for song in train_lang_clean_post_function:\n",
    "    no_punct_song = []\n",
    "    for word in song:\n",
    "        no_punct_song.append(word.translate(str.maketrans('', '', bad_punctuation)))\n",
    "    train_lang_no_punct.append(no_punct_song)\n",
    "\n",
    "val_lang_no_punct = []\n",
    "for song in val_lang_clean_post_function:\n",
    "    no_punct_song = []\n",
    "    for word in song:\n",
    "        no_punct_song.append(word.translate(str.maketrans('', '', bad_punctuation)))\n",
    "    val_lang_no_punct.append(no_punct_song)\n",
    "    \n",
    "test_lang_no_punct = []\n",
    "for song in test_lang_clean_post_function:\n",
    "    no_punct_song = []\n",
    "    for word in song:\n",
    "        no_punct_song.append(word.translate(str.maketrans('', '', bad_punctuation)))\n",
    "    test_lang_no_punct.append(no_punct_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4APT4pSegV4C",
    "outputId": "f4fbd877-13fb-45a3-d65d-66033b353753"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print(val_lang_no_punct[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1WLfejhcPvDM"
   },
   "outputs": [],
   "source": [
    "# add cleaned lyrics to df\n",
    "#df_train['Lyrics'] = train_lang_no_punct\n",
    "#df_val['Lyrics'] = val_lang_no_punct\n",
    "#df_test['Lyrics'] = test_lang_no_punct\n",
    "\n",
    "#df_train['Lyrics'] = train_lang_clean\n",
    "#df_val['Lyrics'] = val_lang_clean\n",
    "#df_test['Lyrics'] = test_lang_clean\n",
    "\n",
    "train['Lyrics'] = train_lang_clean\n",
    "val['Lyrics'] = val_lang_clean\n",
    "test['Lyrics'] = test_lang_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2134     [sun, moon, sky, high, would, wanna, alone, to...\n",
       "3565     [im, afraid, anything, world, theres, nothing,...\n",
       "11392    [dont, know, mind, stand, opposing, sides, let...\n",
       "17093    [born, frozen, wastes, peasant, arctic, gaze, ...\n",
       "18505    [daddys, got, gun, daddys, got, gun, daddys, g...\n",
       "                               ...                        \n",
       "18786    [eyes, like, pisces, weak, ive, locked, inside...\n",
       "12829    [felt, ice, sheets, late, saliva, skin, sealed...\n",
       "5894     [turn, turn, turn, cant, live, cant, live, can...\n",
       "4510     [אני, נוסע, אבל, חושב, עליה, הזיכרונות, במזווד...\n",
       "12429    [one, think, youre, nothing, regrets, plea, do...\n",
       "Name: Lyrics, Length: 13768, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQbofPQps3b7",
    "outputId": "69220f43-9468-4c77-fab2-0dda8f3fc906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13768\n",
      "1792\n",
      "1799\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_val))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "h_a_UcHNgV4C"
   },
   "outputs": [],
   "source": [
    "df_train['length'] = df_train['Lyrics'].apply(len)\n",
    "df_val['length'] = df_val['Lyrics'].apply(len)\n",
    "df_test['length'] = df_test['Lyrics'].apply(len)\n",
    "\n",
    "df_train = df_train[(df_train['length'] != 0)]\n",
    "df_val = df_val[(df_val['length'] != 0)]\n",
    "df_test = df_test[(df_test['length'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_nyRXFqgV4C",
    "outputId": "26b2d301-7476-4d96-9cc9-9d9e5bc8edd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13746\n",
      "1791\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_val))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "r7CNoIwDPvDM"
   },
   "outputs": [],
   "source": [
    "# this takes our cleaned text and converts it to word2vec tokens\n",
    "\n",
    "def text_to_index_post_cleaning(text_data,mapping,max_size):\n",
    "    return_data = []\n",
    "    for text in text_data:\n",
    "        mapped_text = []\n",
    "        for token in text:\n",
    "            try:\n",
    "                mapped_text.append(mapping[token])\n",
    "            except:\n",
    "                mapped_text.append(len(mapping))\n",
    "        \n",
    "        if len(mapped_text) > max_size:\n",
    "            mapped_text = mapped_text[:max_size]\n",
    "        else:\n",
    "            while len(mapped_text) < max_size:\n",
    "                mapped_text.append(len(mapping))\n",
    "                \n",
    "        return_data.append(mapped_text)\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fDnN86uPvDN"
   },
   "source": [
    "one thing i would like to do once we are confident data is in a good place is experiment with prebuilt embedding size - 1000 seems pretty long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "i2ecbcXzPvDN"
   },
   "outputs": [],
   "source": [
    "# tokenize lyrics - for the prebuilt embedding models these are our X\n",
    "#train_tokens_prebuilt_new = text_to_index_post_cleaning(df_train['Lyrics'],vocab_dict,1000)\n",
    "#val_tokens_prebuilt_new = text_to_index_post_cleaning(df_val['Lyrics'],vocab_dict,1000)\n",
    "#test_tokens_prebuilt_new = text_to_index_post_cleaning(df_test['Lyrics'],vocab_dict,1000)\n",
    "#df_train['Lyric_Tokens'] = train_tokens_prebuilt_new\n",
    "#df_val['Lyric_Tokens'] = val_tokens_prebuilt_new\n",
    "#df_test['Lyric_Tokens'] = test_tokens_prebuilt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize lyrics - for the prebuilt embedding models these are our X\n",
    "train_tokens_prebuilt_new = text_to_index_post_cleaning(train['Lyrics'],vocab_dict,1000)\n",
    "val_tokens_prebuilt_new = text_to_index_post_cleaning(val['Lyrics'],vocab_dict,1000)\n",
    "test_tokens_prebuilt_new = text_to_index_post_cleaning(test['Lyrics'],vocab_dict,1000)\n",
    "train['Lyric_Tokens'] = train_tokens_prebuilt_new\n",
    "val['Lyric_Tokens'] = val_tokens_prebuilt_new\n",
    "test['Lyric_Tokens'] = test_tokens_prebuilt_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAwiJ3qQgV4D",
    "outputId": "192d3d1f-eaaf-46e6-b860-03e849864200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [43981, 4757, 4757, 14412, 43981, 43981, 16266...\n",
       "1        [43981, 8663, 43981, 43981, 35368, 25480, 1258...\n",
       "2        [12585, 4757, 2943, 2943, 43981, 43981, 16266,...\n",
       "3        [16266, 43981, 43981, 43981, 43981, 6853, 4398...\n",
       "4        [43981, 4757, 43981, 4757, 43981, 18120, 4757,...\n",
       "                               ...                        \n",
       "14831    [22255, 4757, 43981, 35368, 43981, 25911, 3536...\n",
       "14832    [12585, 4757, 43981, 43981, 6853, 43981, 25911...\n",
       "14833    [43981, 43981, 43981, 43981, 43981, 43981, 439...\n",
       "14834    [2943, 4757, 25911, 43981, 43981, 43981, 43981...\n",
       "14835    [12585, 43981, 25911, 43981, 35368, 43981, 259...\n",
       "Name: Lyric_Tokens, Length: 14821, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Lyric_Tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "gzxMZJ2TPvDO"
   },
   "outputs": [],
   "source": [
    "# get labels \"Y\"\n",
    "#train_labels = df_train['Major Genre']\n",
    "#val_labels = df_val['Major Genre']\n",
    "#test_labels = df_test['Major Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train['Major Genre']\n",
    "val_labels = val['Major Genre']\n",
    "test_labels = test['Major Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BaaHZi3rPvDO",
    "outputId": "6c16394d-2c74-47d7-d658-906e4ce15bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Indie': 0, 'Metal': 1, 'Pop': 2, 'Rock': 3, 'Alternative': 4, 'Hip Hop': 5, 'Blues': 6}\n"
     ]
    }
   ],
   "source": [
    "# create mapper so we can use numeric labels in our networks\n",
    "mapping = {}\n",
    "count = 0\n",
    "for label in train_labels.unique():\n",
    "    mapping[label] = count\n",
    "    count = count + 1\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "XUAQu-GyPvDO"
   },
   "outputs": [],
   "source": [
    "# want to keep the functions consistent across notebooks, so defining this so i can use the DAN and WAN models as-is\n",
    "embedding_matrix_custom = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKMuX_7ogV4E",
    "outputId": "314c2a7d-7a17-4b6f-c68f-c06e003f426f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock           4763\n",
      "Indie          2338\n",
      "Pop            2106\n",
      "Metal          1791\n",
      "Hip Hop        1491\n",
      "Alternative    1435\n",
      "Blues           897\n",
      "Name: Major Genre, dtype: int64\n",
      "14821\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.value_counts())\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "eUefnMI-gV4E"
   },
   "outputs": [],
   "source": [
    "weights = 4763/train_labels.value_counts()\n",
    "class_weights = {}\n",
    "for num in range(len(weights)):\n",
    "    class_weights[mapping[weights.index[num]]] = weights.iloc[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwW5jRXRgV4E",
    "outputId": "d4592573-7b1d-4de1-b168-107ffd7824db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 1.0,\n",
       " 0: 2.0372112917023095,\n",
       " 2: 2.261633428300095,\n",
       " 1: 2.6594081518704633,\n",
       " 5: 3.194500335345406,\n",
       " 4: 3.3191637630662023,\n",
       " 6: 5.309921962095875}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uA0BVg3MPvDO"
   },
   "source": [
    "# 3. Lyric-Only Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mBEGMYdPvDP"
   },
   "source": [
    "DAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "1T9l-WDFPvDP"
   },
   "outputs": [],
   "source": [
    "# i want to try letting these run and using early stopping to see how high we get\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience = 3, verbose=1, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "YJ76XLskPvDP"
   },
   "outputs": [],
   "source": [
    "def create_dan_model(retrain_embeddings=False, \n",
    "                     max_sequence_length=1000,\n",
    "                     embedding_matrix=embedding_matrix_custom, \n",
    "                     hidden_dim=[100,100,100],\n",
    "                     dropout_rate=0.3,\n",
    "                     hidden_layer_activation = 'relu',\n",
    "                     output_layer_size = 4,\n",
    "                     output_activation = 'softmax',\n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Construct the DAN model including the compilation and return it. Parametrize it using the arguments.\n",
    "    retrain_embeddings: bool, indicates whether embeddings are retrainable\n",
    "    max_sequence_length: Number of token IDs to expect in a given input\n",
    "    embedding_matrix: initialize embedding layer with embedding matrix, specifying weights\n",
    "    hidden_dim = number of neurons in hidden layers\n",
    "    dropout = dropout rate\n",
    "    output_layer_size = # of neurons in output layer corresponding to # of classes, each neuron predicts P(class K | x)\n",
    "    output_activation = activation function for output layer\n",
    "    learning_rate = learning rate for gradient descent for finding model params to optimize loss\n",
    "    \"\"\"\n",
    "    \n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    dan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  weights = [embedding_matrix],\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings,\n",
    "                                   name = 'embedding_layer')\n",
    "    \n",
    "    \n",
    "    #Input Layer, sequence of max_sequence_length tokens\n",
    "    dan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
    "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
    "    dan_embeddings = dan_embedding_layer(dan_input_layer)\n",
    "    #Embeddings are averaged, forming single vector represenation of size embedding matrix\n",
    "    dan_avg_input_embeddings = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(dan_embeddings)\n",
    "    \n",
    "    #input into hidden layers\n",
    "    x = dan_avg_input_embeddings #hidden layer initial input\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "        \n",
    "    #dan_hidden_out_1 = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_1')(dan_avg_input_embeddings)\n",
    "    #dan_hidden_out_1 = tf.keras.layers.Dropout(dropout)(dan_hidden_out_1)\n",
    "    dan_classification = tf.keras.layers.Dense(output_layer_size, activation='softmax', name='dan_classification')(x)\n",
    "    dan_model = tf.keras.models.Model(inputs=dan_input_layer, outputs=[dan_classification])\n",
    "    dan_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics='accuracy')\n",
    "    \n",
    "    print(dan_model.summary())\n",
    "\n",
    "    return dan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YS10DUYfPvDP",
    "outputId": "2a521357-21d3-490c-f9fc-c3b9add58cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,229,107\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 15s 7ms/step - loss: 4.3372 - accuracy: 0.1667 - val_loss: 1.9116 - val_accuracy: 0.1551\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 13s 7ms/step - loss: 4.2896 - accuracy: 0.1441 - val_loss: 1.9164 - val_accuracy: 0.1551\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 15s 8ms/step - loss: 4.2854 - accuracy: 0.1427 - val_loss: 1.9293 - val_accuracy: 0.0864\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 15s 8ms/step - loss: 4.2769 - accuracy: 0.1416 - val_loss: 1.9007 - val_accuracy: 0.1767\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 15s 8ms/step - loss: 4.2663 - accuracy: 0.1461 - val_loss: 1.9383 - val_accuracy: 0.0887\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 17s 9ms/step - loss: 4.2611 - accuracy: 0.1431 - val_loss: 1.9315 - val_accuracy: 0.0926\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - 17s 9ms/step - loss: 4.2361 - accuracy: 0.1432 - val_loss: 1.9138 - val_accuracy: 0.1073\n",
      "Epoch 8/30\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.2356 - accuracy: 0.1391 - val_loss: 1.9084 - val_accuracy: 0.1150\n",
      "Epoch 9/30\n",
      " 879/1853 [=============>................] - ETA: 8s - loss: 4.2254 - accuracy: 0.1476"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-826cae27c107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdan_model_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dan_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m dan_sorted_history = dan_model_sorted.fit(np.array(train_tokens_prebuilt_new),\n\u001b[0m\u001b[1;32m      3\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tokens_prebuilt_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix, output_layer_size = 7, hidden_dim = [75,75,75])\n",
    "dan_sorted_history = dan_model_sorted.fit(np.array(train_tokens_prebuilt_new),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(test_tokens_prebuilt_new), np.array(test_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=30,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
    "                        #callbacks = [es],\n",
    "                     class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avDHkm2TPvDQ"
   },
   "source": [
    "high score with class_weights on val set is 31%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFI0rPhePvDQ"
   },
   "source": [
    "Lets see if a WAN will perform any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "NOKQZW8HPvDQ"
   },
   "outputs": [],
   "source": [
    "def create_wan_model(retrain_embeddings=False, \n",
    "                     max_sequence_length=1000,\n",
    "                     embedding_matrix=embedding_matrix_custom,\n",
    "                     num_attention = 1,\n",
    "                     hidden_dim=[100,100,100],\n",
    "                     dropout_rate=0.3,\n",
    "                     hidden_layer_activation = 'relu',\n",
    "                     output_layer_size = 4,\n",
    "                     output_activation = 'softmax',\n",
    "                     learning_rate=0.001,\n",
    "                     loss = keras.losses.SparseCategoricalCrossentropy()):\n",
    "    \"\"\"\n",
    "    Construct the WAN model including the compilation and return it. Parametrize it using the arguments.\n",
    "    retrain_embeddings: bool, indicates whether embeddings are retrainable\n",
    "    max_sequence_length: Number of token IDs to expect in a given input\n",
    "    embedding_matrix: initialize embedding layer with embedding matrix, specifying weights\n",
    "    num_attention = number of parallel attention computations that learn how to balance embeddings into a single\n",
    "    vector representation, final attention layer weights prior attention based representations\n",
    "    hidden_dim = number of neurons in hidden layers\n",
    "    dropout = dropout rate\n",
    "    output_layer_size = # of neurons in output layer corresponding to # of classes, each neuron predicts P(class K | x)\n",
    "    output_activation = activation function for output layer\n",
    "    learning_rate = learning rate for gradient descent for finding model params to optimize loss\n",
    "    \"\"\"\n",
    "    \n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    wan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  weights = [embedding_matrix],\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings,\n",
    "                                   name = 'embedding_layer')\n",
    "    \n",
    "    \n",
    "    #Input Layer, sequence of max_sequence_length tokens\n",
    "    wan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
    "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
    "    wan_embeddings = wan_embedding_layer(wan_input_layer)\n",
    "    \n",
    "    #Create attention based single vector representations of words according to alternative query vectors\n",
    "    attention_embeddings = []\n",
    "    for num in range(num_attention):\n",
    "        #Apply Query Vector to words in embeddings, returning a max_sequence_length x 1 tensor\n",
    "        l1_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query' + str(num+1))(wan_embeddings)\n",
    "        #reshape to 1 x max_sequence_length\n",
    "        l1_reshape_query = tf.keras.layers.Reshape((1,max_sequence_length))(l1_query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        l1_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights' + str(num+1))(l1_reshape_query)\n",
    "        #weight embeddings according to weights\n",
    "        l1_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((wan_embeddings,l1_weights)))\n",
    "        attention_embeddings.append(l1_attention)\n",
    "    \n",
    "    concat_attention = tf.keras.layers.Concatenate()(attention_embeddings)\n",
    "    concat_attention = tf.keras.layers.Reshape((num_attention,embedding_matrix.shape[1]))(concat_attention)\n",
    "    \n",
    "    #Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "    wan_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(concat_attention)\n",
    "    #reshape to 1 x num_attention\n",
    "    reshaped_query = tf.keras.layers.Reshape((1,num_attention))(wan_query)\n",
    "    #Softmax over query * key (words) to obtain weights\n",
    "    wan_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                        name='attention_weights')(reshaped_query)\n",
    "    #weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "    #from prior layer\n",
    "    wan_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((concat_attention,wan_weights)))\n",
    "    \n",
    "    #input into hidden layers\n",
    "    x = wan_attention #hidden layer initial input\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "        \n",
    "    #wan_hidden_out_1 = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_1')(wan_avg_input_embeddings)\n",
    "    #wan_hidden_out_1 = tf.keras.layers.Dropout(dropout)(wan_hidden_out_1)\n",
    "    wan_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation, name='wan_classification')(x)\n",
    "    wan_model = tf.keras.models.Model(inputs=wan_input_layer, outputs=[wan_classification])\n",
    "    wan_model.compile(loss=loss,\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics='accuracy')\n",
    "    \n",
    "    print(wan_model.summary())\n",
    "\n",
    "    return wan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_VzSuuyPvDR",
    "outputId": "3f9fa253-50ce-47c8-844f-fea5d0c191e2"
   },
   "outputs": [],
   "source": [
    "wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix, output_layer_size = 7,\n",
    "                                   num_attention=1)\n",
    "wan_sorted_history = wan_model_sorted.fit(np.array(train_tokens_prebuilt_new),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(val_tokens_prebuilt_new), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=100,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
    "                        callbacks = [es],\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 1000, 300)    13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1000)      0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 1000)      0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 300)          0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 300)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 300)       0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 300, 1)       0           ['reshape_1[0][0]',              \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 300)          0           ['dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,246,207\n",
      "Trainable params: 51,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 40s 21ms/step - loss: 4.3135 - accuracy: 0.1466 - val_loss: 1.9160 - val_accuracy: 0.0864\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 38s 21ms/step - loss: 4.2836 - accuracy: 0.1300 - val_loss: 1.9275 - val_accuracy: 0.0872\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 41s 22ms/step - loss: 4.2760 - accuracy: 0.1210 - val_loss: 1.9097 - val_accuracy: 0.1404\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 39s 21ms/step - loss: 4.2591 - accuracy: 0.1457 - val_loss: 1.8975 - val_accuracy: 0.1535\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 36s 20ms/step - loss: 4.1882 - accuracy: 0.1486 - val_loss: 1.8782 - val_accuracy: 0.1289\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 4.1604 - accuracy: 0.1558 - val_loss: 1.8790 - val_accuracy: 0.1381\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - 39s 21ms/step - loss: 4.1269 - accuracy: 0.1624 - val_loss: 1.8670 - val_accuracy: 0.1620\n",
      "Epoch 8/30\n",
      "1853/1853 [==============================] - 34s 18ms/step - loss: 4.1260 - accuracy: 0.1666 - val_loss: 1.8599 - val_accuracy: 0.1620\n",
      "Epoch 9/30\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 4.1214 - accuracy: 0.1756 - val_loss: 1.8643 - val_accuracy: 0.1836\n",
      "Epoch 10/30\n",
      "1853/1853 [==============================] - 35s 19ms/step - loss: 4.1149 - accuracy: 0.1752 - val_loss: 1.8532 - val_accuracy: 0.1836\n",
      "Epoch 11/30\n",
      "1853/1853 [==============================] - 35s 19ms/step - loss: 4.1101 - accuracy: 0.1804 - val_loss: 1.8543 - val_accuracy: 0.1798\n",
      "Epoch 12/30\n",
      "1853/1853 [==============================] - 36s 19ms/step - loss: 4.1056 - accuracy: 0.1777 - val_loss: 1.8423 - val_accuracy: 0.2106\n",
      "Epoch 13/30\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 4.0931 - accuracy: 0.1850 - val_loss: 1.8352 - val_accuracy: 0.2160\n",
      "Epoch 14/30\n",
      "1853/1853 [==============================] - 38s 21ms/step - loss: 4.0866 - accuracy: 0.1889 - val_loss: 1.8367 - val_accuracy: 0.1790\n",
      "Epoch 15/30\n",
      "1853/1853 [==============================] - 36s 20ms/step - loss: 4.0785 - accuracy: 0.1843 - val_loss: 1.8567 - val_accuracy: 0.1667\n",
      "Epoch 16/30\n",
      "1853/1853 [==============================] - 36s 19ms/step - loss: 4.0718 - accuracy: 0.1880 - val_loss: 1.8546 - val_accuracy: 0.1705\n",
      "Epoch 17/30\n",
      "1853/1853 [==============================] - 34s 18ms/step - loss: 4.0641 - accuracy: 0.1872 - val_loss: 1.8103 - val_accuracy: 0.2122\n",
      "Epoch 18/30\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 4.0631 - accuracy: 0.1926 - val_loss: 1.8280 - val_accuracy: 0.1944\n",
      "Epoch 19/30\n",
      "1853/1853 [==============================] - 35s 19ms/step - loss: 4.0658 - accuracy: 0.1918 - val_loss: 1.8433 - val_accuracy: 0.1860\n",
      "Epoch 20/30\n",
      "1853/1853 [==============================] - 38s 21ms/step - loss: 4.0555 - accuracy: 0.1945 - val_loss: 1.8241 - val_accuracy: 0.1844\n",
      "Epoch 21/30\n",
      "1853/1853 [==============================] - 35s 19ms/step - loss: 4.0535 - accuracy: 0.1928 - val_loss: 1.8246 - val_accuracy: 0.1829\n",
      "Epoch 22/30\n",
      " 206/1853 [==>...........................] - ETA: 32s - loss: 4.0838 - accuracy: 0.1735"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-581b5e6f7779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix, output_layer_size = 7,\n\u001b[1;32m      2\u001b[0m                                    num_attention=1)\n\u001b[0;32m----> 3\u001b[0;31m wan_sorted_history = wan_model_sorted.fit(np.array(train_tokens_prebuilt_new),\n\u001b[0m\u001b[1;32m      4\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tokens_prebuilt_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix, output_layer_size = 7,\n",
    "                                   num_attention=1)\n",
    "wan_sorted_history = wan_model_sorted.fit(np.array(train_tokens_prebuilt_new),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(test_tokens_prebuilt_new), np.array(test_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=30,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhokuPmBPvDR"
   },
   "source": [
    "33% best with val and class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFnrdT0pPvDR"
   },
   "source": [
    "both of those were performed with embedding lengths of 1000 over 10 epochs.  what happens if we experiment with embedding size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMqGbZwqPvDR"
   },
   "source": [
    "# 3A Prebuilt Embeddings, Size Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAYdlZZAgV4H",
    "outputId": "5e7ad683-6a61-49b9-ada9-cb4581e9204f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522.3026583381754\n",
      "823.6520724984748\n",
      "27\n",
      "4995\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Lyrics'].apply(len).mean())\n",
    "print(df_train['Lyrics'].apply(len).std())\n",
    "print(df_train['Lyrics'].apply(len).min())\n",
    "print(df_train['Lyrics'].apply(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMcPkFu4PvDS"
   },
   "outputs": [],
   "source": [
    "#len_list = []\n",
    "\n",
    "#for lyric in new_lyrics:\n",
    "#    len_list.append(len(lyric))\n",
    "\n",
    "#len_list = np.array(len_list)\n",
    "#print('Mean length = ',np.mean(len_list))\n",
    "#print('Stdev = ',np.std(len_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "niBseA53PvDS",
    "outputId": "9c53e3d8-a8d0-4e31-eaf0-835593e01166"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(math.ceil(min(df_train['Lyrics'].apply(len))), \n",
    "                   math.floor(max(df_train['Lyrics'].apply(len))),\n",
    "                   20) # fixed number of bins\n",
    "\n",
    "plt.xlim([min(df_train['Lyrics'].apply(len))-5, max(df_train['Lyrics'].apply(len))+5])\n",
    "\n",
    "plt.hist(df_train['Lyrics'].apply(len), bins=bins, alpha=0.5)\n",
    "plt.title('Song Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DadVG0u-gV4I",
    "outputId": "cf702a80-27f2-4f17-ecd1-6c8b65fd6b45"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(math.ceil(min(df_test['Lyrics'].apply(len))), \n",
    "                   math.floor(max(df_val['Lyrics'].apply(len))),\n",
    "                   20) # fixed number of bins\n",
    "\n",
    "plt.xlim([min(df_val['Lyrics'].apply(len))-5, max(df_val['Lyrics'].apply(len))+5])\n",
    "\n",
    "plt.hist(df_val['Lyrics'].apply(len), bins=bins, alpha=0.5)\n",
    "plt.title('Song Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9o_ba6oygV4I",
    "outputId": "b1afccd1-65e7-4dd1-b14a-93f87897f353"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWkklEQVR4nO3df7DddX3n8eeLIL/EH0EuGBNoYgkouBXdSFVcC1IKuo6w3cXGqdu0gzLToiPo1iXrjq27TUd33OLsVtpmrWuqFhoRS2R3q2nEOnarmCgoAQKpEcgSE6Sr+Gupie/94/vNl0Nyc+9JyPeec5PnY+bM+Z7P98d53dzc+7rf7/ec70lVIUkSwBGjDiBJGh+WgiSpYylIkjqWgiSpYylIkjqWgiSpYylIh5gk5yXZOuocmp0sBR0Skrwiyf9O8r0k/5Dkb5O8ZAQ5Kslph/pz6tB15KgDSE9WkqcDtwC/CawGjgL+GfDYKHNJs5F7CjoUnA5QVddX1a6q+nFVfbaqvg6Q5Igk/z7J/Ul2JPmzJM9o5y1s/9JeluSBJN9J8q7dG05ybJJVSf5vkruTvPNADs0kOTrJ+9vn2J7kj5Mc2847L8nWJO9o821L8hsD6z4ryaeTPJrkK0l+L8kX23lfaBe7I8kPkvzKwHqTbk+aiqWgQ8G9wK72l/erk8zdY/6vt7fzgecCxwN/uMcyrwDOAC4A3p3k+e347wAL2/UuBN54gBnfR1NeZwOnAfOBdw/MfzbwjHb8cuCDA1/HB4Eftsssa28AVNUr28kXVtXxVfUXQ2xP2req8uZt1t+A5wMfAbYCO4E1wMntvHXAbw0sewbwE5rDpwuBAhYMzL8NWNpOfxO4aGDem4CtU+Qo4LQ9xkLzS/1nB8ZeBmxpp88DfgwcOTB/B/BSYE6b9YyBeb8HfHFfzznV9kb9ffI2/jfPKeiQUFV30+wNkOR5wMeADwBvAJ4D3D+w+P00hXDywNi3B6Z/RLM3QbvugwPzBqeHNQEcB2xIsnssNL/wd3ukqnZOkmGizbq/Gfa1PWlKHj7SIaeq7qHZa3hBO/QQ8DMDi5xKszexfYjNbQMWDDw+5QAifYfmL/ezquqZ7e0ZVTXML+mHabI+2QzSUCwFzXpJnteeVF3QPj6FZg/hS+0i1wNXJ1mU5Hjg94G/2OMv6X1ZDSxPMjfJfOAtQ6xzVJJjdt9o9gr+G3BtkpPajPOTXDTdhqpqF3AT8LtJjmv3gn5tj8W205zzkJ40S0GHgu8DPw98OckPacrgTuAd7fwPAx8FvgBsAf4f8NYht/0faM5TbAH+GriR6V/qupFmz2D37TeAfwtsBr6U5NF2W2cMmeEtNCeNv91+HdfvkeF3gVVJvpvk9UNuU5pUqvyQHWlYSX6T5iT0L4www/uAZ1fVsmkXlvaTewrSFJLMS3Ju+16HM2j2Pj41wxmel+Tn0jiH5iWmM5pBhw9ffSRN7SjgT4BFwHeBG4DrZjjD02gOGT2H5qWl/xm4eYYz6DDh4SNJUsfDR5Kkzqw+fHTiiSfWwoULRx1DkmaVDRs2fKeqJiabN6tLYeHChaxfv37UMSRpVkly/77mefhIktSxFCRJHUtBktSxFCRJHUtBktSxFCRJHUtBktSxFCRJHUtBktSZ1e9oHkfXrr33oGzn6gtPPyjbkaT94Z6CJKljKUiSOpaCJKljKUiSOpaCJKnTaykk+VaSbyS5Pcn6duyEJGuT3Nfezx1YfnmSzUk2Jbmoz2ySpL3NxJ7C+VV1dlUtaR9fA6yrqsXAuvYxSc4ElgJnARcD1yWZMwP5JEmtURw+ugRY1U6vAi4dGL+hqh6rqi3AZuCcmY8nSYevvkuhgM8m2ZDkinbs5KraBtDen9SOzwceHFh3azsmSZohfb+j+dyqeijJScDaJPdMsWwmGau9FmrK5QqAU0899eCklCQBPe8pVNVD7f0O4FM0h4O2J5kH0N7vaBffCpwysPoC4KFJtrmyqpZU1ZKJiYk+40vSYae3Ukjy1CRP2z0N/BJwJ7AGWNYutgy4uZ1eAyxNcnSSRcBi4La+8kmS9tbn4aOTgU8l2f08f15Vf5XkK8DqJJcDDwCXAVTVxiSrgbuAncCVVbWrx3ySpD30VgpV9U3ghZOMPwJcsI91VgAr+sokSZqa72iWJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHV6L4Ukc5J8Lckt7eMTkqxNcl97P3dg2eVJNifZlOSivrNJkp5oJvYU3gbcPfD4GmBdVS0G1rWPSXImsBQ4C7gYuC7JnBnIJ0lq9VoKSRYA/xz40MDwJcCqdnoVcOnA+A1V9VhVbQE2A+f0mU+S9ER97yl8AHgn8NOBsZOrahtAe39SOz4feHBgua3t2BMkuSLJ+iTrH3744V5CS9LhqrdSSPJaYEdVbRh2lUnGaq+BqpVVtaSqlkxMTDypjJKkJzqyx22fC7wuyWuAY4CnJ/kYsD3JvKralmQesKNdfitwysD6C4CHeswnSdpDb3sKVbW8qhZU1UKaE8ifq6o3AmuAZe1iy4Cb2+k1wNIkRydZBCwGbusrnyRpb33uKezLe4HVSS4HHgAuA6iqjUlWA3cBO4Erq2rXCPJJ0mFrRkqhqj4PfL6dfgS4YB/LrQBWzEQmSdLeRrGnoCFcu/beJ72Nqy88/SAkkXQ48TIXkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqROb6WQ5JgktyW5I8nGJO9px09IsjbJfe393IF1lifZnGRTkov6yiZJmtxQpZDk3GHG9vAY8KqqeiFwNnBxkpcC1wDrqmoxsK59TJIzgaXAWcDFwHVJ5gz5dUiSDoJh9xT+65BjnWr8oH34lPZWwCXAqnZ8FXBpO30JcENVPVZVW4DNwDlD5pMkHQRHTjUzycuAlwMTSd4+MOvpwLR/xbd/6W8ATgM+WFVfTnJyVW0DqKptSU5qF58PfGlg9a3t2J7bvAK4AuDUU0+dLoIkaT9Mt6dwFHA8TXk8beD2KPCvptt4Ve2qqrOBBcA5SV4wxeKZbBOTbHNlVS2pqiUTExPTRZAk7Ycp9xSq6m+Av0nykaq6/0CfpKq+m+TzNOcKtieZ1+4lzAN2tIttBU4ZWG0B8NCBPqckaf8Ne07h6CQrk3w2yed236ZaIclEkme208cCvwjcA6wBlrWLLQNubqfXAEuTHJ1kEbAYuG3/vhxJ0pMx5Z7CgE8Afwx8CNg15DrzgFXteYUjgNVVdUuSvwNWJ7kceAC4DKCqNiZZDdwF7ASurKphn0uSdBAMWwo7q+qP9mfDVfV14EWTjD8CXLCPdVYAK/bneSRJB8+wh48+neS3ksxr33x2QpITek0mSZpxw+4p7D4H8NsDYwU89+DGkSSN0lClUFWL+g4yDq5de++oI0jSSA1VCkl+bbLxqvqzgxtHkjRKwx4+esnA9DE0J4q/ClgKknQIGfbw0VsHHyd5BvDRXhJJkkbmQC+d/SOaN5dJkg4hw55T+DSPX4doDvB8YHVfoSRJozHsOYX3D0zvBO6vqq095JEkjdBQh4/aC+PdQ3OF1LnAP/YZSpI0GsN+8trraS5OdxnweuDLSaa9dLYkaXYZ9vDRu4CXVNUOaK6ACvw1cGNfwSRJM2/YVx8dsbsQWo/sx7qSpFli2D2Fv0ryGeD69vGvAP+zn0iSpFGZ7jOaTwNOrqrfTvLLwCtoPjbz74CPz0A+SdIMmu4Q0AeA7wNU1U1V9faquppmL+ED/UaTJM206UphYfthOU9QVeuBhb0kkiSNzHSlcMwU8449mEEkSaM3XSl8Jcmb9xxsP195Qz+RJEmjMt2rj64CPpXkV3m8BJYARwH/osdckqQRmLIUqmo78PIk5wMvaIf/R1V9rvdkkqQZN+znKdwK3NpzFknSiPmuZElSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSx1KQJHUsBUlSp7dSSHJKkluT3J1kY5K3teMnJFmb5L72fu7AOsuTbE6yKclFfWWTJE2uzz2FncA7qur5wEuBK5OcCVwDrKuqxcC69jHtvKXAWcDFwHVJ5vSYT5K0h95Koaq2VdVX2+nvA3cD84FLgFXtYquAS9vpS4AbquqxqtoCbAbO6SufJGlvQ10Q78lKshB4EfBlms983gZNcSQ5qV1sPvClgdW2tmN7busK4AqAU089tcfUs9+1a+990tu4+sLTD0ISSbNF7yeakxwPfBK4qqoenWrRScZqr4GqlVW1pKqWTExMHKyYkiR6LoUkT6EphI9X1U3t8PYk89r584Ad7fhW4JSB1RcAD/WZT5L0RH2++ijAnwJ3V9UfDMxaAyxrp5cBNw+ML01ydJJFwGLgtr7ySZL21uc5hXOBfw18I8nt7di/A94LrG4/5/kB4DKAqtqYZDVwF80rl66sql095pMk7aG3UqiqLzL5eQKAC/axzgpgRV+ZJElT8x3NkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqSOpSBJ6lgKkqTOkaMOoPF27dp7D8p2rr7w9IOyHUn9ck9BktSxFCRJnd5KIcmHk+xIcufA2AlJ1ia5r72fOzBveZLNSTYluaivXJKkfetzT+EjwMV7jF0DrKuqxcC69jFJzgSWAme161yXZE6P2SRJk+itFKrqC8A/7DF8CbCqnV4FXDowfkNVPVZVW4DNwDl9ZZMkTW6mzymcXFXbANr7k9rx+cCDA8ttbcf2kuSKJOuTrH/44Yd7DStJh5txOdGcScZqsgWramVVLamqJRMTEz3HkqTDy0yXwvYk8wDa+x3t+FbglIHlFgAPzXA2STrszXQprAGWtdPLgJsHxpcmOTrJImAxcNsMZ5Okw15v72hOcj1wHnBikq3A7wDvBVYnuRx4ALgMoKo2JlkN3AXsBK6sql19ZZMkTa63UqiqN+xj1gX7WH4FsKKvPJKk6Y3LiWZJ0hiwFCRJHUtBktSxFCRJHUtBktSxFCRJHUtBktSxFCRJHUtBktSxFCRJHUtBktTp7dpH0qBr1977pLdx9YWnH4QkkqbinoIkqWMpSJI6h8Tho4NxaEKS5J6CJGmApSBJ6hwSh490eDhYhwl9FZO0b+4pSJI67inosON7JqR9c09BktSxFCRJHQ8fSQdgnA5BjVMWzX6WgjQivulS48jDR5KkjqUgSepYCpKkjqUgSepYCpKkjq8+kuR1pdRxT0GS1Bm7UkhycZJNSTYnuWbUeSTpcDJWpZBkDvBB4NXAmcAbkpw52lSSdPgYt3MK5wCbq+qbAEluAC4B7hppKklDOdTepT1O50hm6nIm41YK84EHBx5vBX5+cIEkVwBXtA9/kGQTcCLwnRlJuP/GORuMdz6zHZhxzgbjne8J2d4+wiCTeNL/bgNfz8/sa5lxK4VMMlZPeFC1Elj5hJWS9VW1pM9gB2qcs8F45zPbgRnnbDDe+cw2ZucUaPYMThl4vAB4aERZJOmwM26l8BVgcZJFSY4ClgJrRpxJkg4bY3X4qKp2JnkL8BlgDvDhqto4xKorp19kZMY5G4x3PrMdmHHOBuOd77DPlqqafilJ0mFh3A4fSZJGyFKQJHVmfSmM+rIYST6cZEeSOwfGTkiyNsl97f3cgXnL26ybklzUc7ZTktya5O4kG5O8bVzyJTkmyW1J7mizvWdcsg0835wkX0tyyxhm+1aSbyS5Pcn6ccqX5JlJbkxyT/t/72XjkC3JGe2/1+7bo0muGods7XNd3f4s3Jnk+vZnZOazVdWsvdGcjP574LnAUcAdwJkznOGVwIuBOwfG/hNwTTt9DfC+dvrMNuPRwKI2+5wes80DXtxOPw24t80w8nw070k5vp1+CvBl4KXjkG0g49uBPwduGafva/uc3wJO3GNsLPIBq4A3tdNHAc8cl2wDGecA36Z5E9fIs9G8cXcLcGz7eDXw66PI1us//Ax8Y18GfGbg8XJg+QhyLOSJpbAJmNdOzwM2TZaP5lVWL5vBnDcDF45bPuA44Ks0714fi2w075FZB7yKx0thLLK1z/Et9i6FkecDnt7+csu4Zdsjzy8Bfzsu2Xj8ag4n0Lwq9JY244xnm+2Hjya7LMb8EWUZdHJVbQNo709qx0eWN8lC4EU0f5GPRb728MztwA5gbVWNTTbgA8A7gZ8OjI1LNmje6f/ZJBvSXPplXPI9F3gY+O/tobcPJXnqmGQbtBS4vp0eebaq+j/A+4EHgG3A96rqs6PINttLYdrLYoyZkeRNcjzwSeCqqnp0qkUnGestX1Xtqqqzaf4qPyfJC6ZYfMayJXktsKOqNgy7yiRjfX9fz62qF9NcUfjKJK+cYtmZzHckzeHUP6qqFwE/pDnssS8z/m/XvjH2dcAnplt0krG+/s/Npbn45yLgOcBTk7xxFNlmeymM62UxtieZB9De72jHZzxvkqfQFMLHq+qmccsHUFXfBT4PXDwm2c4FXpfkW8ANwKuSfGxMsgFQVQ+19zuAT9FcYXgc8m0FtrZ7fQA30pTEOGTb7dXAV6tqe/t4HLL9IrClqh6uqp8ANwEvH0W22V4K43pZjDXAsnZ6Gc2x/N3jS5McnWQRsBi4ra8QSQL8KXB3Vf3BOOVLMpHkme30sTQ/FPeMQ7aqWl5VC6pqIc3/qc9V1RvHIRtAkqcmedruaZpjz3eOQ76q+jbwYJIz2qELaC59P/JsA97A44eOdmcYdbYHgJcmOa79ub0AuHsk2fo+odP3DXgNzatq/h541wie/3qaY4A/oWnvy4Fn0ZykvK+9P2Fg+Xe1WTcBr+452ytodim/Dtze3l4zDvmAnwO+1ma7E3h3Oz7ybHvkPI/HTzSPRTaa4/Z3tLeNu//fj1G+s4H17ff2L4G5Y5TtOOAR4BkDY+OS7T00fxjdCXyU5pVFM57Ny1xIkjqz/fCRJOkgshQkSR1LQZLUsRQkSR1LQZLUsRSkSST5Qc/bvyrJcTP1fNKwLAVpNK6iec28NFbG6jOapXGW5GeBDwITwI+AN1fVPUk+AjwKLAGeDbyzqm5McgTwh8Av0Fw59AjgwzTXtnkOcGuS71TV+e32VwCvBX4MXFKPX4ZBmjHuKUjDWwm8tar+KfBvgOsG5s2jeQf5a4H3tmO/THNZ9X8CvInmUu9U1X+huU7N+bsLAXgq8KWqeiHwBeDNvX4l0j64pyANob3S7MuBTzSXpgGayxDs9pdV9VPgriQnt2OvAD7Rjn87ya1TPMU/0lxDH2ADzedeSDPOUpCGcwTw3Wou9T2Zxwams8f9MH5Sj19zZhf+bGpEPHwkDaGaz6HYkuQyaK5Am+SF06z2ReBfJjmi3Xs4b2De92k+IlUaK5aCNLnjkmwduL0d+FXg8iS7r056yTTb+CTNlXPvBP6E5lPvvtfOWwn8r2kOKUkzzqukSj1KcnxV/SDJs2iud39uNZ85II0lj1tK/bql/TCho4D/aCFo3LmnIEnqeE5BktSxFCRJHUtBktSxFCRJHUtBktT5/8m7e/KD4ofDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(math.ceil(min(df_test['Lyrics'].apply(len))), \n",
    "                   math.floor(max(df_test['Lyrics'].apply(len))),\n",
    "                   20) # fixed number of bins\n",
    "\n",
    "plt.xlim([min(df_test['Lyrics'].apply(len))-5, max(df_test['Lyrics'].apply(len))+5])\n",
    "\n",
    "plt.hist(df_test['Lyrics'].apply(len), bins=bins, alpha=0.5)\n",
    "plt.title('Song Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uQxtis6PvDS"
   },
   "source": [
    "i dont have a great sense for what embedding size will be good, so lets try a few different options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "AwrDDKiVPvDS"
   },
   "outputs": [],
   "source": [
    "embedding_sizes = [200,300,400,500,600]\n",
    "hidden_dim_sizes = [25,50,75,100,150,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsNHUfSBPvDT",
    "outputId": "49bfece6-65f3-41c4-ef5d-0562d502f20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 200, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 25)                7525      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,203,607\n",
      "Trainable params: 9,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.2512 - accuracy: 0.1684 - val_loss: 1.8772 - val_accuracy: 0.2462\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.0325 - accuracy: 0.2355 - val_loss: 1.7706 - val_accuracy: 0.2267\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 3.9122 - accuracy: 0.2436 - val_loss: 1.7537 - val_accuracy: 0.2261\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8892 - accuracy: 0.2564 - val_loss: 1.7405 - val_accuracy: 0.2853\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8407 - accuracy: 0.2618 - val_loss: 1.7254 - val_accuracy: 0.2937\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8146 - accuracy: 0.2629 - val_loss: 1.6907 - val_accuracy: 0.3032\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7952 - accuracy: 0.2576 - val_loss: 1.6958 - val_accuracy: 0.2998\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7710 - accuracy: 0.2658 - val_loss: 1.7260 - val_accuracy: 0.2457\n",
      "Epoch 9/100\n",
      "1702/1719 [============================>.] - ETA: 0s - loss: 3.7573 - accuracy: 0.2516Restoring model weights from the end of the best epoch: 6.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7602 - accuracy: 0.2514 - val_loss: 1.7078 - val_accuracy: 0.2702\n",
      "Epoch 9: early stopping\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 200, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 200, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 200)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 200)       0           ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 300)          0           ['dot_2[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 300)          0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 300)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                    (None, 300, 1)       0           ['reshape_4[0][0]',              \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 300)          0           ['dot_3[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 25)           7525        ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 25)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 25)           650         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 25)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 25)           650         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 25)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            182         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,204,207\n",
      "Trainable params: 9,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 4.1838 - accuracy: 0.1902 - val_loss: 1.8268 - val_accuracy: 0.2602\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9131 - accuracy: 0.2604 - val_loss: 1.7577 - val_accuracy: 0.2624\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.8295 - accuracy: 0.2631 - val_loss: 1.7163 - val_accuracy: 0.2540\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7745 - accuracy: 0.2713 - val_loss: 1.6795 - val_accuracy: 0.2920\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.7386 - accuracy: 0.2664 - val_loss: 1.6736 - val_accuracy: 0.2859\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.7099 - accuracy: 0.2692 - val_loss: 1.6666 - val_accuracy: 0.2831\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.6918 - accuracy: 0.2695 - val_loss: 1.6417 - val_accuracy: 0.2948\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.6303 - accuracy: 0.2800 - val_loss: 1.6506 - val_accuracy: 0.2881\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.6267 - accuracy: 0.2796 - val_loss: 1.6459 - val_accuracy: 0.2898\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5761 - accuracy: 0.2852 - val_loss: 1.6244 - val_accuracy: 0.3071\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5888 - accuracy: 0.2825 - val_loss: 1.6398 - val_accuracy: 0.2931\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5599 - accuracy: 0.2897 - val_loss: 1.6395 - val_accuracy: 0.2920\n",
      "Epoch 13/100\n",
      "1715/1719 [============================>.] - ETA: 0s - loss: 3.5408 - accuracy: 0.2943Restoring model weights from the end of the best epoch: 10.\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5414 - accuracy: 0.2943 - val_loss: 1.6392 - val_accuracy: 0.3021\n",
      "Epoch 13: early stopping\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 300, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 25)                7525      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,203,607\n",
      "Trainable params: 9,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.1930 - accuracy: 0.1817 - val_loss: 1.8644 - val_accuracy: 0.2010\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0824 - accuracy: 0.2044 - val_loss: 1.8322 - val_accuracy: 0.2300\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9570 - accuracy: 0.2316 - val_loss: 1.7881 - val_accuracy: 0.2133\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9094 - accuracy: 0.2420 - val_loss: 1.7728 - val_accuracy: 0.2133\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.8687 - accuracy: 0.2452 - val_loss: 1.7321 - val_accuracy: 0.2702\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8312 - accuracy: 0.2580 - val_loss: 1.7207 - val_accuracy: 0.2842\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8131 - accuracy: 0.2644 - val_loss: 1.7086 - val_accuracy: 0.2792\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8092 - accuracy: 0.2633 - val_loss: 1.7172 - val_accuracy: 0.2401\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7736 - accuracy: 0.2641 - val_loss: 1.6877 - val_accuracy: 0.2937\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7715 - accuracy: 0.2668 - val_loss: 1.6797 - val_accuracy: 0.3127\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7447 - accuracy: 0.2744 - val_loss: 1.6886 - val_accuracy: 0.2820\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7377 - accuracy: 0.2688 - val_loss: 1.6888 - val_accuracy: 0.2808\n",
      "Epoch 13/100\n",
      "1711/1719 [============================>.] - ETA: 0s - loss: 3.7340 - accuracy: 0.2685Restoring model weights from the end of the best epoch: 10.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7335 - accuracy: 0.2684 - val_loss: 1.6857 - val_accuracy: 0.2719\n",
      "Epoch 13: early stopping\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 300, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " dot_4 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 300)          0           ['dot_4[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 300)          0           ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 300)       0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " dot_5 (Dot)                    (None, 300, 1)       0           ['reshape_7[0][0]',              \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 300)          0           ['dot_5[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 25)           7525        ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 25)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 25)           650         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 25)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 25)           650         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 25)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            182         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,204,207\n",
      "Trainable params: 9,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 4.1980 - accuracy: 0.2039 - val_loss: 1.7838 - val_accuracy: 0.2524\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.8938 - accuracy: 0.2475 - val_loss: 1.7052 - val_accuracy: 0.2697\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.8127 - accuracy: 0.2476 - val_loss: 1.6934 - val_accuracy: 0.2808\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.7683 - accuracy: 0.2547 - val_loss: 1.6758 - val_accuracy: 0.2574\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.7344 - accuracy: 0.2540 - val_loss: 1.6798 - val_accuracy: 0.2568\n",
      "Epoch 6/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.7129 - accuracy: 0.2609Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.7145 - accuracy: 0.2607 - val_loss: 1.6652 - val_accuracy: 0.2775\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 400, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 25)                7525      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,203,607\n",
      "Trainable params: 9,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.1879 - accuracy: 0.1696 - val_loss: 1.8519 - val_accuracy: 0.2317\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.0392 - accuracy: 0.2193 - val_loss: 1.8176 - val_accuracy: 0.2200\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.9457 - accuracy: 0.2383 - val_loss: 1.7527 - val_accuracy: 0.2607\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8745 - accuracy: 0.2513 - val_loss: 1.7265 - val_accuracy: 0.2831\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8252 - accuracy: 0.2607 - val_loss: 1.7444 - val_accuracy: 0.2462\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8044 - accuracy: 0.2545 - val_loss: 1.6968 - val_accuracy: 0.2870\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7681 - accuracy: 0.2640 - val_loss: 1.6889 - val_accuracy: 0.2825\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7325 - accuracy: 0.2707 - val_loss: 1.6747 - val_accuracy: 0.3104\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7418 - accuracy: 0.2703 - val_loss: 1.6947 - val_accuracy: 0.2613\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.7156 - accuracy: 0.2706 - val_loss: 1.6834 - val_accuracy: 0.2898\n",
      "Epoch 11/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.6982 - accuracy: 0.2759Restoring model weights from the end of the best epoch: 8.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.6974 - accuracy: 0.2758 - val_loss: 1.6705 - val_accuracy: 0.2853\n",
      "Epoch 11: early stopping\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 400, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 400, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 1, 400)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 400)       0           ['reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      " dot_6 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 300)          0           ['dot_6[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 300)          0           ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 1, 300)       0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_10[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_11 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_11[0][0]']             \n",
      "                                                                                                  \n",
      " dot_7 (Dot)                    (None, 300, 1)       0           ['reshape_10[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 300)          0           ['dot_7[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 25)           7525        ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 25)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 25)           650         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 25)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 25)           650         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 25)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            182         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,204,207\n",
      "Trainable params: 9,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 5ms/step - loss: 4.1775 - accuracy: 0.1757 - val_loss: 1.8406 - val_accuracy: 0.2144\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 4.0144 - accuracy: 0.2198 - val_loss: 1.8115 - val_accuracy: 0.1999\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.9670 - accuracy: 0.2228 - val_loss: 1.7858 - val_accuracy: 0.2211\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9160 - accuracy: 0.2326 - val_loss: 1.7623 - val_accuracy: 0.2529\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.8598 - accuracy: 0.2442 - val_loss: 1.7317 - val_accuracy: 0.2552\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.8005 - accuracy: 0.2575 - val_loss: 1.6878 - val_accuracy: 0.2853\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.7693 - accuracy: 0.2600 - val_loss: 1.6969 - val_accuracy: 0.2954\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.7279 - accuracy: 0.2697 - val_loss: 1.6652 - val_accuracy: 0.2948\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.7165 - accuracy: 0.2721 - val_loss: 1.6649 - val_accuracy: 0.3071\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.6840 - accuracy: 0.2775 - val_loss: 1.6675 - val_accuracy: 0.2982\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.6794 - accuracy: 0.2783 - val_loss: 1.6645 - val_accuracy: 0.3021\n",
      "Epoch 12/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 3.6517 - accuracy: 0.2799Restoring model weights from the end of the best epoch: 9.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6478 - accuracy: 0.2796 - val_loss: 1.6556 - val_accuracy: 0.2987\n",
      "Epoch 12: early stopping\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 500, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 25)                7525      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,203,607\n",
      "Trainable params: 9,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.1876 - accuracy: 0.1799 - val_loss: 1.8765 - val_accuracy: 0.1781\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0737 - accuracy: 0.2018 - val_loss: 1.8426 - val_accuracy: 0.1910\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.9473 - accuracy: 0.2286 - val_loss: 1.7613 - val_accuracy: 0.2496\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.8660 - accuracy: 0.2456 - val_loss: 1.7444 - val_accuracy: 0.2814\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.8196 - accuracy: 0.2577 - val_loss: 1.7338 - val_accuracy: 0.2803\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.7915 - accuracy: 0.2671 - val_loss: 1.7142 - val_accuracy: 0.2540\n",
      "Epoch 7/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 3.7668 - accuracy: 0.2558Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7688 - accuracy: 0.2554 - val_loss: 1.7055 - val_accuracy: 0.2490\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 500, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 500, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_12 (Reshape)           (None, 1, 500)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 500)       0           ['reshape_12[0][0]']             \n",
      "                                                                                                  \n",
      " dot_8 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 300)          0           ['dot_8[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 300)          0           ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_13 (Reshape)           (None, 1, 300)       0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_13[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_14 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_14[0][0]']             \n",
      "                                                                                                  \n",
      " dot_9 (Dot)                    (None, 300, 1)       0           ['reshape_13[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)            (None, 300)          0           ['dot_9[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 25)           7525        ['flatten_9[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 25)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 25)           650         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 25)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 25)           650         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 25)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            182         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,204,207\n",
      "Trainable params: 9,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 4.2033 - accuracy: 0.1544 - val_loss: 1.8761 - val_accuracy: 0.1815\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 4.0719 - accuracy: 0.1993 - val_loss: 1.8222 - val_accuracy: 0.2116\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.9746 - accuracy: 0.2142 - val_loss: 1.7714 - val_accuracy: 0.2585\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.8889 - accuracy: 0.2353 - val_loss: 1.7176 - val_accuracy: 0.2792\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.8441 - accuracy: 0.2470 - val_loss: 1.7115 - val_accuracy: 0.2892\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.8031 - accuracy: 0.2523 - val_loss: 1.6953 - val_accuracy: 0.2708\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 3.7801 - accuracy: 0.2520 - val_loss: 1.6937 - val_accuracy: 0.2792\n",
      "Epoch 8/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 3.7333 - accuracy: 0.2565Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.7323 - accuracy: 0.2567 - val_loss: 1.6753 - val_accuracy: 0.2708\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 600)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 600, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 25)                7525      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 25)                650       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 182       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,203,607\n",
      "Trainable params: 9,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.1930 - accuracy: 0.1910 - val_loss: 1.8756 - val_accuracy: 0.1988\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 4.0874 - accuracy: 0.2059 - val_loss: 1.8394 - val_accuracy: 0.2535\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9926 - accuracy: 0.2267 - val_loss: 1.7827 - val_accuracy: 0.2440\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.9176 - accuracy: 0.2421 - val_loss: 1.7488 - val_accuracy: 0.2351\n",
      "Epoch 5/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.8333 - accuracy: 0.2426Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.8335 - accuracy: 0.2427 - val_loss: 1.7227 - val_accuracy: 0.2501\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 600, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_15 (Reshape)           (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_15[0][0]']             \n",
      "                                                                                                  \n",
      " dot_10 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 300)          0           ['dot_10[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 300)          0           ['flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_16 (Reshape)           (None, 1, 300)       0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_16[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_17 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_17[0][0]']             \n",
      "                                                                                                  \n",
      " dot_11 (Dot)                   (None, 300, 1)       0           ['reshape_16[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_11 (Flatten)           (None, 300)          0           ['dot_11[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 25)           7525        ['flatten_11[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 25)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 25)           650         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 25)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 25)           650         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 25)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            182         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,204,207\n",
      "Trainable params: 9,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 14s 7ms/step - loss: 4.2097 - accuracy: 0.1619 - val_loss: 1.8691 - val_accuracy: 0.1792\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 4.0752 - accuracy: 0.2020 - val_loss: 1.8316 - val_accuracy: 0.2021\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 4.0061 - accuracy: 0.2078 - val_loss: 1.8048 - val_accuracy: 0.2166\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.9432 - accuracy: 0.2182 - val_loss: 1.7653 - val_accuracy: 0.2295\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.8637 - accuracy: 0.2391 - val_loss: 1.7185 - val_accuracy: 0.2356\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.7981 - accuracy: 0.2486 - val_loss: 1.6961 - val_accuracy: 0.2747\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.7693 - accuracy: 0.2568 - val_loss: 1.7232 - val_accuracy: 0.2306\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.7218 - accuracy: 0.2567 - val_loss: 1.6768 - val_accuracy: 0.2490\n",
      "Epoch 9/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.7126 - accuracy: 0.2572Restoring model weights from the end of the best epoch: 6.\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.7124 - accuracy: 0.2569 - val_loss: 1.6726 - val_accuracy: 0.2674\n",
      "Epoch 9: early stopping\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 200, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,215,107\n",
      "Trainable params: 20,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.1473 - accuracy: 0.1996 - val_loss: 1.7863 - val_accuracy: 0.2451\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8594 - accuracy: 0.2642 - val_loss: 1.7160 - val_accuracy: 0.2875\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 3.7329 - accuracy: 0.2727 - val_loss: 1.7098 - val_accuracy: 0.2619\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 3.6928 - accuracy: 0.2722 - val_loss: 1.6737 - val_accuracy: 0.2775\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.6331 - accuracy: 0.2817 - val_loss: 1.6413 - val_accuracy: 0.3160\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5858 - accuracy: 0.2909 - val_loss: 1.6380 - val_accuracy: 0.2870\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5782 - accuracy: 0.2913 - val_loss: 1.6453 - val_accuracy: 0.3015\n",
      "Epoch 8/100\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 3.5307 - accuracy: 0.2982Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5312 - accuracy: 0.2976 - val_loss: 1.6457 - val_accuracy: 0.2970\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 200, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 200, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_18 (Reshape)           (None, 1, 200)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 200)       0           ['reshape_18[0][0]']             \n",
      "                                                                                                  \n",
      " dot_12 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 300)          0           ['dot_12[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 300)          0           ['flatten_12[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_19 (Reshape)           (None, 1, 300)       0           ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_19[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_20 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_20[0][0]']             \n",
      "                                                                                                  \n",
      " dot_13 (Dot)                   (None, 300, 1)       0           ['reshape_19[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_13 (Flatten)           (None, 300)          0           ['dot_13[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 50)           15050       ['flatten_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 50)           2550        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 50)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 50)           2550        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 50)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            357         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,215,707\n",
      "Trainable params: 21,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.1058 - accuracy: 0.2259 - val_loss: 1.7477 - val_accuracy: 0.2591\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7660 - accuracy: 0.2757 - val_loss: 1.6894 - val_accuracy: 0.2797\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.6299 - accuracy: 0.2927 - val_loss: 1.6076 - val_accuracy: 0.3216\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5544 - accuracy: 0.2978 - val_loss: 1.6420 - val_accuracy: 0.2993\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5073 - accuracy: 0.3066 - val_loss: 1.6301 - val_accuracy: 0.3155\n",
      "Epoch 6/100\n",
      "1709/1719 [============================>.] - ETA: 0s - loss: 3.4586 - accuracy: 0.3180Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4569 - accuracy: 0.3188 - val_loss: 1.6034 - val_accuracy: 0.3216\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 300, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,215,107\n",
      "Trainable params: 20,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0991 - accuracy: 0.2210 - val_loss: 1.8077 - val_accuracy: 0.2217\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8600 - accuracy: 0.2462 - val_loss: 1.7406 - val_accuracy: 0.2485\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7414 - accuracy: 0.2688 - val_loss: 1.7060 - val_accuracy: 0.2574\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.6894 - accuracy: 0.2764 - val_loss: 1.6745 - val_accuracy: 0.2887\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.6479 - accuracy: 0.2787 - val_loss: 1.6642 - val_accuracy: 0.3032\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.6028 - accuracy: 0.2890 - val_loss: 1.6535 - val_accuracy: 0.2965\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5836 - accuracy: 0.2924 - val_loss: 1.6247 - val_accuracy: 0.3021\n",
      "Epoch 8/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 3.5413 - accuracy: 0.2996Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5426 - accuracy: 0.2995 - val_loss: 1.7046 - val_accuracy: 0.2691\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 300, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_21 (Reshape)           (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_21[0][0]']             \n",
      "                                                                                                  \n",
      " dot_14 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_14 (Flatten)           (None, 300)          0           ['dot_14[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 300)          0           ['flatten_14[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_22 (Reshape)           (None, 1, 300)       0           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_22[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_23 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_23[0][0]']             \n",
      "                                                                                                  \n",
      " dot_15 (Dot)                   (None, 300, 1)       0           ['reshape_22[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 300)          0           ['dot_15[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 50)           15050       ['flatten_15[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 50)           2550        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 50)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 50)           2550        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 50)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            357         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,215,707\n",
      "Trainable params: 21,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 5ms/step - loss: 4.1040 - accuracy: 0.1886 - val_loss: 1.7549 - val_accuracy: 0.2702\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.7884 - accuracy: 0.2703 - val_loss: 1.7008 - val_accuracy: 0.2574\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.6525 - accuracy: 0.2840 - val_loss: 1.6295 - val_accuracy: 0.3138\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5922 - accuracy: 0.3005 - val_loss: 1.6589 - val_accuracy: 0.3076\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.5189 - accuracy: 0.3055 - val_loss: 1.6236 - val_accuracy: 0.3021\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.4614 - accuracy: 0.3175 - val_loss: 1.6145 - val_accuracy: 0.3311\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.4477 - accuracy: 0.3167 - val_loss: 1.6208 - val_accuracy: 0.3222\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.4312 - accuracy: 0.3200 - val_loss: 1.6310 - val_accuracy: 0.3076\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.4068 - accuracy: 0.3202Restoring model weights from the end of the best epoch: 6.\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.4068 - accuracy: 0.3202 - val_loss: 1.6593 - val_accuracy: 0.2976\n",
      "Epoch 9: early stopping\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 400, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,215,107\n",
      "Trainable params: 20,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.1336 - accuracy: 0.1909 - val_loss: 1.8171 - val_accuracy: 0.2194\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.8276 - accuracy: 0.2621 - val_loss: 1.7431 - val_accuracy: 0.2395\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.7204 - accuracy: 0.2619 - val_loss: 1.6919 - val_accuracy: 0.2831\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6777 - accuracy: 0.2733 - val_loss: 1.6787 - val_accuracy: 0.2814\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6454 - accuracy: 0.2812 - val_loss: 1.6835 - val_accuracy: 0.2736\n",
      "Epoch 6/100\n",
      "1709/1719 [============================>.] - ETA: 0s - loss: 3.5948 - accuracy: 0.2929Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5965 - accuracy: 0.2929 - val_loss: 1.7195 - val_accuracy: 0.2540\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 400, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 400, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_24 (Reshape)           (None, 1, 400)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 400)       0           ['reshape_24[0][0]']             \n",
      "                                                                                                  \n",
      " dot_16 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_16 (Flatten)           (None, 300)          0           ['dot_16[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 300)          0           ['flatten_16[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_25 (Reshape)           (None, 1, 300)       0           ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_25[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_26 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_26[0][0]']             \n",
      "                                                                                                  \n",
      " dot_17 (Dot)                   (None, 300, 1)       0           ['reshape_25[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)           (None, 300)          0           ['dot_17[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 50)           15050       ['flatten_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 50)           2550        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 50)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 50)           2550        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 50)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            357         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,215,707\n",
      "Trainable params: 21,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 4.1327 - accuracy: 0.2075 - val_loss: 1.8132 - val_accuracy: 0.2518\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.8159 - accuracy: 0.2723 - val_loss: 1.7378 - val_accuracy: 0.2591\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6822 - accuracy: 0.2845 - val_loss: 1.6449 - val_accuracy: 0.3082\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6039 - accuracy: 0.2923 - val_loss: 1.6444 - val_accuracy: 0.3004\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.5563 - accuracy: 0.2983 - val_loss: 1.6226 - val_accuracy: 0.3166\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.5112 - accuracy: 0.3053 - val_loss: 1.6143 - val_accuracy: 0.3138\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.4677 - accuracy: 0.3138 - val_loss: 1.6000 - val_accuracy: 0.3222\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4257 - accuracy: 0.3090 - val_loss: 1.5972 - val_accuracy: 0.3238\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4215 - accuracy: 0.3210 - val_loss: 1.5671 - val_accuracy: 0.3428\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3883 - accuracy: 0.3189 - val_loss: 1.5839 - val_accuracy: 0.3194\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.3722 - accuracy: 0.3289 - val_loss: 1.6181 - val_accuracy: 0.3116\n",
      "Epoch 12/100\n",
      "1715/1719 [============================>.] - ETA: 0s - loss: 3.3555 - accuracy: 0.3260Restoring model weights from the end of the best epoch: 9.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3545 - accuracy: 0.3259 - val_loss: 1.6007 - val_accuracy: 0.3183\n",
      "Epoch 12: early stopping\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 500, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,215,107\n",
      "Trainable params: 20,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.0897 - accuracy: 0.2214 - val_loss: 1.8225 - val_accuracy: 0.2317\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.8109 - accuracy: 0.2481 - val_loss: 1.7181 - val_accuracy: 0.2373\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.7423 - accuracy: 0.2687 - val_loss: 1.6893 - val_accuracy: 0.2926\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6980 - accuracy: 0.2810 - val_loss: 1.7118 - val_accuracy: 0.2663\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6396 - accuracy: 0.2856 - val_loss: 1.6542 - val_accuracy: 0.3004\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5976 - accuracy: 0.2906 - val_loss: 1.6612 - val_accuracy: 0.2970\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5560 - accuracy: 0.3028 - val_loss: 1.6351 - val_accuracy: 0.3121\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5375 - accuracy: 0.3010 - val_loss: 1.6242 - val_accuracy: 0.3121\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5171 - accuracy: 0.2997 - val_loss: 1.6434 - val_accuracy: 0.2976\n",
      "Epoch 10/100\n",
      "1705/1719 [============================>.] - ETA: 0s - loss: 3.4937 - accuracy: 0.3015Restoring model weights from the end of the best epoch: 7.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4918 - accuracy: 0.3019 - val_loss: 1.6267 - val_accuracy: 0.2948\n",
      "Epoch 10: early stopping\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 500, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 500, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_27 (Reshape)           (None, 1, 500)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 500)       0           ['reshape_27[0][0]']             \n",
      "                                                                                                  \n",
      " dot_18 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_18 (Flatten)           (None, 300)          0           ['dot_18[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 300)          0           ['flatten_18[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_28 (Reshape)           (None, 1, 300)       0           ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_28[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_29 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_29[0][0]']             \n",
      "                                                                                                  \n",
      " dot_19 (Dot)                   (None, 300, 1)       0           ['reshape_28[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_19 (Flatten)           (None, 300)          0           ['dot_19[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 50)           15050       ['flatten_19[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 50)           2550        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 50)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 50)           2550        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 50)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            357         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,215,707\n",
      "Trainable params: 21,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 14s 7ms/step - loss: 4.1259 - accuracy: 0.1851 - val_loss: 1.7959 - val_accuracy: 0.2686\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.8435 - accuracy: 0.2489 - val_loss: 1.6962 - val_accuracy: 0.3065\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.7099 - accuracy: 0.2759 - val_loss: 1.6717 - val_accuracy: 0.2892\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.6589 - accuracy: 0.2906 - val_loss: 1.6992 - val_accuracy: 0.2496\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.5860 - accuracy: 0.2971 - val_loss: 1.6238 - val_accuracy: 0.3138\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.5563 - accuracy: 0.3048 - val_loss: 1.6234 - val_accuracy: 0.3049\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.5345 - accuracy: 0.3040 - val_loss: 1.6217 - val_accuracy: 0.3322\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.4886 - accuracy: 0.3101 - val_loss: 1.6068 - val_accuracy: 0.3088\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.4598 - accuracy: 0.3102 - val_loss: 1.6093 - val_accuracy: 0.3272\n",
      "Epoch 10/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.4502 - accuracy: 0.3142Restoring model weights from the end of the best epoch: 7.\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.4510 - accuracy: 0.3143 - val_loss: 1.5989 - val_accuracy: 0.3205\n",
      "Epoch 10: early stopping\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 600)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 600, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 357       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,215,107\n",
      "Trainable params: 20,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.1411 - accuracy: 0.1865 - val_loss: 1.8145 - val_accuracy: 0.2641\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9501 - accuracy: 0.2402 - val_loss: 1.7466 - val_accuracy: 0.3305\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.8263 - accuracy: 0.2639 - val_loss: 1.7075 - val_accuracy: 0.2842\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.7589 - accuracy: 0.2730 - val_loss: 1.7080 - val_accuracy: 0.2825\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.7106 - accuracy: 0.2753Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.7106 - accuracy: 0.2753 - val_loss: 1.6907 - val_accuracy: 0.2909\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 600, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_30 (Reshape)           (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_30[0][0]']             \n",
      "                                                                                                  \n",
      " dot_20 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_20 (Flatten)           (None, 300)          0           ['dot_20[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 300)          0           ['flatten_20[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_31 (Reshape)           (None, 1, 300)       0           ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_31[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_32 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_32[0][0]']             \n",
      "                                                                                                  \n",
      " dot_21 (Dot)                   (None, 300, 1)       0           ['reshape_31[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_21 (Flatten)           (None, 300)          0           ['dot_21[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 50)           15050       ['flatten_21[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 50)           2550        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 50)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 50)           2550        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 50)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            357         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,215,707\n",
      "Trainable params: 21,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 16s 8ms/step - loss: 4.1541 - accuracy: 0.1881 - val_loss: 1.8486 - val_accuracy: 0.2568\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.8804 - accuracy: 0.2589 - val_loss: 1.6995 - val_accuracy: 0.2781\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.7420 - accuracy: 0.2720 - val_loss: 1.6603 - val_accuracy: 0.3160\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.6566 - accuracy: 0.2818 - val_loss: 1.6549 - val_accuracy: 0.3032\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.5864 - accuracy: 0.2964 - val_loss: 1.6574 - val_accuracy: 0.2814\n",
      "Epoch 6/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.5482 - accuracy: 0.2950Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.5483 - accuracy: 0.2949 - val_loss: 1.6461 - val_accuracy: 0.3099\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 200, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,229,107\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0898 - accuracy: 0.2011 - val_loss: 1.7237 - val_accuracy: 0.2741\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7811 - accuracy: 0.2613 - val_loss: 1.6764 - val_accuracy: 0.2753\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.7053 - accuracy: 0.2699 - val_loss: 1.6922 - val_accuracy: 0.2714\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6685 - accuracy: 0.2724 - val_loss: 1.6671 - val_accuracy: 0.2898\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6085 - accuracy: 0.2924 - val_loss: 1.7074 - val_accuracy: 0.2568\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.5539 - accuracy: 0.2954 - val_loss: 1.7047 - val_accuracy: 0.2697\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5218 - accuracy: 0.3072 - val_loss: 1.6392 - val_accuracy: 0.2926\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4847 - accuracy: 0.3087 - val_loss: 1.6241 - val_accuracy: 0.3132\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4589 - accuracy: 0.3125 - val_loss: 1.6443 - val_accuracy: 0.3166\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.4503 - accuracy: 0.3189 - val_loss: 1.6681 - val_accuracy: 0.2887\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.4207 - accuracy: 0.3201 - val_loss: 1.6155 - val_accuracy: 0.3110\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.3911 - accuracy: 0.3189 - val_loss: 1.6193 - val_accuracy: 0.3205\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.3871 - accuracy: 0.3182 - val_loss: 1.6071 - val_accuracy: 0.3132\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.3688 - accuracy: 0.3235 - val_loss: 1.5807 - val_accuracy: 0.3345\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.3537 - accuracy: 0.3273 - val_loss: 1.5802 - val_accuracy: 0.3406\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.3500 - accuracy: 0.3330 - val_loss: 1.5813 - val_accuracy: 0.3088\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.3476 - accuracy: 0.3269 - val_loss: 1.5708 - val_accuracy: 0.3350\n",
      "Epoch 18/100\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 3.3182 - accuracy: 0.3317Restoring model weights from the end of the best epoch: 15.\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.3223 - accuracy: 0.3311 - val_loss: 1.6046 - val_accuracy: 0.3227\n",
      "Epoch 18: early stopping\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 200, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 200, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_33 (Reshape)           (None, 1, 200)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 200)       0           ['reshape_33[0][0]']             \n",
      "                                                                                                  \n",
      " dot_22 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_22 (Flatten)           (None, 300)          0           ['dot_22[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 300)          0           ['flatten_22[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_34 (Reshape)           (None, 1, 300)       0           ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_34[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_35 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_35[0][0]']             \n",
      "                                                                                                  \n",
      " dot_23 (Dot)                   (None, 300, 1)       0           ['reshape_34[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_23 (Flatten)           (None, 300)          0           ['dot_23[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 75)           22575       ['flatten_23[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 75)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 75)           5700        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 75)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 75)           5700        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 75)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            532         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,229,707\n",
      "Trainable params: 35,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 5ms/step - loss: 4.0437 - accuracy: 0.2041 - val_loss: 1.7234 - val_accuracy: 0.2535\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.7133 - accuracy: 0.2790 - val_loss: 1.6656 - val_accuracy: 0.3021\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5808 - accuracy: 0.2962 - val_loss: 1.6326 - val_accuracy: 0.3160\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.5004 - accuracy: 0.3070 - val_loss: 1.6532 - val_accuracy: 0.2920\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.4582 - accuracy: 0.3087 - val_loss: 1.6235 - val_accuracy: 0.3155\n",
      "Epoch 6/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 3.4185 - accuracy: 0.3175Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.4193 - accuracy: 0.3175 - val_loss: 1.6145 - val_accuracy: 0.3065\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 300, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,229,107\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.0791 - accuracy: 0.2204 - val_loss: 1.7640 - val_accuracy: 0.2848\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7829 - accuracy: 0.2655 - val_loss: 1.6883 - val_accuracy: 0.2954\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7067 - accuracy: 0.2714 - val_loss: 1.6924 - val_accuracy: 0.2446\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6625 - accuracy: 0.2813 - val_loss: 1.6924 - val_accuracy: 0.2574\n",
      "Epoch 5/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.6169 - accuracy: 0.2831Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6172 - accuracy: 0.2830 - val_loss: 1.6645 - val_accuracy: 0.2825\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 300, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_36 (Reshape)           (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_36[0][0]']             \n",
      "                                                                                                  \n",
      " dot_24 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_24 (Flatten)           (None, 300)          0           ['dot_24[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 300)          0           ['flatten_24[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_37 (Reshape)           (None, 1, 300)       0           ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_37[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_38 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_38[0][0]']             \n",
      "                                                                                                  \n",
      " dot_25 (Dot)                   (None, 300, 1)       0           ['reshape_37[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_25 (Flatten)           (None, 300)          0           ['dot_25[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 75)           22575       ['flatten_25[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 75)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 75)           5700        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 75)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 75)           5700        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 75)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            532         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,229,707\n",
      "Trainable params: 35,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 4.0158 - accuracy: 0.2277 - val_loss: 1.7265 - val_accuracy: 0.2406\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6913 - accuracy: 0.2739 - val_loss: 1.6717 - val_accuracy: 0.2903\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6163 - accuracy: 0.2916 - val_loss: 1.6541 - val_accuracy: 0.2881\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.5399 - accuracy: 0.3034 - val_loss: 1.6535 - val_accuracy: 0.2970\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4909 - accuracy: 0.3124 - val_loss: 1.6159 - val_accuracy: 0.3222\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4367 - accuracy: 0.3185 - val_loss: 1.5871 - val_accuracy: 0.3250\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4046 - accuracy: 0.3254 - val_loss: 1.6152 - val_accuracy: 0.3238\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3851 - accuracy: 0.3297 - val_loss: 1.5844 - val_accuracy: 0.3372\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3609 - accuracy: 0.3314 - val_loss: 1.6876 - val_accuracy: 0.2909\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3331 - accuracy: 0.3325 - val_loss: 1.5662 - val_accuracy: 0.3479\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3051 - accuracy: 0.3346 - val_loss: 1.5709 - val_accuracy: 0.3283\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2994 - accuracy: 0.3397 - val_loss: 1.5774 - val_accuracy: 0.3283\n",
      "Epoch 13/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.2772 - accuracy: 0.3403Restoring model weights from the end of the best epoch: 10.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2764 - accuracy: 0.3403 - val_loss: 1.5635 - val_accuracy: 0.3406\n",
      "Epoch 13: early stopping\n",
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 400, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,229,107\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.1174 - accuracy: 0.2006 - val_loss: 1.7791 - val_accuracy: 0.2250\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.8346 - accuracy: 0.2566 - val_loss: 1.7135 - val_accuracy: 0.2557\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7051 - accuracy: 0.2658 - val_loss: 1.7164 - val_accuracy: 0.2401\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6772 - accuracy: 0.2724 - val_loss: 1.6984 - val_accuracy: 0.2563\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6309 - accuracy: 0.2764 - val_loss: 1.6601 - val_accuracy: 0.2797\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6043 - accuracy: 0.2852 - val_loss: 1.6637 - val_accuracy: 0.2736\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5608 - accuracy: 0.2954 - val_loss: 1.6439 - val_accuracy: 0.3032\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5353 - accuracy: 0.3015 - val_loss: 1.6171 - val_accuracy: 0.3183\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.4865 - accuracy: 0.3086 - val_loss: 1.6441 - val_accuracy: 0.2892\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5012 - accuracy: 0.3080 - val_loss: 1.6376 - val_accuracy: 0.3037\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.4636 - accuracy: 0.3111Restoring model weights from the end of the best epoch: 8.\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4636 - accuracy: 0.3111 - val_loss: 1.6236 - val_accuracy: 0.3060\n",
      "Epoch 11: early stopping\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 400, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 400, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_39 (Reshape)           (None, 1, 400)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 400)       0           ['reshape_39[0][0]']             \n",
      "                                                                                                  \n",
      " dot_26 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_26 (Flatten)           (None, 300)          0           ['dot_26[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 300)          0           ['flatten_26[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_40 (Reshape)           (None, 1, 300)       0           ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_40[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_41 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_41[0][0]']             \n",
      "                                                                                                  \n",
      " dot_27 (Dot)                   (None, 300, 1)       0           ['reshape_40[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_27 (Flatten)           (None, 300)          0           ['dot_27[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 75)           22575       ['flatten_27[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 75)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 75)           5700        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 75)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 75)           5700        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 75)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            532         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,229,707\n",
      "Trainable params: 35,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 12s 6ms/step - loss: 4.0634 - accuracy: 0.2129 - val_loss: 1.7385 - val_accuracy: 0.2390\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.7245 - accuracy: 0.2724 - val_loss: 1.6600 - val_accuracy: 0.3143\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.6194 - accuracy: 0.2924 - val_loss: 1.6836 - val_accuracy: 0.2714\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.5517 - accuracy: 0.3044 - val_loss: 1.6292 - val_accuracy: 0.3194\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4896 - accuracy: 0.3135 - val_loss: 1.6179 - val_accuracy: 0.3155\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.4529 - accuracy: 0.3178 - val_loss: 1.6006 - val_accuracy: 0.3210\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.4055 - accuracy: 0.3234 - val_loss: 1.5841 - val_accuracy: 0.3356\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3933 - accuracy: 0.3242 - val_loss: 1.5866 - val_accuracy: 0.3417\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.3761 - accuracy: 0.3245 - val_loss: 1.5983 - val_accuracy: 0.3266\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3426 - accuracy: 0.3261 - val_loss: 1.5801 - val_accuracy: 0.3272\n",
      "Epoch 11/100\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 3.3284 - accuracy: 0.3365Restoring model weights from the end of the best epoch: 8.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3259 - accuracy: 0.3367 - val_loss: 1.5747 - val_accuracy: 0.3255\n",
      "Epoch 11: early stopping\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 500, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,229,107\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.1388 - accuracy: 0.1764 - val_loss: 1.8213 - val_accuracy: 0.2178\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.8867 - accuracy: 0.2448 - val_loss: 1.7396 - val_accuracy: 0.2641\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.7329 - accuracy: 0.2673 - val_loss: 1.6831 - val_accuracy: 0.2702\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6767 - accuracy: 0.2829 - val_loss: 1.7116 - val_accuracy: 0.2669\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6238 - accuracy: 0.2930 - val_loss: 1.6728 - val_accuracy: 0.2909\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5774 - accuracy: 0.2956 - val_loss: 1.6688 - val_accuracy: 0.3049\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.5499 - accuracy: 0.3021 - val_loss: 1.6514 - val_accuracy: 0.2982\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.5035 - accuracy: 0.3031 - val_loss: 1.6092 - val_accuracy: 0.3177\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4748 - accuracy: 0.3117 - val_loss: 1.6203 - val_accuracy: 0.3076\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4599 - accuracy: 0.3119 - val_loss: 1.6575 - val_accuracy: 0.3009\n",
      "Epoch 11/100\n",
      "1708/1719 [============================>.] - ETA: 0s - loss: 3.4407 - accuracy: 0.3148Restoring model weights from the end of the best epoch: 8.\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4425 - accuracy: 0.3151 - val_loss: 1.5833 - val_accuracy: 0.3177\n",
      "Epoch 11: early stopping\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 500, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 500, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_42 (Reshape)           (None, 1, 500)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 500)       0           ['reshape_42[0][0]']             \n",
      "                                                                                                  \n",
      " dot_28 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_28 (Flatten)           (None, 300)          0           ['dot_28[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 300)          0           ['flatten_28[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_43 (Reshape)           (None, 1, 300)       0           ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_43[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_44 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_44[0][0]']             \n",
      "                                                                                                  \n",
      " dot_29 (Dot)                   (None, 300, 1)       0           ['reshape_43[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_29 (Flatten)           (None, 300)          0           ['dot_29[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 75)           22575       ['flatten_29[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 75)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 75)           5700        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 75)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 75)           5700        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 75)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            532         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,229,707\n",
      "Trainable params: 35,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 4.0727 - accuracy: 0.2118 - val_loss: 1.7561 - val_accuracy: 0.2630\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.7517 - accuracy: 0.2747 - val_loss: 1.6938 - val_accuracy: 0.2892\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.6170 - accuracy: 0.2871 - val_loss: 1.6461 - val_accuracy: 0.3076\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.5467 - accuracy: 0.3002 - val_loss: 1.6488 - val_accuracy: 0.2892\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.4827 - accuracy: 0.3066 - val_loss: 1.6234 - val_accuracy: 0.3188\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.4343 - accuracy: 0.3134 - val_loss: 1.6324 - val_accuracy: 0.3121\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 3.4261 - accuracy: 0.3141 - val_loss: 1.6051 - val_accuracy: 0.3183\n",
      "Epoch 8/100\n",
      "1715/1719 [============================>.] - ETA: 0s - loss: 3.3952 - accuracy: 0.3254Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 3.3962 - accuracy: 0.3253 - val_loss: 1.6031 - val_accuracy: 0.3177\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 600)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 600, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,229,107\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.1362 - accuracy: 0.1926 - val_loss: 1.8337 - val_accuracy: 0.2205\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9028 - accuracy: 0.2437 - val_loss: 1.7578 - val_accuracy: 0.2769\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7835 - accuracy: 0.2679 - val_loss: 1.7396 - val_accuracy: 0.2563\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.7190 - accuracy: 0.2687 - val_loss: 1.7048 - val_accuracy: 0.2535\n",
      "Epoch 5/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.6691 - accuracy: 0.2827Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6688 - accuracy: 0.2826 - val_loss: 1.6896 - val_accuracy: 0.2697\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 600, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_45 (Reshape)           (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_45[0][0]']             \n",
      "                                                                                                  \n",
      " dot_30 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_30 (Flatten)           (None, 300)          0           ['dot_30[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 300)          0           ['flatten_30[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_46 (Reshape)           (None, 1, 300)       0           ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_46[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_47 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_47[0][0]']             \n",
      "                                                                                                  \n",
      " dot_31 (Dot)                   (None, 300, 1)       0           ['reshape_46[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_31 (Flatten)           (None, 300)          0           ['dot_31[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 75)           22575       ['flatten_31[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 75)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 75)           5700        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 75)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 75)           5700        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 75)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            532         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,229,707\n",
      "Trainable params: 35,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 4.1414 - accuracy: 0.1918 - val_loss: 1.8263 - val_accuracy: 0.2105\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.8180 - accuracy: 0.2556 - val_loss: 1.7213 - val_accuracy: 0.2568\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.6750 - accuracy: 0.2764 - val_loss: 1.6694 - val_accuracy: 0.2624\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.6185 - accuracy: 0.2901 - val_loss: 1.6527 - val_accuracy: 0.2903\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.5519 - accuracy: 0.2948 - val_loss: 1.6636 - val_accuracy: 0.3110\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.5090 - accuracy: 0.3063 - val_loss: 1.6210 - val_accuracy: 0.3110\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.4612 - accuracy: 0.3139 - val_loss: 1.6189 - val_accuracy: 0.3183\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.4416 - accuracy: 0.3165 - val_loss: 1.6084 - val_accuracy: 0.3171\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.4038 - accuracy: 0.3315 - val_loss: 1.5804 - val_accuracy: 0.3244\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3811 - accuracy: 0.3250 - val_loss: 1.6109 - val_accuracy: 0.3199\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3715 - accuracy: 0.3328 - val_loss: 1.5998 - val_accuracy: 0.3300\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3494 - accuracy: 0.3395 - val_loss: 1.6141 - val_accuracy: 0.3155\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.3281 - accuracy: 0.3346 - val_loss: 1.5859 - val_accuracy: 0.3523\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3135 - accuracy: 0.3444 - val_loss: 1.6044 - val_accuracy: 0.3194\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.3075 - accuracy: 0.3402 - val_loss: 1.5856 - val_accuracy: 0.3233\n",
      "Epoch 16/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.3000 - accuracy: 0.3358Restoring model weights from the end of the best epoch: 13.\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.2994 - accuracy: 0.3357 - val_loss: 1.5953 - val_accuracy: 0.3166\n",
      "Epoch 16: early stopping\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 200, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,607\n",
      "Trainable params: 51,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0356 - accuracy: 0.2200 - val_loss: 1.7124 - val_accuracy: 0.2965\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.7194 - accuracy: 0.2800 - val_loss: 1.6945 - val_accuracy: 0.2831\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6284 - accuracy: 0.2867 - val_loss: 1.6616 - val_accuracy: 0.3043\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.5623 - accuracy: 0.2932 - val_loss: 1.6293 - val_accuracy: 0.3188\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.5301 - accuracy: 0.3010 - val_loss: 1.6065 - val_accuracy: 0.3194\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.4917 - accuracy: 0.3090 - val_loss: 1.6228 - val_accuracy: 0.2993\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.4472 - accuracy: 0.3138 - val_loss: 1.6176 - val_accuracy: 0.3199\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.4274 - accuracy: 0.3230 - val_loss: 1.5771 - val_accuracy: 0.3311\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.3962 - accuracy: 0.3256 - val_loss: 1.6005 - val_accuracy: 0.3356\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.3890 - accuracy: 0.3297 - val_loss: 1.5988 - val_accuracy: 0.3171\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.3613 - accuracy: 0.3358 - val_loss: 1.5801 - val_accuracy: 0.3261\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.3518 - accuracy: 0.3327Restoring model weights from the end of the best epoch: 9.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.3518 - accuracy: 0.3327 - val_loss: 1.5916 - val_accuracy: 0.3350\n",
      "Epoch 12: early stopping\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 200, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 200, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_48 (Reshape)           (None, 1, 200)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 200)       0           ['reshape_48[0][0]']             \n",
      "                                                                                                  \n",
      " dot_32 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_32 (Flatten)           (None, 300)          0           ['dot_32[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 300)          0           ['flatten_32[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_49 (Reshape)           (None, 1, 300)       0           ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_49[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_50 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_50[0][0]']             \n",
      "                                                                                                  \n",
      " dot_33 (Dot)                   (None, 300, 1)       0           ['reshape_49[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_33 (Flatten)           (None, 300)          0           ['dot_33[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_33[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,246,207\n",
      "Trainable params: 51,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9818 - accuracy: 0.2334 - val_loss: 1.6649 - val_accuracy: 0.3188\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.6379 - accuracy: 0.2928 - val_loss: 1.7187 - val_accuracy: 0.2602\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5067 - accuracy: 0.3066 - val_loss: 1.6002 - val_accuracy: 0.3311\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.4585 - accuracy: 0.3104 - val_loss: 1.5951 - val_accuracy: 0.3350\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.3985 - accuracy: 0.3199 - val_loss: 1.6208 - val_accuracy: 0.3149\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.3697 - accuracy: 0.3224 - val_loss: 1.5925 - val_accuracy: 0.3272\n",
      "Epoch 7/100\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 3.3390 - accuracy: 0.3343Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.3365 - accuracy: 0.3342 - val_loss: 1.5790 - val_accuracy: 0.3328\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 300, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,607\n",
      "Trainable params: 51,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0210 - accuracy: 0.2155 - val_loss: 1.7663 - val_accuracy: 0.2289\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.7291 - accuracy: 0.2625 - val_loss: 1.6531 - val_accuracy: 0.3244\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6555 - accuracy: 0.2786 - val_loss: 1.7055 - val_accuracy: 0.2479\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6062 - accuracy: 0.2895 - val_loss: 1.6588 - val_accuracy: 0.2993\n",
      "Epoch 5/100\n",
      "1711/1719 [============================>.] - ETA: 0s - loss: 3.5363 - accuracy: 0.3043Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5356 - accuracy: 0.3040 - val_loss: 1.6162 - val_accuracy: 0.3104\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 300, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_51 (Reshape)           (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_51[0][0]']             \n",
      "                                                                                                  \n",
      " dot_34 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_34 (Flatten)           (None, 300)          0           ['dot_34[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 300)          0           ['flatten_34[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_52 (Reshape)           (None, 1, 300)       0           ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_52[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_53 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_53[0][0]']             \n",
      "                                                                                                  \n",
      " dot_35 (Dot)                   (None, 300, 1)       0           ['reshape_52[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_35 (Flatten)           (None, 300)          0           ['dot_35[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_35[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,246,207\n",
      "Trainable params: 51,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 4.0042 - accuracy: 0.2221 - val_loss: 1.7147 - val_accuracy: 0.2820\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6773 - accuracy: 0.2786 - val_loss: 1.6589 - val_accuracy: 0.2954\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.5806 - accuracy: 0.2983 - val_loss: 1.6206 - val_accuracy: 0.3227\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.5006 - accuracy: 0.3046 - val_loss: 1.6405 - val_accuracy: 0.3015\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4389 - accuracy: 0.3157 - val_loss: 1.6037 - val_accuracy: 0.3227\n",
      "Epoch 6/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.4036 - accuracy: 0.3206Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4037 - accuracy: 0.3205 - val_loss: 1.6367 - val_accuracy: 0.3171\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 400, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,607\n",
      "Trainable params: 51,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0556 - accuracy: 0.2073 - val_loss: 1.7463 - val_accuracy: 0.2691\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.7545 - accuracy: 0.2695 - val_loss: 1.7087 - val_accuracy: 0.2842\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6647 - accuracy: 0.2884 - val_loss: 1.6830 - val_accuracy: 0.3015\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6070 - accuracy: 0.2858 - val_loss: 1.7048 - val_accuracy: 0.2585\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5573 - accuracy: 0.2970 - val_loss: 1.6472 - val_accuracy: 0.3277\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.5128 - accuracy: 0.3063 - val_loss: 1.6452 - val_accuracy: 0.2954\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4826 - accuracy: 0.3099 - val_loss: 1.6317 - val_accuracy: 0.3160\n",
      "Epoch 8/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.4537 - accuracy: 0.3149Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.4531 - accuracy: 0.3149 - val_loss: 1.6445 - val_accuracy: 0.2931\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 400, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 400, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_54 (Reshape)           (None, 1, 400)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 400)       0           ['reshape_54[0][0]']             \n",
      "                                                                                                  \n",
      " dot_36 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_36 (Flatten)           (None, 300)          0           ['dot_36[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 300)          0           ['flatten_36[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_55 (Reshape)           (None, 1, 300)       0           ['concatenate_18[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_55[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_56 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_56[0][0]']             \n",
      "                                                                                                  \n",
      " dot_37 (Dot)                   (None, 300, 1)       0           ['reshape_55[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_37 (Flatten)           (None, 300)          0           ['dot_37[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_37[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,246,207\n",
      "Trainable params: 51,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 12s 6ms/step - loss: 4.0689 - accuracy: 0.2044 - val_loss: 1.7395 - val_accuracy: 0.2680\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.7539 - accuracy: 0.2770 - val_loss: 1.6839 - val_accuracy: 0.2730\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.6339 - accuracy: 0.2909 - val_loss: 1.6372 - val_accuracy: 0.3244\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.5393 - accuracy: 0.3085 - val_loss: 1.6755 - val_accuracy: 0.2764\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4915 - accuracy: 0.3082 - val_loss: 1.6135 - val_accuracy: 0.3116\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.4356 - accuracy: 0.3122 - val_loss: 1.5869 - val_accuracy: 0.3261\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3865 - accuracy: 0.3250 - val_loss: 1.5785 - val_accuracy: 0.3317\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.3836 - accuracy: 0.3245 - val_loss: 1.6225 - val_accuracy: 0.3093\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.3439 - accuracy: 0.3304 - val_loss: 1.6097 - val_accuracy: 0.3277\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3182 - accuracy: 0.3360 - val_loss: 1.5468 - val_accuracy: 0.3395\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.3055 - accuracy: 0.3327 - val_loss: 1.5787 - val_accuracy: 0.3350\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3026 - accuracy: 0.3401 - val_loss: 1.5588 - val_accuracy: 0.3367\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2736 - accuracy: 0.3412 - val_loss: 1.5506 - val_accuracy: 0.3501\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.2668 - accuracy: 0.3482 - val_loss: 1.5723 - val_accuracy: 0.3423\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.2527 - accuracy: 0.3461 - val_loss: 1.5608 - val_accuracy: 0.3277\n",
      "Epoch 16/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.2247 - accuracy: 0.3479Restoring model weights from the end of the best epoch: 13.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2254 - accuracy: 0.3479 - val_loss: 1.5584 - val_accuracy: 0.3467\n",
      "Epoch 16: early stopping\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 500, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,607\n",
      "Trainable params: 51,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.0541 - accuracy: 0.2142 - val_loss: 1.7509 - val_accuracy: 0.2602\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.7703 - accuracy: 0.2667 - val_loss: 1.7039 - val_accuracy: 0.2529\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.6862 - accuracy: 0.2808 - val_loss: 1.7057 - val_accuracy: 0.2803\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6190 - accuracy: 0.2855 - val_loss: 1.6766 - val_accuracy: 0.2792\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5824 - accuracy: 0.2914 - val_loss: 1.6519 - val_accuracy: 0.2903\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5343 - accuracy: 0.2987 - val_loss: 1.6899 - val_accuracy: 0.2875\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4953 - accuracy: 0.3104 - val_loss: 1.6231 - val_accuracy: 0.3076\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.4768 - accuracy: 0.3063 - val_loss: 1.6100 - val_accuracy: 0.3149\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4617 - accuracy: 0.3104 - val_loss: 1.6103 - val_accuracy: 0.3227\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4280 - accuracy: 0.3163 - val_loss: 1.6501 - val_accuracy: 0.2931\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4136 - accuracy: 0.3191 - val_loss: 1.6061 - val_accuracy: 0.3283\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.4002 - accuracy: 0.3220 - val_loss: 1.6086 - val_accuracy: 0.3255\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.3909 - accuracy: 0.3270 - val_loss: 1.6233 - val_accuracy: 0.2875\n",
      "Epoch 14/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 3.3666 - accuracy: 0.3274Restoring model weights from the end of the best epoch: 11.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3652 - accuracy: 0.3277 - val_loss: 1.6149 - val_accuracy: 0.3155\n",
      "Epoch 14: early stopping\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 500, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 500, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_57 (Reshape)           (None, 1, 500)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 500)       0           ['reshape_57[0][0]']             \n",
      "                                                                                                  \n",
      " dot_38 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_38 (Flatten)           (None, 300)          0           ['dot_38[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 300)          0           ['flatten_38[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_58 (Reshape)           (None, 1, 300)       0           ['concatenate_19[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_58[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_59 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_59[0][0]']             \n",
      "                                                                                                  \n",
      " dot_39 (Dot)                   (None, 300, 1)       0           ['reshape_58[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_39 (Flatten)           (None, 300)          0           ['dot_39[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_39[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,246,207\n",
      "Trainable params: 51,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 14s 7ms/step - loss: 4.0399 - accuracy: 0.2152 - val_loss: 1.7538 - val_accuracy: 0.2245\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.7237 - accuracy: 0.2729 - val_loss: 1.6820 - val_accuracy: 0.2591\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.6234 - accuracy: 0.2861 - val_loss: 1.6769 - val_accuracy: 0.2803\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 3.5445 - accuracy: 0.3039 - val_loss: 1.6057 - val_accuracy: 0.3439\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.4714 - accuracy: 0.3196 - val_loss: 1.5968 - val_accuracy: 0.2976\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.4344 - accuracy: 0.3157 - val_loss: 1.5848 - val_accuracy: 0.3238\n",
      "Epoch 7/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 3.3972 - accuracy: 0.3247Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3968 - accuracy: 0.3245 - val_loss: 1.5924 - val_accuracy: 0.3261\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 600)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 600, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,607\n",
      "Trainable params: 51,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 4.0632 - accuracy: 0.2188 - val_loss: 1.7818 - val_accuracy: 0.2473\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7902 - accuracy: 0.2600 - val_loss: 1.7077 - val_accuracy: 0.2669\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6973 - accuracy: 0.2723 - val_loss: 1.6835 - val_accuracy: 0.2853\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6447 - accuracy: 0.2783 - val_loss: 1.6695 - val_accuracy: 0.2808\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.6200 - accuracy: 0.2903 - val_loss: 1.6864 - val_accuracy: 0.2557\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5511 - accuracy: 0.2918 - val_loss: 1.6562 - val_accuracy: 0.2998\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5328 - accuracy: 0.3036 - val_loss: 1.7011 - val_accuracy: 0.2674\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5060 - accuracy: 0.3077 - val_loss: 1.6488 - val_accuracy: 0.2898\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4827 - accuracy: 0.3072 - val_loss: 1.6257 - val_accuracy: 0.3015\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4637 - accuracy: 0.3066 - val_loss: 1.6336 - val_accuracy: 0.2937\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4302 - accuracy: 0.3165 - val_loss: 1.6063 - val_accuracy: 0.3149\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4257 - accuracy: 0.3165 - val_loss: 1.6285 - val_accuracy: 0.3082\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3972 - accuracy: 0.3273 - val_loss: 1.6417 - val_accuracy: 0.2954\n",
      "Epoch 14/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.3891 - accuracy: 0.3230Restoring model weights from the end of the best epoch: 11.\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.3882 - accuracy: 0.3230 - val_loss: 1.6433 - val_accuracy: 0.3021\n",
      "Epoch 14: early stopping\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 600, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_60 (Reshape)           (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_60[0][0]']             \n",
      "                                                                                                  \n",
      " dot_40 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_40 (Flatten)           (None, 300)          0           ['dot_40[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 300)          0           ['flatten_40[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_61 (Reshape)           (None, 1, 300)       0           ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_61[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_62 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_62[0][0]']             \n",
      "                                                                                                  \n",
      " dot_41 (Dot)                   (None, 300, 1)       0           ['reshape_61[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_41 (Flatten)           (None, 300)          0           ['dot_41[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_41[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,246,207\n",
      "Trainable params: 51,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 4.0661 - accuracy: 0.2198 - val_loss: 1.7319 - val_accuracy: 0.2674\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.7534 - accuracy: 0.2655 - val_loss: 1.7029 - val_accuracy: 0.2490\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.6585 - accuracy: 0.2788 - val_loss: 1.6524 - val_accuracy: 0.2959\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.6037 - accuracy: 0.2940 - val_loss: 1.6779 - val_accuracy: 0.2842\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.5269 - accuracy: 0.3066 - val_loss: 1.6200 - val_accuracy: 0.3099\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.4803 - accuracy: 0.3151 - val_loss: 1.6353 - val_accuracy: 0.3004\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.4400 - accuracy: 0.3140 - val_loss: 1.5840 - val_accuracy: 0.3076\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.4027 - accuracy: 0.3240 - val_loss: 1.5944 - val_accuracy: 0.3227\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.3927 - accuracy: 0.3239 - val_loss: 1.6389 - val_accuracy: 0.3037\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3437 - accuracy: 0.3266 - val_loss: 1.5847 - val_accuracy: 0.3400\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3468 - accuracy: 0.3312 - val_loss: 1.5702 - val_accuracy: 0.3423\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 3.3050 - accuracy: 0.3392 - val_loss: 1.6005 - val_accuracy: 0.3333\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.2945 - accuracy: 0.3424 - val_loss: 1.5640 - val_accuracy: 0.3199\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.2882 - accuracy: 0.3428Restoring model weights from the end of the best epoch: 11.\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 3.2882 - accuracy: 0.3428 - val_loss: 1.6005 - val_accuracy: 0.3132\n",
      "Epoch 14: early stopping\n",
      "Model: \"model_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 200, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 150)               45150     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1057      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,286,107\n",
      "Trainable params: 91,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9875 - accuracy: 0.2326 - val_loss: 1.7741 - val_accuracy: 0.2552\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6923 - accuracy: 0.2781 - val_loss: 1.7282 - val_accuracy: 0.2775\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.5962 - accuracy: 0.2914 - val_loss: 1.6419 - val_accuracy: 0.3060\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5386 - accuracy: 0.3019 - val_loss: 1.6031 - val_accuracy: 0.3183\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4829 - accuracy: 0.3067 - val_loss: 1.5950 - val_accuracy: 0.3194\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4486 - accuracy: 0.3237 - val_loss: 1.6185 - val_accuracy: 0.3076\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4098 - accuracy: 0.3206 - val_loss: 1.6040 - val_accuracy: 0.3283\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3829 - accuracy: 0.3285 - val_loss: 1.6131 - val_accuracy: 0.3138\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3661 - accuracy: 0.3309 - val_loss: 1.6065 - val_accuracy: 0.3183\n",
      "Epoch 10/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.3438 - accuracy: 0.3299Restoring model weights from the end of the best epoch: 7.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3449 - accuracy: 0.3296 - val_loss: 1.6294 - val_accuracy: 0.3104\n",
      "Epoch 10: early stopping\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 200, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 200, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_63 (Reshape)           (None, 1, 200)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 200)       0           ['reshape_63[0][0]']             \n",
      "                                                                                                  \n",
      " dot_42 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_42 (Flatten)           (None, 300)          0           ['dot_42[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 300)          0           ['flatten_42[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_64 (Reshape)           (None, 1, 300)       0           ['concatenate_21[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_64[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_65 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_65[0][0]']             \n",
      "                                                                                                  \n",
      " dot_43 (Dot)                   (None, 300, 1)       0           ['reshape_64[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_43 (Flatten)           (None, 300)          0           ['dot_43[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_43[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,286,707\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.9559 - accuracy: 0.2479 - val_loss: 1.7258 - val_accuracy: 0.2875\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6202 - accuracy: 0.2924 - val_loss: 1.6527 - val_accuracy: 0.3060\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.5072 - accuracy: 0.3053 - val_loss: 1.6298 - val_accuracy: 0.3255\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 3.4430 - accuracy: 0.3192 - val_loss: 1.5949 - val_accuracy: 0.3266\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4002 - accuracy: 0.3263 - val_loss: 1.5942 - val_accuracy: 0.3322\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3637 - accuracy: 0.3328 - val_loss: 1.6482 - val_accuracy: 0.3160\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3308 - accuracy: 0.3416 - val_loss: 1.5416 - val_accuracy: 0.3523\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3127 - accuracy: 0.3383 - val_loss: 1.5652 - val_accuracy: 0.3512\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2777 - accuracy: 0.3514 - val_loss: 1.5828 - val_accuracy: 0.3277\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2395 - accuracy: 0.3527 - val_loss: 1.5528 - val_accuracy: 0.3562\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2213 - accuracy: 0.3533 - val_loss: 1.5882 - val_accuracy: 0.3439\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2083 - accuracy: 0.3574 - val_loss: 1.5514 - val_accuracy: 0.3456\n",
      "Epoch 13/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.1809 - accuracy: 0.3581Restoring model weights from the end of the best epoch: 10.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.1802 - accuracy: 0.3582 - val_loss: 1.5453 - val_accuracy: 0.3551\n",
      "Epoch 13: early stopping\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 300, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 150)               45150     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1057      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,286,107\n",
      "Trainable params: 91,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.9487 - accuracy: 0.2419 - val_loss: 1.7379 - val_accuracy: 0.2339\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.6854 - accuracy: 0.2730 - val_loss: 1.6881 - val_accuracy: 0.3021\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.5887 - accuracy: 0.2876 - val_loss: 1.6551 - val_accuracy: 0.2998\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5365 - accuracy: 0.3026 - val_loss: 1.6400 - val_accuracy: 0.3088\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4902 - accuracy: 0.3098 - val_loss: 1.6192 - val_accuracy: 0.3233\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4598 - accuracy: 0.3141 - val_loss: 1.6388 - val_accuracy: 0.3116\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4376 - accuracy: 0.3183 - val_loss: 1.6509 - val_accuracy: 0.3160\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.4023 - accuracy: 0.3290Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4023 - accuracy: 0.3290 - val_loss: 1.6068 - val_accuracy: 0.3132\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 300, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_66 (Reshape)           (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_66[0][0]']             \n",
      "                                                                                                  \n",
      " dot_44 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_44 (Flatten)           (None, 300)          0           ['dot_44[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 300)          0           ['flatten_44[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_67 (Reshape)           (None, 1, 300)       0           ['concatenate_22[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_67[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_68 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_68[0][0]']             \n",
      "                                                                                                  \n",
      " dot_45 (Dot)                   (None, 300, 1)       0           ['reshape_67[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_45 (Flatten)           (None, 300)          0           ['dot_45[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_45[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,286,707\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 12s 6ms/step - loss: 3.9547 - accuracy: 0.2412 - val_loss: 1.7212 - val_accuracy: 0.2406\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.6466 - accuracy: 0.2883 - val_loss: 1.6394 - val_accuracy: 0.3076\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.5359 - accuracy: 0.3000 - val_loss: 1.6271 - val_accuracy: 0.3205\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.4585 - accuracy: 0.3186 - val_loss: 1.6274 - val_accuracy: 0.3138\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4136 - accuracy: 0.3245 - val_loss: 1.6272 - val_accuracy: 0.3183\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3664 - accuracy: 0.3312 - val_loss: 1.5825 - val_accuracy: 0.3356\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.3425 - accuracy: 0.3367 - val_loss: 1.5842 - val_accuracy: 0.3445\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3202 - accuracy: 0.3335 - val_loss: 1.5349 - val_accuracy: 0.3523\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2819 - accuracy: 0.3387 - val_loss: 1.5918 - val_accuracy: 0.3361\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.2638 - accuracy: 0.3413 - val_loss: 1.5605 - val_accuracy: 0.3395\n",
      "Epoch 11/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 3.2426 - accuracy: 0.3423Restoring model weights from the end of the best epoch: 8.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2446 - accuracy: 0.3421 - val_loss: 1.6090 - val_accuracy: 0.3166\n",
      "Epoch 11: early stopping\n",
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 400, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 150)               45150     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1057      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,286,107\n",
      "Trainable params: 91,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.0092 - accuracy: 0.2217 - val_loss: 1.7399 - val_accuracy: 0.2289\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.7068 - accuracy: 0.2711 - val_loss: 1.7020 - val_accuracy: 0.2915\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.6028 - accuracy: 0.2931 - val_loss: 1.6675 - val_accuracy: 0.3054\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5289 - accuracy: 0.3018 - val_loss: 1.7014 - val_accuracy: 0.3026\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4921 - accuracy: 0.3078 - val_loss: 1.6871 - val_accuracy: 0.2909\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4537 - accuracy: 0.3226 - val_loss: 1.6324 - val_accuracy: 0.3121\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4288 - accuracy: 0.3213 - val_loss: 1.6367 - val_accuracy: 0.2903\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3934 - accuracy: 0.3237 - val_loss: 1.5954 - val_accuracy: 0.3210\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.3863 - accuracy: 0.3271 - val_loss: 1.6131 - val_accuracy: 0.3004\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3635 - accuracy: 0.3318 - val_loss: 1.6475 - val_accuracy: 0.2948\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.3499 - accuracy: 0.3352Restoring model weights from the end of the best epoch: 8.\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.3499 - accuracy: 0.3352 - val_loss: 1.5882 - val_accuracy: 0.3132\n",
      "Epoch 11: early stopping\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 400, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 400, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_69 (Reshape)           (None, 1, 400)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 400)       0           ['reshape_69[0][0]']             \n",
      "                                                                                                  \n",
      " dot_46 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_46 (Flatten)           (None, 300)          0           ['dot_46[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 300)          0           ['flatten_46[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_70 (Reshape)           (None, 1, 300)       0           ['concatenate_23[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_70[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_71 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_71[0][0]']             \n",
      "                                                                                                  \n",
      " dot_47 (Dot)                   (None, 300, 1)       0           ['reshape_70[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_47 (Flatten)           (None, 300)          0           ['dot_47[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_47[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,286,707\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.9641 - accuracy: 0.2276 - val_loss: 1.6974 - val_accuracy: 0.2686\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.6366 - accuracy: 0.2893 - val_loss: 1.6418 - val_accuracy: 0.3088\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.5382 - accuracy: 0.3047 - val_loss: 1.6461 - val_accuracy: 0.3037\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 3.4578 - accuracy: 0.3189 - val_loss: 1.6250 - val_accuracy: 0.3132\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.4143 - accuracy: 0.3221 - val_loss: 1.5660 - val_accuracy: 0.3451\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3859 - accuracy: 0.3290 - val_loss: 1.6284 - val_accuracy: 0.3149\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3419 - accuracy: 0.3307 - val_loss: 1.5836 - val_accuracy: 0.3076\n",
      "Epoch 8/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 3.3140 - accuracy: 0.3340Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3133 - accuracy: 0.3341 - val_loss: 1.5969 - val_accuracy: 0.3322\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 500, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 150)               45150     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1057      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,286,107\n",
      "Trainable params: 91,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.0317 - accuracy: 0.2105 - val_loss: 1.7494 - val_accuracy: 0.2501\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.7733 - accuracy: 0.2557 - val_loss: 1.7320 - val_accuracy: 0.2663\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.6803 - accuracy: 0.2659 - val_loss: 1.6649 - val_accuracy: 0.3060\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6098 - accuracy: 0.2846 - val_loss: 1.6402 - val_accuracy: 0.3121\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5557 - accuracy: 0.2956 - val_loss: 1.6373 - val_accuracy: 0.3026\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5142 - accuracy: 0.3101 - val_loss: 1.7070 - val_accuracy: 0.2641\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.4662 - accuracy: 0.3117 - val_loss: 1.6084 - val_accuracy: 0.3244\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4406 - accuracy: 0.3119 - val_loss: 1.6469 - val_accuracy: 0.3155\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.4224 - accuracy: 0.3152 - val_loss: 1.6900 - val_accuracy: 0.2781\n",
      "Epoch 10/100\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 3.4026 - accuracy: 0.3255Restoring model weights from the end of the best epoch: 7.\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.4025 - accuracy: 0.3247 - val_loss: 1.6259 - val_accuracy: 0.2993\n",
      "Epoch 10: early stopping\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 500, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 500, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_72 (Reshape)           (None, 1, 500)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 500)       0           ['reshape_72[0][0]']             \n",
      "                                                                                                  \n",
      " dot_48 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_48 (Flatten)           (None, 300)          0           ['dot_48[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 300)          0           ['flatten_48[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_73 (Reshape)           (None, 1, 300)       0           ['concatenate_24[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_73[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_74 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_74[0][0]']             \n",
      "                                                                                                  \n",
      " dot_49 (Dot)                   (None, 300, 1)       0           ['reshape_73[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_49 (Flatten)           (None, 300)          0           ['dot_49[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_49[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,286,707\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 4.0119 - accuracy: 0.2284 - val_loss: 1.7657 - val_accuracy: 0.2317\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.6823 - accuracy: 0.2847 - val_loss: 1.6907 - val_accuracy: 0.2518\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.5568 - accuracy: 0.3029 - val_loss: 1.6320 - val_accuracy: 0.2903\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.4722 - accuracy: 0.3087 - val_loss: 1.6114 - val_accuracy: 0.3177\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.4211 - accuracy: 0.3207 - val_loss: 1.6308 - val_accuracy: 0.3037\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.3972 - accuracy: 0.3213 - val_loss: 1.5898 - val_accuracy: 0.3266\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.3512 - accuracy: 0.3292 - val_loss: 1.6147 - val_accuracy: 0.3127\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3289 - accuracy: 0.3314 - val_loss: 1.5725 - val_accuracy: 0.3400\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.3062 - accuracy: 0.3349 - val_loss: 1.5904 - val_accuracy: 0.3272\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.2951 - accuracy: 0.3375 - val_loss: 1.6153 - val_accuracy: 0.3138\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.2690 - accuracy: 0.3424 - val_loss: 1.5590 - val_accuracy: 0.3456\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.2410 - accuracy: 0.3471 - val_loss: 1.5775 - val_accuracy: 0.3177\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.2224 - accuracy: 0.3503 - val_loss: 1.5713 - val_accuracy: 0.3255\n",
      "Epoch 14/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.2130 - accuracy: 0.3507Restoring model weights from the end of the best epoch: 11.\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.2122 - accuracy: 0.3510 - val_loss: 1.5519 - val_accuracy: 0.3423\n",
      "Epoch 14: early stopping\n",
      "Model: \"model_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 600)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 600, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 150)               45150     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 150)               22650     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 150)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1057      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,286,107\n",
      "Trainable params: 91,507\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.0751 - accuracy: 0.2067 - val_loss: 1.7572 - val_accuracy: 0.2652\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7852 - accuracy: 0.2647 - val_loss: 1.7259 - val_accuracy: 0.2339\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6932 - accuracy: 0.2744 - val_loss: 1.7058 - val_accuracy: 0.2524\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.6379 - accuracy: 0.2818 - val_loss: 1.6606 - val_accuracy: 0.2965\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5827 - accuracy: 0.2916 - val_loss: 1.6627 - val_accuracy: 0.2875\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5337 - accuracy: 0.2964 - val_loss: 1.6543 - val_accuracy: 0.2931\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5117 - accuracy: 0.2983 - val_loss: 1.6117 - val_accuracy: 0.3110\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4809 - accuracy: 0.3073 - val_loss: 1.6507 - val_accuracy: 0.2926\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.4474 - accuracy: 0.3146 - val_loss: 1.5995 - val_accuracy: 0.3194\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4356 - accuracy: 0.3118 - val_loss: 1.6496 - val_accuracy: 0.2920\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4176 - accuracy: 0.3099 - val_loss: 1.6152 - val_accuracy: 0.3009\n",
      "Epoch 12/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.4038 - accuracy: 0.3160Restoring model weights from the end of the best epoch: 9.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4035 - accuracy: 0.3159 - val_loss: 1.5929 - val_accuracy: 0.3183\n",
      "Epoch 12: early stopping\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 600, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_75 (Reshape)           (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_75[0][0]']             \n",
      "                                                                                                  \n",
      " dot_50 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_50 (Flatten)           (None, 300)          0           ['dot_50[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 300)          0           ['flatten_50[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_76 (Reshape)           (None, 1, 300)       0           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_76[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_77 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_77[0][0]']             \n",
      "                                                                                                  \n",
      " dot_51 (Dot)                   (None, 300, 1)       0           ['reshape_76[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_51 (Flatten)           (None, 300)          0           ['dot_51[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_51[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,286,707\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 4.0365 - accuracy: 0.2188 - val_loss: 1.7463 - val_accuracy: 0.2725\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.7082 - accuracy: 0.2708 - val_loss: 1.6732 - val_accuracy: 0.2864\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.6190 - accuracy: 0.2852 - val_loss: 1.6591 - val_accuracy: 0.2820\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.5632 - accuracy: 0.2940 - val_loss: 1.6879 - val_accuracy: 0.2764\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.4885 - accuracy: 0.3108 - val_loss: 1.6534 - val_accuracy: 0.2887\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.4541 - accuracy: 0.3183 - val_loss: 1.5777 - val_accuracy: 0.3596\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.4133 - accuracy: 0.3256 - val_loss: 1.6074 - val_accuracy: 0.3205\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3817 - accuracy: 0.3261 - val_loss: 1.6003 - val_accuracy: 0.3076\n",
      "Epoch 9/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.3454 - accuracy: 0.3334Restoring model weights from the end of the best epoch: 6.\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3456 - accuracy: 0.3336 - val_loss: 1.6934 - val_accuracy: 0.2881\n",
      "Epoch 9: early stopping\n",
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 200, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1407      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,336,607\n",
      "Trainable params: 142,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.9648 - accuracy: 0.2348 - val_loss: 1.7034 - val_accuracy: 0.2993\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.6862 - accuracy: 0.2743 - val_loss: 1.7359 - val_accuracy: 0.2529\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5711 - accuracy: 0.2952 - val_loss: 1.6817 - val_accuracy: 0.2820\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5192 - accuracy: 0.3045 - val_loss: 1.6389 - val_accuracy: 0.3127\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4743 - accuracy: 0.3129 - val_loss: 1.6011 - val_accuracy: 0.3317\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4414 - accuracy: 0.3215 - val_loss: 1.6110 - val_accuracy: 0.3099\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4193 - accuracy: 0.3199 - val_loss: 1.6507 - val_accuracy: 0.2875\n",
      "Epoch 8/100\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 3.3913 - accuracy: 0.3256Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3931 - accuracy: 0.3252 - val_loss: 1.5989 - val_accuracy: 0.3127\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 200, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 200, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_78 (Reshape)           (None, 1, 200)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 200)       0           ['reshape_78[0][0]']             \n",
      "                                                                                                  \n",
      " dot_52 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_52 (Flatten)           (None, 300)          0           ['dot_52[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 300)          0           ['flatten_52[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_79 (Reshape)           (None, 1, 300)       0           ['concatenate_26[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_79[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_80 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_80[0][0]']             \n",
      "                                                                                                  \n",
      " dot_53 (Dot)                   (None, 300, 1)       0           ['reshape_79[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_53 (Flatten)           (None, 300)          0           ['dot_53[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 200)          60200       ['flatten_53[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 200)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 200)          40200       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 200)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 200)          40200       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 200)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1407        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,337,207\n",
      "Trainable params: 142,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.9235 - accuracy: 0.2427 - val_loss: 1.7030 - val_accuracy: 0.2658\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.6174 - accuracy: 0.2900 - val_loss: 1.6645 - val_accuracy: 0.2987\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4961 - accuracy: 0.3095 - val_loss: 1.6144 - val_accuracy: 0.3210\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4398 - accuracy: 0.3182 - val_loss: 1.6578 - val_accuracy: 0.3093\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.3886 - accuracy: 0.3233 - val_loss: 1.5633 - val_accuracy: 0.3384\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3569 - accuracy: 0.3292 - val_loss: 1.5594 - val_accuracy: 0.3445\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3273 - accuracy: 0.3410 - val_loss: 1.6106 - val_accuracy: 0.3205\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.2823 - accuracy: 0.3437 - val_loss: 1.5725 - val_accuracy: 0.3428\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2515 - accuracy: 0.3468 - val_loss: 1.5630 - val_accuracy: 0.3523\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2187 - accuracy: 0.3496 - val_loss: 1.5678 - val_accuracy: 0.3305\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.1962 - accuracy: 0.3534 - val_loss: 1.5868 - val_accuracy: 0.3384\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.1784 - accuracy: 0.3585Restoring model weights from the end of the best epoch: 9.\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.1784 - accuracy: 0.3585 - val_loss: 1.6056 - val_accuracy: 0.3238\n",
      "Epoch 12: early stopping\n",
      "Model: \"model_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 300, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1407      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,336,607\n",
      "Trainable params: 142,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.9266 - accuracy: 0.2431 - val_loss: 1.7178 - val_accuracy: 0.2574\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6811 - accuracy: 0.2811 - val_loss: 1.6602 - val_accuracy: 0.3088\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.5850 - accuracy: 0.2936 - val_loss: 1.6441 - val_accuracy: 0.2993\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5153 - accuracy: 0.3034 - val_loss: 1.6657 - val_accuracy: 0.2993\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4720 - accuracy: 0.3129 - val_loss: 1.6201 - val_accuracy: 0.3171\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4397 - accuracy: 0.3192 - val_loss: 1.6785 - val_accuracy: 0.2870\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4021 - accuracy: 0.3251 - val_loss: 1.6466 - val_accuracy: 0.2998\n",
      "Epoch 8/100\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 3.3831 - accuracy: 0.3243Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3829 - accuracy: 0.3244 - val_loss: 1.6105 - val_accuracy: 0.3110\n",
      "Epoch 8: early stopping\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 300, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_81 (Reshape)           (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_81[0][0]']             \n",
      "                                                                                                  \n",
      " dot_54 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_54 (Flatten)           (None, 300)          0           ['dot_54[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 300)          0           ['flatten_54[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_82 (Reshape)           (None, 1, 300)       0           ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_82[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_83 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_83[0][0]']             \n",
      "                                                                                                  \n",
      " dot_55 (Dot)                   (None, 300, 1)       0           ['reshape_82[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_55 (Flatten)           (None, 300)          0           ['dot_55[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 200)          60200       ['flatten_55[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 200)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 200)          40200       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 200)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 200)          40200       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 200)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1407        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,337,207\n",
      "Trainable params: 142,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.8959 - accuracy: 0.2359 - val_loss: 1.7169 - val_accuracy: 0.2635\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6205 - accuracy: 0.2844 - val_loss: 1.6475 - val_accuracy: 0.2942\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.5259 - accuracy: 0.2992 - val_loss: 1.6677 - val_accuracy: 0.2836\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.4543 - accuracy: 0.3133 - val_loss: 1.5838 - val_accuracy: 0.3266\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.3862 - accuracy: 0.3318 - val_loss: 1.6272 - val_accuracy: 0.2926\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.3552 - accuracy: 0.3253 - val_loss: 1.5931 - val_accuracy: 0.3356\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.3209 - accuracy: 0.3389 - val_loss: 1.5982 - val_accuracy: 0.3439\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.2919 - accuracy: 0.3365 - val_loss: 1.5712 - val_accuracy: 0.3255\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.2649 - accuracy: 0.3475 - val_loss: 1.5802 - val_accuracy: 0.3227\n",
      "Epoch 10/100\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 3.2473 - accuracy: 0.3452Restoring model weights from the end of the best epoch: 7.\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.2474 - accuracy: 0.3452 - val_loss: 1.5844 - val_accuracy: 0.3238\n",
      "Epoch 10: early stopping\n",
      "Model: \"model_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 400, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1407      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,336,607\n",
      "Trainable params: 142,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.9713 - accuracy: 0.2264 - val_loss: 1.7407 - val_accuracy: 0.2513\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.6974 - accuracy: 0.2724 - val_loss: 1.6725 - val_accuracy: 0.2898\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6316 - accuracy: 0.2854 - val_loss: 1.6787 - val_accuracy: 0.2747\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.5476 - accuracy: 0.2985 - val_loss: 1.6365 - val_accuracy: 0.3166\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4991 - accuracy: 0.3085 - val_loss: 1.6268 - val_accuracy: 0.3088\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.4574 - accuracy: 0.3138 - val_loss: 1.6442 - val_accuracy: 0.2948\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.4360 - accuracy: 0.3173 - val_loss: 1.6328 - val_accuracy: 0.3199\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.4017 - accuracy: 0.3174 - val_loss: 1.5991 - val_accuracy: 0.3244\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3894 - accuracy: 0.3221 - val_loss: 1.5930 - val_accuracy: 0.3233\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3605 - accuracy: 0.3265 - val_loss: 1.5963 - val_accuracy: 0.3250\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.3378 - accuracy: 0.3262 - val_loss: 1.6108 - val_accuracy: 0.3199\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3393 - accuracy: 0.3312 - val_loss: 1.6014 - val_accuracy: 0.3300\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3125 - accuracy: 0.3318 - val_loss: 1.5913 - val_accuracy: 0.3317\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.3092 - accuracy: 0.3402 - val_loss: 1.6341 - val_accuracy: 0.2931\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.2804 - accuracy: 0.3381 - val_loss: 1.6295 - val_accuracy: 0.3127\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.2701 - accuracy: 0.3454 - val_loss: 1.5745 - val_accuracy: 0.3406\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.2716 - accuracy: 0.3490 - val_loss: 1.5809 - val_accuracy: 0.3384\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.2640 - accuracy: 0.3509 - val_loss: 1.5886 - val_accuracy: 0.3171\n",
      "Epoch 19/100\n",
      "1711/1719 [============================>.] - ETA: 0s - loss: 3.2299 - accuracy: 0.3479Restoring model weights from the end of the best epoch: 16.\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.2299 - accuracy: 0.3482 - val_loss: 1.6051 - val_accuracy: 0.3277\n",
      "Epoch 19: early stopping\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 400, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 400, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_84 (Reshape)           (None, 1, 400)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 400)       0           ['reshape_84[0][0]']             \n",
      "                                                                                                  \n",
      " dot_56 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_56 (Flatten)           (None, 300)          0           ['dot_56[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 300)          0           ['flatten_56[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_85 (Reshape)           (None, 1, 300)       0           ['concatenate_28[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_85[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_86 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_86[0][0]']             \n",
      "                                                                                                  \n",
      " dot_57 (Dot)                   (None, 300, 1)       0           ['reshape_85[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_57 (Flatten)           (None, 300)          0           ['dot_57[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 200)          60200       ['flatten_57[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 200)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 200)          40200       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 200)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 200)          40200       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 200)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1407        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,337,207\n",
      "Trainable params: 142,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.9314 - accuracy: 0.2364 - val_loss: 1.7085 - val_accuracy: 0.2568\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 3.6395 - accuracy: 0.2818 - val_loss: 1.6549 - val_accuracy: 0.2998\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.5411 - accuracy: 0.3011 - val_loss: 1.6348 - val_accuracy: 0.2982\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.4612 - accuracy: 0.3188 - val_loss: 1.6077 - val_accuracy: 0.3350\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.4052 - accuracy: 0.3263 - val_loss: 1.6158 - val_accuracy: 0.3076\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3707 - accuracy: 0.3266 - val_loss: 1.5963 - val_accuracy: 0.3361\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3359 - accuracy: 0.3352 - val_loss: 1.5820 - val_accuracy: 0.3238\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3132 - accuracy: 0.3387 - val_loss: 1.5968 - val_accuracy: 0.3266\n",
      "Epoch 9/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.3013 - accuracy: 0.3403Restoring model weights from the end of the best epoch: 6.\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.3012 - accuracy: 0.3403 - val_loss: 1.5760 - val_accuracy: 0.3333\n",
      "Epoch 9: early stopping\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 500, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1407      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,336,607\n",
      "Trainable params: 142,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9824 - accuracy: 0.2247 - val_loss: 1.7412 - val_accuracy: 0.2323\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.7171 - accuracy: 0.2663 - val_loss: 1.7244 - val_accuracy: 0.2401\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.6490 - accuracy: 0.2788 - val_loss: 1.6584 - val_accuracy: 0.3205\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5924 - accuracy: 0.2946 - val_loss: 1.6636 - val_accuracy: 0.2915\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.5342 - accuracy: 0.3017 - val_loss: 1.6685 - val_accuracy: 0.2853\n",
      "Epoch 6/100\n",
      "1711/1719 [============================>.] - ETA: 0s - loss: 3.4880 - accuracy: 0.3065Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.4887 - accuracy: 0.3062 - val_loss: 1.6740 - val_accuracy: 0.2730\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 500, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 500, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_87 (Reshape)           (None, 1, 500)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 500)       0           ['reshape_87[0][0]']             \n",
      "                                                                                                  \n",
      " dot_58 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_58 (Flatten)           (None, 300)          0           ['dot_58[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 300)          0           ['flatten_58[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_88 (Reshape)           (None, 1, 300)       0           ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_88[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_89 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_89[0][0]']             \n",
      "                                                                                                  \n",
      " dot_59 (Dot)                   (None, 300, 1)       0           ['reshape_88[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_59 (Flatten)           (None, 300)          0           ['dot_59[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 200)          60200       ['flatten_59[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 200)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 200)          40200       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 200)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 200)          40200       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 200)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1407        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,337,207\n",
      "Trainable params: 142,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 3.9551 - accuracy: 0.2289 - val_loss: 1.7028 - val_accuracy: 0.2926\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.6710 - accuracy: 0.2783 - val_loss: 1.7138 - val_accuracy: 0.2859\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.5401 - accuracy: 0.3090 - val_loss: 1.6500 - val_accuracy: 0.2976\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.4648 - accuracy: 0.3117 - val_loss: 1.6057 - val_accuracy: 0.3110\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.4234 - accuracy: 0.3157 - val_loss: 1.6174 - val_accuracy: 0.3071\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3722 - accuracy: 0.3274 - val_loss: 1.6245 - val_accuracy: 0.3233\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3575 - accuracy: 0.3332 - val_loss: 1.5962 - val_accuracy: 0.3210\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.3113 - accuracy: 0.3398 - val_loss: 1.5858 - val_accuracy: 0.3272\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.2891 - accuracy: 0.3425 - val_loss: 1.5796 - val_accuracy: 0.3289\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.2688 - accuracy: 0.3464 - val_loss: 1.5285 - val_accuracy: 0.3384\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.2530 - accuracy: 0.3515 - val_loss: 1.6313 - val_accuracy: 0.3233\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.2292 - accuracy: 0.3577 - val_loss: 1.5425 - val_accuracy: 0.3451\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 3.2011 - accuracy: 0.3601 - val_loss: 1.5581 - val_accuracy: 0.3456\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.1893 - accuracy: 0.3599 - val_loss: 1.5651 - val_accuracy: 0.3473\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.1748 - accuracy: 0.3587 - val_loss: 1.5648 - val_accuracy: 0.3216\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.1386 - accuracy: 0.3592 - val_loss: 1.5510 - val_accuracy: 0.3490\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.1380 - accuracy: 0.3638 - val_loss: 1.5589 - val_accuracy: 0.3322\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 3.1080 - accuracy: 0.3670 - val_loss: 1.5358 - val_accuracy: 0.3512\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.0995 - accuracy: 0.3691 - val_loss: 1.5247 - val_accuracy: 0.3501\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.0855 - accuracy: 0.3687 - val_loss: 1.5840 - val_accuracy: 0.3322\n",
      "Epoch 21/100\n",
      "1715/1719 [============================>.] - ETA: 0s - loss: 3.0819 - accuracy: 0.3711Restoring model weights from the end of the best epoch: 18.\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.0811 - accuracy: 0.3714 - val_loss: 1.5792 - val_accuracy: 0.3412\n",
      "Epoch 21: early stopping\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 600)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 600, 300)         13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 1407      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,336,607\n",
      "Trainable params: 142,007\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 4.0446 - accuracy: 0.2100 - val_loss: 1.7527 - val_accuracy: 0.2641\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.7597 - accuracy: 0.2630 - val_loss: 1.6875 - val_accuracy: 0.2903\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.6697 - accuracy: 0.2803 - val_loss: 1.6961 - val_accuracy: 0.2686\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.6004 - accuracy: 0.2918 - val_loss: 1.6728 - val_accuracy: 0.3004\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.5462 - accuracy: 0.3022 - val_loss: 1.6320 - val_accuracy: 0.3043\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.4980 - accuracy: 0.3071 - val_loss: 1.6695 - val_accuracy: 0.2875\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.4710 - accuracy: 0.3079 - val_loss: 1.6209 - val_accuracy: 0.2942\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.4448 - accuracy: 0.3178 - val_loss: 1.5943 - val_accuracy: 0.3272\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.4173 - accuracy: 0.3174 - val_loss: 1.6062 - val_accuracy: 0.2970\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.3991 - accuracy: 0.3183 - val_loss: 1.6028 - val_accuracy: 0.3255\n",
      "Epoch 11/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.3860 - accuracy: 0.3306Restoring model weights from the end of the best epoch: 8.\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.3855 - accuracy: 0.3309 - val_loss: 1.5978 - val_accuracy: 0.3138\n",
      "Epoch 11: early stopping\n",
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 600, 300)     13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_90 (Reshape)           (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_90[0][0]']             \n",
      "                                                                                                  \n",
      " dot_60 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_60 (Flatten)           (None, 300)          0           ['dot_60[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 300)          0           ['flatten_60[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_91 (Reshape)           (None, 1, 300)       0           ['concatenate_30[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_91[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_92 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_92[0][0]']             \n",
      "                                                                                                  \n",
      " dot_61 (Dot)                   (None, 300, 1)       0           ['reshape_91[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_61 (Flatten)           (None, 300)          0           ['dot_61[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 200)          60200       ['flatten_61[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 200)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 200)          40200       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 200)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 200)          40200       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 200)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1407        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,337,207\n",
      "Trainable params: 142,607\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 4.0087 - accuracy: 0.2220 - val_loss: 1.6859 - val_accuracy: 0.3037\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 3.6959 - accuracy: 0.2716 - val_loss: 1.6419 - val_accuracy: 0.3322\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 3.5851 - accuracy: 0.2891 - val_loss: 1.6566 - val_accuracy: 0.2982\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 3.5194 - accuracy: 0.3093 - val_loss: 1.6207 - val_accuracy: 0.3255\n",
      "Epoch 5/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.4368 - accuracy: 0.3217Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 3.4360 - accuracy: 0.3216 - val_loss: 1.5961 - val_accuracy: 0.3099\n",
      "Epoch 5: early stopping\n",
      "best dan performance  0.3405918478965759\n",
      "best dan embedding size  200\n",
      "best wan performance  0.35957565903663635\n",
      "best wan embedding size  600\n"
     ]
    }
   ],
   "source": [
    "best_dan_score, best_wan_score  = 0,0\n",
    "best_dan_emb_size, best_wan_emb_size = None, None\n",
    "\n",
    "for hd in hidden_dim_sizes:\n",
    "  for embedding_size in embedding_sizes:\n",
    "      \n",
    "      train_tokens_prebuilt = text_to_index_post_cleaning(df_train['Lyrics'],vocab_dict,embedding_size)\n",
    "      val_tokens_prebuilt = text_to_index_post_cleaning(df_val['Lyrics'],vocab_dict,embedding_size)\n",
    "      \n",
    "      dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix, output_layer_size = 7, max_sequence_length=embedding_size, hidden_dim=[hd,hd,hd])\n",
    "      dan_sorted_history = dan_model_sorted.fit(np.array(train_tokens_prebuilt),\n",
    "                          np.array(train_labels.map(mapping)),\n",
    "                          validation_data=(np.array(val_tokens_prebuilt), np.array(val_labels.map(mapping))),\n",
    "                          batch_size=8,\n",
    "                          epochs=100,\n",
    "                          shuffle=True,\n",
    "                          use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
    "                          callbacks = [es],\n",
    "                          class_weight = class_weights)\n",
    "      \n",
    "      \n",
    "      if max(dan_sorted_history.history['val_accuracy']) > best_dan_score:\n",
    "              best_dan_score = max(dan_sorted_history.history['val_accuracy'])\n",
    "              best_dan_emb_size = embedding_size\n",
    "              \n",
    "      wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix, output_layer_size = 7, max_sequence_length=embedding_size,\n",
    "                                    num_attention=1, hidden_dim=[hd,hd,hd])\n",
    "      wan_sorted_history = wan_model_sorted.fit(np.array(train_tokens_prebuilt),\n",
    "                          np.array(train_labels.map(mapping)),\n",
    "                          validation_data=(np.array(val_tokens_prebuilt), np.array(val_labels.map(mapping))),\n",
    "                          batch_size=8,\n",
    "                          epochs=100,\n",
    "                          shuffle=True,\n",
    "                          use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
    "                          callbacks = [es],\n",
    "                          class_weight = class_weights)\n",
    "      \n",
    "      \n",
    "      if max(wan_sorted_history.history['val_accuracy']) > best_wan_score:\n",
    "              best_wan_score = max(wan_sorted_history.history['val_accuracy'])\n",
    "              best_wan_emb_size = embedding_size\n",
    "\n",
    "print('best dan performance ', best_dan_score)\n",
    "print('best dan embedding size ', best_dan_emb_size)\n",
    "print('best wan performance ', best_wan_score)\n",
    "print('best wan embedding size ', best_wan_emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3B Prebuilt Word Vectors, size experimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMF7vRI6PvDT"
   },
   "source": [
    "# 4 Custom Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilvYcJtMPvDT"
   },
   "source": [
    "Both of those models used prebuilt embeddings, what happens if we use custom ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Gl8E864kPvDT"
   },
   "outputs": [],
   "source": [
    "train['Lyrics_String']=train['Lyrics'].apply(lambda x: \" \".join(x))\n",
    "val['Lyrics_String']=val['Lyrics'].apply(lambda x: \" \".join(x))\n",
    "test['Lyrics_String']=test['Lyrics'].apply(lambda x: \" \".join(x))\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nG4hX9NkPvDU",
    "outputId": "c04abd06-f1e0-49a7-f99f-2a17e58fcaa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        d e e p   d i v e   s l i t h e r i n g   h e ...\n",
       "1        a n d   h o w   d o e s   i t   f e e l   l i ...\n",
       "2        w e l l ,   i   d o n ' t   w a n t   t o   b ...\n",
       "3        i ' m   j u s t   t r y i n g   t o   m a k e ...\n",
       "4        d e c e m b e r   3 1 s t ,   i   g r a b b e ...\n",
       "                               ...                        \n",
       "14831    y e a h   t h a n k   y o u ,   t h a n k   y ...\n",
       "14832    w e   m u s t   p l a y   o u r   l i v e s   ...\n",
       "14833    א ל   ת ח כ י   ל י   ע ו ד   ל י ד   ה ד ל ת ...\n",
       "14834    l e t ' s   d a n c e   l i t t l e   s t r a ...\n",
       "14835    w a t c h   t h a t   c i t y   b y   t h e   ...\n",
       "Name: Lyrics_String, Length: 14821, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Lyrics_String']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train['Lyrics'].iloc[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NktullVSPvDU",
    "outputId": "0fc49fb5-6e71-4f02-a76e-fcaeb50d0b48",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizer.fit(train['Lyrics_String'])\n",
    "vectorizer.fit(train['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fItq1bp4PvDU",
    "outputId": "be86617b-9860-476b-8bd3-4adb329e4cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83372"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYWOv3B4PvDU",
    "outputId": "f30091b7-214e-448c-d942-060e1eabdec3"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_cust = np.random.random((len(vectorizer.get_feature_names()) + 1) * 300).reshape((len(vectorizer.get_feature_names()) + 1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "dK388WVSPvDV"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_cust[-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83373, 300)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix_cust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_e2raEZ2PvDV",
    "outputId": "e6604c37-b9ce-4657-b710-f762367e05f0"
   },
   "outputs": [],
   "source": [
    "mapping_dict = {}\n",
    "i = 0\n",
    "for feature_name in vectorizer.get_feature_names():\n",
    "    mapping_dict[feature_name] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "uWOojmW7PvDV"
   },
   "outputs": [],
   "source": [
    "def get_unique_words(dataset, mapping_dict, seq_size = 1000):\n",
    "    mapped_lyrics = []\n",
    "    for song in dataset:\n",
    "        song_tokens = []\n",
    "        try:\n",
    "          for word in song.split():\n",
    "            try:\n",
    "                song_tokens.append(mapping_dict[word])\n",
    "            except:\n",
    "                song_tokens.append(len(mapping_dict))\n",
    "        except:\n",
    "          print(song)\n",
    "          continue\n",
    "        if len(song_tokens) > seq_size:\n",
    "            song_tokens = song_tokens[:seq_size]\n",
    "        elif len(song_tokens) < seq_size:\n",
    "            while len(song_tokens) < seq_size:\n",
    "                song_tokens.append(len(mapping_dict))\n",
    "                    \n",
    "        mapped_lyrics.append(song_tokens)\n",
    "    return np.array(mapped_lyrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "DecTaok3PvDV"
   },
   "outputs": [],
   "source": [
    "#mapped_lyrics_train = get_unique_words(df_train['Lyrics_String'], mapping_dict, seq_size = 1000)\n",
    "#mapped_lyrics_val = get_unique_words(df_val['Lyrics_String'], mapping_dict, seq_size = 1000)\n",
    "#mapped_lyrics_test = get_unique_words(df_test['Lyrics_String'], mapping_dict, seq_size = 1000)\n",
    "\n",
    "mapped_lyrics_train = get_unique_words(train['Lyrics'], mapping_dict, seq_size = 1000)\n",
    "mapped_lyrics_val = get_unique_words(val['Lyrics'], mapping_dict, seq_size = 1000)\n",
    "mapped_lyrics_test = get_unique_words(test['Lyrics'], mapping_dict, seq_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYCvk137Meq1",
    "outputId": "5870763c-6c53-49b7-81f3-d92223ce1773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14821\n",
      "1301\n",
      "1296\n"
     ]
    }
   ],
   "source": [
    "#mapped_lyrics_train[0]\n",
    "print(len(mapped_lyrics_train))\n",
    "print(len(mapped_lyrics_val))\n",
    "print(len(mapped_lyrics_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5ZHY-9dPvDV",
    "outputId": "812880e3-d129-4102-cab2-27d1ee069cef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Indie': 0,\n",
       " 'Metal': 1,\n",
       " 'Pop': 2,\n",
       " 'Rock': 3,\n",
       " 'Alternative': 4,\n",
       " 'Hip Hop': 5,\n",
       " 'Blues': 6}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWBH_i1QjHy3",
    "outputId": "48c51b42-442f-4065-c7ec-8969e4b61fdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock           4763\n",
       "Indie          2338\n",
       "Pop            2106\n",
       "Metal          1791\n",
       "Hip Hop        1491\n",
       "Alternative    1435\n",
       "Blues           897\n",
       "Name: Major Genre, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "vqFLf2IJPvDW"
   },
   "outputs": [],
   "source": [
    "weights = 4763/train_labels.value_counts()\n",
    "class_weights = {}\n",
    "for num in range(len(weights)):\n",
    "    class_weights[mapping[weights.index[num]]] = weights.iloc[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-GJ7Nr6PvDW",
    "outputId": "8c308513-4052-41bf-b3e0-4bf7e17c34ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 1.0,\n",
       " 0: 2.0372112917023095,\n",
       " 2: 2.261633428300095,\n",
       " 1: 2.6594081518704633,\n",
       " 5: 3.194500335345406,\n",
       " 4: 3.3191637630662023,\n",
       " 6: 5.309921962095875}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdesAc6-PvDW",
    "outputId": "96a2bc90-3ff6-44b1-dd95-15499ccecebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        25011900  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 707       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,062,907\n",
      "Trainable params: 51,007\n",
      "Non-trainable params: 25,011,900\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 21s 10ms/step - loss: 4.2660 - accuracy: 0.1775 - val_loss: 1.8878 - val_accuracy: 0.1111\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 17s 9ms/step - loss: 4.1944 - accuracy: 0.1934 - val_loss: 1.8706 - val_accuracy: 0.1914\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.1721 - accuracy: 0.1943 - val_loss: 1.8622 - val_accuracy: 0.1590\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.1628 - accuracy: 0.1890 - val_loss: 1.8534 - val_accuracy: 0.1836\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.1579 - accuracy: 0.1996 - val_loss: 1.8465 - val_accuracy: 0.2292\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.1403 - accuracy: 0.1986 - val_loss: 1.8403 - val_accuracy: 0.1782\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - 18s 10ms/step - loss: 4.1311 - accuracy: 0.2056 - val_loss: 1.8354 - val_accuracy: 0.1798\n",
      "Epoch 8/30\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.1130 - accuracy: 0.1864 - val_loss: 1.8126 - val_accuracy: 0.2770\n",
      "Epoch 9/30\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.1062 - accuracy: 0.2005 - val_loss: 1.8230 - val_accuracy: 0.1944\n",
      "Epoch 10/30\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.1081 - accuracy: 0.1926 - val_loss: 1.7986 - val_accuracy: 0.2562\n",
      "Epoch 11/30\n",
      "1851/1853 [============================>.] - ETA: 0s - loss: 4.0911 - accuracy: 0.2041Restoring model weights from the end of the best epoch: 8.\n",
      "1853/1853 [==============================] - 16s 9ms/step - loss: 4.0910 - accuracy: 0.2041 - val_loss: 1.8043 - val_accuracy: 0.1991\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix_cust, output_layer_size = 7)\n",
    "dan_sorted_history = dan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(mapped_lyrics_test), np.array(test_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=30,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 2,\n",
    "                        callbacks = [es],\n",
    "                        class_weight = class_weights                  \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMJiN9esPvDW",
    "outputId": "a219f9f3-a521-49b2-ea49-40e57cdfc554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 1000, 300)    25011900    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 1000)      0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 1000)      0           ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 300)          0           ['dot_2[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 300)          0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 300)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                    (None, 300, 1)       0           ['reshape_4[0][0]',              \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 300)          0           ['dot_3[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,104,007\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 25,011,900\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1853/1853 [==============================] - 35s 18ms/step - loss: 4.2673 - accuracy: 0.1799 - val_loss: 1.8664 - val_accuracy: 0.1659\n",
      "Epoch 2/100\n",
      "1853/1853 [==============================] - 34s 18ms/step - loss: 4.1769 - accuracy: 0.1988 - val_loss: 1.8236 - val_accuracy: 0.3009\n",
      "Epoch 3/100\n",
      "1853/1853 [==============================] - 39s 21ms/step - loss: 4.1188 - accuracy: 0.2030 - val_loss: 1.7965 - val_accuracy: 0.3241\n",
      "Epoch 4/100\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 4.0912 - accuracy: 0.2074 - val_loss: 1.8177 - val_accuracy: 0.1906\n",
      "Epoch 5/100\n",
      "1853/1853 [==============================] - 36s 19ms/step - loss: 4.0735 - accuracy: 0.2019 - val_loss: 1.7885 - val_accuracy: 0.2971\n",
      "Epoch 6/100\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 4.0290 - accuracy: 0.2156 - val_loss: 1.7777 - val_accuracy: 0.2955\n",
      "Epoch 7/100\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 3.9937 - accuracy: 0.2192 - val_loss: 1.8355 - val_accuracy: 0.2315\n",
      "Epoch 8/100\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 3.9937 - accuracy: 0.2104 - val_loss: 1.8404 - val_accuracy: 0.1535\n",
      "Epoch 9/100\n",
      "1853/1853 [==============================] - 43s 23ms/step - loss: 3.9655 - accuracy: 0.2156 - val_loss: 1.7736 - val_accuracy: 0.2145\n",
      "Epoch 10/100\n",
      "1853/1853 [==============================] - 41s 22ms/step - loss: 3.9517 - accuracy: 0.2106 - val_loss: 1.7471 - val_accuracy: 0.2546\n",
      "Epoch 11/100\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 3.9226 - accuracy: 0.2163 - val_loss: 1.7850 - val_accuracy: 0.1852\n",
      "Epoch 12/100\n",
      "1853/1853 [==============================] - 37s 20ms/step - loss: 3.9279 - accuracy: 0.2076 - val_loss: 1.7791 - val_accuracy: 0.2076\n",
      "Epoch 13/100\n",
      " 142/1853 [=>............................] - ETA: 34s - loss: 3.8599 - accuracy: 0.2113"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-097e435e1e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix_cust, output_layer_size = 7,\n\u001b[1;32m      2\u001b[0m                                    num_attention=1, hidden_dim = [150,150,150])\n\u001b[0;32m----> 3\u001b[0;31m wan_sorted_history = wan_model_sorted.fit(np.array(mapped_lyrics_train),\n\u001b[0m\u001b[1;32m      4\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_lyrics_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix_cust, output_layer_size = 7,\n",
    "                                   num_attention=1, hidden_dim = [150,150,150])\n",
    "wan_sorted_history = wan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(mapped_lyrics_test), np.array(test_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=100,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
    "                        #callbacks = [es],\n",
    "                        class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOsYoA7_PvDW"
   },
   "source": [
    "best result .29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiwLWj6TPvDX"
   },
   "source": [
    "lets experiment with embedding size and see if we find anything interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrt9vYEbPvDX",
    "outputId": "0aa7cacb-127e-4be9-bc3d-49b113066d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 100, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.3006 - accuracy: 0.1241 - val_loss: 1.9446 - val_accuracy: 0.1173\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.2966 - accuracy: 0.1627 - val_loss: 1.9431 - val_accuracy: 0.1044\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.2968 - accuracy: 0.1242 - val_loss: 1.9432 - val_accuracy: 0.1044\n",
      "Epoch 4/100\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 4.2949 - accuracy: 0.1117Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.2981 - accuracy: 0.1119 - val_loss: 1.9402 - val_accuracy: 0.1039\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_68\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 100, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 100, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_96 (Reshape)           (None, 1, 100)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 100)       0           ['reshape_96[0][0]']             \n",
      "                                                                                                  \n",
      " dot_64 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_64 (Flatten)           (None, 300)          0           ['dot_64[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 300)          0           ['flatten_64[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_97 (Reshape)           (None, 1, 300)       0           ['concatenate_32[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_97[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_98 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_98[0][0]']             \n",
      "                                                                                                  \n",
      " dot_65 (Dot)                   (None, 300, 1)       0           ['reshape_97[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_65 (Flatten)           (None, 300)          0           ['dot_65[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_65[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.2911 - accuracy: 0.1411 - val_loss: 1.9345 - val_accuracy: 0.1128\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.2483 - accuracy: 0.1477 - val_loss: 1.9684 - val_accuracy: 0.0905\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.2373 - accuracy: 0.1392 - val_loss: 1.9237 - val_accuracy: 0.1468\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 4.2339 - accuracy: 0.1470 - val_loss: 1.9348 - val_accuracy: 0.1396\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 4.2245 - accuracy: 0.1404 - val_loss: 1.9326 - val_accuracy: 0.1106\n",
      "Epoch 6/100\n",
      "1712/1719 [============================>.] - ETA: 0s - loss: 4.2318 - accuracy: 0.1330Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.2312 - accuracy: 0.1331 - val_loss: 1.9299 - val_accuracy: 0.1468\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 200, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.2336 - accuracy: 0.1647 - val_loss: 1.9255 - val_accuracy: 0.0949\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.1589 - accuracy: 0.1692 - val_loss: 1.9494 - val_accuracy: 0.0782\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.1192 - accuracy: 0.1613 - val_loss: 1.9523 - val_accuracy: 0.0932\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.1127 - accuracy: 0.1629 - val_loss: 1.8648 - val_accuracy: 0.1513\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.1057 - accuracy: 0.1662 - val_loss: 1.9703 - val_accuracy: 0.0865\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.1025 - accuracy: 0.1580 - val_loss: 2.0360 - val_accuracy: 0.0804\n",
      "Epoch 7/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 4.0987 - accuracy: 0.1694Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.0984 - accuracy: 0.1696 - val_loss: 1.9729 - val_accuracy: 0.1357\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_70\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 200)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 200, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 200, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_99 (Reshape)           (None, 1, 200)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 200)       0           ['reshape_99[0][0]']             \n",
      "                                                                                                  \n",
      " dot_66 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_66 (Flatten)           (None, 300)          0           ['dot_66[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 300)          0           ['flatten_66[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_100 (Reshape)          (None, 1, 300)       0           ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_100[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_101 (Reshape)          (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_101[0][0]']            \n",
      "                                                                                                  \n",
      " dot_67 (Dot)                   (None, 300, 1)       0           ['reshape_100[0][0]',            \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_67 (Flatten)           (None, 300)          0           ['dot_67[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_67[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 4.0736 - accuracy: 0.1923 - val_loss: 1.8369 - val_accuracy: 0.2133\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 4.0449 - accuracy: 0.1954 - val_loss: 1.8852 - val_accuracy: 0.1195\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 4.0263 - accuracy: 0.1955 - val_loss: 1.8526 - val_accuracy: 0.1977\n",
      "Epoch 4/100\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 3.9960 - accuracy: 0.1963Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.9960 - accuracy: 0.1963 - val_loss: 1.8798 - val_accuracy: 0.1418\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 300)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 300, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.1674 - accuracy: 0.1779 - val_loss: 1.8241 - val_accuracy: 0.2116\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.0520 - accuracy: 0.2157 - val_loss: 1.8752 - val_accuracy: 0.1295\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.0192 - accuracy: 0.1922 - val_loss: 1.8457 - val_accuracy: 0.1614\n",
      "Epoch 4/100\n",
      "1711/1719 [============================>.] - ETA: 0s - loss: 4.0079 - accuracy: 0.1880Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 4.0087 - accuracy: 0.1885 - val_loss: 1.8673 - val_accuracy: 0.1904\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_72\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 300, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_102 (Reshape)          (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_102[0][0]']            \n",
      "                                                                                                  \n",
      " dot_68 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_68 (Flatten)           (None, 300)          0           ['dot_68[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 300)          0           ['flatten_68[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_103 (Reshape)          (None, 1, 300)       0           ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_103[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_104 (Reshape)          (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_104[0][0]']            \n",
      "                                                                                                  \n",
      " dot_69 (Dot)                   (None, 300, 1)       0           ['reshape_103[0][0]',            \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_69 (Flatten)           (None, 300)          0           ['dot_69[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_69[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 5ms/step - loss: 4.0456 - accuracy: 0.2046 - val_loss: 1.8325 - val_accuracy: 0.2060\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9814 - accuracy: 0.2196 - val_loss: 1.8060 - val_accuracy: 0.2803\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.9576 - accuracy: 0.2278 - val_loss: 1.8606 - val_accuracy: 0.1446\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.9569 - accuracy: 0.2258 - val_loss: 1.8226 - val_accuracy: 0.2395\n",
      "Epoch 5/100\n",
      "1711/1719 [============================>.] - ETA: 0s - loss: 3.9269 - accuracy: 0.2233Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9306 - accuracy: 0.2233 - val_loss: 1.7988 - val_accuracy: 0.2133\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 400)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 400, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.1035 - accuracy: 0.2019 - val_loss: 1.8761 - val_accuracy: 0.1859\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.9979 - accuracy: 0.2235 - val_loss: 1.8725 - val_accuracy: 0.1999\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.9877 - accuracy: 0.2154 - val_loss: 1.8166 - val_accuracy: 0.2250\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.9798 - accuracy: 0.2110 - val_loss: 1.8368 - val_accuracy: 0.2284\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.9674 - accuracy: 0.2184 - val_loss: 1.8569 - val_accuracy: 0.2155\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.9582 - accuracy: 0.2157 - val_loss: 1.8316 - val_accuracy: 0.1982\n",
      "Epoch 7/100\n",
      "1706/1719 [============================>.] - ETA: 0s - loss: 3.9498 - accuracy: 0.2092Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.9511 - accuracy: 0.2090 - val_loss: 1.8138 - val_accuracy: 0.2111\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_74\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 400)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 400, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 400, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_105 (Reshape)          (None, 1, 400)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 400)       0           ['reshape_105[0][0]']            \n",
      "                                                                                                  \n",
      " dot_70 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_70 (Flatten)           (None, 300)          0           ['dot_70[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 300)          0           ['flatten_70[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_106 (Reshape)          (None, 1, 300)       0           ['concatenate_35[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_106[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_107 (Reshape)          (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_107[0][0]']            \n",
      "                                                                                                  \n",
      " dot_71 (Dot)                   (None, 300, 1)       0           ['reshape_106[0][0]',            \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_71 (Flatten)           (None, 300)          0           ['dot_71[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_71[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 4.0632 - accuracy: 0.2022 - val_loss: 1.8250 - val_accuracy: 0.2334\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 4.0019 - accuracy: 0.2076 - val_loss: 1.8710 - val_accuracy: 0.1256\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 3.9777 - accuracy: 0.2161 - val_loss: 1.8069 - val_accuracy: 0.1859\n",
      "Epoch 4/100\n",
      "1718/1719 [============================>.] - ETA: 0s - loss: 3.9642 - accuracy: 0.2148Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9639 - accuracy: 0.2148 - val_loss: 1.8011 - val_accuracy: 0.2250\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 500, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.1190 - accuracy: 0.2022 - val_loss: 1.8504 - val_accuracy: 0.1815\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0122 - accuracy: 0.2118 - val_loss: 1.8675 - val_accuracy: 0.1541\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 4.0049 - accuracy: 0.2124 - val_loss: 1.8648 - val_accuracy: 0.1530\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 3.9951 - accuracy: 0.2034 - val_loss: 1.8908 - val_accuracy: 0.1898\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9885 - accuracy: 0.2124 - val_loss: 1.8382 - val_accuracy: 0.1993\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9852 - accuracy: 0.2122 - val_loss: 1.8507 - val_accuracy: 0.1831\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.9773 - accuracy: 0.2083 - val_loss: 1.8224 - val_accuracy: 0.1943\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.9666 - accuracy: 0.2125 - val_loss: 1.8394 - val_accuracy: 0.2334\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.9645 - accuracy: 0.2161 - val_loss: 1.8117 - val_accuracy: 0.2111\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9616 - accuracy: 0.2134 - val_loss: 1.8425 - val_accuracy: 0.1904\n",
      "Epoch 11/100\n",
      "1710/1719 [============================>.] - ETA: 0s - loss: 3.9688 - accuracy: 0.2107Restoring model weights from the end of the best epoch: 8.\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9682 - accuracy: 0.2107 - val_loss: 1.8361 - val_accuracy: 0.1725\n",
      "Epoch 11: early stopping\n",
      "Model: \"model_76\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 500, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 500, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_108 (Reshape)          (None, 1, 500)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 500)       0           ['reshape_108[0][0]']            \n",
      "                                                                                                  \n",
      " dot_72 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_72 (Flatten)           (None, 300)          0           ['dot_72[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, 300)          0           ['flatten_72[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_109 (Reshape)          (None, 1, 300)       0           ['concatenate_36[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_109[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_110 (Reshape)          (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_110[0][0]']            \n",
      "                                                                                                  \n",
      " dot_73 (Dot)                   (None, 300, 1)       0           ['reshape_109[0][0]',            \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_73 (Flatten)           (None, 300)          0           ['dot_73[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_73[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 4.0933 - accuracy: 0.1910 - val_loss: 1.8466 - val_accuracy: 0.1876\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 4.0051 - accuracy: 0.1996 - val_loss: 1.8239 - val_accuracy: 0.1820\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 3.9757 - accuracy: 0.2145 - val_loss: 1.7824 - val_accuracy: 0.2808\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.9558 - accuracy: 0.2144 - val_loss: 1.8307 - val_accuracy: 0.2049\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 3.9297 - accuracy: 0.2149 - val_loss: 1.8196 - val_accuracy: 0.2284\n",
      "Epoch 6/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.9245 - accuracy: 0.2196Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.9251 - accuracy: 0.2195 - val_loss: 1.7934 - val_accuracy: 0.1982\n",
      "Epoch 6: early stopping\n",
      "Model: \"model_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 600)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 600, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.1197 - accuracy: 0.1942 - val_loss: 1.8596 - val_accuracy: 0.1491\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.0186 - accuracy: 0.1996 - val_loss: 1.8477 - val_accuracy: 0.1508\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9962 - accuracy: 0.2081 - val_loss: 1.8351 - val_accuracy: 0.1748\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9944 - accuracy: 0.2058 - val_loss: 1.8201 - val_accuracy: 0.1787\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.9744 - accuracy: 0.2079 - val_loss: 1.8180 - val_accuracy: 0.2116\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9580 - accuracy: 0.2217 - val_loss: 1.8286 - val_accuracy: 0.1770\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9740 - accuracy: 0.2027 - val_loss: 1.8150 - val_accuracy: 0.2317\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9614 - accuracy: 0.2156 - val_loss: 1.8169 - val_accuracy: 0.2451\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9552 - accuracy: 0.2231 - val_loss: 1.8699 - val_accuracy: 0.1580\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9459 - accuracy: 0.2163 - val_loss: 1.7942 - val_accuracy: 0.2635\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9470 - accuracy: 0.2279 - val_loss: 1.8409 - val_accuracy: 0.1993\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9424 - accuracy: 0.2119 - val_loss: 1.7943 - val_accuracy: 0.2379\n",
      "Epoch 13/100\n",
      "1704/1719 [============================>.] - ETA: 0s - loss: 3.9395 - accuracy: 0.2259Restoring model weights from the end of the best epoch: 10.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9373 - accuracy: 0.2256 - val_loss: 1.8307 - val_accuracy: 0.1904\n",
      "Epoch 13: early stopping\n",
      "Model: \"model_78\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 600)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 600, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_111 (Reshape)          (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_111[0][0]']            \n",
      "                                                                                                  \n",
      " dot_74 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_74 (Flatten)           (None, 300)          0           ['dot_74[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, 300)          0           ['flatten_74[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_112 (Reshape)          (None, 1, 300)       0           ['concatenate_37[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_112[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_113 (Reshape)          (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_113[0][0]']            \n",
      "                                                                                                  \n",
      " dot_75 (Dot)                   (None, 300, 1)       0           ['reshape_112[0][0]',            \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_75 (Flatten)           (None, 300)          0           ['dot_75[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_75[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 15s 8ms/step - loss: 4.0969 - accuracy: 0.2006 - val_loss: 1.8365 - val_accuracy: 0.2501\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 4.0210 - accuracy: 0.2041 - val_loss: 1.7869 - val_accuracy: 0.2077\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 3.9812 - accuracy: 0.2134 - val_loss: 1.8083 - val_accuracy: 0.1982\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.9663 - accuracy: 0.2075 - val_loss: 1.7941 - val_accuracy: 0.2524\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.9346 - accuracy: 0.2176 - val_loss: 1.7871 - val_accuracy: 0.2362\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.9257 - accuracy: 0.2135 - val_loss: 1.8247 - val_accuracy: 0.2379\n",
      "Epoch 7/100\n",
      "1714/1719 [============================>.] - ETA: 0s - loss: 3.9236 - accuracy: 0.2154Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 14s 8ms/step - loss: 3.9229 - accuracy: 0.2152 - val_loss: 1.7974 - val_accuracy: 0.2066\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 700)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 700, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 4.1221 - accuracy: 0.1966 - val_loss: 1.8574 - val_accuracy: 0.2166\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.0131 - accuracy: 0.2006 - val_loss: 1.8355 - val_accuracy: 0.2540\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9902 - accuracy: 0.2100 - val_loss: 1.8533 - val_accuracy: 0.2021\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9765 - accuracy: 0.2182 - val_loss: 1.8161 - val_accuracy: 0.2540\n",
      "Epoch 5/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.9658 - accuracy: 0.2185Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.9658 - accuracy: 0.2183 - val_loss: 1.8438 - val_accuracy: 0.2083\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_80\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 700)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 700, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 700, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_114 (Reshape)          (None, 1, 700)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 700)       0           ['reshape_114[0][0]']            \n",
      "                                                                                                  \n",
      " dot_76 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_76 (Flatten)           (None, 300)          0           ['dot_76[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, 300)          0           ['flatten_76[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_115 (Reshape)          (None, 1, 300)       0           ['concatenate_38[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_115[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_116 (Reshape)          (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_116[0][0]']            \n",
      "                                                                                                  \n",
      " dot_77 (Dot)                   (None, 300, 1)       0           ['reshape_115[0][0]',            \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_77 (Flatten)           (None, 300)          0           ['dot_77[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_77[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 4.0940 - accuracy: 0.1823 - val_loss: 1.8313 - val_accuracy: 0.2060\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 4.0175 - accuracy: 0.1987 - val_loss: 1.8188 - val_accuracy: 0.2401\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 3.9848 - accuracy: 0.2054 - val_loss: 1.8112 - val_accuracy: 0.2004\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9580 - accuracy: 0.2070 - val_loss: 1.7891 - val_accuracy: 0.3037\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 3.9364 - accuracy: 0.2062 - val_loss: 1.8279 - val_accuracy: 0.1642\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 3.9049 - accuracy: 0.2204 - val_loss: 1.7822 - val_accuracy: 0.2049\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 3.8860 - accuracy: 0.2158Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 3.8860 - accuracy: 0.2158 - val_loss: 1.7958 - val_accuracy: 0.2183\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 800)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 800, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 4.1068 - accuracy: 0.1843 - val_loss: 1.8629 - val_accuracy: 0.1619\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 4.0072 - accuracy: 0.2036 - val_loss: 1.8625 - val_accuracy: 0.1882\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9981 - accuracy: 0.2041 - val_loss: 1.8473 - val_accuracy: 0.1882\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9845 - accuracy: 0.2062 - val_loss: 1.8022 - val_accuracy: 0.2630\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.9700 - accuracy: 0.2300 - val_loss: 1.8364 - val_accuracy: 0.1965\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 3.9723 - accuracy: 0.2235 - val_loss: 1.8290 - val_accuracy: 0.2306\n",
      "Epoch 7/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.9615 - accuracy: 0.2221Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9602 - accuracy: 0.2223 - val_loss: 1.7933 - val_accuracy: 0.2501\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 800)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 800, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 800, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_117 (Reshape)          (None, 1, 800)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 800)       0           ['reshape_117[0][0]']            \n",
      "                                                                                                  \n",
      " dot_78 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_78 (Flatten)           (None, 300)          0           ['dot_78[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, 300)          0           ['flatten_78[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_118 (Reshape)          (None, 1, 300)       0           ['concatenate_39[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_118[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_119 (Reshape)          (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_119[0][0]']            \n",
      "                                                                                                  \n",
      " dot_79 (Dot)                   (None, 300, 1)       0           ['reshape_118[0][0]',            \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_79 (Flatten)           (None, 300)          0           ['dot_79[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_79[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 19s 10ms/step - loss: 4.1136 - accuracy: 0.1838 - val_loss: 1.8796 - val_accuracy: 0.1898\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 4.0000 - accuracy: 0.2036 - val_loss: 1.8187 - val_accuracy: 0.1859\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9759 - accuracy: 0.2062 - val_loss: 1.8102 - val_accuracy: 0.1815\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9510 - accuracy: 0.2111 - val_loss: 1.8001 - val_accuracy: 0.2468\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9368 - accuracy: 0.2219 - val_loss: 1.8089 - val_accuracy: 0.2071\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 3.9197 - accuracy: 0.2132 - val_loss: 1.8557 - val_accuracy: 0.1401\n",
      "Epoch 7/100\n",
      "1715/1719 [============================>.] - ETA: 0s - loss: 3.9061 - accuracy: 0.2173Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9046 - accuracy: 0.2172 - val_loss: 1.7837 - val_accuracy: 0.2356\n",
      "Epoch 7: early stopping\n",
      "Model: \"model_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 900)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 900, 300)         30549300  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                22575     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,583,807\n",
      "Trainable params: 34,507\n",
      "Non-trainable params: 30,549,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.0957 - accuracy: 0.1886 - val_loss: 1.8554 - val_accuracy: 0.1714\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.0110 - accuracy: 0.2101 - val_loss: 1.8513 - val_accuracy: 0.1882\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9880 - accuracy: 0.2104 - val_loss: 1.8639 - val_accuracy: 0.1552\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 3.9766 - accuracy: 0.2105 - val_loss: 1.8481 - val_accuracy: 0.1653\n",
      "Epoch 5/100\n",
      "1707/1719 [============================>.] - ETA: 0s - loss: 3.9735 - accuracy: 0.2031Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9732 - accuracy: 0.2028 - val_loss: 1.8443 - val_accuracy: 0.1776\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_84\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 900)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 900, 300)     30549300    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 900, 1)       300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_120 (Reshape)          (None, 1, 900)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 900)       0           ['reshape_120[0][0]']            \n",
      "                                                                                                  \n",
      " dot_80 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_80 (Flatten)           (None, 300)          0           ['dot_80[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenate)   (None, 300)          0           ['flatten_80[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_121 (Reshape)          (None, 1, 300)       0           ['concatenate_40[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_121[0][0]']            \n",
      "                                                                                                  \n",
      " reshape_122 (Reshape)          (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_122[0][0]']            \n",
      "                                                                                                  \n",
      " dot_81 (Dot)                   (None, 300, 1)       0           ['reshape_121[0][0]',            \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_81 (Flatten)           (None, 300)          0           ['dot_81[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          45150       ['flatten_81[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,641,407\n",
      "Trainable params: 92,107\n",
      "Non-trainable params: 30,549,300\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 4.0901 - accuracy: 0.1960 - val_loss: 1.8462 - val_accuracy: 0.1837\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9909 - accuracy: 0.2071 - val_loss: 1.8105 - val_accuracy: 0.2373\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 3.9571 - accuracy: 0.2182 - val_loss: 1.9580 - val_accuracy: 0.1803\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9544 - accuracy: 0.2136 - val_loss: 1.7807 - val_accuracy: 0.2390\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9318 - accuracy: 0.2228 - val_loss: 1.8172 - val_accuracy: 0.1792\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.9172 - accuracy: 0.2141 - val_loss: 1.7930 - val_accuracy: 0.2183\n",
      "Epoch 7/100\n",
      "1717/1719 [============================>.] - ETA: 0s - loss: 3.8892 - accuracy: 0.2225Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 3.8892 - accuracy: 0.2223 - val_loss: 1.7976 - val_accuracy: 0.2094\n",
      "Epoch 7: early stopping\n",
      "best dan performance  0.2635399103164673\n",
      "best dan embedding size  600\n",
      "best wan performance  0.303740918636322\n",
      "best wan embedding size  700\n"
     ]
    }
   ],
   "source": [
    "best_dan_score, best_wan_score  = 0,0\n",
    "best_dan_emb_size, best_wan_emb_size = None, None\n",
    "embedding_sizes_cust = [100,200,300,400,500,600,700,800,900]\n",
    "\n",
    "for embedding_size in embedding_sizes_cust:\n",
    "    \n",
    "    mapped_lyrics_train = get_unique_words(df_train['Lyrics_String'], mapping_dict, seq_size = embedding_size)\n",
    "    mapped_lyrics_val = get_unique_words(df_val['Lyrics_String'], mapping_dict, seq_size = embedding_size)\n",
    "    \n",
    "    dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix_cust, output_layer_size = 7, max_sequence_length=embedding_size, hidden_dim=[75,75,75])\n",
    "    dan_sorted_history = dan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(mapped_lyrics_val), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=100,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 2,\n",
    "                        callbacks = [es],\n",
    "                        class_weight = class_weights)\n",
    "    \n",
    "    \n",
    "    if max(dan_sorted_history.history['val_accuracy']) > best_dan_score:\n",
    "            best_dan_score = max(dan_sorted_history.history['val_accuracy'])\n",
    "            best_dan_emb_size = embedding_size\n",
    "            \n",
    "    wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix_cust, output_layer_size = 7, max_sequence_length=embedding_size, hidden_dim=[150,150,150],\n",
    "                                   num_attention=1)\n",
    "    wan_sorted_history = wan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(mapped_lyrics_val), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=100,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 2,\n",
    "                        callbacks = [es],\n",
    "                        class_weight = class_weights)\n",
    "    \n",
    "    \n",
    "    if max(wan_sorted_history.history['val_accuracy']) > best_wan_score:\n",
    "            best_wan_score = max(wan_sorted_history.history['val_accuracy'])\n",
    "            best_wan_emb_size = embedding_size\n",
    "\n",
    "print('best dan performance ', best_dan_score)\n",
    "print('best dan embedding size ', best_dan_emb_size)\n",
    "print('best wan performance ', best_wan_score)\n",
    "print('best wan embedding size ', best_wan_emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf5yJRSqPvDX"
   },
   "source": [
    "currently:\n",
    "\n",
    "best dan performance  0.2635399103164673\n",
    "best dan embedding size  600\n",
    "best wan performance  0.303740918636322\n",
    "best wan embedding size  700\n",
    "\n",
    "700 probably best size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGZ0QdofPvDX"
   },
   "source": [
    "# 5 Audio Feature DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNroRtuAPvDX"
   },
   "source": [
    "lets look at the audio features we have too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "UGcMWmwKX0Za"
   },
   "outputs": [],
   "source": [
    "# let's create a df that is all of the normalized audio features we want to use\n",
    "#df_train_audio_normalized = df_train[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "#df_train_audio_normalized = (df_train_audio_normalized-df_train_audio_normalized.mean())/df_train_audio_normalized.std()\n",
    "\n",
    "#df_val_audio_normalized = df_val[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "#df_val_audio_normalized = (df_val_audio_normalized-df_val_audio_normalized.mean())/df_val_audio_normalized.std()\n",
    "\n",
    "#df_test_audio_normalized = df_test[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "#df_test_audio_normalized = (df_test_audio_normalized-df_test_audio_normalized.mean())/df_test_audio_normalized.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a df that is all of the normalized audio features we want to use\n",
    "df_train_audio_normalized = train[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "df_train_audio_normalized = (df_train_audio_normalized-df_train_audio_normalized.mean())/df_train_audio_normalized.std()\n",
    "\n",
    "df_val_audio_normalized = val[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "df_val_audio_normalized = (df_val_audio_normalized-df_val_audio_normalized.mean())/df_val_audio_normalized.std()\n",
    "\n",
    "df_test_audio_normalized = test[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
    "df_test_audio_normalized = (df_test_audio_normalized-df_test_audio_normalized.mean())/df_test_audio_normalized.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WgCEAB7VX3NR",
    "outputId": "06bc74b5-d57a-442c-999b-bb1b082ca6ae"
   },
   "outputs": [],
   "source": [
    "#len(df_train_audio_normalized)\n",
    "#len(df_val_audio_normalized)\n",
    "#len(df_test_audio_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rqWtnMQtPvDY",
    "outputId": "23e2222c-3054-49a2-efa5-58245d18ca81",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.073187</td>\n",
       "      <td>0.955241</td>\n",
       "      <td>0.570070</td>\n",
       "      <td>-0.179892</td>\n",
       "      <td>-0.548726</td>\n",
       "      <td>-0.255777</td>\n",
       "      <td>1.646805</td>\n",
       "      <td>0.381884</td>\n",
       "      <td>-0.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.781914</td>\n",
       "      <td>0.793719</td>\n",
       "      <td>1.071145</td>\n",
       "      <td>-0.647344</td>\n",
       "      <td>-0.092345</td>\n",
       "      <td>-0.419146</td>\n",
       "      <td>-0.409744</td>\n",
       "      <td>0.076545</td>\n",
       "      <td>0.092574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.066636</td>\n",
       "      <td>1.151025</td>\n",
       "      <td>1.179788</td>\n",
       "      <td>-0.683648</td>\n",
       "      <td>0.084061</td>\n",
       "      <td>-0.418755</td>\n",
       "      <td>-0.327827</td>\n",
       "      <td>1.473613</td>\n",
       "      <td>0.161564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.652435</td>\n",
       "      <td>-1.638895</td>\n",
       "      <td>-0.726406</td>\n",
       "      <td>-0.031913</td>\n",
       "      <td>0.060161</td>\n",
       "      <td>-0.051744</td>\n",
       "      <td>-1.220292</td>\n",
       "      <td>0.052641</td>\n",
       "      <td>1.579205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.922919</td>\n",
       "      <td>-0.552295</td>\n",
       "      <td>-0.020225</td>\n",
       "      <td>1.663839</td>\n",
       "      <td>1.379225</td>\n",
       "      <td>-0.419170</td>\n",
       "      <td>-0.478727</td>\n",
       "      <td>-1.340843</td>\n",
       "      <td>-0.647679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831</th>\n",
       "      <td>0.832758</td>\n",
       "      <td>0.407046</td>\n",
       "      <td>0.905876</td>\n",
       "      <td>-0.442654</td>\n",
       "      <td>0.912602</td>\n",
       "      <td>-0.419186</td>\n",
       "      <td>1.107877</td>\n",
       "      <td>-0.596040</td>\n",
       "      <td>-0.323360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14832</th>\n",
       "      <td>-0.826206</td>\n",
       "      <td>-0.317354</td>\n",
       "      <td>-1.223531</td>\n",
       "      <td>-0.556237</td>\n",
       "      <td>-0.486130</td>\n",
       "      <td>-0.363956</td>\n",
       "      <td>-0.263156</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>0.487865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14833</th>\n",
       "      <td>0.682489</td>\n",
       "      <td>-1.736787</td>\n",
       "      <td>-0.436691</td>\n",
       "      <td>3.035640</td>\n",
       "      <td>-0.531654</td>\n",
       "      <td>-0.419186</td>\n",
       "      <td>0.577572</td>\n",
       "      <td>0.386009</td>\n",
       "      <td>-1.101218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>-0.122950</td>\n",
       "      <td>1.033554</td>\n",
       "      <td>0.384389</td>\n",
       "      <td>-0.679983</td>\n",
       "      <td>-0.187946</td>\n",
       "      <td>0.758457</td>\n",
       "      <td>1.181171</td>\n",
       "      <td>0.332792</td>\n",
       "      <td>-0.323903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>-0.291251</td>\n",
       "      <td>0.524516</td>\n",
       "      <td>0.371878</td>\n",
       "      <td>-0.682799</td>\n",
       "      <td>-0.456539</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>-0.060519</td>\n",
       "      <td>0.213138</td>\n",
       "      <td>0.007926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14821 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       danceability    energy  loudness  acousticness  speechiness  \\\n",
       "0          1.073187  0.955241  0.570070     -0.179892    -0.548726   \n",
       "1         -1.781914  0.793719  1.071145     -0.647344    -0.092345   \n",
       "2         -1.066636  1.151025  1.179788     -0.683648     0.084061   \n",
       "3          0.652435 -1.638895 -0.726406     -0.031913     0.060161   \n",
       "4          0.922919 -0.552295 -0.020225      1.663839     1.379225   \n",
       "...             ...       ...       ...           ...          ...   \n",
       "14831      0.832758  0.407046  0.905876     -0.442654     0.912602   \n",
       "14832     -0.826206 -0.317354 -1.223531     -0.556237    -0.486130   \n",
       "14833      0.682489 -1.736787 -0.436691      3.035640    -0.531654   \n",
       "14834     -0.122950  1.033554  0.384389     -0.679983    -0.187946   \n",
       "14835     -0.291251  0.524516  0.371878     -0.682799    -0.456539   \n",
       "\n",
       "       instrumentalness   valence     tempo  duration_ms  \n",
       "0             -0.255777  1.646805  0.381884    -0.493200  \n",
       "1             -0.419146 -0.409744  0.076545     0.092574  \n",
       "2             -0.418755 -0.327827  1.473613     0.161564  \n",
       "3             -0.051744 -1.220292  0.052641     1.579205  \n",
       "4             -0.419170 -0.478727 -1.340843    -0.647679  \n",
       "...                 ...       ...       ...          ...  \n",
       "14831         -0.419186  1.107877 -0.596040    -0.323360  \n",
       "14832         -0.363956 -0.263156 -0.007304     0.487865  \n",
       "14833         -0.419186  0.577572  0.386009    -1.101218  \n",
       "14834          0.758457  1.181171  0.332792    -0.323903  \n",
       "14835          0.001661 -0.060519  0.213138     0.007926  \n",
       "\n",
       "[14821 rows x 9 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reminder, what does our data look like?\n",
    "df_train_audio_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzubBPA5PvDY",
    "outputId": "85713893-fabe-40d5-d29b-b5595119ca9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 5s 2ms/step - loss: 3.4414 - accuracy: 0.3662 - val_loss: 1.5544 - val_accuracy: 0.3873\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.3268 - accuracy: 0.3848 - val_loss: 1.5761 - val_accuracy: 0.3889\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.2871 - accuracy: 0.3940 - val_loss: 1.5315 - val_accuracy: 0.4074\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.2493 - accuracy: 0.3967 - val_loss: 1.5937 - val_accuracy: 0.3812\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.2066 - accuracy: 0.3994 - val_loss: 1.5464 - val_accuracy: 0.3765\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1950 - accuracy: 0.4006 - val_loss: 1.5184 - val_accuracy: 0.4120\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - 5s 3ms/step - loss: 3.2039 - accuracy: 0.3994 - val_loss: 1.5346 - val_accuracy: 0.3434\n",
      "Epoch 8/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1652 - accuracy: 0.4038 - val_loss: 1.5291 - val_accuracy: 0.3789\n",
      "Epoch 9/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1573 - accuracy: 0.4060 - val_loss: 1.4940 - val_accuracy: 0.3750\n",
      "Epoch 10/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1549 - accuracy: 0.4094 - val_loss: 1.5277 - val_accuracy: 0.3897\n",
      "Epoch 11/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1428 - accuracy: 0.4085 - val_loss: 1.5296 - val_accuracy: 0.3650\n",
      "Epoch 12/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1434 - accuracy: 0.4129 - val_loss: 1.5508 - val_accuracy: 0.3356\n",
      "Epoch 13/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1295 - accuracy: 0.4060 - val_loss: 1.6003 - val_accuracy: 0.3457\n",
      "Epoch 14/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1382 - accuracy: 0.4052 - val_loss: 1.5400 - val_accuracy: 0.3827\n",
      "Epoch 15/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1398 - accuracy: 0.4057 - val_loss: 1.4545 - val_accuracy: 0.4252\n",
      "Epoch 16/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1257 - accuracy: 0.4085 - val_loss: 1.5503 - val_accuracy: 0.3642\n",
      "Epoch 17/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1119 - accuracy: 0.4135 - val_loss: 1.5189 - val_accuracy: 0.3958\n",
      "Epoch 18/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1131 - accuracy: 0.4090 - val_loss: 1.4982 - val_accuracy: 0.4074\n",
      "Epoch 19/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.1190 - accuracy: 0.4125 - val_loss: 1.5281 - val_accuracy: 0.3935\n",
      "Epoch 20/30\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 3.0903 - accuracy: 0.4155 - val_loss: 1.4950 - val_accuracy: 0.4120\n",
      "Epoch 21/30\n",
      "1853/1853 [==============================] - 5s 3ms/step - loss: 3.0823 - accuracy: 0.4226 - val_loss: 1.5308 - val_accuracy: 0.3881\n",
      "Epoch 22/30\n",
      "1853/1853 [==============================] - 5s 3ms/step - loss: 3.0956 - accuracy: 0.4220 - val_loss: 1.5549 - val_accuracy: 0.3519\n",
      "Epoch 23/30\n",
      "1853/1853 [==============================] - 5s 3ms/step - loss: 3.0989 - accuracy: 0.4164 - val_loss: 1.5169 - val_accuracy: 0.3920\n",
      "Epoch 24/30\n",
      "1853/1853 [==============================] - 6s 3ms/step - loss: 3.0798 - accuracy: 0.4278 - val_loss: 1.5962 - val_accuracy: 0.3688\n",
      "Epoch 25/30\n",
      "1853/1853 [==============================] - 5s 3ms/step - loss: 3.0850 - accuracy: 0.4215 - val_loss: 1.5291 - val_accuracy: 0.4051\n",
      "Epoch 26/30\n",
      "1853/1853 [==============================] - 6s 3ms/step - loss: 3.0814 - accuracy: 0.4301 - val_loss: 1.6092 - val_accuracy: 0.3642\n",
      "Epoch 27/30\n",
      "1853/1853 [==============================] - 6s 3ms/step - loss: 3.0700 - accuracy: 0.4301 - val_loss: 1.5537 - val_accuracy: 0.4252\n",
      "Epoch 28/30\n",
      "1853/1853 [==============================] - 5s 3ms/step - loss: 3.0784 - accuracy: 0.4253 - val_loss: 1.5856 - val_accuracy: 0.4012\n",
      "Epoch 29/30\n",
      "1853/1853 [==============================] - 5s 3ms/step - loss: 3.0802 - accuracy: 0.4329 - val_loss: 1.5085 - val_accuracy: 0.4205\n",
      "Epoch 30/30\n",
      "1853/1853 [==============================] - 5s 2ms/step - loss: 3.0502 - accuracy: 0.4410 - val_loss: 1.5595 - val_accuracy: 0.4074\n"
     ]
    }
   ],
   "source": [
    "# audio features should help too: lets see what results we get from\n",
    "# a standard feed-forward network\n",
    "# note: audio features have been normalized\n",
    "hidden_sizes = [100]\n",
    "best_score, best_hidden_size = 0,0\n",
    "\n",
    "for hs in hidden_sizes:\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Dense(hs,activation='relu'),\n",
    "      keras.layers.Dense(hs,activation='relu'),\n",
    "      keras.layers.Dense(7,activation='softmax')\n",
    "  ])\n",
    "\n",
    "  #Compile the model, specifying loss function, optimizer, and performance metric\n",
    "  model.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "  model_history = model.fit(x = np.array(df_train_audio_normalized),y = train_labels.map(mapping),batch_size=8,epochs=30,\n",
    "          validation_data = (np.array(df_test_audio_normalized), test_labels.map(mapping)),\n",
    "          use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1, class_weight = class_weights)\n",
    "  \n",
    "  if max(model_history.history['val_accuracy']) > best_score:\n",
    "            best_score = max(model_history.history['val_accuracy'])\n",
    "            best_hidden_size = hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNR1b51tZCk9",
    "outputId": "fae1569a-b0e3-4e0d-9f72-c8658a9369d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4379521310329437\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(best_score)\n",
    "print(best_hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lsl5WE8fdO2X"
   },
   "source": [
    "best hidden size 0.42211055755615234\n",
    "best score 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vW7yIErrdAu9"
   },
   "source": [
    "best score = \n",
    "best h size = \n",
    "\n",
    "```\n",
    "`# This is formatted as code`\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "WIvGRlPsPvDY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#predictions = model.predict(np.array(df_test_audio_normalized))\n",
    "#predictions = model.predict([np.array(test_term_df), np.array(df_test_audio_normalized)])\n",
    "predictions = model.predict(np.array(df_test_audio_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "crhZxBHRPvDY"
   },
   "outputs": [],
   "source": [
    "predictions_ = [x.argmax() for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Yc3pRpI2PvDY",
    "outputId": "2aa96df9-763c-49bf-ca81-db9ba9933343"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indie</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Alternative</th>\n",
       "      <th>Hip Hop</th>\n",
       "      <th>Blues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Indie</th>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metal</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>27</td>\n",
       "      <td>152</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hip Hop</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blues</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Indie  Metal  Pop  Rock  Alternative  Hip Hop  Blues\n",
       "Indie           21     23   30    62           49        6     32\n",
       "Metal            1    100    1    27            8        0      0\n",
       "Pop              4      3   99    33           13       25     22\n",
       "Rock             5    104   27   152           38       18     58\n",
       "Alternative      4     21   18    47           18        8     21\n",
       "Hip Hop          3      0   15     3            3       95      5\n",
       "Blues            2      0   13    12            4        0     43"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = sklearn.metrics.confusion_matrix(test_labels.map(mapping), predictions_)\n",
    "conf = pd.DataFrame(conf, index = mapping.keys(), columns = mapping.keys())\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEHE3oFxPvDZ"
   },
   "source": [
    "write up some precision/recall stuff on the final conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8pWPtfJPvDZ"
   },
   "source": [
    "# 6. Lyrics + Audio DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYdqLcc2PvDZ"
   },
   "outputs": [],
   "source": [
    "def create_multimodal_genre_FFN(max_sequence_length = 1000, retrain_embeddings = True, learning_rate = 0.01):\n",
    "    audio_inputs = keras.layers.Input(shape = (8,), dtype = 'float32', name = 'audio_input')\n",
    "    lyric_inputs = keras.layers.Input(shape = (1000,), dtype='int64',name='lyric_input')\n",
    "                                    \n",
    "    ffn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  weights = [embedding_matrix],\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings,\n",
    "                                   name = 'embedding_layer')\n",
    "    \n",
    "    #Input Layer, sequence of max_sequence_length tokens\n",
    "    #ffn_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
    "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
    "    ffn_embeddings = ffn_embedding_layer(lyric_inputs)\n",
    "    ffn_avg_input_embeddings = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(ffn_embeddings)\n",
    "    concat_ffn = tf.keras.layers.Concatenate()([ffn_avg_input_embeddings,audio_inputs])\n",
    "    hidden = keras.layers.Dense(100,activation='relu')(concat_ffn)\n",
    "    classification = keras.layers.Dense(7,activation='softmax')(hidden)\n",
    "    \n",
    "    ffn_model = tf.keras.models.Model(inputs=[audio_inputs,lyric_inputs], outputs=[classification])\n",
    "    ffn_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics='accuracy',\n",
    "                     run_eagerly = True)\n",
    "    \n",
    "    print(ffn_model.summary())\n",
    "\n",
    "    return ffn_model\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200 was our best prebuilt embedding size so lets try it here\n",
    "\n",
    "#train_tokens_prebuilt_new = text_to_index_post_cleaning(df_train['Lyrics'],vocab_dict,200)\n",
    "#val_tokens_prebuilt_new = text_to_index_post_cleaning(df_val['Lyrics'],vocab_dict,200)\n",
    "#test_tokens_prebuilt_new = text_to_index_post_cleaning(df_test['Lyrics'],vocab_dict,200)\n",
    "\n",
    "train_tokens_prebuilt_new = text_to_index_post_cleaning(train['Lyrics'],vocab_dict,200)\n",
    "val_tokens_prebuilt_new = text_to_index_post_cleaning(val['Lyrics'],vocab_dict,200)\n",
    "test_tokens_prebuilt_new = text_to_index_post_cleaning(test['Lyrics'],vocab_dict,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "0s7V_vxQPvDZ"
   },
   "outputs": [],
   "source": [
    "# define two sets of inputs\n",
    "inputA = Input(shape=(200,))\n",
    "inputB = Input(shape=(9,))\n",
    "# the first branch operates on the first input\n",
    "x = Dense(8, activation=\"relu\")(inputA)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(4, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "# apply a FC layer and then a classification prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)\n",
    "z = Dense(7, activation=\"softmax\")(z)\n",
    "#z = Dense(1, activation=\"linear\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "TZK0NSgAPvDZ"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "             metrics='accuracy',\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "zlbT23J8PvDZ",
    "outputId": "81829cd4-2b3e-4d24-bc5c-668274332438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1853/1853 [==============================] - 5s 2ms/step - loss: 6.0094 - accuracy: 0.1434 - val_loss: 1.9388 - val_accuracy: 0.1080\n",
      "Epoch 2/100\n",
      "1853/1853 [==============================] - 4s 2ms/step - loss: 4.3253 - accuracy: 0.1161 - val_loss: 1.9344 - val_accuracy: 0.1103\n",
      "Epoch 3/100\n",
      "1853/1853 [==============================] - 6s 3ms/step - loss: 4.3152 - accuracy: 0.1179 - val_loss: 1.9333 - val_accuracy: 0.1165\n",
      "Epoch 4/100\n",
      "1853/1853 [==============================] - 6s 3ms/step - loss: 4.3055 - accuracy: 0.1202 - val_loss: 1.9280 - val_accuracy: 0.1258\n",
      "Epoch 5/100\n",
      "1853/1853 [==============================] - 5s 3ms/step - loss: 4.2979 - accuracy: 0.1339 - val_loss: 1.9239 - val_accuracy: 0.1204\n",
      "Epoch 6/100\n",
      "1853/1853 [==============================] - 6s 3ms/step - loss: 4.3226 - accuracy: 0.1251 - val_loss: 1.9413 - val_accuracy: 0.0957\n",
      "Epoch 7/100\n",
      "1850/1853 [============================>.] - ETA: 0s - loss: 4.3783 - accuracy: 0.1141Restoring model weights from the end of the best epoch: 4.\n",
      "1853/1853 [==============================] - 6s 3ms/step - loss: 4.3789 - accuracy: 0.1140 - val_loss: 1.9453 - val_accuracy: 0.1057\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feff669e040>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[np.array(train_tokens_prebuilt_new), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_tokens_prebuilt_new), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=100, batch_size=8,\n",
    "             class_weight = class_weights, callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".3634 with emb size 200 val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-569e2ba40ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 600 was best performing emb size in the basic wan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_tokens_prebuilt_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_index_post_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lyrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_tokens_prebuilt_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_index_post_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lyrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_tokens_prebuilt_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_index_post_cleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lyrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 600 was best performing emb size in the basic wan\n",
    "\n",
    "#train_tokens_prebuilt_new = text_to_index_post_cleaning(df_train['Lyrics'],vocab_dict,600)\n",
    "#val_tokens_prebuilt_new = text_to_index_post_cleaning(df_val['Lyrics'],vocab_dict,600)\n",
    "#test_tokens_prebuilt_new = text_to_index_post_cleaning(df_test['Lyrics'],vocab_dict,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_prebuilt_new = text_to_index_post_cleaning(train['Lyrics'],vocab_dict,600)\n",
    "val_tokens_prebuilt_new = text_to_index_post_cleaning(val['Lyrics'],vocab_dict,600)\n",
    "test_tokens_prebuilt_new = text_to_index_post_cleaning(test['Lyrics'],vocab_dict,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "zblDxEY-PvDa"
   },
   "outputs": [],
   "source": [
    "# run this\n",
    "\n",
    "# -------------------------------Model that accepts input and creates embedding matrix-------------------------------\n",
    "#input_layer = tf.keras.layers.Input(shape=(1000,))\n",
    "lyric_input = tf.keras.layers.Input(shape=(600,))\n",
    "audio_input = tf.keras.layers.Input(shape=(9,))\n",
    "#Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length=1000,\n",
    "                            trainable=True,\n",
    "                            name = 'embedding_layer')\n",
    "\n",
    "embeddings = embedding_layer(lyric_input)\n",
    "embedding_model = tf.keras.Model(inputs = [lyric_input],outputs=[embeddings])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------AUDIO FFN MODEL-----------------------------------------------------\n",
    "\n",
    "# AUDIO\n",
    "#audio_layer = Dense(300, activation=\"relu\")(audio_input)\n",
    "# add more layers?\n",
    "audio_model = tf.keras.Model(inputs = [audio_input],outputs=[audio_input])\n",
    "\n",
    "# -----------------------------------------------------WAN Model-----------------------------------------------------\n",
    "# LYRICS\n",
    "#Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(embedding_model.output)\n",
    "#reshape to 1 x num_attention\n",
    "reshaped_query = tf.keras.layers.Reshape((1,600))(query)\n",
    "#Softmax over query * key (words) to obtain weights\n",
    "weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                    name='attention_weights')(reshaped_query)\n",
    "#weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "#from prior layer\n",
    "wan_embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((embedding_model.output,weights)))\n",
    "wan_embedding = tf.keras.Model(inputs=[embedding_model.input],outputs=[wan_embedding])\n",
    "\n",
    "# WAN Model that uses an attention layer with a single node to learn how to combine WAN/DAN embeddings into single representation\n",
    "dual_embedding = tf.keras.layers.concatenate([audio_model.output,wan_embedding.output])\n",
    "#dual_embedding = tf.keras.layers.Reshape((2,embedding_matrix.shape[1]))(dual_embedding)\n",
    "#query = tf.keras.layers.Dense(1,activation='linear',use_bias=False)(dual_embedding)\n",
    "#reshaped_query = tf.keras.layers.Reshape((1,2))(query)\n",
    "#weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x))(reshaped_query)\n",
    "#embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((dual_embedding,weights)))\n",
    "hidden = tf.keras.layers.Dense(100,activation='relu')(dual_embedding)\n",
    "hidden = tf.keras.layers.Dense(100,activation='relu')(hidden)\n",
    "output = tf.keras.layers.Dense(7,activation='softmax')(hidden)\n",
    "final_model = tf.keras.Model(inputs=[audio_model.input, embedding_model.input],outputs=[output])\n",
    "\n",
    "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                            metrics='accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "6bz8qbetPvDa",
    "outputId": "84036026-5956-4efd-f4f3-d8343cbf75b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 326s 172ms/step - loss: 3.2117 - accuracy: 0.3939 - val_loss: 1.4412 - val_accuracy: 0.4120\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 351s 189ms/step - loss: 3.0254 - accuracy: 0.4183 - val_loss: 1.4330 - val_accuracy: 0.3974\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 291s 157ms/step - loss: 2.9538 - accuracy: 0.4298 - val_loss: 1.4250 - val_accuracy: 0.4028\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 325s 175ms/step - loss: 2.9018 - accuracy: 0.4334 - val_loss: 1.3837 - val_accuracy: 0.4529\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 336s 181ms/step - loss: 2.8575 - accuracy: 0.4424 - val_loss: 1.4286 - val_accuracy: 0.4244\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 311s 168ms/step - loss: 2.8046 - accuracy: 0.4519 - val_loss: 1.4349 - val_accuracy: 0.4074\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - ETA: 0s - loss: 2.7653 - accuracy: 0.4552Restoring model weights from the end of the best epoch: 4.\n",
      "1853/1853 [==============================] - 291s 157ms/step - loss: 2.7653 - accuracy: 0.4552 - val_loss: 1.4061 - val_accuracy: 0.4213\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feff78f1fd0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(x=[np.array(df_train_audio_normalized), np.array(train_tokens_prebuilt_new)], y=train_labels.map(mapping), validation_data=([np.array(df_test_audio_normalized), np.array(test_tokens_prebuilt_new)], test_labels.map(mapping)), epochs=30, batch_size=8,\n",
    "             class_weight = class_weights, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "1HZA2OjXPvDa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 100\n",
      "2 200\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 310s 180ms/step - loss: 3.1187 - accuracy: 0.3891 - val_loss: 1.4125 - val_accuracy: 0.4324\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 285s 166ms/step - loss: 2.5840 - accuracy: 0.4650 - val_loss: 1.3665 - val_accuracy: 0.4174\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 265s 154ms/step - loss: 2.1200 - accuracy: 0.5378 - val_loss: 1.4928 - val_accuracy: 0.3973\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.7342 - accuracy: 0.6041Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 263s 153ms/step - loss: 1.7342 - accuracy: 0.6041 - val_loss: 1.5417 - val_accuracy: 0.4101\n",
      "Epoch 4: early stopping\n",
      "2 300\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 272s 158ms/step - loss: 3.1208 - accuracy: 0.3924 - val_loss: 1.4565 - val_accuracy: 0.4279\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 274s 159ms/step - loss: 2.6081 - accuracy: 0.4561 - val_loss: 1.4051 - val_accuracy: 0.3973\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 262s 152ms/step - loss: 2.1722 - accuracy: 0.5232 - val_loss: 1.3711 - val_accuracy: 0.4435\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 227s 132ms/step - loss: 1.7826 - accuracy: 0.5913 - val_loss: 1.6246 - val_accuracy: 0.4235\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 226s 131ms/step - loss: 1.5211 - accuracy: 0.6455 - val_loss: 1.8251 - val_accuracy: 0.4268\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.3204 - accuracy: 0.6891Restoring model weights from the end of the best epoch: 3.\n",
      "1719/1719 [==============================] - 12407s 7s/step - loss: 1.3204 - accuracy: 0.6891 - val_loss: 1.9093 - val_accuracy: 0.3996\n",
      "Epoch 6: early stopping\n",
      "2 500\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 325s 188ms/step - loss: 3.1340 - accuracy: 0.3946 - val_loss: 1.3846 - val_accuracy: 0.4235\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 294s 171ms/step - loss: 2.6312 - accuracy: 0.4541 - val_loss: 1.4309 - val_accuracy: 0.3929\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 329s 191ms/step - loss: 2.2166 - accuracy: 0.5170 - val_loss: 1.6039 - val_accuracy: 0.3784\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.8472 - accuracy: 0.5783Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 296s 172ms/step - loss: 1.8472 - accuracy: 0.5783 - val_loss: 1.6256 - val_accuracy: 0.4040\n",
      "Epoch 4: early stopping\n",
      "0.44351696968078613 300\n",
      "3 100\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 300s 174ms/step - loss: 3.1439 - accuracy: 0.3943 - val_loss: 1.4307 - val_accuracy: 0.4357\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 293s 170ms/step - loss: 2.5912 - accuracy: 0.4709 - val_loss: 1.3887 - val_accuracy: 0.4012\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 282s 164ms/step - loss: 2.1200 - accuracy: 0.5439 - val_loss: 1.5034 - val_accuracy: 0.3973\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.7337 - accuracy: 0.6137Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 314s 183ms/step - loss: 1.7337 - accuracy: 0.6137 - val_loss: 1.5977 - val_accuracy: 0.3817\n",
      "Epoch 4: early stopping\n",
      "3 200\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 280s 162ms/step - loss: 3.1459 - accuracy: 0.3833 - val_loss: 1.3984 - val_accuracy: 0.4018\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 305s 177ms/step - loss: 2.6336 - accuracy: 0.4569 - val_loss: 1.3468 - val_accuracy: 0.4597\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 274s 159ms/step - loss: 2.2031 - accuracy: 0.5113 - val_loss: 1.4383 - val_accuracy: 0.4129\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 290s 169ms/step - loss: 1.8233 - accuracy: 0.5842 - val_loss: 1.5231 - val_accuracy: 0.3929\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.5466 - accuracy: 0.6406Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 287s 167ms/step - loss: 1.5466 - accuracy: 0.6406 - val_loss: 1.8576 - val_accuracy: 0.3762\n",
      "Epoch 5: early stopping\n",
      "3 300\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 301s 174ms/step - loss: 3.1850 - accuracy: 0.3885 - val_loss: 1.3993 - val_accuracy: 0.4168\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 291s 169ms/step - loss: 2.6674 - accuracy: 0.4534 - val_loss: 1.3829 - val_accuracy: 0.4029\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 316s 184ms/step - loss: 2.2663 - accuracy: 0.5055 - val_loss: 1.5058 - val_accuracy: 0.4140\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.8978 - accuracy: 0.5700Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 277s 161ms/step - loss: 1.8978 - accuracy: 0.5700 - val_loss: 1.5374 - val_accuracy: 0.3834\n",
      "Epoch 4: early stopping\n",
      "3 500\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 314s 182ms/step - loss: 3.2241 - accuracy: 0.3853 - val_loss: 1.5035 - val_accuracy: 0.3806\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 261s 152ms/step - loss: 2.7142 - accuracy: 0.4442 - val_loss: 1.4398 - val_accuracy: 0.3895\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 283s 164ms/step - loss: 2.3058 - accuracy: 0.5004 - val_loss: 1.4583 - val_accuracy: 0.3895\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 308s 179ms/step - loss: 1.9553 - accuracy: 0.5587 - val_loss: 1.4780 - val_accuracy: 0.4341\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 319s 185ms/step - loss: 1.6846 - accuracy: 0.6109 - val_loss: 1.6439 - val_accuracy: 0.4090\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 325s 189ms/step - loss: 1.4808 - accuracy: 0.6531 - val_loss: 1.8445 - val_accuracy: 0.3751\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.3310 - accuracy: 0.6864Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 313s 182ms/step - loss: 1.3310 - accuracy: 0.6864 - val_loss: 2.0851 - val_accuracy: 0.3667\n",
      "Epoch 7: early stopping\n",
      "0.4596549868583679 200\n",
      "1 100\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 319s 179ms/step - loss: 3.1143 - accuracy: 0.3954 - val_loss: 1.3852 - val_accuracy: 0.4179\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 309s 180ms/step - loss: 2.5026 - accuracy: 0.4854 - val_loss: 1.3580 - val_accuracy: 0.4480\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 300s 175ms/step - loss: 1.9533 - accuracy: 0.5830 - val_loss: 1.5619 - val_accuracy: 0.3845\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 291s 169ms/step - loss: 1.4984 - accuracy: 0.6685 - val_loss: 1.7553 - val_accuracy: 0.3856\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.2136 - accuracy: 0.7222Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 261s 152ms/step - loss: 1.2136 - accuracy: 0.7222 - val_loss: 1.9730 - val_accuracy: 0.3606\n",
      "Epoch 5: early stopping\n",
      "1 200\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 253s 146ms/step - loss: 3.0622 - accuracy: 0.4032 - val_loss: 1.4201 - val_accuracy: 0.3957\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 252s 147ms/step - loss: 2.4780 - accuracy: 0.4922 - val_loss: 1.4463 - val_accuracy: 0.3834\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 735s 428ms/step - loss: 1.9422 - accuracy: 0.5762 - val_loss: 1.5662 - val_accuracy: 0.3767\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.5131 - accuracy: 0.6599Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 287s 167ms/step - loss: 1.5131 - accuracy: 0.6599 - val_loss: 1.6920 - val_accuracy: 0.3717\n",
      "Epoch 4: early stopping\n",
      "1 300\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 316s 183ms/step - loss: 3.0483 - accuracy: 0.4093 - val_loss: 1.3564 - val_accuracy: 0.4691\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 278s 162ms/step - loss: 2.4797 - accuracy: 0.4945 - val_loss: 1.4011 - val_accuracy: 0.4040\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 253s 147ms/step - loss: 1.9591 - accuracy: 0.5775 - val_loss: 1.5277 - val_accuracy: 0.4101\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.5327 - accuracy: 0.6587Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 252s 147ms/step - loss: 1.5327 - accuracy: 0.6587 - val_loss: 1.7506 - val_accuracy: 0.3667\n",
      "Epoch 4: early stopping\n",
      "1 500\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 258s 149ms/step - loss: 3.0349 - accuracy: 0.4060 - val_loss: 1.3439 - val_accuracy: 0.4385\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 257s 150ms/step - loss: 2.4837 - accuracy: 0.4905 - val_loss: 1.4373 - val_accuracy: 0.4023\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 250s 146ms/step - loss: 1.9861 - accuracy: 0.5679 - val_loss: 1.4908 - val_accuracy: 0.4213\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 1.5623 - accuracy: 0.6472Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 253s 147ms/step - loss: 1.5623 - accuracy: 0.6472 - val_loss: 1.7546 - val_accuracy: 0.3795\n",
      "Epoch 4: early stopping\n",
      "0.4691151976585388 300\n"
     ]
    }
   ],
   "source": [
    "#def run_big_combined_model(num_h = 1, hidden_sizes = [100]):\n",
    "hidden_sizes = [100,200,300,500]\n",
    "num_hs = [2,3,1]\n",
    "\n",
    "best_score, best_hidden_size = 0,0\n",
    "for num_h in num_hs:   \n",
    "    for hidden_size in hidden_sizes:\n",
    "        print(num_h, hidden_size)\n",
    "        if num_h == 2 and hidden_size == 100:\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "\n",
    "            # -------------------------------Model that accepts input and creates embedding matrix-------------------------------\n",
    "            #input_layer = tf.keras.layers.Input(shape=(1000,))\n",
    "            lyric_input = tf.keras.layers.Input(shape=(600,))\n",
    "            audio_input = tf.keras.layers.Input(shape=(9,))\n",
    "            #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "            embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                        embedding_matrix.shape[1],\n",
    "                                        weights = [embedding_matrix],\n",
    "                                        input_length=1000,\n",
    "                                        trainable=True,\n",
    "                                        name = 'embedding_layer')\n",
    "\n",
    "            embeddings = embedding_layer(lyric_input)\n",
    "            embedding_model = tf.keras.Model(inputs = [lyric_input],outputs=[embeddings])\n",
    "\n",
    "\n",
    "            # -----------------------------------------------------AUDIO FFN MODEL-----------------------------------------------------\n",
    "\n",
    "            # AUDIO\n",
    "            #audio_layer = Dense(300, activation=\"relu\")(audio_input)\n",
    "            # add more layers?\n",
    "            audio_model = tf.keras.Model(inputs = [audio_input],outputs=[audio_input])\n",
    "\n",
    "            # -----------------------------------------------------WAN Model-----------------------------------------------------\n",
    "            # LYRICS\n",
    "            #Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "            query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(embedding_model.output)\n",
    "            #reshape to 1 x num_attention\n",
    "            reshaped_query = tf.keras.layers.Reshape((1,600))(query)\n",
    "            #Softmax over query * key (words) to obtain weights\n",
    "            weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                                name='attention_weights')(reshaped_query)\n",
    "            #weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "            #from prior layer\n",
    "            wan_embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((embedding_model.output,weights)))\n",
    "            wan_embedding = tf.keras.Model(inputs=[embedding_model.input],outputs=[wan_embedding])\n",
    "\n",
    "            # WAN Model that uses an attention layer with a single node to learn how to combine WAN/DAN embeddings into single representation\n",
    "            dual_embedding = tf.keras.layers.concatenate([audio_model.output,wan_embedding.output])\n",
    "            #dual_embedding = tf.keras.layers.Reshape((2,embedding_matrix.shape[1]))(dual_embedding)\n",
    "            #query = tf.keras.layers.Dense(1,activation='linear',use_bias=False)(dual_embedding)\n",
    "            #reshaped_query = tf.keras.layers.Reshape((1,2))(query)\n",
    "            #weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x))(reshaped_query)\n",
    "            #embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((dual_embedding,weights)))\n",
    "            hidden = tf.keras.layers.Dense(hidden_size,activation='relu')(dual_embedding)\n",
    "            if num_h > 1:\n",
    "                for num in range(num_h):\n",
    "                    hidden = tf.keras.layers.Dense(hidden_size,activation='relu')(hidden)\n",
    "            output = tf.keras.layers.Dense(7,activation='softmax')(hidden)\n",
    "            final_model = tf.keras.Model(inputs=[audio_model.input, embedding_model.input],outputs=[output])\n",
    "\n",
    "            final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                                        loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                                        metrics='accuracy')\n",
    "\n",
    "            final_model_history = final_model.fit(x=[np.array(df_train_audio_normalized), np.array(train_tokens_prebuilt_new)], y=train_labels.map(mapping), validation_data=([np.array(df_test_audio_normalized), np.array(test_tokens_prebuilt_new)], test_labels.map(mapping)), epochs=10, batch_size=8,\n",
    "                     class_weight = class_weights, callbacks = [es]) \n",
    "\n",
    "            if max(final_model_history.history['val_accuracy']) > best_score:\n",
    "                    best_score = max(final_model_history.history['val_accuracy'])\n",
    "                    best_hidden_size = hidden_size\n",
    "\n",
    "    print(best_score, best_hidden_size)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.4691151976585388 300, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KjKNy6OYPvDa",
    "outputId": "1560b9c2-46dc-4e40-f853-b2ee61938b76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCXuvGlMPvDa",
    "outputId": "91410aea-6392-4291-ecb9-87034007e64b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_48\" is incompatible with the layer: expected shape=(None, 9), found shape=(None, 1000)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-5a32e48b853b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m final_model.fit(x=[np.array(train_tokens_prebuilt_new), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_tokens_prebuilt_new), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8,\n\u001b[0m\u001b[1;32m      2\u001b[0m              class_weight = class_weights)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_48\" is incompatible with the layer: expected shape=(None, 9), found shape=(None, 1000)\n"
     ]
    }
   ],
   "source": [
    "final_model.fit(x=[np.array(train_tokens_prebuilt_new), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_tokens_prebuilt_new), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8,\n",
    "             class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16-ThMsGPvDb",
    "outputId": "34c5aa2c-9e38-471a-b574-2a5959553da8"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_4\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [], output_shape = [1, 300]\n\nCall arguments received by layer \"reshape_4\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None,), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-b6bf6ee86d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# AUDIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mavg_embedding_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mavg_embedding_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_embedding_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mavg_embedding_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maudio_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mavg_embedding_audio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/layers/reshaping/reshape.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_4\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [], output_shape = [1, 300]\n\nCall arguments received by layer \"reshape_4\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None,), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# -------------------------------Model that accepts input and creates embedding matrix-------------------------------\n",
    "#input_layer = tf.keras.layers.Input(shape=(1000,))\n",
    "lyric_input = tf.keras.layers.Input(shape=(1000,))\n",
    "audio_input = tf.keras.layers.Input(shape=(9,))\n",
    "#Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights = [embedding_matrix],\n",
    "                            input_length=1000,\n",
    "                            trainable=True,\n",
    "                            name = 'embedding_layer')\n",
    "\n",
    "audio_layer = Dense(100, activation=\"relu\")(audio_input)\n",
    "\n",
    "embeddings = embedding_layer(lyric_input)\n",
    "embedding_model = tf.keras.Model(inputs = [lyric_input],outputs=[embeddings])\n",
    "\n",
    "audio_model = tf.keras.Model(inputs = [audio_input],outputs=[audio_layer])\n",
    "\n",
    "# -----------------------------------------------------DAN MODEL-----------------------------------------------------\n",
    "# AUDIO\n",
    "avg_embedding_audio = tf.keras.layers.Lambda(lambda x:K.mean(x,axis=1))(audio_model.output)\n",
    "avg_embedding_audio = tf.keras.layers.Reshape((1,embedding_matrix.shape[1]))(avg_embedding_audio)\n",
    "avg_embedding_audio = tf.keras.Model(inputs = [audio_model.input], outputs = [avg_embedding_audio])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------WAN Model-----------------------------------------------------\n",
    "# LYRICS\n",
    "#Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(embedding_model.output)\n",
    "#reshape to 1 x num_attention\n",
    "reshaped_query = tf.keras.layers.Reshape((1,1000))(query)\n",
    "#Softmax over query * key (words) to obtain weights\n",
    "weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                    name='attention_weights')(reshaped_query)\n",
    "#weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "#from prior layer\n",
    "wan_embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((embedding_model.output,weights)))\n",
    "wan_embedding = tf.keras.Model(inputs=[embedding_model.input],outputs=[wan_embedding])\n",
    "\n",
    "# WAN Model that uses an attention layer with a single node to learn how to combine WAN/DAN embeddings into single representation\n",
    "dual_embedding = tf.keras.layers.concatenate([audio_reshaped.output,wan_embedding.output])\n",
    "dual_embedding = tf.keras.layers.Reshape((2,embedding_matrix_custom.shape[1]))(dual_embedding)\n",
    "query = tf.keras.layers.Dense(1,activation='linear',use_bias=False)(dual_embedding)\n",
    "reshaped_query = tf.keras.layers.Reshape((1,2))(query)\n",
    "weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x))(reshaped_query)\n",
    "embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((dual_embedding,weights)))\n",
    "hidden = tf.keras.layers.Dense(100,activation='relu')(embedding)\n",
    "output = tf.keras.layers.Dense(11,activation='softmax')(hidden)\n",
    "final_model = tf.keras.Model(inputs=[embedding_model.input],outputs=[output])\n",
    "\n",
    "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                            metrics='accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmmtI1hYPvDc",
    "outputId": "e8ec3715-1891-4ad4-aef7-7012a6a8aa6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43982 300\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape[0], embedding_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mW4GQ50-PvDc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6a Joint Model with Custom Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_lyrics_train = get_unique_words(df_train['Lyrics_String'], mapping_dict, seq_size = embedding_size)\n",
    "mapped_lyrics_val = get_unique_words(df_val['Lyrics_String'], mapping_dict, seq_size = embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43982\n",
      "300\n",
      "101831\n",
      "300\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape[0])\n",
    "print(embedding_matrix.shape[1])\n",
    "\n",
    "print(embedding_matrix_cust.shape[0])\n",
    "print(embedding_matrix_cust.shape[1])\n",
    "\n",
    "print(embedding_matrix_custom)\n",
    "\n",
    "#print((mapped_lyrics_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1853/1853 [==============================] - ETA: 0s - loss: 3.3436 - accuracy: 0.3638"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 1 of layer \"model_29\" is incompatible with the layer: expected shape=(None, 600), found shape=(8, 700)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-87b4a235cbe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m                                 metrics='accuracy')\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     final_model_history = final_model.fit(x=[np.array(df_train_audio_normalized), np.array(mapped_lyrics_train)], y=train_labels.map(mapping), validation_data=([np.array(df_test_audio_normalized), np.array(mapped_lyrics_test)], test_labels.map(mapping)), epochs=30, batch_size=8,\n\u001b[0m\u001b[1;32m     78\u001b[0m              class_weight = class_weights, callbacks = [es]) \n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1499, in test_step\n        y_pred = self(x, training=False)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 1 of layer \"model_29\" is incompatible with the layer: expected shape=(None, 600), found shape=(8, 700)\n"
     ]
    }
   ],
   "source": [
    "embedding_sizes_cust = [600]\n",
    "hidden_size = 300\n",
    "num_h = 1\n",
    "\n",
    "# need to run with 1,300 too or whatever max ends up being\n",
    "\n",
    "best_score, best_embedding_size = 0,0\n",
    "for embedding_size in embedding_sizes_cust:\n",
    "    \n",
    "    mapped_lyrics_train = get_unique_words(train['Lyrics'], mapping_dict, seq_size = embedding_size)\n",
    "    mapped_lyrics_val = get_unique_words(test['Lyrics'], mapping_dict, seq_size = embedding_size)\n",
    "\n",
    "    # -------------------------------Model that accepts input and creates embedding matrix-------------------------------\n",
    "    #input_layer = tf.keras.layers.Input(shape=(1000,))\n",
    "    lyric_input = tf.keras.layers.Input(shape=(embedding_size,))\n",
    "    audio_input = tf.keras.layers.Input(shape=(9,))\n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    #embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "     #                           embedding_matrix.shape[1],\n",
    "      #                          weights = [embedding_matrix],\n",
    "       #                         input_length=1000,\n",
    "        #                        trainable=True,\n",
    "         #                       name = 'embedding_layer')\n",
    "    \n",
    "    embedding_layer = Embedding(embedding_matrix_cust.shape[0],\n",
    "                                embedding_matrix_cust.shape[1],\n",
    "                                weights = [embedding_matrix_cust],\n",
    "                                input_length=1000,\n",
    "                                trainable=True,\n",
    "                                name = 'embedding_layer')\n",
    "    \n",
    "    \n",
    "\n",
    "    embeddings = embedding_layer(lyric_input)\n",
    "    embedding_model = tf.keras.Model(inputs = [lyric_input],outputs=[embeddings])\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------AUDIO FFN MODEL-----------------------------------------------------\n",
    "\n",
    "    # AUDIO\n",
    "    #audio_layer = Dense(300, activation=\"relu\")(audio_input)\n",
    "    # add more layers?\n",
    "    audio_model = tf.keras.Model(inputs = [audio_input],outputs=[audio_input])\n",
    "\n",
    "    # -----------------------------------------------------WAN Model-----------------------------------------------------\n",
    "    # LYRICS\n",
    "    #Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "    query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(embedding_model.output)\n",
    "    #reshape to 1 x num_attention\n",
    "    reshaped_query = tf.keras.layers.Reshape((1,embedding_size))(query)\n",
    "    #Softmax over query * key (words) to obtain weights\n",
    "    weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                        name='attention_weights')(reshaped_query)\n",
    "    #weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "    #from prior layer\n",
    "    wan_embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((embedding_model.output,weights)))\n",
    "    wan_embedding = tf.keras.Model(inputs=[embedding_model.input],outputs=[wan_embedding])\n",
    "\n",
    "    # WAN Model that uses an attention layer with a single node to learn how to combine WAN/DAN embeddings into single representation\n",
    "    dual_embedding = tf.keras.layers.concatenate([audio_model.output,wan_embedding.output])\n",
    "    #dual_embedding = tf.keras.layers.Reshape((2,embedding_matrix.shape[1]))(dual_embedding)\n",
    "    #query = tf.keras.layers.Dense(1,activation='linear',use_bias=False)(dual_embedding)\n",
    "    #reshaped_query = tf.keras.layers.Reshape((1,2))(query)\n",
    "    #weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x))(reshaped_query)\n",
    "    #embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((dual_embedding,weights)))\n",
    "    hidden = tf.keras.layers.Dense(hidden_size,activation='relu')(dual_embedding)\n",
    "    if num_h > 1:\n",
    "        for num in range(num_h):\n",
    "            hidden = tf.keras.layers.Dense(hidden_size,activation='relu')(hidden)\n",
    "    output = tf.keras.layers.Dense(7,activation='softmax')(hidden)\n",
    "    final_model = tf.keras.Model(inputs=[audio_model.input, embedding_model.input],outputs=[output])\n",
    "\n",
    "    final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                                loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                                metrics='accuracy')\n",
    "\n",
    "    final_model_history = final_model.fit(x=[np.array(df_train_audio_normalized), np.array(mapped_lyrics_train)], y=train_labels.map(mapping), validation_data=([np.array(df_test_audio_normalized), np.array(mapped_lyrics_test)], test_labels.map(mapping)), epochs=30, batch_size=8,\n",
    "             class_weight = class_weights, callbacks = [es]) \n",
    "\n",
    "    if max(final_model_history.history['val_accuracy']) > best_score:\n",
    "            best_score = max(final_model_history.history['val_accuracy'])\n",
    "            best_embedding_size = embedding_size\n",
    "\n",
    "print(best_score, best_embedding_size)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: good_model_test/assets\n"
     ]
    }
   ],
   "source": [
    "#final_model.save('good_model_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trespimentel/Desktop/w266_final_project/Genre_Classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = tf.keras.models.load_model('good_model_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.0820261e-06, 7.9149986e-04, 9.1551046e-05, ..., 2.2805509e-07,\n",
       "        2.5850213e-07, 1.2769316e-09],\n",
       "       [9.5683151e-01, 2.1962963e-07, 2.9518318e-03, ..., 3.9531521e-02,\n",
       "        1.8403094e-05, 8.1324533e-06],\n",
       "       [2.2439309e-03, 1.2515628e-07, 9.8650473e-01, ..., 3.9521365e-05,\n",
       "        3.3364543e-03, 4.3913207e-08],\n",
       "       ...,\n",
       "       [3.2632285e-01, 4.4970532e-04, 1.0403032e-02, ..., 6.1456382e-01,\n",
       "        8.5839181e-04, 4.9903565e-03],\n",
       "       [3.1927954e-09, 7.9302890e-03, 3.6399148e-09, ..., 1.2767193e-09,\n",
       "        4.4041080e-11, 5.4085321e-12],\n",
       "       [2.2727152e-02, 1.9894808e-04, 8.9302385e-01, ..., 1.0763549e-03,\n",
       "        5.7666916e-02, 4.0817195e-05]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.predict([np.array(df_test_audio_normalized), np.array(mapped_lyrics_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    " mapped_lyrics_test = get_unique_words(test['Lyrics'], mapping_dict, seq_size = embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_final_model = test_model.predict([np.array(df_test_audio_normalized), np.array(mapped_lyrics_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(predictions_final_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-71a746dcd864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_final_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-e7a32fe99b66>\u001b[0m in \u001b[0;36mclass_recall\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclass_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#true labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#predicted prob of each class for each sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "class_recall(np.array(test_labels.map(mapping)), predictions_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       3\n",
      "1       4\n",
      "2       3\n",
      "3       1\n",
      "4       4\n",
      "       ..\n",
      "1295    3\n",
      "1296    1\n",
      "1297    2\n",
      "1298    3\n",
      "1299    2\n",
      "Name: Major Genre, Length: 1296, dtype: int64\n",
      "[[7.0820261e-06 7.9149986e-04 9.1551046e-05 ... 2.2805509e-07\n",
      "  2.5850213e-07 1.2769316e-09]\n",
      " [9.5683151e-01 2.1962963e-07 2.9518318e-03 ... 3.9531521e-02\n",
      "  1.8403094e-05 8.1324533e-06]\n",
      " [2.2439309e-03 1.2515628e-07 9.8650473e-01 ... 3.9521365e-05\n",
      "  3.3364543e-03 4.3913207e-08]\n",
      " ...\n",
      " [3.2632285e-01 4.4970532e-04 1.0403032e-02 ... 6.1456382e-01\n",
      "  8.5839181e-04 4.9903565e-03]\n",
      " [3.1927954e-09 7.9302890e-03 3.6399148e-09 ... 1.2767193e-09\n",
      "  4.4041080e-11 5.4085321e-12]\n",
      " [2.2727152e-02 1.9894808e-04 8.9302385e-01 ... 1.0763549e-03\n",
      "  5.7666916e-02 4.0817195e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels.map(mapping))\n",
    "print(predictions_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859420591578508\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([x.argmax() for x in predictions_final_model])\n",
    "    #confusion matrix\n",
    "confuse = confusion_matrix(test_labels.map(mapping),pred)\n",
    "confuse_sum = confuse.sum(axis=1)\n",
    "score = 0\n",
    "for num in range(len(confuse_sum)):\n",
    "    if confuse_sum[num]!=0:\n",
    "        score = score + confuse[num][num]/confuse_sum[num]\n",
    "    \n",
    "print(score/len(confuse_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indie</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Alternative</th>\n",
       "      <th>Hip Hop</th>\n",
       "      <th>Blues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Indie</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metal</th>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pop</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rock</th>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>240</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alternative</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hip Hop</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blues</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Indie  Metal  Pop  Rock  Alternative  Hip Hop  Blues\n",
       "Indie          112      2   20    22           62        3      2\n",
       "Metal            2    120    1    11            1        1      1\n",
       "Pop             18      2  142    12           11       14      0\n",
       "Rock            26     38   24   240           52        7     15\n",
       "Alternative     29      2   14    23           65        1      3\n",
       "Hip Hop          2      0    5     5            0      111      1\n",
       "Blues            2      1    1    12            1        2     55"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame(confuse)\n",
    "confusion_final_model = pd.DataFrame(confuse, index = mapping.keys(), columns = mapping.keys())\n",
    "confusion_final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(confusion_final_model,open('final_model_confusion.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/trespimentel/Desktop/w266_final_project/Genre_Classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6B Token Size Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "100\n",
      "Model: \"model_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 700)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 700, 100)         10183100  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                7575      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,202,607\n",
      "Trainable params: 19,507\n",
      "Non-trainable params: 10,183,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 12s 6ms/step - loss: 4.1086 - accuracy: 0.1861 - val_loss: 1.8541 - val_accuracy: 0.2161\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 4.0265 - accuracy: 0.1995 - val_loss: 1.8285 - val_accuracy: 0.2954\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.0067 - accuracy: 0.2164 - val_loss: 1.8216 - val_accuracy: 0.2312\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.9910 - accuracy: 0.2094 - val_loss: 1.8284 - val_accuracy: 0.1965\n",
      "Epoch 5/100\n",
      "1705/1719 [============================>.] - ETA: 0s - loss: 3.9786 - accuracy: 0.2034Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 3.9816 - accuracy: 0.2036 - val_loss: 1.8318 - val_accuracy: 0.2205\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_115\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 700)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 700, 100)     10183100    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 700, 1)       100         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_48 (Reshape)           (None, 1, 700)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 700)       0           ['reshape_48[0][0]']             \n",
      "                                                                                                  \n",
      " dot_39 (Dot)                   (None, 100, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_39 (Flatten)           (None, 100)          0           ['dot_39[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 100)          0           ['flatten_39[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_49 (Reshape)           (None, 1, 100)       0           ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         100         ['reshape_49[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_50 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_50[0][0]']             \n",
      "                                                                                                  \n",
      " dot_40 (Dot)                   (None, 100, 1)       0           ['reshape_49[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_40 (Flatten)           (None, 100)          0           ['dot_40[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          15150       ['flatten_40[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,244,807\n",
      "Trainable params: 61,707\n",
      "Non-trainable params: 10,183,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 41s 9ms/step - loss: 4.0735 - accuracy: 0.1962 - val_loss: 1.8232 - val_accuracy: 0.1887\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.9947 - accuracy: 0.2055 - val_loss: 1.8543 - val_accuracy: 0.1547\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9721 - accuracy: 0.2075 - val_loss: 1.8090 - val_accuracy: 0.2021\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 3.9567 - accuracy: 0.2181 - val_loss: 1.7994 - val_accuracy: 0.2647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.9410 - accuracy: 0.2204 - val_loss: 1.7993 - val_accuracy: 0.2367\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 3.9376 - accuracy: 0.2206 - val_loss: 1.7964 - val_accuracy: 0.1999\n",
      "Epoch 7/100\n",
      "1715/1719 [============================>.] - ETA: 0s - loss: 3.9305 - accuracy: 0.2208Restoring model weights from the end of the best epoch: 4.\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.9296 - accuracy: 0.2207 - val_loss: 1.7952 - val_accuracy: 0.2418\n",
      "Epoch 7: early stopping\n",
      "200\n",
      "Model: \"model_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 700)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 700, 200)         20366200  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 200)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                15075     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,393,207\n",
      "Trainable params: 27,007\n",
      "Non-trainable params: 20,366,200\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 4.3025 - accuracy: 0.1208 - val_loss: 1.9451 - val_accuracy: 0.1435\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 4.2964 - accuracy: 0.1320 - val_loss: 1.9481 - val_accuracy: 0.1039\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.2968 - accuracy: 0.1120 - val_loss: 1.9452 - val_accuracy: 0.1435\n",
      "Epoch 4/100\n",
      "1703/1719 [============================>.] - ETA: 0s - loss: 4.2926 - accuracy: 0.1138Restoring model weights from the end of the best epoch: 1.\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.2964 - accuracy: 0.1148 - val_loss: 1.9425 - val_accuracy: 0.1039\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_117\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 700)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 700, 200)     20366200    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 700, 1)       200         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_51 (Reshape)           (None, 1, 700)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 700)       0           ['reshape_51[0][0]']             \n",
      "                                                                                                  \n",
      " dot_41 (Dot)                   (None, 200, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_41 (Flatten)           (None, 200)          0           ['dot_41[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 200)          0           ['flatten_41[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_52 (Reshape)           (None, 1, 200)       0           ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         200         ['reshape_52[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_53 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_53[0][0]']             \n",
      "                                                                                                  \n",
      " dot_42 (Dot)                   (None, 200, 1)       0           ['reshape_52[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_42 (Flatten)           (None, 200)          0           ['dot_42[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          30150       ['flatten_42[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,443,107\n",
      "Trainable params: 76,907\n",
      "Non-trainable params: 20,366,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 4.1173 - accuracy: 0.1807 - val_loss: 1.8308 - val_accuracy: 0.2289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.9713 - accuracy: 0.2030 - val_loss: 1.8010 - val_accuracy: 0.2111\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.9336 - accuracy: 0.2187 - val_loss: 1.7933 - val_accuracy: 0.2272\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 3.9228 - accuracy: 0.2132 - val_loss: 1.7999 - val_accuracy: 0.2323\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 3.9182 - accuracy: 0.2106 - val_loss: 1.7858 - val_accuracy: 0.2390\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 3.9050 - accuracy: 0.2100 - val_loss: 1.7942 - val_accuracy: 0.2189\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 3.9069 - accuracy: 0.2065 - val_loss: 1.8079 - val_accuracy: 0.2278\n",
      "Epoch 8/100\n",
      "1716/1719 [============================>.] - ETA: 0s - loss: 3.9033 - accuracy: 0.2102Restoring model weights from the end of the best epoch: 5.\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 3.9026 - accuracy: 0.2102 - val_loss: 1.7983 - val_accuracy: 0.2367\n",
      "Epoch 8: early stopping\n",
      "250\n",
      "Model: \"model_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 700)]             0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 700, 250)         25457750  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 250)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 75)                18825     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 75)                5700      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 75)                0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 7)                 532       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,488,507\n",
      "Trainable params: 30,757\n",
      "Non-trainable params: 25,457,750\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 5ms/step - loss: 4.1788 - accuracy: 0.1614 - val_loss: 1.8485 - val_accuracy: 0.2189\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 4.1022 - accuracy: 0.1851 - val_loss: 1.8284 - val_accuracy: 0.2747\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 4.0942 - accuracy: 0.1921 - val_loss: 1.8357 - val_accuracy: 0.1882\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 4.0866 - accuracy: 0.1886 - val_loss: 1.8337 - val_accuracy: 0.1960\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 4.0910 - accuracy: 0.1789Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 4.0910 - accuracy: 0.1789 - val_loss: 1.8209 - val_accuracy: 0.1893\n",
      "Epoch 5: early stopping\n",
      "Model: \"model_119\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 700)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 700, 250)     25457750    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 700, 1)       250         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_54 (Reshape)           (None, 1, 700)       0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 700)       0           ['reshape_54[0][0]']             \n",
      "                                                                                                  \n",
      " dot_43 (Dot)                   (None, 250, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_43 (Flatten)           (None, 250)          0           ['dot_43[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 250)          0           ['flatten_43[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_55 (Reshape)           (None, 1, 250)       0           ['concatenate_35[0][0]']         \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         250         ['reshape_55[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_56 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_56[0][0]']             \n",
      "                                                                                                  \n",
      " dot_44 (Dot)                   (None, 250, 1)       0           ['reshape_55[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_44 (Flatten)           (None, 250)          0           ['dot_44[0][0]']                 \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 150)          37650       ['flatten_44[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 150)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 150)          22650       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 150)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 150)          22650       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 150)          0           ['hidden_3[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 7)            1057        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,542,257\n",
      "Trainable params: 84,507\n",
      "Non-trainable params: 25,457,750\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 25s 14ms/step - loss: 4.0920 - accuracy: 0.1900 - val_loss: 1.8185 - val_accuracy: 0.1943\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 26s 15ms/step - loss: 3.9909 - accuracy: 0.2121 - val_loss: 1.7922 - val_accuracy: 0.2563\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 34s 20ms/step - loss: 3.9578 - accuracy: 0.2290 - val_loss: 1.8001 - val_accuracy: 0.2183\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 25s 14ms/step - loss: 3.9168 - accuracy: 0.2261 - val_loss: 1.7795 - val_accuracy: 0.2345\n",
      "Epoch 5/100\n",
      "1713/1719 [============================>.] - ETA: 0s - loss: 3.9065 - accuracy: 0.2339Restoring model weights from the end of the best epoch: 2.\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 3.9046 - accuracy: 0.2340 - val_loss: 1.7811 - val_accuracy: 0.2501\n",
      "Epoch 5: early stopping\n",
      "best dan performance  0.29536572098731995\n",
      "best dan embedding size  100\n",
      "best wan performance  0.25628140568733215\n",
      "best wan embedding size  250\n"
     ]
    }
   ],
   "source": [
    "token_sizes = [100,200,250]\n",
    "embedding_size = 700\n",
    "best_dan_score, best_wan_score, best_dan_token_size, best_wan_token_size = 0,0,0,0\n",
    "print(best_embedding_size)\n",
    "\n",
    "for token_size in token_sizes:\n",
    "    embedding_matrix_cust = np.random.random((len(vectorizer.get_feature_names()) + 1) * token_size).reshape((len(vectorizer.get_feature_names()) + 1,token_size))\n",
    "    mapped_lyrics_train = get_unique_words(df_train['Lyrics_String'], mapping_dict, seq_size = embedding_size)\n",
    "    mapped_lyrics_val = get_unique_words(df_val['Lyrics_String'], mapping_dict, seq_size = embedding_size)\n",
    "    mapped_lyrics_test = get_unique_words(df_test['Lyrics_String'], mapping_dict, seq_size = embedding_size)\n",
    "    \n",
    "    print(token_size)\n",
    "    \n",
    "    dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix_cust, output_layer_size = 7, max_sequence_length=embedding_size, hidden_dim=[75,75,75])\n",
    "    dan_sorted_history = dan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(mapped_lyrics_val), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=100,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 2,\n",
    "                        callbacks = [es],\n",
    "                        class_weight = class_weights)\n",
    "    \n",
    "    \n",
    "    if max(dan_sorted_history.history['val_accuracy']) > best_dan_score:\n",
    "            best_dan_score = max(dan_sorted_history.history['val_accuracy'])\n",
    "            best_dan_token_size = token_size\n",
    "            \n",
    "    wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix_cust, output_layer_size = 7, max_sequence_length=embedding_size, hidden_dim=[150,150,150],\n",
    "                                   num_attention=1)\n",
    "    wan_sorted_history = wan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(mapped_lyrics_val), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=100,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 2,\n",
    "                        callbacks = [es],\n",
    "                        class_weight = class_weights)\n",
    "    \n",
    "    \n",
    "    if max(wan_sorted_history.history['val_accuracy']) > best_score:\n",
    "            best_wan_score = max(wan_sorted_history.history['val_accuracy'])\n",
    "            best_wan_token_size = token_size\n",
    "\n",
    "\n",
    "print('best dan performance ', best_dan_score)\n",
    "print('best dan embedding size ', best_dan_token_size)\n",
    "print('best wan performance ', best_wan_score)\n",
    "print('best wan embedding size ', best_wan_token_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best dan performance  0.29536572098731995\n",
    "best dan embedding size  100\n",
    "best wan performance  .316\n",
    "best wan embedding size  tie 500-700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n",
      "Epoch 1/10\n",
      "1853/1853 [==============================] - 1833s 988ms/step - loss: 3.3761 - accuracy: 0.3547 - val_loss: 1.4373 - val_accuracy: 0.3997\n",
      "Epoch 2/10\n",
      "1853/1853 [==============================] - 1701s 918ms/step - loss: 2.5340 - accuracy: 0.5126 - val_loss: 1.2144 - val_accuracy: 0.4969\n",
      "Epoch 3/10\n",
      "1853/1853 [==============================] - 1654s 893ms/step - loss: 1.6496 - accuracy: 0.6892 - val_loss: 1.2294 - val_accuracy: 0.5633\n",
      "Epoch 4/10\n",
      "1853/1853 [==============================] - 1615s 872ms/step - loss: 1.0990 - accuracy: 0.7902 - val_loss: 1.2083 - val_accuracy: 0.6196\n",
      "Epoch 5/10\n",
      "1853/1853 [==============================] - 1584s 855ms/step - loss: 0.8501 - accuracy: 0.8321 - val_loss: 1.3164 - val_accuracy: 0.6181\n",
      "Epoch 6/10\n",
      "1853/1853 [==============================] - 1576s 851ms/step - loss: 0.7103 - accuracy: 0.8571 - val_loss: 1.3787 - val_accuracy: 0.6319\n",
      "Epoch 7/10\n",
      "1853/1853 [==============================] - 1581s 853ms/step - loss: 0.6385 - accuracy: 0.8640 - val_loss: 1.5605 - val_accuracy: 0.6281\n",
      "Epoch 8/10\n",
      "1853/1853 [==============================] - 1629s 879ms/step - loss: 0.5895 - accuracy: 0.8705 - val_loss: 1.6481 - val_accuracy: 0.6404\n",
      "Epoch 9/10\n",
      "1853/1853 [==============================] - 1600s 863ms/step - loss: 0.5602 - accuracy: 0.8745 - val_loss: 1.5548 - val_accuracy: 0.6250\n",
      "Epoch 10/10\n",
      "1853/1853 [==============================] - 1573s 849ms/step - loss: 0.5150 - accuracy: 0.8785 - val_loss: 1.7425 - val_accuracy: 0.6373\n",
      "0.6404321193695068 700\n"
     ]
    }
   ],
   "source": [
    "token_sizes = [700]\n",
    "embedding_size = 700\n",
    "num_h = 1\n",
    "best_score, best_token_size = 0,0\n",
    "\n",
    "\n",
    "for token_size in token_sizes:\n",
    "    embedding_matrix_cust = np.random.random((len(vectorizer.get_feature_names()) + 1) * token_size).reshape((len(vectorizer.get_feature_names()) + 1,700))\n",
    "    mapped_lyrics_train = get_unique_words(train['Lyrics'], mapping_dict, seq_size = embedding_size)\n",
    "    #mapped_lyrics_val = get_unique_words(df_val['Lyrics'], mapping_dict, seq_size = embedding_size)\n",
    "    mapped_lyrics_test = get_unique_words(test['Lyrics'], mapping_dict, seq_size = embedding_size)\n",
    "    \n",
    "    print(token_size)\n",
    "    \n",
    "  # -------------------------------Model that accepts input and creates embedding matrix-------------------------------\n",
    "    #input_layer = tf.keras.layers.Input(shape=(1000,))\n",
    "    lyric_input = tf.keras.layers.Input(shape=(embedding_size,))\n",
    "    audio_input = tf.keras.layers.Input(shape=(9,))\n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    #embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "     #                           embedding_matrix.shape[1],\n",
    "      #                          weights = [embedding_matrix],\n",
    "       #                         input_length=1000,\n",
    "        #                        trainable=True,\n",
    "         #                       name = 'embedding_layer')\n",
    "    \n",
    "    embedding_layer = Embedding(embedding_matrix_cust.shape[0],\n",
    "                                embedding_matrix_cust.shape[1],\n",
    "                                weights = [embedding_matrix_cust],\n",
    "                                input_length=1000,\n",
    "                                trainable=True,\n",
    "                                name = 'embedding_layer')\n",
    "    \n",
    "    \n",
    "\n",
    "    embeddings = embedding_layer(lyric_input)\n",
    "    embedding_model = tf.keras.Model(inputs = [lyric_input],outputs=[embeddings])\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------AUDIO FFN MODEL-----------------------------------------------------\n",
    "\n",
    "    # AUDIO\n",
    "    #audio_layer = Dense(300, activation=\"relu\")(audio_input)\n",
    "    # add more layers?\n",
    "    audio_model = tf.keras.Model(inputs = [audio_input],outputs=[audio_input])\n",
    "\n",
    "    # -----------------------------------------------------WAN Model-----------------------------------------------------\n",
    "    # LYRICS\n",
    "    #Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "    query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(embedding_model.output)\n",
    "    #reshape to 1 x num_attention\n",
    "    reshaped_query = tf.keras.layers.Reshape((1,embedding_size))(query)\n",
    "    #Softmax over query * key (words) to obtain weights\n",
    "    weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                        name='attention_weights')(reshaped_query)\n",
    "    #weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "    #from prior layer\n",
    "    wan_embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((embedding_model.output,weights)))\n",
    "    wan_embedding = tf.keras.Model(inputs=[embedding_model.input],outputs=[wan_embedding])\n",
    "\n",
    "    # WAN Model that uses an attention layer with a single node to learn how to combine WAN/DAN embeddings into single representation\n",
    "    dual_embedding = tf.keras.layers.concatenate([audio_model.output,wan_embedding.output])\n",
    "    #dual_embedding = tf.keras.layers.Reshape((2,embedding_matrix.shape[1]))(dual_embedding)\n",
    "    #query = tf.keras.layers.Dense(1,activation='linear',use_bias=False)(dual_embedding)\n",
    "    #reshaped_query = tf.keras.layers.Reshape((1,2))(query)\n",
    "    #weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x))(reshaped_query)\n",
    "    #embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((dual_embedding,weights)))\n",
    "    hidden = tf.keras.layers.Dense(hidden_size,activation='relu')(dual_embedding)\n",
    "    if num_h > 1:\n",
    "        for num in range(num_h):\n",
    "            hidden = tf.keras.layers.Dense(hidden_size,activation='relu')(hidden)\n",
    "    output = tf.keras.layers.Dense(7,activation='softmax')(hidden)\n",
    "    final_model = tf.keras.Model(inputs=[audio_model.input, embedding_model.input],outputs=[output])\n",
    "\n",
    "    final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                                loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                                metrics='accuracy')\n",
    "\n",
    "    final_model_history = final_model.fit(x=[np.array(df_train_audio_normalized), np.array(mapped_lyrics_train)], y=train_labels.map(mapping), validation_data=([np.array(df_test_audio_normalized), np.array(mapped_lyrics_test)], test_labels.map(mapping)), epochs=10, batch_size=8,\n",
    "             class_weight = class_weights, callbacks = [es]) \n",
    "\n",
    "    if max(final_model_history.history['val_accuracy']) > best_score:\n",
    "            best_score = max(final_model_history.history['val_accuracy'])\n",
    "            best_token_size = token_size\n",
    "\n",
    "print(best_score, best_token_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: good2_model_test/assets\n"
     ]
    }
   ],
   "source": [
    "#final_model.save('good2_model_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_model = tf.keras.models.load_model('good2_model_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.94864526e-06, 1.38037768e-03, 2.06432724e-03, ...,\n",
       "        3.17465333e-06, 7.81255494e-06, 1.08711247e-03],\n",
       "       [9.89617646e-01, 1.01818378e-05, 1.49761129e-03, ...,\n",
       "        3.90229374e-03, 1.16231274e-06, 3.86196101e-04],\n",
       "       [9.58163198e-03, 1.90265418e-05, 8.19721520e-01, ...,\n",
       "        3.15128942e-04, 9.96350660e-04, 1.10060116e-02],\n",
       "       ...,\n",
       "       [6.38349652e-01, 4.29924467e-06, 1.78403080e-01, ...,\n",
       "        7.91075360e-03, 5.13671403e-05, 2.26892419e-02],\n",
       "       [1.60561956e-06, 1.06113395e-02, 7.31110558e-05, ...,\n",
       "        1.08606282e-05, 1.35933055e-06, 1.73171167e-04],\n",
       "       [3.56508739e-04, 4.37126744e-08, 9.83124256e-01, ...,\n",
       "        9.79557899e-06, 1.13505195e-03, 3.23415414e-04]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_model.predict([np.array(df_test_audio_normalized), np.array(mapped_lyrics_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run conf matrix here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_final = final_model.predict([np.array(df_test_audio_normalized), np.array(mapped_lyrics_test)])\n",
    "predictions_final_ = [x.argmax() for x in predictions_final]\n",
    "conf_final = sklearn.metrics.confusion_matrix(test_labels.map(mapping), predictions_final_)\n",
    "conf_final = pd.DataFrame(conf_final, index = mapping.keys(), columns = mapping.keys())\n",
    "conf_finalonf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic ff with custom embeddings with custom length + audio\n",
    "\n",
    "# define two sets of inputs\n",
    "inputA = Input(shape=(700,))\n",
    "inputB = Input(shape=(9,))\n",
    "# the first branch operates on the first input\n",
    "x = Dense(300, activation=\"relu\")(inputA)\n",
    "x = Dense(100, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(25, activation=\"relu\")(inputB)\n",
    "y = Dense(50, activation=\"relu\")(y)\n",
    "y = Dense(100, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "# apply a FC layer and then a classification prediction on the\n",
    "# combined outputs\n",
    "z = Dense(100, activation=\"relu\")(combined)\n",
    "z = Dense(100, activation=\"relu\")(z)\n",
    "z = Dense(7, activation=\"softmax\")(z)\n",
    "#z = Dense(1, activation=\"linear\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1853/1853 [==============================] - 25s 5ms/step - loss: 1597.9989 - accuracy: 0.3061 - val_loss: 1.6143 - val_accuracy: 0.3673\n",
      "Epoch 2/30\n",
      "1853/1853 [==============================] - 9s 5ms/step - loss: 3.4040 - accuracy: 0.3932 - val_loss: 1.5523 - val_accuracy: 0.3943\n",
      "Epoch 3/30\n",
      "1853/1853 [==============================] - 7s 4ms/step - loss: 3.2140 - accuracy: 0.4092 - val_loss: 1.5232 - val_accuracy: 0.3850\n",
      "Epoch 4/30\n",
      "1853/1853 [==============================] - 7s 4ms/step - loss: 6.3264 - accuracy: 0.4072 - val_loss: 1.4861 - val_accuracy: 0.4082\n",
      "Epoch 5/30\n",
      "1853/1853 [==============================] - 10s 5ms/step - loss: 3.1324 - accuracy: 0.4125 - val_loss: 1.5153 - val_accuracy: 0.3935\n",
      "Epoch 6/30\n",
      "1853/1853 [==============================] - 8s 4ms/step - loss: 3.0993 - accuracy: 0.4168 - val_loss: 1.4829 - val_accuracy: 0.3989\n",
      "Epoch 7/30\n",
      "1853/1853 [==============================] - ETA: 0s - loss: 3.0855 - accuracy: 0.4155Restoring model weights from the end of the best epoch: 4.\n",
      "1853/1853 [==============================] - 7s 4ms/step - loss: 3.0855 - accuracy: 0.4155 - val_loss: 1.5261 - val_accuracy: 0.3796\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef7ea25ee0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "             metrics='accuracy',\n",
    "             )\n",
    "\n",
    "model.fit(x=[np.array(mapped_lyrics_train), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(mapped_lyrics_test), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=30, batch_size=8,\n",
    "             class_weight = class_weights, callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDx2bBpkPvDc"
   },
   "source": [
    "# 7. Subgenre Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzB0krLdPvDc"
   },
   "source": [
    "once we have predicted a genre, let's see if we can predict the correct subgenres a song fits into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bcmUFXrPvDc"
   },
   "outputs": [],
   "source": [
    "df_train['lyric_token_array'] = [np.array(song) for song in train_tokens_prebuilt_new]\n",
    "df_test['lyric_token_array'] = [np.array(song) for song in test_tokens_prebuilt_new]\n",
    "\n",
    "def run_subgenre_model(major_genre, sub_genre_label, df_train, df_test, model_type = 'dan'):\n",
    "    # create df for major genre\n",
    "    df_train_major_genre = df_train[df_train['Major Genre'] == major_genre]\n",
    "    df_test_major_genre = df_test[df_test['Major Genre'] == major_genre]\n",
    "    \n",
    "    # now get an array of the tokens\n",
    "    train_tokens_prebuilt_major_genre = df_train_major_genre['lyric_token_array'].to_numpy()\n",
    "    test_tokens_prebuilt_major_genre  = df_test_major_genre['lyric_token_array'].to_numpy()\n",
    "    \n",
    "    # convert those tokens to a tensor (not sure why i have to do this, but its the only way i can get the model to run)\n",
    "    tensor_train_major_genre = tf.convert_to_tensor(np.array([np.array(song) for song in train_tokens_prebuilt_major_genre]))\n",
    "    tensor_test_major_genre = tf.convert_to_tensor(np.array([np.array(song) for song in test_tokens_prebuilt_major_genre]))\n",
    "    \n",
    "    # run the model\n",
    "    if model_type == 'dan':\n",
    "        dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix, output_activation = 'sigmoid', output_layer_size = 2)\n",
    "        dan_sorted_history = dan_model_sorted.fit(tensor_train_major_genre,\n",
    "                        np.array(df_train_major_genre[sub_genre_label]),\n",
    "                        validation_data=(tensor_test_major_genre, np.array(df_test_major_genre[sub_genre_label])),\n",
    "                        batch_size=8,\n",
    "                        epochs=100,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
    "                        callbacks = [es])\n",
    "        return(dan_model_sorted.predict(tensor_test_pop))\n",
    "        \n",
    "    elif model_type == 'wan':\n",
    "        wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix, output_layer_size = 1, output_activation = 'sigmoid',\n",
    "                                   num_attention=1, loss = tf.keras.losses.BinaryCrossentropy())\n",
    "        wan_sorted_history = wan_model_sorted.fit(tensor_train_major_genre,\n",
    "                        np.array(df_train_major_genre[sub_genre_label]),\n",
    "                        validation_data=(tensor_test_major_genre, np.array(df_test_major_genre[sub_genre_label])),\n",
    "                        batch_size=8,\n",
    "                        epochs=100,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
    "                        callbacks = [es])\n",
    "        return(wan_model_sorted.predict(tensor_test_pop))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JToGkZMIPvDc",
    "outputId": "f10a34d0-1d27-4459-bcc9-fd90b4fd1133",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 1000, 300)    13194600    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 1, 1000)      0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 1000)      0           ['reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      " dot_6 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 300)          0           ['dot_6[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 300)          0           ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 1, 300)       0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1, 1)         300         ['reshape_10[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_11 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_11[0][0]']             \n",
      "                                                                                                  \n",
      " dot_7 (Dot)                    (None, 300, 1)       0           ['reshape_10[0][0]',             \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 300)          0           ['dot_7[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " wan_classification (Dense)     (None, 1)            101         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,245,601\n",
      "Trainable params: 51,001\n",
      "Non-trainable params: 13,194,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 7s 20ms/step - loss: 0.2856 - accuracy: 0.9335 - val_loss: 0.2182 - val_accuracy: 0.9451\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.2372 - accuracy: 0.9344 - val_loss: 0.2036 - val_accuracy: 0.9451\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.2339 - accuracy: 0.9344 - val_loss: 0.2043 - val_accuracy: 0.9451\n",
      "Epoch 4/100\n",
      "266/267 [============================>.] - ETA: 0s - loss: 0.2301 - accuracy: 0.9342Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.2297 - accuracy: 0.9344 - val_loss: 0.2127 - val_accuracy: 0.9451\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "run_subgenre_model('Pop', 'Sub-Genre: electropop', df_train, df_test, 'wan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBbtTmrqPvDd"
   },
   "outputs": [],
   "source": [
    "pop_subgenres = ['Sub-Genre: electropop', 'Sub-Genre: new rave', 'Sub-Genre: post-teen pop', 'Sub-Genre: art pop', 'Sub-Genre: dance pop', 'Sub-Genre: pop', 'Sub-Genre: pop rap', 'Sub-Genre: pop rock', 'Sub-Genre: indie pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wF2ncjzPvDd",
    "outputId": "1d23310e-693e-42ed-82b6-fe68266bfedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 0.2786 - accuracy: 0.9344 - val_loss: 0.2109 - val_accuracy: 0.9451\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.2415 - accuracy: 0.9344 - val_loss: 0.2069 - val_accuracy: 0.9451\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.2357 - accuracy: 0.9344 - val_loss: 0.2044 - val_accuracy: 0.9451\n",
      "Epoch 4/100\n",
      "267/267 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9344Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.2286 - accuracy: 0.9344 - val_loss: 0.2063 - val_accuracy: 0.9451\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 4s 11ms/step - loss: 0.0729 - accuracy: 0.9963 - val_loss: 0.0245 - val_accuracy: 0.9971\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.0255 - accuracy: 0.9972 - val_loss: 0.0223 - val_accuracy: 0.9971\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.0253 - accuracy: 0.9972 - val_loss: 0.0239 - val_accuracy: 0.9971\n",
      "Epoch 4/100\n",
      "261/267 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9971Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.0254 - accuracy: 0.9972 - val_loss: 0.0232 - val_accuracy: 0.9971\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 4s 11ms/step - loss: 0.3839 - accuracy: 0.8824 - val_loss: 0.2912 - val_accuracy: 0.9104\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 0.3369 - accuracy: 0.8852 - val_loss: 0.2970 - val_accuracy: 0.9104\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.3318 - accuracy: 0.8852 - val_loss: 0.2944 - val_accuracy: 0.9104\n",
      "Epoch 4/100\n",
      "265/267 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8854Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.3294 - accuracy: 0.8852 - val_loss: 0.3027 - val_accuracy: 0.9104\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 4s 11ms/step - loss: 0.1147 - accuracy: 0.9873 - val_loss: 0.0789 - val_accuracy: 0.9884\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.0665 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9884\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 2s 7ms/step - loss: 0.0593 - accuracy: 0.9902 - val_loss: 0.0647 - val_accuracy: 0.9884\n",
      "Epoch 4/100\n",
      "264/267 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9905Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 3s 9ms/step - loss: 0.0588 - accuracy: 0.9902 - val_loss: 0.0692 - val_accuracy: 0.9884\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 8s 28ms/step - loss: 0.4094 - accuracy: 0.8650 - val_loss: 0.3572 - val_accuracy: 0.8728\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.3655 - accuracy: 0.8664 - val_loss: 0.3432 - val_accuracy: 0.8728\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.3617 - accuracy: 0.8664 - val_loss: 0.3351 - val_accuracy: 0.8728\n",
      "Epoch 4/100\n",
      "264/267 [============================>.] - ETA: 0s - loss: 0.3551 - accuracy: 0.8660Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.3549 - accuracy: 0.8664 - val_loss: 0.3337 - val_accuracy: 0.8728\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 0.5485 - accuracy: 0.7470 - val_loss: 0.4528 - val_accuracy: 0.8035\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.5160 - accuracy: 0.7470 - val_loss: 0.4466 - val_accuracy: 0.8035\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 3s 9ms/step - loss: 0.5072 - accuracy: 0.7470 - val_loss: 0.4507 - val_accuracy: 0.8035\n",
      "Epoch 4/100\n",
      "260/267 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.7462Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.5046 - accuracy: 0.7470 - val_loss: 0.4594 - val_accuracy: 0.8035\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 0.2302 - accuracy: 0.9527 - val_loss: 0.2260 - val_accuracy: 0.9335\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.1693 - accuracy: 0.9536 - val_loss: 0.2154 - val_accuracy: 0.9335\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.1612 - accuracy: 0.9536 - val_loss: 0.2192 - val_accuracy: 0.9335\n",
      "Epoch 4/100\n",
      "262/267 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9532Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.1540 - accuracy: 0.9536 - val_loss: 0.2068 - val_accuracy: 0.9335\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 3s 10ms/step - loss: 0.2748 - accuracy: 0.9391 - val_loss: 0.2175 - val_accuracy: 0.9422\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.2254 - accuracy: 0.9405 - val_loss: 0.2094 - val_accuracy: 0.9422\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.2204 - accuracy: 0.9405 - val_loss: 0.2087 - val_accuracy: 0.9422\n",
      "Epoch 4/100\n",
      "265/267 [============================>.] - ETA: 0s - loss: 0.2192 - accuracy: 0.9401Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.2183 - accuracy: 0.9405 - val_loss: 0.2085 - val_accuracy: 0.9422\n",
      "Epoch 4: early stopping\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dan_classification (Dense)  (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,245,102\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 13,194,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 3s 9ms/step - loss: 0.2196 - accuracy: 0.9555 - val_loss: 0.1973 - val_accuracy: 0.9509\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 3s 13ms/step - loss: 0.1827 - accuracy: 0.9564 - val_loss: 0.1903 - val_accuracy: 0.9509\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 2s 8ms/step - loss: 0.1784 - accuracy: 0.9564 - val_loss: 0.1864 - val_accuracy: 0.9509\n",
      "Epoch 4/100\n",
      "262/267 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 0.9571Restoring model weights from the end of the best epoch: 1.\n",
      "267/267 [==============================] - 2s 9ms/step - loss: 0.1731 - accuracy: 0.9564 - val_loss: 0.1873 - val_accuracy: 0.9509\n",
      "Epoch 4: early stopping\n"
     ]
    }
   ],
   "source": [
    "predicted_subgenres = []\n",
    "for sub_genre in pop_subgenres:\n",
    "    predictions = run_subgenre_model('Pop', sub_genre, df_train, df_test)\n",
    "    for pred in predictions:\n",
    "        single_pred = []\n",
    "        if pred[1] > pred[0]:\n",
    "            single_pred.append(sub_genre)\n",
    "        predicted_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lkdqpd0PPvDd",
    "outputId": "0368df2a-0285-4563-d8b3-9c5d3d73138a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 44ms/step\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = dan_model_sorted.predict(tensor_test_pop)\n",
    "rounded_predictions = []\n",
    "for prediction in predictions:\n",
    "    if prediction[0] > prediction[1]:\n",
    "        rounded_predictions.append(0)\n",
    "    else:\n",
    "        rounded_predictions.append(1)\n",
    "\n",
    "print(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dd6MiwjKPvDd"
   },
   "outputs": [],
   "source": [
    "subgenre_predictions = []\n",
    "for pred in rounded_predictions:\n",
    "    single_pred = []\n",
    "    if pred == 1:\n",
    "        single_pred.append('subgenre')\n",
    "    subgenre_predictions.append(single_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgqcPeXXPvDd"
   },
   "source": [
    "# 8. BERT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "d90c72579cb646079551103c732f0770",
      "7b9281b67f1d4847a5a12c243583a7af",
      "b74b3efd33cf4f1cb68f953ce64df4b5",
      "549bc7a2f1f34fed82be71e2ff403981",
      "fede47e020b24b33b70973f2368354a6",
      "26cfb653005a401c9873023531a3b214",
      "0ddc3de572e747b3a9af3231f97baffb",
      "bdc599fab9d84a739bf77810c816f678",
      "a19d3b02c85945bb94101dbb19f5eac3",
      "3a7cea6d31864643bb693575e802a166",
      "583e3ba45df74cb5bf80cfab7db15dff",
      "3b6c7b2fd344415389855cec0b503c50",
      "d4ff3361af4649e48b68c499df4b8ec5",
      "581ad14fabab4b828a51c34daaa5dedd",
      "79f42f28bacf4917ad260fdff4a44939",
      "6ba0ad9e0d154e9686c2df22060c6281",
      "69c0cc823f02429e96ccd9004f3c5301",
      "6fa43aff58174bacbc84b3443195d8a4",
      "546ab8aac5ad40408c33491746194b13",
      "98e89fd326604d8aa28d56d079e8fac9",
      "4e1619a6edd94b5a9f31f4f9144bcb26",
      "fd2d2a45fd654dce815110f7ce3b8c53",
      "2a7bc750c4424c32817015e5de481d4d",
      "f1dbf229fc39436b8de525a442333682",
      "656499608fd64e3f864179ca6c32d817",
      "5d8dfcab42cb4e48bcf458e1372f468d",
      "65eb48b74c104f31a6130529019543b2",
      "5364b89a3f5a4feebdb39104fe7e1908",
      "15a00f8bb5574b2aa558b7d04b9a5e2c",
      "e6c08e97aaae488dae290d9c5250cdfb",
      "aa38386ad94f45b3a654ad1f637bcf6e",
      "69f9f858699b4226a7d61257b5c0b317",
      "510844178fc4484fb215656f32b447ea"
     ]
    },
    "id": "FH4FqJcDPvDe",
    "outputId": "d0b531ac-192a-4e14-faf6-094d5d58f12a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90c72579cb646079551103c732f0770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6c7b2fd344415389855cec0b503c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7bc750c4424c32817015e5de481d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "aHlZk2VEPvDe",
    "outputId": "c7007372-94b5-4ac8-8249-574cda41ea9a"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Lyrics_String'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-40b672a80ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lyrics_String'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Lyrics_String'"
     ]
    }
   ],
   "source": [
    "#df_train['Lyrics_String']\n",
    "df_train['final_modified_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lX0L2NcWPvDe"
   },
   "outputs": [],
   "source": [
    "#train_bert_ids = bert_tokenizer(list(df_train['Lyrics_String']),\n",
    " #                              max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
    "#test_bert_ids = bert_tokenizer(list(df_test['Lyrics_String']),\n",
    " #                            max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
    "\n",
    "train_bert_ids = bert_tokenizer(list(df_train['final_modified_lyrics']),\n",
    "                               max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
    "test_bert_ids = bert_tokenizer(list(df_test['final_modified_lyrics']),\n",
    "                             max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "c112913ebbc94b51a3b44e390c2a884b",
      "c5a025221c8f400ca218beee6faf65c8",
      "c5ebc5d4679e49a0992b4793a52aab7f",
      "c28b77e093324a2fbcb4174c44bec661",
      "5f1b35e982b34fc9bc2291681e3f1e19",
      "1469420a34154e9f9257458b290507d2",
      "c03d0915a8c249618a4d84af34bf0669",
      "2e79aa4e1b6f4c4a858fc41ddafd1c3a",
      "e7b6924b8a3547b7a16397663358a36d",
      "96556f35e08247898751de10d37057ed",
      "9f6f23efebff447eba4e35867df061c6"
     ]
    },
    "id": "UGK29e_ZPvDe",
    "outputId": "f90cc49e-65c6-4450-dc5b-43a0eac08240"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c112913ebbc94b51a3b44e390c2a884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfWULamoPvDe"
   },
   "outputs": [],
   "source": [
    "def create_bert_model(train_layers=-1,\n",
    "                      embedding_dim=768,\n",
    "                      token = 'cls', # 'cls' or 'pooled' or 'avg'\n",
    "                      num_attention = 0,\n",
    "                      hidden_dim=[10,10,10],\n",
    "                      dropout_rate=0.3,\n",
    "                      hidden_layer_activation = 'relu',\n",
    "                      output_layer_size = 4,\n",
    "                      output_activation = 'softmax',\n",
    "                      learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load BERT\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers (SPECIFY WHICH BERT LAYERS ARE TRAINABLE)\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "    \n",
    "    #Input Layer\n",
    "    input_ids = tf.keras.layers.Input(shape = (512,),dtype=tf.int64, name='input_ids_layer') \n",
    "    #Get Contextual Embeddings + Single Vector Representations of Input (CLS or Pooled)\n",
    "    bert_out = bert_model(input_ids) \n",
    "    \n",
    "    if token == 'cls':\n",
    "        token = bert_out[0][:,0] #Get CLS Tokens\n",
    "    elif token == 'pooled':\n",
    "        token = bert_out[1] #Pooled Token\n",
    "    elif token == 'avg':\n",
    "        token = tf.math.reduce_mean(bert_out[0][:,1:-1],axis=1)\n",
    "    elif token == 'word_embeddings':\n",
    "        token = bert_out[0][:,1:-1]\n",
    "    \n",
    "    # Attention to Combine CLS/Pooled Tokens into single representation in the event of chunking text for single example\n",
    "    if num_attention == 0: # Single CLS/Pooled Token\n",
    "        embedding = token\n",
    "    elif num_attention == 1:\n",
    "        #Apply Query Vector to BERT Token, returning a num_attention x 1 tensor\n",
    "        query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(token)\n",
    "        if token.shape == (None,768):\n",
    "            reshaped_query = tf.keras.layers.Reshape((1,1))(query)\n",
    "            token = tf.keras.layers.Reshape((1,token.shape[1]))(token)\n",
    "        else:\n",
    "            reshaped_query = tf.keras.layers.Reshape((1,token.shape[1]))(query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights')(reshaped_query)\n",
    "        #weight attention embeddings according to weights\n",
    "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((token,weights)))\n",
    "    else:\n",
    "        #Create attention based single vector representations of words according to alternative query vectors\n",
    "        attention_embeddings = []\n",
    "        for num in range(num_attention):\n",
    "            #Apply Query Vector to words in embeddings, returning a embedding_dim x 1 tensor\n",
    "            l1_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query_l' + str(num+1))(token)\n",
    "            if token.shape == (None,768):\n",
    "                l1_reshaped_query = tf.keras.layers.Reshape((1,1))(l1_query)\n",
    "                l1_token = tf.keras.layers.Reshape((1,token.shape[1]))(token)\n",
    "            else:\n",
    "                l1_reshaped_query = tf.keras.layers.Reshape((1,token.shape[1]))(l1_query)\n",
    "                l1_token = token\n",
    "                \n",
    "            #Softmax over query * key (words) to obtain weights\n",
    "            l1_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                                name='attention_weights_l' + str(num+1))(l1_reshaped_query)\n",
    "            \n",
    "            #weight attention embeddings according to weights\n",
    "            l1_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((l1_token,l1_weights)))\n",
    "            attention_embeddings.append(l1_attention)\n",
    "\n",
    "        concat_attention = tf.keras.layers.Concatenate()(attention_embeddings)\n",
    "        concat_attention = tf.keras.layers.Reshape((num_attention,embedding_dim))(concat_attention)\n",
    "        \n",
    "        #Apply Query Vector to BERT Embeddings with Various Attention-Based representations, returning a num_attention x 1 tensor\n",
    "        query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(concat_attention)\n",
    "        #reshape to 1 x num_attention\n",
    "        reshaped_query = tf.keras.layers.Reshape((1,num_attention))(query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights')(reshaped_query)\n",
    "        #weight attention embeddings according to weights\n",
    "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((concat_attention,weights)))\n",
    "        \n",
    "    x = embedding\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "\n",
    "    bert_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation,name='classification_layer')(x)\n",
    "    \n",
    "    bert_model = tf.keras.Model(inputs=[input_ids], outputs=[bert_classification])\n",
    "    \n",
    "    bert_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics=['accuracy'],\n",
    "                     run_eagerly=True) \n",
    "    \n",
    "    print(bert_model.summary())\n",
    "    \n",
    "    return bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cVfixhBPvDf",
    "outputId": "b89e73d1-4b9b-494b-d1a8-20dbd61d4c99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids_layer (InputLayer)   [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_ids_layer[0][0]']        \n",
      "                                thPoolingAndCrossAt                                               \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 512,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 510, 768)    0           ['tf_bert_model_1[0][0]']        \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " attention_query_l1 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " attention_query_l2 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " attention_query_l3 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " attention_query_l4 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " attention_query_l5 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 510)       0           ['attention_query_l1[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 510)       0           ['attention_query_l2[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 510)       0           ['attention_query_l3[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 510)       0           ['attention_query_l4[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 510)       0           ['attention_query_l5[0][0]']     \n",
      "                                                                                                  \n",
      " attention_weights_l1 (Lambda)  (None, 1, 510)       0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " attention_weights_l2 (Lambda)  (None, 1, 510)       0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " attention_weights_l3 (Lambda)  (None, 1, 510)       0           ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " attention_weights_l4 (Lambda)  (None, 1, 510)       0           ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " attention_weights_l5 (Lambda)  (None, 1, 510)       0           ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'attention_weights_l1[0][0]']  \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'attention_weights_l2[0][0]']  \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                    (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'attention_weights_l3[0][0]']  \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                    (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'attention_weights_l4[0][0]']  \n",
      "                                                                                                  \n",
      " dot_4 (Dot)                    (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'attention_weights_l5[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 768)          0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 768)          0           ['dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 768)          0           ['dot_2[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 768)          0           ['dot_3[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 768)          0           ['dot_4[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3840)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 5, 768)       0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 5, 1)         768         ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 5)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 5)         0           ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " dot_5 (Dot)                    (None, 768, 1)       0           ['reshape_5[0][0]',              \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 768)          0           ['dot_5[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 50)           38450       ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50)           0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 50)           2550        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 50)           0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 50)           2550        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 50)           0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 7)            357         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,530,755\n",
      "Trainable params: 109,530,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/13 [=>............................] - ETA: 8:13 - loss: 1.8959 - accuracy: 0.2500WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 2/13 [===>..........................] - ETA: 7:29 - loss: 2.5921 - accuracy: 0.1250WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 3/13 [=====>........................] - ETA: 6:33 - loss: 2.5171 - accuracy: 0.0833WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 4/13 [========>.....................] - ETA: 5:48 - loss: 2.4308 - accuracy: 0.0625WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 5/13 [==========>...................] - ETA: 5:04 - loss: 2.6485 - accuracy: 0.0750WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 6/13 [============>.................] - ETA: 4:34 - loss: 2.6062 - accuracy: 0.0833"
     ]
    }
   ],
   "source": [
    "cls_bert_model = create_bert_model(learning_rate=0.0005,output_layer_size=7,num_attention=2,token='word_embeddings')\n",
    "                        \n",
    "cls_bert_model.fit(train_bert_ids[:100], df_train['Major Genre'].map(mapping).iloc[:100], \n",
    "                   validation_data=(test_bert_ids[:100],df_test['Major Genre'].map(mapping).iloc[:100]),\n",
    "                   batch_size=8, epochs=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk3Z_8CkPvDf"
   },
   "source": [
    "# 9 Extra Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLMuJyexPvDf",
    "outputId": "b8e7089f-6543-46e5-9551-0192596e59ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16303    [go, take, life, dreams, fire, go, take, day, ...\n",
       "8721     [bitch, one, click, ruin, life, trip, yea, tak...\n",
       "11930    [eyes, like, face, bit, different, bit, fucked...\n",
       "7945     [ugh, ugh, what, what, ugh, what, what, ugh, u...\n",
       "15504    [age, darkness, light, appears, wards, away, a...\n",
       "                               ...                        \n",
       "7303     [saucey, genius, aztro, cut, put, magnum, bott...\n",
       "9125     [i’ve, loved, /, i’ve, done, months, made, fee...\n",
       "5125     [another, it's, kel, p, vibes, wanna, give, ev...\n",
       "15805    [woke, mornin', understand, means, give, life,...\n",
       "2952     [läppar, döljer, dina, tänder, och, din, tunga...\n",
       "Name: Lyrics, Length: 14778, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nML6-HQvPvDg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-w-95itPvDg"
   },
   "source": [
    "# 10 Term Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBRtbybGPvDg"
   },
   "outputs": [],
   "source": [
    "term_freq = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0n9qsPvIPvDh"
   },
   "outputs": [],
   "source": [
    "df_test = pkl.load(open('genre_sub_genre_test.pkl', 'rb'))\n",
    "df_train = pkl.load(open('genre_sub_genre_train.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDr-t1lwaM1F"
   },
   "outputs": [],
   "source": [
    "df_train = df_train[:8250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 852
    },
    "id": "GeKSL5a7PvDh",
    "outputId": "94888364-3790-4df4-ec48-509088ec7f4a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-740dda0c-8eff-4622-b38e-030fc1dda5f2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub-Genre: modern alternative rock</th>\n",
       "      <th>Sub-Genre: southern hip hop</th>\n",
       "      <th>Sub-Genre: nu metal</th>\n",
       "      <th>Sub-Genre: israeli mediterranean</th>\n",
       "      <th>Sub-Genre: thrash metal</th>\n",
       "      <th>Sub-Genre: pop rock</th>\n",
       "      <th>Sub-Genre: chicago blues</th>\n",
       "      <th>Sub-Genre: indie pop</th>\n",
       "      <th>Sub-Genre: classic rock</th>\n",
       "      <th>Sub-Genre: hardcore hip hop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stevie Ray Vaughan</td>\n",
       "      <td>Life By The Drop</td>\n",
       "      <td>51</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.163</td>\n",
       "      <td>6</td>\n",
       "      <td>-11.864</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.76600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DARKSIDE</td>\n",
       "      <td>Paper Trails</td>\n",
       "      <td>55</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.419</td>\n",
       "      <td>8</td>\n",
       "      <td>-13.043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.77800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Christone \"Kingfish\" Ingram</td>\n",
       "      <td>Outside Of This Town</td>\n",
       "      <td>48</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.866</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.033</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0513</td>\n",
       "      <td>0.00381</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Jesse Cook</td>\n",
       "      <td>I Put A Spell On You</td>\n",
       "      <td>34</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.373</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.302</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.92200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Christone \"Kingfish\" Ingram</td>\n",
       "      <td>Before I'm Old</td>\n",
       "      <td>41</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.649</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.526</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.04380</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>Woolbright</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>23</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.819</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.01220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19321</th>\n",
       "      <td>Runnin' Wild</td>\n",
       "      <td>How You Want It Done</td>\n",
       "      <td>27</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.953</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.539</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>0.07710</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19344</th>\n",
       "      <td>Four Year Strong</td>\n",
       "      <td>Go Down in History</td>\n",
       "      <td>48</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.985</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19355</th>\n",
       "      <td>Nathaniel Rateliff &amp; The Night Sweats</td>\n",
       "      <td>S.O.B.</td>\n",
       "      <td>66</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.579</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.26700</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19356</th>\n",
       "      <td>Muskets</td>\n",
       "      <td>17 Years</td>\n",
       "      <td>31</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.935</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.677</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2581 rows × 72 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-740dda0c-8eff-4622-b38e-030fc1dda5f2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-740dda0c-8eff-4622-b38e-030fc1dda5f2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-740dda0c-8eff-4622-b38e-030fc1dda5f2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                 Artist Name            Track Name  \\\n",
       "5                         Stevie Ray Vaughan      Life By The Drop   \n",
       "6                                   DARKSIDE          Paper Trails   \n",
       "11               Christone \"Kingfish\" Ingram  Outside Of This Town   \n",
       "28                                Jesse Cook  I Put A Spell On You   \n",
       "31               Christone \"Kingfish\" Ingram        Before I'm Old   \n",
       "...                                      ...                   ...   \n",
       "19316                             Woolbright               Tuesday   \n",
       "19321                           Runnin' Wild  How You Want It Done   \n",
       "19344                       Four Year Strong    Go Down in History   \n",
       "19355  Nathaniel Rateliff & The Night Sweats                S.O.B.   \n",
       "19356                                Muskets              17 Years   \n",
       "\n",
       "       Popularity  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "5              51         0.659   0.163    6   -11.864     0       0.0388   \n",
       "6              55         0.947   0.419    8   -13.043     0       0.0578   \n",
       "11             48         0.418   0.866   11    -4.033     0       0.0513   \n",
       "28             34         0.420   0.373    1    -9.302     0       0.0320   \n",
       "31             41         0.534   0.649    2    -5.526     1       0.0410   \n",
       "...           ...           ...     ...  ...       ...   ...          ...   \n",
       "19316          23         0.514   0.819   11    -6.713     0       0.0375   \n",
       "19321          27         0.614   0.953    9    -3.539     1       0.0517   \n",
       "19344          48         0.505   0.985    5    -4.401     1       0.1190   \n",
       "19355          66         0.699   0.579    1    -6.504     1       0.0416   \n",
       "19356          31         0.446   0.935    8    -4.677     1       0.0357   \n",
       "\n",
       "       acousticness  ...  Sub-Genre: modern alternative rock  \\\n",
       "5           0.76600  ...                                   0   \n",
       "6           0.77800  ...                                   0   \n",
       "11          0.00381  ...                                   0   \n",
       "28          0.92200  ...                                   0   \n",
       "31          0.04380  ...                                   0   \n",
       "...             ...  ...                                 ...   \n",
       "19316       0.01220  ...                                   0   \n",
       "19321       0.07710  ...                                   0   \n",
       "19344       0.00006  ...                                   0   \n",
       "19355       0.26700  ...                                   0   \n",
       "19356       0.00007  ...                                   0   \n",
       "\n",
       "       Sub-Genre: southern hip hop  Sub-Genre: nu metal  \\\n",
       "5                                0                    0   \n",
       "6                                0                    0   \n",
       "11                               0                    0   \n",
       "28                               0                    0   \n",
       "31                               0                    0   \n",
       "...                            ...                  ...   \n",
       "19316                            0                    0   \n",
       "19321                            0                    0   \n",
       "19344                            0                    0   \n",
       "19355                            0                    0   \n",
       "19356                            0                    0   \n",
       "\n",
       "       Sub-Genre: israeli mediterranean Sub-Genre: thrash metal  \\\n",
       "5                                     0                       0   \n",
       "6                                     0                       0   \n",
       "11                                    0                       0   \n",
       "28                                    0                       0   \n",
       "31                                    0                       0   \n",
       "...                                 ...                     ...   \n",
       "19316                                 0                       0   \n",
       "19321                                 0                       0   \n",
       "19344                                 0                       0   \n",
       "19355                                 0                       0   \n",
       "19356                                 0                       0   \n",
       "\n",
       "      Sub-Genre: pop rock Sub-Genre: chicago blues Sub-Genre: indie pop  \\\n",
       "5                       0                        0                    0   \n",
       "6                       0                        0                    0   \n",
       "11                      0                        0                    0   \n",
       "28                      0                        0                    0   \n",
       "31                      0                        0                    0   \n",
       "...                   ...                      ...                  ...   \n",
       "19316                   0                        0                    0   \n",
       "19321                   0                        0                    0   \n",
       "19344                   0                        0                    0   \n",
       "19355                   0                        0                    0   \n",
       "19356                   0                        0                    0   \n",
       "\n",
       "       Sub-Genre: classic rock  Sub-Genre: hardcore hip hop  \n",
       "5                            1                            0  \n",
       "6                            0                            0  \n",
       "11                           0                            0  \n",
       "28                           0                            0  \n",
       "31                           0                            0  \n",
       "...                        ...                          ...  \n",
       "19316                        0                            0  \n",
       "19321                        0                            0  \n",
       "19344                        0                            0  \n",
       "19355                        0                            0  \n",
       "19356                        0                            0  \n",
       "\n",
       "[2581 rows x 72 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out results\n",
    "df_train.drop(df_train[df_train['Lyrics'].str.len() > 5000].index, inplace=True)\n",
    "df_train[df_train['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
    "df_train[df_train['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
    "\n",
    "df_test.drop(df_test[df_test['Lyrics'].str.len() > 5000].index, inplace=True)\n",
    "df_test[df_test['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
    "df_test[df_test['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-u9GNgFDkhDI",
    "outputId": "dfee6708-1d68-4c04-bd32-3407a8f0dd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock           2406\n",
      "Indie          1196\n",
      "Pop            1057\n",
      "Metal           934\n",
      "Alternative     720\n",
      "Hip Hop         675\n",
      "Blues           420\n",
      "Name: Major Genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_labels = df_train['Major Genre']\n",
    "test_labels = df_test['Major Genre']\n",
    "print(train_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff9Fne58yB2W",
    "outputId": "7a4a47cd-e1e7-4da8-e771-3ed5ef35dfe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock           781\n",
      "Indie          427\n",
      "Metal          353\n",
      "Pop            346\n",
      "Hip Hop        272\n",
      "Alternative    239\n",
      "Blues          163\n",
      "Name: Major Genre, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEU-dAQPmGEa",
    "outputId": "7a0d414a-4baa-41a1-bc9b-985fab9d8a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rock': 0, 'Indie': 1, 'Alternative': 2, 'Hip Hop': 3, 'Metal': 4, 'Pop': 5, 'Blues': 6}\n"
     ]
    }
   ],
   "source": [
    "# create mapper so we can use numeric labels in our networks\n",
    "mapping = {}\n",
    "count = 0\n",
    "for label in train_labels.unique():\n",
    "    mapping[label] = count\n",
    "    count = count + 1\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcgqPbMQkdf-",
    "outputId": "65b70a76-82ff-48ef-c2cb-c36ac4c73e82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0,\n",
       " 1: 2.011705685618729,\n",
       " 2: 3.341666666666667,\n",
       " 3: 3.5644444444444443,\n",
       " 4: 2.576017130620985,\n",
       " 5: 2.2762535477767267,\n",
       " 6: 5.728571428571429}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = 2406/train_labels.value_counts()\n",
    "class_weights = {}\n",
    "for num in range(len(weights)):\n",
    "    class_weights[mapping[weights.index[num]]] = weights.iloc[num]\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5HSpXBJPvDh",
    "outputId": "68b6c75b-9432-4c8c-d31d-fddf9691ef52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16303    Unbreakable Lyrics[Intro]\\nGo take it all\\nYou...\n",
       "8721     NOBODY LyricsTake a bitch\\nThat I have in one ...\n",
       "11930    Worth It Lyrics[Verse 1]\\nYour eyes are just l...\n",
       "7945     Bloodrush Lyrics[Intro: Denzel Curry]\\nUgh\\nUg...\n",
       "15504    Age of Man Lyrics[Intro]\\nIn an age of darknes...\n",
       "                               ...                        \n",
       "3883     Kid Milli & dress - Kitty ft. MIYEON (Romanize...\n",
       "2531     Earthless Lyrics[Verse 1]\\nDescending through ...\n",
       "1133     We Get By Lyrics[Verse 1: Mavis Staples and Be...\n",
       "14500    Fly Away LyricsI wish that I could fly\\nInto t...\n",
       "4249     Shney Yeladim Ba’olam - שני ילדים בעולם Lyrics...\n",
       "Name: Lyrics, Length: 7408, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Fj94ZqSPvDh"
   },
   "outputs": [],
   "source": [
    "df_train['modified_lyrics'] = df_train['Lyrics'].apply(lambda x: ' '.join(str(x).split('Lyrics')[1:]).lower())\n",
    "df_test['modified_lyrics'] = df_test['Lyrics'].apply(lambda x: ' '.join(str(x).split('Lyrics')[1:]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLmGOsaOPvDi"
   },
   "outputs": [],
   "source": [
    "df_train['modified_lyrics'] = df_train['modified_lyrics'].apply(lambda x: split_text_into_regions(x))\n",
    "df_test['modified_lyrics'] = df_test['modified_lyrics'].apply(lambda x: split_text_into_regions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zxyJVI9PvDi",
    "outputId": "bf4f4c5c-8f57-4888-af60-b93d1ff7d7cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16303    [[go take it all, your life, your dreams, your...\n",
       "8721     [[take a bitch, that i have in one click, ruin...\n",
       "11930    [[your eyes are just like his, but your face i...\n",
       "7945     [[ugh, ugh,  ugh,  ugh, ugh], [behind every sm...\n",
       "15504    [[in an age of darkness light appears, and it ...\n",
       "                               ...                        \n",
       "3883     [[i don't tryna be a good boy, nae saenggage, ...\n",
       "2531     [[descending through the mouth, engulfing teet...\n",
       "1133     [[we get by on love and faith, we get by with ...\n",
       "14500    [[i wish that i could fly, into the sky so ver...\n",
       "4249     [[איך הכל ממהר לי פתאום, רציתי לראות את השמיים...\n",
       "Name: modified_lyrics, Length: 7408, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['modified_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xboQsTKZPvDi"
   },
   "outputs": [],
   "source": [
    "df_train['final_modified_lyrics'] = df_train['modified_lyrics'].apply(lambda x: single_text_lyrics(x))\n",
    "df_test['final_modified_lyrics'] = df_test['modified_lyrics'].apply(lambda x: single_text_lyrics(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVcMZEe2rcLF",
    "outputId": "5e5888b5-2eff-485c-92ba-55ab96bdbafc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16303    go take it all your life, your dreams, your fi...\n",
       "8721     take a bitch that i have in one click ruin my ...\n",
       "11930    your eyes are just like his but your face is a...\n",
       "7945     ugh ugh  ugh  ugh ugh behind every smile, it b...\n",
       "15504    in an age of darkness light appears and it war...\n",
       "                               ...                        \n",
       "3883     i don't tryna be a good boy nae saenggage you ...\n",
       "2531     descending through the mouth engulfing teeth p...\n",
       "1133     we get by on love and faith we get by with a s...\n",
       "14500    i wish that i could fly into the sky so very h...\n",
       "4249     איך הכל ממהר לי פתאום רציתי לראות את השמיים שנ...\n",
       "Name: final_modified_lyrics, Length: 7408, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['final_modified_lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b64ZEK8MPvDj",
    "outputId": "086d5fbf-bf50-46d7-97da-1ae50eb7ca78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq.fit(df_train['final_modified_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hY8j63pdPvDj",
    "outputId": "e9f13bb0-cbdc-44bc-8bd9-cd8691cb9c56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_term_df = pd.DataFrame(term_freq.transform(df_train['final_modified_lyrics']).todense(), columns = term_freq.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wtUuUowBYxei",
    "outputId": "edba7d39-34e5-41e0-e36d-7750490fce6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7408, 66198)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_term_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOmLruKrPvDj"
   },
   "outputs": [],
   "source": [
    "train_term_sums = np.array(train_term_df.sum(axis = 1)).astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwE1X3olPvDj",
    "outputId": "91aa0b0d-3a09-464b-e6db-0fedcfa64540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.0\n"
     ]
    }
   ],
   "source": [
    "print(train_term_sums[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7tqcp2SPvDj",
    "outputId": "ce3bf4ed-0ab5-4026-e7eb-0e79b4b386a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_term_sums_reshaped = train_term_sums.repeat(len(term_freq.get_feature_names())).reshape(train_term_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdI5o6s6PvDj"
   },
   "outputs": [],
   "source": [
    "# bigger numbers = better words for that song\n",
    "train_term_df = (train_term_df / train_term_sums_reshaped).astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I9dC2VkMbBZN",
    "outputId": "5befe411-1294-428c-aba6-d08eb47c4713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7408, 74)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_term_df.shape\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjiNa02Paucv",
    "outputId": "fa5dd673-30c4-4ade-ef53-1a5eb0389aa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_term_df = pd.DataFrame(term_freq.transform(df_test['final_modified_lyrics']).todense(), columns = term_freq.get_feature_names())\n",
    "test_term_sums = np.array(test_term_df.sum(axis = 1)).astype('float16')\n",
    "test_term_sums_reshaped = test_term_sums.repeat(len(term_freq.get_feature_names())).reshape(test_term_df.shape)\n",
    "test_term_df = (test_term_df / test_term_sums_reshaped).astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xK_4QTZGxBft",
    "outputId": "9402c41f-ccb5-4a6d-fa43-d1c594b192e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16303    0\n",
      "8721     1\n",
      "11930    2\n",
      "7945     3\n",
      "15504    0\n",
      "Name: Major Genre, dtype: int64\n",
      "16303           Rock\n",
      "8721           Indie\n",
      "11930    Alternative\n",
      "7945         Hip Hop\n",
      "15504           Rock\n",
      "Name: Major Genre, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.map(mapping)[0:5])\n",
    "print(train_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKFFVR5_xziF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjKrIfSFxspR",
    "outputId": "0cdb37b9-9bf9-4386-c480-43a3cd08d4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5     6\n",
      "6     6\n",
      "11    6\n",
      "28    6\n",
      "31    6\n",
      "Name: Major Genre, dtype: int64\n",
      "5     Blues\n",
      "6     Blues\n",
      "11    Blues\n",
      "28    Blues\n",
      "31    Blues\n",
      "Name: Major Genre, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_labels.map(mapping)[0:5])\n",
    "print(test_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbpI8zUY0leC",
    "outputId": "0169e95a-7c5a-4da3-8831-673b6654a30d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00              0.000000\n",
       "thes            0.000000\n",
       "thesaurus       0.000000\n",
       "thescrivener    0.000000\n",
       "these           0.000000\n",
       "                  ...   \n",
       "how             0.027176\n",
       "that            0.032623\n",
       "living          0.043488\n",
       "the             0.054352\n",
       "it              0.054352\n",
       "Name: 0, Length: 66198, dtype: float16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_term_df.iloc[0].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJOdkNhY1ZQr",
    "outputId": "a35f0b08-05a9-4f26-f348-064ab4e5cbc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00              0.000000\n",
       "thesaurus       0.000000\n",
       "thescrivener    0.000000\n",
       "these           0.000000\n",
       "thesis          0.000000\n",
       "                  ...   \n",
       "go              0.040649\n",
       "the             0.040649\n",
       "on              0.048767\n",
       "to              0.065063\n",
       "you             0.081299\n",
       "Name: 1, Length: 66198, dtype: float16"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_term_df.iloc[1].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gVDV-1cbKfL",
    "outputId": "284a7201-b9c3-48c4-c6c3-d7a73ce96f54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "926/926 [==============================] - 19s 20ms/step - loss: nan - accuracy: 0.3224 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 2/10\n",
      "926/926 [==============================] - 14s 15ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 3/10\n",
      "926/926 [==============================] - 14s 15ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 4/10\n",
      "926/926 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 5/10\n",
      "926/926 [==============================] - 15s 17ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 6/10\n",
      "926/926 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 7/10\n",
      "926/926 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 8/10\n",
      "926/926 [==============================] - 14s 16ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 9/10\n",
      "926/926 [==============================] - 14s 15ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 10/10\n",
      "926/926 [==============================] - 14s 15ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a0573b210>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first lets see if we can do a basic FFN with just the dfs\n",
    "# a standard feed-forward network\n",
    "# note: audio features have been normalized\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(50,activation='leaky_relu'),\n",
    "    keras.layers.Dense(50,activation='leaky_relu'),\n",
    "    keras.layers.Dense(10,activation='leaky_relu'),\n",
    "    keras.layers.Dense(7,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#Compile the model, specifying loss function, optimizer, and performance metric\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
    "             metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "\n",
    "#model.fit(x = np.array(train_term_df),y = train_labels.map(mapping),batch_size=20,epochs=3,\n",
    "  #       validation_data = (np.array(test_term_df), test_labels.map(mapping)),\n",
    "   #      use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1)\n",
    "\n",
    "model.fit(x = np.array(train_term_df),y = train_labels.map(mapping),batch_size=8,epochs=10,\n",
    "         validation_data = (np.array(test_term_df) ,test_labels.map(mapping)),\n",
    "         use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1, class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_ARbN7fxrrR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWfSElahPvDk"
   },
   "outputs": [],
   "source": [
    "# let's try with audio features too...this will be a big model\n",
    "# define two sets of inputs\n",
    "inputA = Input(shape=(66198,))\n",
    "inputB = Input(shape=(9,))\n",
    "# the first branch operates on the first input\n",
    "x = Dense(1000, activation=\"relu\")(inputA)\n",
    "x = Dense(1000, activation=\"relu\")(x)\n",
    "x = Dense(100, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(10, activation=\"relu\")(inputB)\n",
    "y = Dense(50, activation=\"relu\")(y)\n",
    "y = Dense(100, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "# apply a FC layer and then a classification prediction on the\n",
    "# combined outputs\n",
    "z = Dense(50, activation=\"relu\")(combined)\n",
    "z = Dense(20, activation=\"relu\")(z)\n",
    "z = Dense(7, activation=\"softmax\")(z)\n",
    "#z = Dense(1, activation=\"linear\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bhHoPisdoJu"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "             metrics='accuracy',\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "aFIiI8h3d5fN",
    "outputId": "79299943-8499-48a6-9912-97b765a10934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "926/926 [==============================] - 211s 227ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
      "Epoch 2/10\n",
      " 66/926 [=>............................] - ETA: 3:06 - loss: nan - accuracy: 0.2803"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c97fb2182e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m  \u001b[0;31m#            class_weight = class_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_term_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_audio_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_term_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_audio_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model.fit(x=[np.array(train_term_df), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_term_df), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8,\n",
    " #            class_weight = class_weights)\n",
    "\n",
    "model.fit(x=[np.array(train_term_df), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_term_df), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quK3IY19dB4W"
   },
   "outputs": [],
   "source": [
    "# concatenate with audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability                                                              0.727\n",
       "energy                                                                    0.905\n",
       "loudness                                                                 -5.274\n",
       "speechiness                                                              0.0376\n",
       "acousticness                                                              0.126\n",
       "instrumentalness                                                         0.0358\n",
       "liveness                                                                  0.125\n",
       "valence                                                                   0.876\n",
       "tempo                                                                   135.969\n",
       "duration_ms                                                              193227\n",
       "Lyrics                        deep dive slithering height of the skyline blu...\n",
       "Major Genre                                                               Indie\n",
       "Lyric Group                   [[deep dive, slithering height of the skyline,...\n",
       "Cleaner Lyrics                deep dive slithering height of the skyline blu...\n",
       "final_modified_lyrics_list    deep dive slithering height of the skyline blu...\n",
       "Lyric_Tokens                  [43981, 4757, 4757, 14412, 43981, 43981, 16266...\n",
       "Lyrics_String                 d e e p   d i v e   s l i t h e r i n g   h e ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability                                                              0.252\n",
       "energy                                                                    0.872\n",
       "loudness                                                                 -3.752\n",
       "speechiness                                                              0.0777\n",
       "acousticness                                                            0.00912\n",
       "instrumentalness                                                       0.000009\n",
       "liveness                                                                  0.109\n",
       "valence                                                                   0.399\n",
       "tempo                                                                   126.938\n",
       "duration_ms                                                              236360\n",
       "Lyrics                        and how does it feel like to wake up in the su...\n",
       "Major Genre                                                               Indie\n",
       "Lyric Group                   [[and how does it feel like, to wake up in the...\n",
       "Cleaner Lyrics                and how does it feel like to wake up in the su...\n",
       "final_modified_lyrics_list    and how does it feel like to wake up in the su...\n",
       "Lyric_Tokens                  [43981, 8663, 43981, 43981, 35368, 25480, 1258...\n",
       "Lyrics_String                 a n d   h o w   d o e s   i t   f e e l   l i ...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability                                                              0.456\n",
       "energy                                                                    0.961\n",
       "loudness                                                                 -4.353\n",
       "speechiness                                                              0.0772\n",
       "acousticness                                                           0.000288\n",
       "instrumentalness                                                        0.00201\n",
       "liveness                                                                  0.366\n",
       "valence                                                                   0.712\n",
       "tempo                                                                    76.547\n",
       "duration_ms                                                              118720\n",
       "Lyrics                        let's pretend this is a family trip we're stuc...\n",
       "Major Genre                                                         Alternative\n",
       "Lyric Group                   [[let's pretend this is a family trip, we're s...\n",
       "Cleaner Lyrics                let's pretend this is a family trip we're stuc...\n",
       "final_modified_lyrics_list    let's pretend this is a family trip we're stuc...\n",
       "Lyric_Tokens                  [2943, 4757, 25911, 43981, 43981, 43981, 14412...\n",
       "Lyrics_String                 l e t ' s   p r e t e n d   t h i s   i s   a ...\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability                                                              0.428\n",
       "energy                                                                    0.804\n",
       "loudness                                                                  -4.84\n",
       "speechiness                                                              0.0564\n",
       "acousticness                                                             0.0544\n",
       "instrumentalness                                                       0.000008\n",
       "liveness                                                                  0.124\n",
       "valence                                                                   0.595\n",
       "tempo                                                                   184.238\n",
       "duration_ms                                                              197232\n",
       "Lyrics                        i didn't like you when you first told me your ...\n",
       "Major Genre                                                               Indie\n",
       "Lyric Group                   [[i didn't like you, when you first told me yo...\n",
       "Cleaner Lyrics                i didn't like you when you first told me your ...\n",
       "final_modified_lyrics_list    i didn't like you when you first told me your ...\n",
       "Lyric_Tokens                  [16266, 43981, 43981, 16266, 43981, 8663, 4398...\n",
       "Lyrics_String                 i   d i d n ' t   l i k e   y o u   w h e n   ...\n",
       "Name: 9, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability                                                              0.472\n",
       "energy                                                                    0.735\n",
       "loudness                                                                 -9.822\n",
       "speechiness                                                              0.0305\n",
       "acousticness                                                            0.00596\n",
       "instrumentalness                                                        0.00124\n",
       "liveness                                                                  0.166\n",
       "valence                                                                   0.643\n",
       "tempo                                                                   110.809\n",
       "duration_ms                                                              186733\n",
       "Lyrics                        stop it! ooh-ooh, ooh-ooh-ooh-ooh ooh-ooh, ooh...\n",
       "Major Genre                                                         Alternative\n",
       "Lyric Group                   [[stop it!], [ooh-ooh, ooh-ooh-ooh-ooh, ooh-oo...\n",
       "Cleaner Lyrics                stop it! ooh-ooh, ooh-ooh-ooh-ooh ooh-ooh, ooh...\n",
       "final_modified_lyrics_list    stop it! ooh-ooh, ooh-ooh-ooh-ooh ooh-ooh, ooh...\n",
       "Lyric_Tokens                  [43981, 25911, 25480, 14412, 43981, 16266, 259...\n",
       "Lyrics_String                 s t o p   i t !   o o h - o o h ,   o o h - o ...\n",
       "Name: 22, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "B8pWPtfJPvDZ",
    "NDx2bBpkPvDc",
    "JgqcPeXXPvDd",
    "Uk3Z_8CkPvDf",
    "n-w-95itPvDg"
   ],
   "machine_shape": "hm",
   "name": "Genre_Prediction_new.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ddc3de572e747b3a9af3231f97baffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1469420a34154e9f9257458b290507d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15a00f8bb5574b2aa558b7d04b9a5e2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26cfb653005a401c9873023531a3b214": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a7bc750c4424c32817015e5de481d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1dbf229fc39436b8de525a442333682",
       "IPY_MODEL_656499608fd64e3f864179ca6c32d817",
       "IPY_MODEL_5d8dfcab42cb4e48bcf458e1372f468d"
      ],
      "layout": "IPY_MODEL_65eb48b74c104f31a6130529019543b2"
     }
    },
    "2e79aa4e1b6f4c4a858fc41ddafd1c3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a7cea6d31864643bb693575e802a166": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b6c7b2fd344415389855cec0b503c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4ff3361af4649e48b68c499df4b8ec5",
       "IPY_MODEL_581ad14fabab4b828a51c34daaa5dedd",
       "IPY_MODEL_79f42f28bacf4917ad260fdff4a44939"
      ],
      "layout": "IPY_MODEL_6ba0ad9e0d154e9686c2df22060c6281"
     }
    },
    "4e1619a6edd94b5a9f31f4f9144bcb26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "510844178fc4484fb215656f32b447ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5364b89a3f5a4feebdb39104fe7e1908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "546ab8aac5ad40408c33491746194b13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "549bc7a2f1f34fed82be71e2ff403981": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a7cea6d31864643bb693575e802a166",
      "placeholder": "​",
      "style": "IPY_MODEL_583e3ba45df74cb5bf80cfab7db15dff",
      "value": " 226k/226k [00:00&lt;00:00, 2.48MB/s]"
     }
    },
    "581ad14fabab4b828a51c34daaa5dedd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_546ab8aac5ad40408c33491746194b13",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98e89fd326604d8aa28d56d079e8fac9",
      "value": 28
     }
    },
    "583e3ba45df74cb5bf80cfab7db15dff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d8dfcab42cb4e48bcf458e1372f468d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69f9f858699b4226a7d61257b5c0b317",
      "placeholder": "​",
      "style": "IPY_MODEL_510844178fc4484fb215656f32b447ea",
      "value": " 570/570 [00:00&lt;00:00, 12.9kB/s]"
     }
    },
    "5f1b35e982b34fc9bc2291681e3f1e19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "656499608fd64e3f864179ca6c32d817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6c08e97aaae488dae290d9c5250cdfb",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa38386ad94f45b3a654ad1f637bcf6e",
      "value": 570
     }
    },
    "65eb48b74c104f31a6130529019543b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69c0cc823f02429e96ccd9004f3c5301": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69f9f858699b4226a7d61257b5c0b317": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ba0ad9e0d154e9686c2df22060c6281": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fa43aff58174bacbc84b3443195d8a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79f42f28bacf4917ad260fdff4a44939": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e1619a6edd94b5a9f31f4f9144bcb26",
      "placeholder": "​",
      "style": "IPY_MODEL_fd2d2a45fd654dce815110f7ce3b8c53",
      "value": " 28.0/28.0 [00:00&lt;00:00, 755B/s]"
     }
    },
    "7b9281b67f1d4847a5a12c243583a7af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26cfb653005a401c9873023531a3b214",
      "placeholder": "​",
      "style": "IPY_MODEL_0ddc3de572e747b3a9af3231f97baffb",
      "value": "Downloading: 100%"
     }
    },
    "96556f35e08247898751de10d37057ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98e89fd326604d8aa28d56d079e8fac9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9f6f23efebff447eba4e35867df061c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a19d3b02c85945bb94101dbb19f5eac3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa38386ad94f45b3a654ad1f637bcf6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b74b3efd33cf4f1cb68f953ce64df4b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdc599fab9d84a739bf77810c816f678",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a19d3b02c85945bb94101dbb19f5eac3",
      "value": 231508
     }
    },
    "bdc599fab9d84a739bf77810c816f678": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c03d0915a8c249618a4d84af34bf0669": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c112913ebbc94b51a3b44e390c2a884b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5a025221c8f400ca218beee6faf65c8",
       "IPY_MODEL_c5ebc5d4679e49a0992b4793a52aab7f",
       "IPY_MODEL_c28b77e093324a2fbcb4174c44bec661"
      ],
      "layout": "IPY_MODEL_5f1b35e982b34fc9bc2291681e3f1e19"
     }
    },
    "c28b77e093324a2fbcb4174c44bec661": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96556f35e08247898751de10d37057ed",
      "placeholder": "​",
      "style": "IPY_MODEL_9f6f23efebff447eba4e35867df061c6",
      "value": " 511M/511M [00:12&lt;00:00, 44.2MB/s]"
     }
    },
    "c5a025221c8f400ca218beee6faf65c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1469420a34154e9f9257458b290507d2",
      "placeholder": "​",
      "style": "IPY_MODEL_c03d0915a8c249618a4d84af34bf0669",
      "value": "Downloading: 100%"
     }
    },
    "c5ebc5d4679e49a0992b4793a52aab7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e79aa4e1b6f4c4a858fc41ddafd1c3a",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7b6924b8a3547b7a16397663358a36d",
      "value": 536063208
     }
    },
    "d4ff3361af4649e48b68c499df4b8ec5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69c0cc823f02429e96ccd9004f3c5301",
      "placeholder": "​",
      "style": "IPY_MODEL_6fa43aff58174bacbc84b3443195d8a4",
      "value": "Downloading: 100%"
     }
    },
    "d90c72579cb646079551103c732f0770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b9281b67f1d4847a5a12c243583a7af",
       "IPY_MODEL_b74b3efd33cf4f1cb68f953ce64df4b5",
       "IPY_MODEL_549bc7a2f1f34fed82be71e2ff403981"
      ],
      "layout": "IPY_MODEL_fede47e020b24b33b70973f2368354a6"
     }
    },
    "e6c08e97aaae488dae290d9c5250cdfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7b6924b8a3547b7a16397663358a36d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f1dbf229fc39436b8de525a442333682": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5364b89a3f5a4feebdb39104fe7e1908",
      "placeholder": "​",
      "style": "IPY_MODEL_15a00f8bb5574b2aa558b7d04b9a5e2c",
      "value": "Downloading: 100%"
     }
    },
    "fd2d2a45fd654dce815110f7ce3b8c53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fede47e020b24b33b70973f2368354a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
