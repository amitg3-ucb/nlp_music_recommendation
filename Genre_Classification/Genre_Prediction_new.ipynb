{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ibI44CbFPvC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bde490-33da-4e6d-f931-9e256fa7519f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Embedding\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "import string\n",
        "import multiprocessing\n",
        "import unicodedata\n",
        "import re\n",
        "import gc\n",
        "import sklearn\n",
        "\n",
        "import gensim\n",
        "import nltk\n",
        "nltk.download('word2vec_sample')\n",
        "from nltk.data import find\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG2aCR59PvC5",
        "outputId": "973433f6-1c23-4de1-c6bb-26368de93e39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/trespimentel/Desktop/w266_final_project/Genre_Classification\r\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRhYLs2tPvC6"
      },
      "source": [
        "# 1. Import data, filter out problematic data, create normalized feature set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-jwOWUgPvC7"
      },
      "outputs": [],
      "source": [
        "# import train and test data\n",
        "df_test = pkl.load(open('Train_Test_Data/genre_sub_genre_test.pkl', 'rb'))\n",
        "df_train = pkl.load(open('Train_Test_Data/genre_sub_genre_train.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3vEwxhEPvC8",
        "outputId": "7ace3dd3-43df-40e9-ed36-cfc25dd35036"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16303    Unbreakable Lyrics[Intro]\\nGo take it all\\nYou...\n",
              "8721     NOBODY LyricsTake a bitch\\nThat I have in one ...\n",
              "11930    Worth It Lyrics[Verse 1]\\nYour eyes are just l...\n",
              "7945     Bloodrush Lyrics[Intro: Denzel Curry]\\nUgh\\nUg...\n",
              "15504    Age of Man Lyrics[Intro]\\nIn an age of darknes...\n",
              "Name: Lyrics, dtype: object"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['Lyrics'].iloc[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeS--6ecPvC8"
      },
      "source": [
        "data cleanliness issue: it seems that a few things were causing us to get incorrect lyrics from genius:\n",
        "\n",
        "1. our dataset contains versions of songs e.g. xyz remastered, xyz live version, etc. which genius thinks is a different song than the actual \"base\" song\n",
        "\n",
        "2. genius saves songs/artists in \"unaccented\" characters (e.g. cafe vs café) - our dataset has these accents which is causing us to get incorrect results\n",
        "\n",
        "we can solve these problems in 2 ways - cleaning pre-genius query or filtering post-query.  for now, i have filtered them post-query but we can always re-run the query if we want.\n",
        "\n",
        "based on exploration of this error, it appears that the incorrect data we are getting are all very long documents - there exists a risk that we are getting incorrect lyric data that is the same size as the correct results, but i have no way of checking this other than spot-checking (which i have done).  the only additional errors i found using this method had to do with a special case of (2) above - i believe filtering out any rows where the song or artist contains accented characters will be enough to solve this issue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp_XXhFXPvDF"
      },
      "outputs": [],
      "source": [
        "# in case we want to clean pre-query, here are variables we can use to find problem words/chars\n",
        "#problem_words = ['acoustic', 'version', 'remastered', 'anniversary', 'remaster']\n",
        "#accented_characters = \"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93TWoqahPvDF",
        "outputId": "9e7b4bf4-477e-4200-bb0f-ea6615e6ea32"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist Name</th>\n",
              "      <th>Track Name</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>key</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>...</th>\n",
              "      <th>Sub-Genre: modern alternative rock</th>\n",
              "      <th>Sub-Genre: southern hip hop</th>\n",
              "      <th>Sub-Genre: nu metal</th>\n",
              "      <th>Sub-Genre: israeli mediterranean</th>\n",
              "      <th>Sub-Genre: thrash metal</th>\n",
              "      <th>Sub-Genre: pop rock</th>\n",
              "      <th>Sub-Genre: chicago blues</th>\n",
              "      <th>Sub-Genre: indie pop</th>\n",
              "      <th>Sub-Genre: classic rock</th>\n",
              "      <th>Sub-Genre: hardcore hip hop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Stevie Ray Vaughan</td>\n",
              "      <td>Life By The Drop</td>\n",
              "      <td>51</td>\n",
              "      <td>0.659</td>\n",
              "      <td>0.163</td>\n",
              "      <td>6</td>\n",
              "      <td>-11.864</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0388</td>\n",
              "      <td>0.76600</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DARKSIDE</td>\n",
              "      <td>Paper Trails</td>\n",
              "      <td>55</td>\n",
              "      <td>0.947</td>\n",
              "      <td>0.419</td>\n",
              "      <td>8</td>\n",
              "      <td>-13.043</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0578</td>\n",
              "      <td>0.77800</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Christone \"Kingfish\" Ingram</td>\n",
              "      <td>Outside Of This Town</td>\n",
              "      <td>48</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.866</td>\n",
              "      <td>11</td>\n",
              "      <td>-4.033</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0513</td>\n",
              "      <td>0.00381</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Jesse Cook</td>\n",
              "      <td>I Put A Spell On You</td>\n",
              "      <td>34</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.373</td>\n",
              "      <td>1</td>\n",
              "      <td>-9.302</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0320</td>\n",
              "      <td>0.92200</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Christone \"Kingfish\" Ingram</td>\n",
              "      <td>Before I'm Old</td>\n",
              "      <td>41</td>\n",
              "      <td>0.534</td>\n",
              "      <td>0.649</td>\n",
              "      <td>2</td>\n",
              "      <td>-5.526</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0410</td>\n",
              "      <td>0.04380</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19316</th>\n",
              "      <td>Woolbright</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>23</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.819</td>\n",
              "      <td>11</td>\n",
              "      <td>-6.713</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0375</td>\n",
              "      <td>0.01220</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19321</th>\n",
              "      <td>Runnin' Wild</td>\n",
              "      <td>How You Want It Done</td>\n",
              "      <td>27</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.953</td>\n",
              "      <td>9</td>\n",
              "      <td>-3.539</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0517</td>\n",
              "      <td>0.07710</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19344</th>\n",
              "      <td>Four Year Strong</td>\n",
              "      <td>Go Down in History</td>\n",
              "      <td>48</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.985</td>\n",
              "      <td>5</td>\n",
              "      <td>-4.401</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1190</td>\n",
              "      <td>0.00006</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19355</th>\n",
              "      <td>Nathaniel Rateliff &amp; The Night Sweats</td>\n",
              "      <td>S.O.B.</td>\n",
              "      <td>66</td>\n",
              "      <td>0.699</td>\n",
              "      <td>0.579</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.504</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0416</td>\n",
              "      <td>0.26700</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19356</th>\n",
              "      <td>Muskets</td>\n",
              "      <td>17 Years</td>\n",
              "      <td>31</td>\n",
              "      <td>0.446</td>\n",
              "      <td>0.935</td>\n",
              "      <td>8</td>\n",
              "      <td>-4.677</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.00007</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2581 rows × 72 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Artist Name            Track Name  \\\n",
              "5                         Stevie Ray Vaughan      Life By The Drop   \n",
              "6                                   DARKSIDE          Paper Trails   \n",
              "11               Christone \"Kingfish\" Ingram  Outside Of This Town   \n",
              "28                                Jesse Cook  I Put A Spell On You   \n",
              "31               Christone \"Kingfish\" Ingram        Before I'm Old   \n",
              "...                                      ...                   ...   \n",
              "19316                             Woolbright               Tuesday   \n",
              "19321                           Runnin' Wild  How You Want It Done   \n",
              "19344                       Four Year Strong    Go Down in History   \n",
              "19355  Nathaniel Rateliff & The Night Sweats                S.O.B.   \n",
              "19356                                Muskets              17 Years   \n",
              "\n",
              "       Popularity  danceability  energy  key  loudness  mode  speechiness  \\\n",
              "5              51         0.659   0.163    6   -11.864     0       0.0388   \n",
              "6              55         0.947   0.419    8   -13.043     0       0.0578   \n",
              "11             48         0.418   0.866   11    -4.033     0       0.0513   \n",
              "28             34         0.420   0.373    1    -9.302     0       0.0320   \n",
              "31             41         0.534   0.649    2    -5.526     1       0.0410   \n",
              "...           ...           ...     ...  ...       ...   ...          ...   \n",
              "19316          23         0.514   0.819   11    -6.713     0       0.0375   \n",
              "19321          27         0.614   0.953    9    -3.539     1       0.0517   \n",
              "19344          48         0.505   0.985    5    -4.401     1       0.1190   \n",
              "19355          66         0.699   0.579    1    -6.504     1       0.0416   \n",
              "19356          31         0.446   0.935    8    -4.677     1       0.0357   \n",
              "\n",
              "       acousticness  ...  Sub-Genre: modern alternative rock  \\\n",
              "5           0.76600  ...                                   0   \n",
              "6           0.77800  ...                                   0   \n",
              "11          0.00381  ...                                   0   \n",
              "28          0.92200  ...                                   0   \n",
              "31          0.04380  ...                                   0   \n",
              "...             ...  ...                                 ...   \n",
              "19316       0.01220  ...                                   0   \n",
              "19321       0.07710  ...                                   0   \n",
              "19344       0.00006  ...                                   0   \n",
              "19355       0.26700  ...                                   0   \n",
              "19356       0.00007  ...                                   0   \n",
              "\n",
              "       Sub-Genre: southern hip hop  Sub-Genre: nu metal  \\\n",
              "5                                0                    0   \n",
              "6                                0                    0   \n",
              "11                               0                    0   \n",
              "28                               0                    0   \n",
              "31                               0                    0   \n",
              "...                            ...                  ...   \n",
              "19316                            0                    0   \n",
              "19321                            0                    0   \n",
              "19344                            0                    0   \n",
              "19355                            0                    0   \n",
              "19356                            0                    0   \n",
              "\n",
              "       Sub-Genre: israeli mediterranean Sub-Genre: thrash metal  \\\n",
              "5                                     0                       0   \n",
              "6                                     0                       0   \n",
              "11                                    0                       0   \n",
              "28                                    0                       0   \n",
              "31                                    0                       0   \n",
              "...                                 ...                     ...   \n",
              "19316                                 0                       0   \n",
              "19321                                 0                       0   \n",
              "19344                                 0                       0   \n",
              "19355                                 0                       0   \n",
              "19356                                 0                       0   \n",
              "\n",
              "      Sub-Genre: pop rock Sub-Genre: chicago blues Sub-Genre: indie pop  \\\n",
              "5                       0                        0                    0   \n",
              "6                       0                        0                    0   \n",
              "11                      0                        0                    0   \n",
              "28                      0                        0                    0   \n",
              "31                      0                        0                    0   \n",
              "...                   ...                      ...                  ...   \n",
              "19316                   0                        0                    0   \n",
              "19321                   0                        0                    0   \n",
              "19344                   0                        0                    0   \n",
              "19355                   0                        0                    0   \n",
              "19356                   0                        0                    0   \n",
              "\n",
              "       Sub-Genre: classic rock  Sub-Genre: hardcore hip hop  \n",
              "5                            1                            0  \n",
              "6                            0                            0  \n",
              "11                           0                            0  \n",
              "28                           0                            0  \n",
              "31                           0                            0  \n",
              "...                        ...                          ...  \n",
              "19316                        0                            0  \n",
              "19321                        0                            0  \n",
              "19344                        0                            0  \n",
              "19355                        0                            0  \n",
              "19356                        0                            0  \n",
              "\n",
              "[2581 rows x 72 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# filter out results\n",
        "df_train.drop(df_train[df_train['Lyrics'].str.len() > 5000].index, inplace=True)\n",
        "df_train[df_train['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
        "df_train[df_train['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
        "\n",
        "df_test.drop(df_test[df_test['Lyrics'].str.len() > 5000].index, inplace=True)\n",
        "df_test[df_test['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
        "df_test[df_test['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlktVKpFPvDG",
        "outputId": "f8ed1c57-5892-4e98-ef61-d055f5d509ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14778\n",
            "2581\n"
          ]
        }
      ],
      "source": [
        "# this removes ~10% of both train/test data\n",
        "print(len(df_train))\n",
        "print(len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WYFJiw9PvDG"
      },
      "source": [
        "below cells are related to the tensorflow issue involving lyric + audio data.  leaving until resolved (do not run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1M0SetEPvDG"
      },
      "outputs": [],
      "source": [
        "#test = df_train_audio_normalized.iloc[:5,:-1].copy()\n",
        "#test1 = [np.array(x) for x in train_tokens_prebuilt[0:5]]\n",
        "#test1 = train_tokens_prebuilt[0:5]\n",
        "#print(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZfKU0bTPvDH"
      },
      "outputs": [],
      "source": [
        "#ls = list([list(test.iloc[num]) for num in range(len(test))])\n",
        "\n",
        "#print(ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TAixcPEPvDH"
      },
      "outputs": [],
      "source": [
        "#final_array = list([list(x) for x in zip(ls, test1)])\n",
        "#print(final_array[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1jZO9lQPvDH"
      },
      "source": [
        "end issue section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "r_Sm1do1PvDI"
      },
      "outputs": [],
      "source": [
        "# let's create a df that is all of the normalized audio features we want to use\n",
        "df_train_audio_normalized = df_train[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
        "df_train_audio_normalized = (df_train_audio_normalized-df_train_audio_normalized.mean())/df_train_audio_normalized.std()\n",
        "\n",
        "df_test_audio_normalized = df_test[['danceability', 'energy', 'loudness', 'acousticness', 'speechiness', 'instrumentalness', 'valence', 'tempo','duration_ms']].copy()\n",
        "df_test_audio_normalized = (df_test_audio_normalized-df_test_audio_normalized.mean())/df_test_audio_normalized.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9or6vVbPvDI",
        "outputId": "93178609-0ac1-4437-964b-714d880467a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>loudness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>duration_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16303</th>\n",
              "      <td>0.083890</td>\n",
              "      <td>0.541561</td>\n",
              "      <td>0.082481</td>\n",
              "      <td>-0.663296</td>\n",
              "      <td>-0.419475</td>\n",
              "      <td>-0.421705</td>\n",
              "      <td>0.281600</td>\n",
              "      <td>-0.045805</td>\n",
              "      <td>-0.635516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8721</th>\n",
              "      <td>1.777120</td>\n",
              "      <td>0.379438</td>\n",
              "      <td>-0.018027</td>\n",
              "      <td>-0.311507</td>\n",
              "      <td>0.535964</td>\n",
              "      <td>-0.420469</td>\n",
              "      <td>0.204008</td>\n",
              "      <td>-0.455375</td>\n",
              "      <td>-1.530281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11930</th>\n",
              "      <td>0.162224</td>\n",
              "      <td>0.202576</td>\n",
              "      <td>0.573121</td>\n",
              "      <td>-0.635356</td>\n",
              "      <td>-0.672419</td>\n",
              "      <td>-0.422246</td>\n",
              "      <td>-0.485701</td>\n",
              "      <td>-0.726473</td>\n",
              "      <td>-0.476165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7945</th>\n",
              "      <td>0.867234</td>\n",
              "      <td>-0.475394</td>\n",
              "      <td>-1.048238</td>\n",
              "      <td>-0.368260</td>\n",
              "      <td>2.019137</td>\n",
              "      <td>-0.423698</td>\n",
              "      <td>-0.856420</td>\n",
              "      <td>0.194771</td>\n",
              "      <td>-0.346021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15504</th>\n",
              "      <td>-0.536761</td>\n",
              "      <td>-0.534348</td>\n",
              "      <td>0.497078</td>\n",
              "      <td>-0.535344</td>\n",
              "      <td>-0.632178</td>\n",
              "      <td>2.799775</td>\n",
              "      <td>-1.059022</td>\n",
              "      <td>0.425864</td>\n",
              "      <td>1.866022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7303</th>\n",
              "      <td>0.626205</td>\n",
              "      <td>-0.401702</td>\n",
              "      <td>-0.481556</td>\n",
              "      <td>0.156409</td>\n",
              "      <td>3.410330</td>\n",
              "      <td>-0.424316</td>\n",
              "      <td>1.363581</td>\n",
              "      <td>1.375829</td>\n",
              "      <td>-0.792824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9125</th>\n",
              "      <td>1.572245</td>\n",
              "      <td>0.615253</td>\n",
              "      <td>-1.054850</td>\n",
              "      <td>0.763627</td>\n",
              "      <td>-0.007866</td>\n",
              "      <td>-0.415252</td>\n",
              "      <td>1.962766</td>\n",
              "      <td>0.043757</td>\n",
              "      <td>0.134579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5125</th>\n",
              "      <td>1.801223</td>\n",
              "      <td>0.163273</td>\n",
              "      <td>-0.034888</td>\n",
              "      <td>0.751721</td>\n",
              "      <td>-0.057305</td>\n",
              "      <td>-0.418003</td>\n",
              "      <td>0.919581</td>\n",
              "      <td>-0.827523</td>\n",
              "      <td>-0.473074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15805</th>\n",
              "      <td>-0.386117</td>\n",
              "      <td>-1.477611</td>\n",
              "      <td>-2.291367</td>\n",
              "      <td>0.287377</td>\n",
              "      <td>-0.662071</td>\n",
              "      <td>0.707498</td>\n",
              "      <td>-0.826245</td>\n",
              "      <td>1.420558</td>\n",
              "      <td>0.838621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2952</th>\n",
              "      <td>0.252610</td>\n",
              "      <td>-0.716122</td>\n",
              "      <td>-1.335877</td>\n",
              "      <td>-0.634960</td>\n",
              "      <td>-0.490759</td>\n",
              "      <td>3.376955</td>\n",
              "      <td>-0.377934</td>\n",
              "      <td>0.776225</td>\n",
              "      <td>0.866398</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14778 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       danceability    energy  loudness  acousticness  speechiness  \\\n",
              "16303      0.083890  0.541561  0.082481     -0.663296    -0.419475   \n",
              "8721       1.777120  0.379438 -0.018027     -0.311507     0.535964   \n",
              "11930      0.162224  0.202576  0.573121     -0.635356    -0.672419   \n",
              "7945       0.867234 -0.475394 -1.048238     -0.368260     2.019137   \n",
              "15504     -0.536761 -0.534348  0.497078     -0.535344    -0.632178   \n",
              "...             ...       ...       ...           ...          ...   \n",
              "7303       0.626205 -0.401702 -0.481556      0.156409     3.410330   \n",
              "9125       1.572245  0.615253 -1.054850      0.763627    -0.007866   \n",
              "5125       1.801223  0.163273 -0.034888      0.751721    -0.057305   \n",
              "15805     -0.386117 -1.477611 -2.291367      0.287377    -0.662071   \n",
              "2952       0.252610 -0.716122 -1.335877     -0.634960    -0.490759   \n",
              "\n",
              "       instrumentalness   valence     tempo  duration_ms  \n",
              "16303         -0.421705  0.281600 -0.045805    -0.635516  \n",
              "8721          -0.420469  0.204008 -0.455375    -1.530281  \n",
              "11930         -0.422246 -0.485701 -0.726473    -0.476165  \n",
              "7945          -0.423698 -0.856420  0.194771    -0.346021  \n",
              "15504          2.799775 -1.059022  0.425864     1.866022  \n",
              "...                 ...       ...       ...          ...  \n",
              "7303          -0.424316  1.363581  1.375829    -0.792824  \n",
              "9125          -0.415252  1.962766  0.043757     0.134579  \n",
              "5125          -0.418003  0.919581 -0.827523    -0.473074  \n",
              "15805          0.707498 -0.826245  1.420558     0.838621  \n",
              "2952           3.376955 -0.377934  0.776225     0.866398  \n",
              "\n",
              "[14778 rows x 9 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# looks good\n",
        "df_train_audio_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FCoicSGPvDI"
      },
      "source": [
        "# 2. Embedding Creation, get token and label data ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPHrBp7NPvDJ"
      },
      "outputs": [],
      "source": [
        "# get word2vec model\n",
        "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaojUbp7PvDJ"
      },
      "outputs": [],
      "source": [
        "# how big does our embedding matrix need to be\n",
        "print(len(model.key_to_index.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o88SBWR-PvDJ"
      },
      "outputs": [],
      "source": [
        "#construct embedding matrix w/ prebuilt embedding\n",
        "vocab_dict = model.key_to_index.copy()\n",
        "embedding_matrix = np.zeros((43982,300))\n",
        "for word,index in model.key_to_index.items():\n",
        "    embedding_matrix[index] = model[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHT-pe7TPvDK"
      },
      "outputs": [],
      "source": [
        "# text cleaning function - this is just part 1\n",
        "def text_cleaner(text_data):\n",
        "    return_data = []\n",
        "    for text in text_data:\n",
        "        final_text = []\n",
        "        new_text = text.lower()\n",
        "        new_text = new_text.replace('\\n',' ')\n",
        "        new_text = re.sub(r\"[,.;@#?!&$]+\\ *\", \" \", new_text)\n",
        "        new_text = new_text.replace('   ',' ')\n",
        "        new_text = new_text.replace('  ',' ')\n",
        "        new_text = new_text.split()\n",
        "        for word in new_text:\n",
        "            if word not in stopWords:\n",
        "                final_text.append(word)\n",
        "        return_data.append(final_text)\n",
        "    return return_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0gH5zl7PvDK"
      },
      "outputs": [],
      "source": [
        "train_lang_clean = text_cleaner(df_train['Lyrics'])\n",
        "test_lang_clean = text_cleaner(df_test['Lyrics'])\n",
        "#train_lang_clean[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtL7Hh-UPvDL"
      },
      "outputs": [],
      "source": [
        "# this is a messy implementation, but this basically is a step 2 text cleaner that is slightly different based off the format of the text\n",
        "# if i have time, i will combine into a single function, but for now this runs and does what it intends to do\n",
        "\n",
        "def more_cleaning_if_brackets(song):\n",
        "    include_word = False\n",
        "    clean_song = []\n",
        "    final_song_counter = 0\n",
        "    \n",
        "    for word in song:\n",
        "        final_song_counter += 1\n",
        "        if ']' in word and '[' in word:\n",
        "            include_word = True\n",
        "            continue\n",
        "        \n",
        "        if include_word == False:\n",
        "            if ']' in word:\n",
        "                    include_word = True\n",
        "                    continue\n",
        "                    \n",
        "        else: # if include_word == True\n",
        "            if '[' in word:\n",
        "                    include_word = False\n",
        "                    \n",
        "        if include_word == True and final_song_counter != len(song):\n",
        "            new_word = word.replace('(','').replace(')','')\n",
        "            new_word = new_word.lower()\n",
        "            clean_song.append(new_word)\n",
        "        elif include_word == True and final_song_counter == len(song):\n",
        "            try:\n",
        "                r = re.compile(\"([a-zA-Z]+)([0-9]+)\")\n",
        "                clean_song.append(r.match(word).groups()[0])\n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "    return(clean_song)\n",
        "\n",
        "def more_cleaning_if_no_brackets(song):\n",
        "    include_word = False\n",
        "    clean_song = []\n",
        "    final_song_counter = 0\n",
        "    \n",
        "    for word in song:\n",
        "        final_song_counter += 1\n",
        "        if ']' in word and '[' in word:\n",
        "            continue\n",
        "        \n",
        "        if include_word == False:\n",
        "            if 'lyrics' in word:\n",
        "                    include_word = True\n",
        "                    continue\n",
        "                    \n",
        "        else: # if include_word == True\n",
        "            if '[' in word:\n",
        "                    include_word = False\n",
        "                    \n",
        "        if include_word == True and final_song_counter != len(song):\n",
        "            new_word = word.replace('(','').replace(')','')\n",
        "            new_word = new_word.lower()\n",
        "            clean_song.append(new_word)\n",
        "        elif include_word == True and final_song_counter == len(song):\n",
        "            try:\n",
        "                r = re.compile(\"([a-zA-Z]+)([0-9]+)\")\n",
        "                clean_song.append(r.match(word).groups()[0])\n",
        "            except:\n",
        "                pass\n",
        "            \n",
        "    return(clean_song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6qirREQPvDL"
      },
      "outputs": [],
      "source": [
        "train_lang_clean_post_function = []\n",
        "for song in train_lang_clean:\n",
        "    if '[' in ''.join(song):\n",
        "        new_song = more_cleaning_if_brackets(song)\n",
        "        train_lang_clean_post_function.append(new_song)\n",
        "    else:\n",
        "        new_song = more_cleaning_if_no_brackets(song)\n",
        "        train_lang_clean_post_function.append(new_song)\n",
        "        \n",
        "test_lang_clean_post_function = []\n",
        "for song in test_lang_clean:\n",
        "    if '[' in ''.join(song):\n",
        "        new_song = more_cleaning_if_brackets(song)\n",
        "        test_lang_clean_post_function.append(new_song)\n",
        "    else:\n",
        "        new_song = more_cleaning_if_no_brackets(song)\n",
        "        test_lang_clean_post_function.append(new_song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lT9GXOvPvDM"
      },
      "outputs": [],
      "source": [
        "#checks\n",
        "print(len(test_lang_clean_post_function))\n",
        "#train_lang_clean_post_function[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WLfejhcPvDM"
      },
      "outputs": [],
      "source": [
        "# add cleaned lyrics to df\n",
        "df_train['Lyrics'] = train_lang_clean_post_function\n",
        "df_test['Lyrics'] = test_lang_clean_post_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7CNoIwDPvDM"
      },
      "outputs": [],
      "source": [
        "# this takes our cleaned text and converts it to word2vec tokens\n",
        "\n",
        "def text_to_index_post_cleaning(text_data,mapping,max_size):\n",
        "    return_data = []\n",
        "    for text in text_data:\n",
        "        mapped_text = []\n",
        "        for token in text:\n",
        "            try:\n",
        "                mapped_text.append(mapping[token])\n",
        "            except:\n",
        "                mapped_text.append(len(mapping))\n",
        "        \n",
        "        if len(mapped_text) > max_size:\n",
        "            mapped_text = mapped_text[:max_size]\n",
        "        else:\n",
        "            while len(mapped_text) < max_size:\n",
        "                mapped_text.append(len(mapping))\n",
        "                \n",
        "        return_data.append(mapped_text)\n",
        "    \n",
        "    return return_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fDnN86uPvDN"
      },
      "source": [
        "one thing i would like to do once we are confident data is in a good place is experiment with prebuilt embedding size - 1000 seems pretty long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2ecbcXzPvDN"
      },
      "outputs": [],
      "source": [
        "# tokenize lyrics - for the prebuilt embedding models these are our X\n",
        "train_tokens_prebuilt_new = text_to_index_post_cleaning(df_train['Lyrics'],vocab_dict,1000)\n",
        "test_tokens_prebuilt_new = text_to_index_post_cleaning(df_test['Lyrics'],vocab_dict,1000)\n",
        "df_train['Lyric_Tokens'] = train_tokens_prebuilt_new\n",
        "df_test['Lyric_Tokens'] = test_tokens_prebuilt_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gzxMZJ2TPvDO"
      },
      "outputs": [],
      "source": [
        "# get labels \"Y\"\n",
        "train_labels = df_train['Major Genre']\n",
        "test_labels = df_test['Major Genre']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BaaHZi3rPvDO",
        "outputId": "b3a70619-4723-429b-9067-aa1df736d63c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Rock': 0, 'Indie': 1, 'Alternative': 2, 'Hip Hop': 3, 'Metal': 4, 'Pop': 5, 'Blues': 6}\n"
          ]
        }
      ],
      "source": [
        "# create mapper so we can use numeric labels in our networks\n",
        "mapping = {}\n",
        "count = 0\n",
        "for label in train_labels.unique():\n",
        "    mapping[label] = count\n",
        "    count = count + 1\n",
        "print(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUAQu-GyPvDO"
      },
      "outputs": [],
      "source": [
        "# want to keep the functions consistent across notebooks, so defining this so i can use the DAN and WAN models as-is\n",
        "embedding_matrix_custom = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA0BVg3MPvDO"
      },
      "source": [
        "# 3. Lyric-Only Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mBEGMYdPvDP"
      },
      "source": [
        "DAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T9l-WDFPvDP"
      },
      "outputs": [],
      "source": [
        "# i want to try letting these run and using early stopping to see how high we get\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience = 3, verbose=1, restore_best_weights = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ76XLskPvDP"
      },
      "outputs": [],
      "source": [
        "def create_dan_model(retrain_embeddings=False, \n",
        "                     max_sequence_length=1000,\n",
        "                     embedding_matrix=embedding_matrix_custom, \n",
        "                     hidden_dim=[100,100,100],\n",
        "                     dropout_rate=0.3,\n",
        "                     hidden_layer_activation = 'relu',\n",
        "                     output_layer_size = 4,\n",
        "                     output_activation = 'softmax',\n",
        "                     learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Construct the DAN model including the compilation and return it. Parametrize it using the arguments.\n",
        "    retrain_embeddings: bool, indicates whether embeddings are retrainable\n",
        "    max_sequence_length: Number of token IDs to expect in a given input\n",
        "    embedding_matrix: initialize embedding layer with embedding matrix, specifying weights\n",
        "    hidden_dim = number of neurons in hidden layers\n",
        "    dropout = dropout rate\n",
        "    output_layer_size = # of neurons in output layer corresponding to # of classes, each neuron predicts P(class K | x)\n",
        "    output_activation = activation function for output layer\n",
        "    learning_rate = learning rate for gradient descent for finding model params to optimize loss\n",
        "    \"\"\"\n",
        "    \n",
        "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
        "    dan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                                  embedding_matrix.shape[1],\n",
        "                                  weights = [embedding_matrix],\n",
        "                                  input_length=max_sequence_length,\n",
        "                                  trainable=retrain_embeddings,\n",
        "                                   name = 'embedding_layer')\n",
        "    \n",
        "    \n",
        "    #Input Layer, sequence of max_sequence_length tokens\n",
        "    dan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
        "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
        "    dan_embeddings = dan_embedding_layer(dan_input_layer)\n",
        "    #Embeddings are averaged, forming single vector represenation of size embedding matrix\n",
        "    dan_avg_input_embeddings = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(dan_embeddings)\n",
        "    \n",
        "    #input into hidden layers\n",
        "    x = dan_avg_input_embeddings #hidden layer initial input\n",
        "    count = 1\n",
        "    for layer in hidden_dim:\n",
        "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
        "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
        "        count = count + 1\n",
        "        x = dropout\n",
        "        \n",
        "    #dan_hidden_out_1 = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_1')(dan_avg_input_embeddings)\n",
        "    #dan_hidden_out_1 = tf.keras.layers.Dropout(dropout)(dan_hidden_out_1)\n",
        "    dan_classification = tf.keras.layers.Dense(output_layer_size, activation='softmax', name='dan_classification')(x)\n",
        "    dan_model = tf.keras.models.Model(inputs=dan_input_layer, outputs=[dan_classification])\n",
        "    dan_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
        "                                                beta_1=0.9,\n",
        "                                                beta_2=0.999,\n",
        "                                                epsilon=1e-07,\n",
        "                                                amsgrad=False,\n",
        "                                                name='Adam'),\n",
        "                 metrics='accuracy')\n",
        "    \n",
        "    print(dan_model.summary())\n",
        "\n",
        "    return dan_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS10DUYfPvDP",
        "outputId": "10bca405-380c-4d48-82e8-3a95683e05c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,607\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.7661 - accuracy: 0.3390 - val_loss: 1.6863 - val_accuracy: 0.3537\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 1.6623 - accuracy: 0.3708 - val_loss: 1.5890 - val_accuracy: 0.3894\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.6144 - accuracy: 0.3918 - val_loss: 1.6029 - val_accuracy: 0.3929\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 1.5961 - accuracy: 0.3954 - val_loss: 1.5860 - val_accuracy: 0.3944\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 1.5802 - accuracy: 0.3999 - val_loss: 1.5539 - val_accuracy: 0.4018\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.5708 - accuracy: 0.4024 - val_loss: 1.5532 - val_accuracy: 0.4029\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.5605 - accuracy: 0.4061 - val_loss: 1.5431 - val_accuracy: 0.3971\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 1.5529 - accuracy: 0.4084 - val_loss: 1.5461 - val_accuracy: 0.4018\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 1.5482 - accuracy: 0.4093 - val_loss: 1.5303 - val_accuracy: 0.4045\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 1.5402 - accuracy: 0.4067 - val_loss: 1.5234 - val_accuracy: 0.4091\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 1.5347 - accuracy: 0.4130 - val_loss: 1.5110 - val_accuracy: 0.4099\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.5320 - accuracy: 0.4117 - val_loss: 1.5173 - val_accuracy: 0.4064\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.5252 - accuracy: 0.4144 - val_loss: 1.5153 - val_accuracy: 0.4126\n",
            "Epoch 14/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.5210 - accuracy: 0.4141 - val_loss: 1.5085 - val_accuracy: 0.4091\n",
            "Epoch 15/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.5125 - accuracy: 0.4154 - val_loss: 1.5068 - val_accuracy: 0.4033\n",
            "Epoch 16/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.5129 - accuracy: 0.4153 - val_loss: 1.4895 - val_accuracy: 0.4169\n",
            "Epoch 17/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.5119 - accuracy: 0.4143 - val_loss: 1.4917 - val_accuracy: 0.4064\n",
            "Epoch 18/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 1.5041 - accuracy: 0.4188 - val_loss: 1.4920 - val_accuracy: 0.4215\n",
            "Epoch 19/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.5034 - accuracy: 0.4176 - val_loss: 1.4859 - val_accuracy: 0.4200\n",
            "Epoch 20/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 1.4949 - accuracy: 0.4210 - val_loss: 1.4841 - val_accuracy: 0.4177\n",
            "Epoch 21/100\n",
            "1841/1848 [============================>.] - ETA: 0s - loss: 1.4956 - accuracy: 0.4216Restoring model weights from the end of the best epoch: 18.\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 1.4956 - accuracy: 0.4214 - val_loss: 1.4933 - val_accuracy: 0.4091\n",
            "Epoch 21: early stopping\n"
          ]
        }
      ],
      "source": [
        "dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix, output_layer_size = 7)\n",
        "dan_sorted_history = dan_model_sorted.fit(np.array(train_tokens_prebuilt_new),\n",
        "                        np.array(train_labels.map(mapping)),\n",
        "                        validation_data=(np.array(test_tokens_prebuilt_new), np.array(test_labels.map(mapping))),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
        "                        callbacks = [es])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avDHkm2TPvDQ"
      },
      "source": [
        "40% validation accuracy after 10 epochs - so not very good!  but the model is learning a little, at least"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFI0rPhePvDQ"
      },
      "source": [
        "Lets see if a WAN will perform any better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOKQZW8HPvDQ"
      },
      "outputs": [],
      "source": [
        "def create_wan_model(retrain_embeddings=False, \n",
        "                     max_sequence_length=1000,\n",
        "                     embedding_matrix=embedding_matrix_custom,\n",
        "                     num_attention = 1,\n",
        "                     hidden_dim=[100,100,100],\n",
        "                     dropout_rate=0.3,\n",
        "                     hidden_layer_activation = 'relu',\n",
        "                     output_layer_size = 4,\n",
        "                     output_activation = 'softmax',\n",
        "                     learning_rate=0.001,\n",
        "                     loss = keras.losses.SparseCategoricalCrossentropy()):\n",
        "    \"\"\"\n",
        "    Construct the WAN model including the compilation and return it. Parametrize it using the arguments.\n",
        "    retrain_embeddings: bool, indicates whether embeddings are retrainable\n",
        "    max_sequence_length: Number of token IDs to expect in a given input\n",
        "    embedding_matrix: initialize embedding layer with embedding matrix, specifying weights\n",
        "    num_attention = number of parallel attention computations that learn how to balance embeddings into a single\n",
        "    vector representation, final attention layer weights prior attention based representations\n",
        "    hidden_dim = number of neurons in hidden layers\n",
        "    dropout = dropout rate\n",
        "    output_layer_size = # of neurons in output layer corresponding to # of classes, each neuron predicts P(class K | x)\n",
        "    output_activation = activation function for output layer\n",
        "    learning_rate = learning rate for gradient descent for finding model params to optimize loss\n",
        "    \"\"\"\n",
        "    \n",
        "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
        "    wan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                                  embedding_matrix.shape[1],\n",
        "                                  weights = [embedding_matrix],\n",
        "                                  input_length=max_sequence_length,\n",
        "                                  trainable=retrain_embeddings,\n",
        "                                   name = 'embedding_layer')\n",
        "    \n",
        "    \n",
        "    #Input Layer, sequence of max_sequence_length tokens\n",
        "    wan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
        "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
        "    wan_embeddings = wan_embedding_layer(wan_input_layer)\n",
        "    \n",
        "    #Create attention based single vector representations of words according to alternative query vectors\n",
        "    attention_embeddings = []\n",
        "    for num in range(num_attention):\n",
        "        #Apply Query Vector to words in embeddings, returning a max_sequence_length x 1 tensor\n",
        "        l1_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query' + str(num+1))(wan_embeddings)\n",
        "        #reshape to 1 x max_sequence_length\n",
        "        l1_reshape_query = tf.keras.layers.Reshape((1,max_sequence_length))(l1_query)\n",
        "        #Softmax over query * key (words) to obtain weights\n",
        "        l1_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
        "                                            name='attention_weights' + str(num+1))(l1_reshape_query)\n",
        "        #weight embeddings according to weights\n",
        "        l1_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((wan_embeddings,l1_weights)))\n",
        "        attention_embeddings.append(l1_attention)\n",
        "    \n",
        "    concat_attention = tf.keras.layers.Concatenate()(attention_embeddings)\n",
        "    concat_attention = tf.keras.layers.Reshape((num_attention,embedding_matrix.shape[1]))(concat_attention)\n",
        "    \n",
        "    #Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
        "    wan_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(concat_attention)\n",
        "    #reshape to 1 x num_attention\n",
        "    reshaped_query = tf.keras.layers.Reshape((1,num_attention))(wan_query)\n",
        "    #Softmax over query * key (words) to obtain weights\n",
        "    wan_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
        "                                        name='attention_weights')(reshaped_query)\n",
        "    #weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
        "    #from prior layer\n",
        "    wan_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((concat_attention,wan_weights)))\n",
        "    \n",
        "    #input into hidden layers\n",
        "    x = wan_attention #hidden layer initial input\n",
        "    count = 1\n",
        "    for layer in hidden_dim:\n",
        "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
        "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
        "        count = count + 1\n",
        "        x = dropout\n",
        "        \n",
        "    #wan_hidden_out_1 = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_1')(wan_avg_input_embeddings)\n",
        "    #wan_hidden_out_1 = tf.keras.layers.Dropout(dropout)(wan_hidden_out_1)\n",
        "    wan_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation, name='wan_classification')(x)\n",
        "    wan_model = tf.keras.models.Model(inputs=wan_input_layer, outputs=[wan_classification])\n",
        "    wan_model.compile(loss=loss,\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
        "                                                beta_1=0.9,\n",
        "                                                beta_2=0.999,\n",
        "                                                epsilon=1e-07,\n",
        "                                                amsgrad=False,\n",
        "                                                name='Adam'),\n",
        "                 metrics='accuracy')\n",
        "    \n",
        "    print(wan_model.summary())\n",
        "\n",
        "    return wan_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_VzSuuyPvDR",
        "outputId": "9484a7dc-f28e-4015-9c0c-262f19e5a98b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 1000)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 1000, 300)    13194600    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 1, 1000)      0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 1000)      0           ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 300)          0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 300)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 300)       0           ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 300, 1)       0           ['reshape_1[0][0]',              \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 300)          0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,246,207\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 43s 23ms/step - loss: 4.1772 - accuracy: 0.1857 - val_loss: 1.8446 - val_accuracy: 0.2030\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 32s 18ms/step - loss: 4.0294 - accuracy: 0.2127 - val_loss: 1.7257 - val_accuracy: 0.2693\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 36s 20ms/step - loss: 3.8349 - accuracy: 0.2663 - val_loss: 1.6657 - val_accuracy: 0.3216\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 38s 20ms/step - loss: 3.7281 - accuracy: 0.2792 - val_loss: 1.6579 - val_accuracy: 0.2871\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 35s 19ms/step - loss: 3.6457 - accuracy: 0.2864 - val_loss: 1.6424 - val_accuracy: 0.2995\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - ETA: 0s - loss: 3.5881 - accuracy: 0.2884Restoring model weights from the end of the best epoch: 3.\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 3.5881 - accuracy: 0.2884 - val_loss: 1.6086 - val_accuracy: 0.3165\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ],
      "source": [
        "wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix, output_layer_size = 7,\n",
        "                                   num_attention=1)\n",
        "wan_sorted_history = wan_model_sorted.fit(np.array(train_tokens_prebuilt_new),\n",
        "                        np.array(train_labels.map(mapping)),\n",
        "                        validation_data=(np.array(test_tokens_prebuilt_new), np.array(test_labels.map(mapping))),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
        "                        callbacks = [es],\n",
        "                        class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhokuPmBPvDR"
      },
      "source": [
        "42%...so not much better - but it seems like it was steadily improving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFnrdT0pPvDR"
      },
      "source": [
        "both of those were performed with embedding lengths of 1000 over 10 epochs.  what happens if we experiment with embedding size?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMqGbZwqPvDR"
      },
      "source": [
        "# 3A Prebuilt Embeddings, Size Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I10wf3jPvDS"
      },
      "outputs": [],
      "source": [
        "# let's start by splitting our data up so we can easily get length\n",
        "def clean_and_split(text_data):\n",
        "    return_data = []\n",
        "    for text in text_data:\n",
        "        new_text = text.lower()\n",
        "        new_text = text.replace('\\n',' ')\n",
        "        new_text = text.replace('  ',' ')\n",
        "        new_text = new_text.split()\n",
        "        return_data.append(new_text)\n",
        "    return(return_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xTUagujPvDS"
      },
      "outputs": [],
      "source": [
        "list_lyrics = clean_and_split(df_train['Lyrics'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMcPkFu4PvDS"
      },
      "outputs": [],
      "source": [
        "len_list = []\n",
        "\n",
        "for lyric in new_lyrics:\n",
        "    len_list.append(len(lyric))\n",
        "\n",
        "len_list = np.array(len_list)\n",
        "print('Mean length = ',np.mean(len_list))\n",
        "print('Stdev = ',np.std(len_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niBseA53PvDS"
      },
      "outputs": [],
      "source": [
        "bins = np.linspace(math.ceil(min(len_list)), \n",
        "                   math.floor(max(len_list)),\n",
        "                   20) # fixed number of bins\n",
        "\n",
        "plt.xlim([min(len_list)-5, max(len_list)+5])\n",
        "\n",
        "plt.hist(len_list, bins=bins, alpha=0.5)\n",
        "plt.title('Song Length')\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uQxtis6PvDS"
      },
      "source": [
        "i dont have a great sense for what embedding size will be good, so lets try a few different options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwrDDKiVPvDS"
      },
      "outputs": [],
      "source": [
        "embedding_sizes = [300,450,600,750,900]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsNHUfSBPvDT",
        "outputId": "ce2b63a3-09dc-4e8d-d926-c41bd0071e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 300, 300)         13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,607\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 1.7201 - accuracy: 0.3526 - val_loss: 1.5945 - val_accuracy: 0.3824\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 1.6049 - accuracy: 0.3902 - val_loss: 1.5578 - val_accuracy: 0.3998\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 1.5826 - accuracy: 0.3993 - val_loss: 1.5365 - val_accuracy: 0.4037\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 1.5569 - accuracy: 0.4042 - val_loss: 1.5495 - val_accuracy: 0.4064\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 1.5445 - accuracy: 0.4066 - val_loss: 1.5297 - val_accuracy: 0.4041\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 1.5344 - accuracy: 0.4123 - val_loss: 1.5108 - val_accuracy: 0.4107\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 1.5267 - accuracy: 0.4140 - val_loss: 1.4999 - val_accuracy: 0.4115\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 1.5143 - accuracy: 0.4145 - val_loss: 1.4946 - val_accuracy: 0.4239\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 1.5083 - accuracy: 0.4170 - val_loss: 1.4885 - val_accuracy: 0.4181\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 1.4987 - accuracy: 0.4176 - val_loss: 1.4955 - val_accuracy: 0.4219\n",
            "Epoch 11/100\n",
            "1842/1848 [============================>.] - ETA: 0s - loss: 1.4921 - accuracy: 0.4231Restoring model weights from the end of the best epoch: 8.\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 1.4920 - accuracy: 0.4230 - val_loss: 1.4884 - val_accuracy: 0.4192\n",
            "Epoch 11: early stopping\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 300, 300)     13194600    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_21 (Reshape)           (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_21[0][0]']             \n",
            "                                                                                                  \n",
            " dot_14 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_14 (Flatten)           (None, 300)          0           ['dot_14[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 300)          0           ['flatten_14[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_22 (Reshape)           (None, 1, 300)       0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_22[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_23 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_23[0][0]']             \n",
            "                                                                                                  \n",
            " dot_15 (Dot)                   (None, 300, 1)       0           ['reshape_22[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_15 (Flatten)           (None, 300)          0           ['dot_15[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_15[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================================================================\n",
            "Total params: 13,246,207\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.7016 - accuracy: 0.3590 - val_loss: 1.5610 - val_accuracy: 0.4018\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 1.5814 - accuracy: 0.3978 - val_loss: 1.5411 - val_accuracy: 0.4049\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.5491 - accuracy: 0.4032 - val_loss: 1.5045 - val_accuracy: 0.4103\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 12s 7ms/step - loss: 1.5301 - accuracy: 0.4103 - val_loss: 1.4958 - val_accuracy: 0.4173\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 1.5166 - accuracy: 0.4116 - val_loss: 1.4814 - val_accuracy: 0.4150\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 1.4963 - accuracy: 0.4234 - val_loss: 1.4730 - val_accuracy: 0.4177\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 1.4823 - accuracy: 0.4239 - val_loss: 1.4821 - val_accuracy: 0.4289\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 1.4724 - accuracy: 0.4285 - val_loss: 1.4642 - val_accuracy: 0.4274\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.4644 - accuracy: 0.4353 - val_loss: 1.4517 - val_accuracy: 0.4339\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 12s 7ms/step - loss: 1.4550 - accuracy: 0.4365 - val_loss: 1.4582 - val_accuracy: 0.4324\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 1.4540 - accuracy: 0.4357 - val_loss: 1.4690 - val_accuracy: 0.4378\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 12s 7ms/step - loss: 1.4384 - accuracy: 0.4441 - val_loss: 1.4446 - val_accuracy: 0.4343\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 1.4317 - accuracy: 0.4435 - val_loss: 1.4448 - val_accuracy: 0.4378\n",
            "Epoch 14/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 1.4270 - accuracy: 0.4480 - val_loss: 1.4413 - val_accuracy: 0.4421\n",
            "Epoch 15/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 1.4243 - accuracy: 0.4481 - val_loss: 1.4547 - val_accuracy: 0.4297\n",
            "Epoch 16/100\n",
            "1848/1848 [==============================] - 13s 7ms/step - loss: 1.4134 - accuracy: 0.4486 - val_loss: 1.4403 - val_accuracy: 0.4378\n",
            "Epoch 17/100\n",
            "1847/1848 [============================>.] - ETA: 0s - loss: 1.4026 - accuracy: 0.4543Restoring model weights from the end of the best epoch: 14.\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.4026 - accuracy: 0.4543 - val_loss: 1.4410 - val_accuracy: 0.4386\n",
            "Epoch 17: early stopping\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 450)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 450, 300)         13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,607\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 1.7520 - accuracy: 0.3406 - val_loss: 1.6456 - val_accuracy: 0.3534\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.6301 - accuracy: 0.3810 - val_loss: 1.5702 - val_accuracy: 0.3995\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 1.5890 - accuracy: 0.3979 - val_loss: 1.5512 - val_accuracy: 0.3964\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5752 - accuracy: 0.3985 - val_loss: 1.5386 - val_accuracy: 0.4037\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 1.5576 - accuracy: 0.4052 - val_loss: 1.5442 - val_accuracy: 0.4006\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5503 - accuracy: 0.4047 - val_loss: 1.5096 - val_accuracy: 0.4057\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 1.5361 - accuracy: 0.4055 - val_loss: 1.5141 - val_accuracy: 0.4103\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5268 - accuracy: 0.4093 - val_loss: 1.4955 - val_accuracy: 0.4107\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 1.5209 - accuracy: 0.4107 - val_loss: 1.4907 - val_accuracy: 0.4130\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5128 - accuracy: 0.4176 - val_loss: 1.4919 - val_accuracy: 0.4126\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 1.5022 - accuracy: 0.4204 - val_loss: 1.4781 - val_accuracy: 0.4254\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5029 - accuracy: 0.4172 - val_loss: 1.4857 - val_accuracy: 0.4184\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.4928 - accuracy: 0.4212 - val_loss: 1.4681 - val_accuracy: 0.4227\n",
            "Epoch 14/100\n",
            "1838/1848 [============================>.] - ETA: 0s - loss: 1.4850 - accuracy: 0.4246Restoring model weights from the end of the best epoch: 11.\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.4850 - accuracy: 0.4247 - val_loss: 1.4833 - val_accuracy: 0.4227\n",
            "Epoch 14: early stopping\n",
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 450)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 450, 300)     13194600    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 450, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_24 (Reshape)           (None, 1, 450)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 450)       0           ['reshape_24[0][0]']             \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dot_16 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_16 (Flatten)           (None, 300)          0           ['dot_16[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 300)          0           ['flatten_16[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_25 (Reshape)           (None, 1, 300)       0           ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_25[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_26 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_26[0][0]']             \n",
            "                                                                                                  \n",
            " dot_17 (Dot)                   (None, 300, 1)       0           ['reshape_25[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_17 (Flatten)           (None, 300)          0           ['dot_17[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_17[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,246,207\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.7321 - accuracy: 0.3484 - val_loss: 1.6133 - val_accuracy: 0.3987\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.6000 - accuracy: 0.3928 - val_loss: 1.5463 - val_accuracy: 0.4014\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.5627 - accuracy: 0.4045 - val_loss: 1.5260 - val_accuracy: 0.4072\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.5417 - accuracy: 0.4098 - val_loss: 1.5110 - val_accuracy: 0.4138\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.5292 - accuracy: 0.4128 - val_loss: 1.4969 - val_accuracy: 0.4150\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.5116 - accuracy: 0.4156 - val_loss: 1.5028 - val_accuracy: 0.4181\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.5005 - accuracy: 0.4202 - val_loss: 1.4748 - val_accuracy: 0.4215\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 1.4873 - accuracy: 0.4238 - val_loss: 1.4780 - val_accuracy: 0.4165\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.4762 - accuracy: 0.4275 - val_loss: 1.4738 - val_accuracy: 0.4277\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 1.4716 - accuracy: 0.4276 - val_loss: 1.4700 - val_accuracy: 0.4285\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 1.4617 - accuracy: 0.4289 - val_loss: 1.4574 - val_accuracy: 0.4367\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 1.4551 - accuracy: 0.4336 - val_loss: 1.4513 - val_accuracy: 0.4324\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.4493 - accuracy: 0.4333 - val_loss: 1.4532 - val_accuracy: 0.4347\n",
            "Epoch 14/100\n",
            "1847/1848 [============================>.] - ETA: 0s - loss: 1.4413 - accuracy: 0.4376Restoring model weights from the end of the best epoch: 11.\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.4413 - accuracy: 0.4376 - val_loss: 1.4566 - val_accuracy: 0.4281\n",
            "Epoch 14: early stopping\n",
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 600, 300)         13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,607\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.7520 - accuracy: 0.3408 - val_loss: 1.6363 - val_accuracy: 0.3836\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.6371 - accuracy: 0.3830 - val_loss: 1.5791 - val_accuracy: 0.3964\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5990 - accuracy: 0.3955 - val_loss: 1.5549 - val_accuracy: 0.3952\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5836 - accuracy: 0.3992 - val_loss: 1.5409 - val_accuracy: 0.4014\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5652 - accuracy: 0.4013 - val_loss: 1.5349 - val_accuracy: 0.4045\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 10s 6ms/step - loss: 1.5543 - accuracy: 0.4090 - val_loss: 1.5357 - val_accuracy: 0.4057\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 10s 6ms/step - loss: 1.5456 - accuracy: 0.4078 - val_loss: 1.5162 - val_accuracy: 0.4091\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5330 - accuracy: 0.4072 - val_loss: 1.5203 - val_accuracy: 0.4060\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5292 - accuracy: 0.4118 - val_loss: 1.4950 - val_accuracy: 0.4157\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5151 - accuracy: 0.4139 - val_loss: 1.5069 - val_accuracy: 0.4165\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5132 - accuracy: 0.4119 - val_loss: 1.4872 - val_accuracy: 0.4173\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5044 - accuracy: 0.4187 - val_loss: 1.4844 - val_accuracy: 0.4243\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 1.5040 - accuracy: 0.4204 - val_loss: 1.4898 - val_accuracy: 0.4165\n",
            "Epoch 14/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 1.4898 - accuracy: 0.4249 - val_loss: 1.4862 - val_accuracy: 0.4157\n",
            "Epoch 15/100\n",
            "1839/1848 [============================>.] - ETA: 0s - loss: 1.4941 - accuracy: 0.4254Restoring model weights from the end of the best epoch: 12.\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 1.4941 - accuracy: 0.4252 - val_loss: 1.4841 - val_accuracy: 0.4227\n",
            "Epoch 15: early stopping\n",
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 600)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 600, 300)     13194600    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_27 (Reshape)           (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_27[0][0]']             \n",
            "                                                                                                  \n",
            " dot_18 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_18 (Flatten)           (None, 300)          0           ['dot_18[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 300)          0           ['flatten_18[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_28 (Reshape)           (None, 1, 300)       0           ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_28[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_29 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_29[0][0]']             \n",
            "                                                                                                  \n",
            " dot_19 (Dot)                   (None, 300, 1)       0           ['reshape_28[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_19 (Flatten)           (None, 300)          0           ['dot_19[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_19[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,246,207\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 21s 11ms/step - loss: 1.7292 - accuracy: 0.3490 - val_loss: 1.5952 - val_accuracy: 0.3874\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 22s 12ms/step - loss: 1.5985 - accuracy: 0.3949 - val_loss: 1.5666 - val_accuracy: 0.3956\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 1.5635 - accuracy: 0.4005 - val_loss: 1.5394 - val_accuracy: 0.4045\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 1.5441 - accuracy: 0.4065 - val_loss: 1.5164 - val_accuracy: 0.4103\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 1.5282 - accuracy: 0.4117 - val_loss: 1.5061 - val_accuracy: 0.4084\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 1.5190 - accuracy: 0.4125 - val_loss: 1.4902 - val_accuracy: 0.4184\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 23s 12ms/step - loss: 1.5019 - accuracy: 0.4204 - val_loss: 1.4764 - val_accuracy: 0.4219\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 1.4929 - accuracy: 0.4216 - val_loss: 1.4928 - val_accuracy: 0.4212\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 19s 11ms/step - loss: 1.4895 - accuracy: 0.4206 - val_loss: 1.4654 - val_accuracy: 0.4250\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 1.4722 - accuracy: 0.4275 - val_loss: 1.4620 - val_accuracy: 0.4320\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 23s 12ms/step - loss: 1.4683 - accuracy: 0.4294 - val_loss: 1.4675 - val_accuracy: 0.4312\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 1.4619 - accuracy: 0.4323 - val_loss: 1.4519 - val_accuracy: 0.4359\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 1.4514 - accuracy: 0.4377 - val_loss: 1.4487 - val_accuracy: 0.4390\n",
            "Epoch 14/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 1.4505 - accuracy: 0.4361 - val_loss: 1.4451 - val_accuracy: 0.4382\n",
            "Epoch 15/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 1.4451 - accuracy: 0.4415 - val_loss: 1.4415 - val_accuracy: 0.4382\n",
            "Epoch 16/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 1.4328 - accuracy: 0.4449 - val_loss: 1.4429 - val_accuracy: 0.4401\n",
            "Epoch 17/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 1.4327 - accuracy: 0.4421 - val_loss: 1.4541 - val_accuracy: 0.4351\n",
            "Epoch 18/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 1.4247 - accuracy: 0.4477 - val_loss: 1.4412 - val_accuracy: 0.4378\n",
            "Epoch 19/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 1.4156 - accuracy: 0.4526 - val_loss: 1.4349 - val_accuracy: 0.4436\n",
            "Epoch 20/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 1.4190 - accuracy: 0.4506 - val_loss: 1.4384 - val_accuracy: 0.4417\n",
            "Epoch 21/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.4079 - accuracy: 0.4510 - val_loss: 1.4479 - val_accuracy: 0.4370\n",
            "Epoch 22/100\n",
            "1844/1848 [============================>.] - ETA: 0s - loss: 1.4054 - accuracy: 0.4585Restoring model weights from the end of the best epoch: 19.\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 1.4057 - accuracy: 0.4585 - val_loss: 1.4347 - val_accuracy: 0.4386\n",
            "Epoch 22: early stopping\n",
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 750)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 750, 300)         13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,607\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 1.7595 - accuracy: 0.3406 - val_loss: 1.6743 - val_accuracy: 0.3506\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 1.6473 - accuracy: 0.3796 - val_loss: 1.5918 - val_accuracy: 0.3890\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.6085 - accuracy: 0.3931 - val_loss: 1.5736 - val_accuracy: 0.3820\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5853 - accuracy: 0.4009 - val_loss: 1.5693 - val_accuracy: 0.3995\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5746 - accuracy: 0.4046 - val_loss: 1.5365 - val_accuracy: 0.4053\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 1.5617 - accuracy: 0.4022 - val_loss: 1.5230 - val_accuracy: 0.4029\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5541 - accuracy: 0.4041 - val_loss: 1.5257 - val_accuracy: 0.4010\n",
            "Epoch 8/100\n",
            "1845/1848 [============================>.] - ETA: 0s - loss: 1.5404 - accuracy: 0.4072Restoring model weights from the end of the best epoch: 5.\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5406 - accuracy: 0.4072 - val_loss: 1.5282 - val_accuracy: 0.4037\n",
            "Epoch 8: early stopping\n",
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 750)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 750, 300)     13194600    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 750, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_30 (Reshape)           (None, 1, 750)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 750)       0           ['reshape_30[0][0]']             \n",
            "                                                                                                  \n",
            " dot_20 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_20 (Flatten)           (None, 300)          0           ['dot_20[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 300)          0           ['flatten_20[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_31 (Reshape)           (None, 1, 300)       0           ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_31[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_32 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_32[0][0]']             \n",
            "                                                                                                  \n",
            " dot_21 (Dot)                   (None, 300, 1)       0           ['reshape_31[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_21 (Flatten)           (None, 300)          0           ['dot_21[0][0]']                 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_21[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,246,207\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 1.7530 - accuracy: 0.3421 - val_loss: 1.6665 - val_accuracy: 0.3483\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.6261 - accuracy: 0.3846 - val_loss: 1.5688 - val_accuracy: 0.3975\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 1.5815 - accuracy: 0.4003 - val_loss: 1.5344 - val_accuracy: 0.3991\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.5559 - accuracy: 0.4022 - val_loss: 1.5172 - val_accuracy: 0.4053\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 1.5354 - accuracy: 0.4068 - val_loss: 1.5040 - val_accuracy: 0.4088\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 1.5272 - accuracy: 0.4111 - val_loss: 1.4914 - val_accuracy: 0.4150\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.5129 - accuracy: 0.4124 - val_loss: 1.4893 - val_accuracy: 0.4165\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 1.5017 - accuracy: 0.4191 - val_loss: 1.4699 - val_accuracy: 0.4204\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 1.4887 - accuracy: 0.4229 - val_loss: 1.4576 - val_accuracy: 0.4281\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 23s 13ms/step - loss: 1.4791 - accuracy: 0.4252 - val_loss: 1.4654 - val_accuracy: 0.4239\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.4750 - accuracy: 0.4269 - val_loss: 1.4506 - val_accuracy: 0.4239\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 21s 12ms/step - loss: 1.4675 - accuracy: 0.4321 - val_loss: 1.4632 - val_accuracy: 0.4285\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.4526 - accuracy: 0.4323 - val_loss: 1.4533 - val_accuracy: 0.4262\n",
            "Epoch 14/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.4532 - accuracy: 0.4329 - val_loss: 1.4397 - val_accuracy: 0.4367\n",
            "Epoch 15/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.4457 - accuracy: 0.4392 - val_loss: 1.4570 - val_accuracy: 0.4394\n",
            "Epoch 16/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.4369 - accuracy: 0.4411 - val_loss: 1.4555 - val_accuracy: 0.4301\n",
            "Epoch 17/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.4323 - accuracy: 0.4444 - val_loss: 1.4394 - val_accuracy: 0.4374\n",
            "Epoch 18/100\n",
            "1843/1848 [============================>.] - ETA: 0s - loss: 1.4240 - accuracy: 0.4425Restoring model weights from the end of the best epoch: 15.\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 1.4239 - accuracy: 0.4426 - val_loss: 1.4392 - val_accuracy: 0.4386\n",
            "Epoch 18: early stopping\n",
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 900)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 900, 300)         13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,607\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 13s 6ms/step - loss: 1.7636 - accuracy: 0.3400 - val_loss: 1.7083 - val_accuracy: 0.3448\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 10s 6ms/step - loss: 1.6608 - accuracy: 0.3697 - val_loss: 1.6101 - val_accuracy: 0.3925\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.6162 - accuracy: 0.3879 - val_loss: 1.5821 - val_accuracy: 0.3975\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5975 - accuracy: 0.3940 - val_loss: 1.5678 - val_accuracy: 0.3991\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5834 - accuracy: 0.3980 - val_loss: 1.5435 - val_accuracy: 0.4033\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 10s 6ms/step - loss: 1.5657 - accuracy: 0.4045 - val_loss: 1.5338 - val_accuracy: 0.3998\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5590 - accuracy: 0.4066 - val_loss: 1.5406 - val_accuracy: 0.4006\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5540 - accuracy: 0.4055 - val_loss: 1.5196 - val_accuracy: 0.4068\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5432 - accuracy: 0.4072 - val_loss: 1.5144 - val_accuracy: 0.4064\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 10s 6ms/step - loss: 1.5353 - accuracy: 0.4097 - val_loss: 1.5113 - val_accuracy: 0.4107\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 1.5352 - accuracy: 0.4081 - val_loss: 1.5039 - val_accuracy: 0.4076\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 1.5283 - accuracy: 0.4117 - val_loss: 1.5105 - val_accuracy: 0.4060\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 1.5197 - accuracy: 0.4127 - val_loss: 1.4960 - val_accuracy: 0.4146\n",
            "Epoch 14/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 1.5146 - accuracy: 0.4204 - val_loss: 1.5040 - val_accuracy: 0.4192\n",
            "Epoch 15/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 1.5104 - accuracy: 0.4169 - val_loss: 1.5147 - val_accuracy: 0.4099\n",
            "Epoch 16/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 1.5113 - accuracy: 0.4185 - val_loss: 1.5042 - val_accuracy: 0.4150\n",
            "Epoch 17/100\n",
            "1842/1848 [============================>.] - ETA: 0s - loss: 1.5041 - accuracy: 0.4180Restoring model weights from the end of the best epoch: 14.\n",
            "1848/1848 [==============================] - 13s 7ms/step - loss: 1.5035 - accuracy: 0.4187 - val_loss: 1.4825 - val_accuracy: 0.4181\n",
            "Epoch 17: early stopping\n",
            "Model: \"model_24\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 900)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 900, 300)     13194600    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 900, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_33 (Reshape)           (None, 1, 900)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 900)       0           ['reshape_33[0][0]']             \n",
            "                                                                                                  \n",
            " dot_22 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_22 (Flatten)           (None, 300)          0           ['dot_22[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 300)          0           ['flatten_22[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_34 (Reshape)           (None, 1, 300)       0           ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_34[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_35 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_35[0][0]']             \n",
            "                                                                                                  \n",
            " dot_23 (Dot)                   (None, 300, 1)       0           ['reshape_34[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_23 (Flatten)           (None, 300)          0           ['dot_23[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_23[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,246,207\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 33s 17ms/step - loss: 1.7579 - accuracy: 0.3444 - val_loss: 1.6740 - val_accuracy: 0.3495\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 1.6413 - accuracy: 0.3786 - val_loss: 1.5891 - val_accuracy: 0.3967\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 1.5827 - accuracy: 0.3971 - val_loss: 1.5534 - val_accuracy: 0.4091\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 30s 16ms/step - loss: 1.5600 - accuracy: 0.4005 - val_loss: 1.5297 - val_accuracy: 0.3998\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 1.5393 - accuracy: 0.4079 - val_loss: 1.5063 - val_accuracy: 0.4126\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 1.5216 - accuracy: 0.4097 - val_loss: 1.4945 - val_accuracy: 0.4115\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 1.5111 - accuracy: 0.4124 - val_loss: 1.4799 - val_accuracy: 0.4204\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 35s 19ms/step - loss: 1.5033 - accuracy: 0.4159 - val_loss: 1.4689 - val_accuracy: 0.4184\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 35s 19ms/step - loss: 1.4908 - accuracy: 0.4223 - val_loss: 1.4879 - val_accuracy: 0.4200\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 1.4825 - accuracy: 0.4227 - val_loss: 1.4644 - val_accuracy: 0.4293\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 32s 17ms/step - loss: 1.4770 - accuracy: 0.4282 - val_loss: 1.4597 - val_accuracy: 0.4215\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 1.4721 - accuracy: 0.4280 - val_loss: 1.4601 - val_accuracy: 0.4312\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 32s 17ms/step - loss: 1.4629 - accuracy: 0.4313 - val_loss: 1.4650 - val_accuracy: 0.4258\n",
            "Epoch 14/100\n",
            "1848/1848 [==============================] - 31s 17ms/step - loss: 1.4580 - accuracy: 0.4350 - val_loss: 1.4620 - val_accuracy: 0.4212\n",
            "Epoch 15/100\n",
            "1848/1848 [==============================] - 35s 19ms/step - loss: 1.4535 - accuracy: 0.4370 - val_loss: 1.4504 - val_accuracy: 0.4363\n",
            "Epoch 16/100\n",
            "1848/1848 [==============================] - 35s 19ms/step - loss: 1.4469 - accuracy: 0.4410 - val_loss: 1.4527 - val_accuracy: 0.4266\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/100\n",
            "1848/1848 [==============================] - 32s 17ms/step - loss: 1.4424 - accuracy: 0.4415 - val_loss: 1.4513 - val_accuracy: 0.4374\n",
            "Epoch 18/100\n",
            "1848/1848 [==============================] - 34s 19ms/step - loss: 1.4357 - accuracy: 0.4424 - val_loss: 1.4593 - val_accuracy: 0.4401\n",
            "Epoch 19/100\n",
            "1848/1848 [==============================] - 30s 16ms/step - loss: 1.4292 - accuracy: 0.4451 - val_loss: 1.4408 - val_accuracy: 0.4312\n",
            "Epoch 20/100\n",
            "1848/1848 [==============================] - 35s 19ms/step - loss: 1.4212 - accuracy: 0.4437 - val_loss: 1.4465 - val_accuracy: 0.4417\n",
            "Epoch 21/100\n",
            "1848/1848 [==============================] - 30s 16ms/step - loss: 1.4204 - accuracy: 0.4480 - val_loss: 1.4466 - val_accuracy: 0.4386\n",
            "Epoch 22/100\n",
            "1848/1848 [==============================] - 30s 16ms/step - loss: 1.4214 - accuracy: 0.4432 - val_loss: 1.4519 - val_accuracy: 0.4227\n",
            "Epoch 23/100\n",
            "1847/1848 [============================>.] - ETA: 0s - loss: 1.4166 - accuracy: 0.4434Restoring model weights from the end of the best epoch: 20.\n",
            "1848/1848 [==============================] - 30s 16ms/step - loss: 1.4167 - accuracy: 0.4433 - val_loss: 1.4449 - val_accuracy: 0.4343\n",
            "Epoch 23: early stopping\n",
            "best dan performance  0.425416499376297\n",
            "best dan embedding size  450\n",
            "best wan performance  0.4436264932155609\n",
            "best wan embedding size  600\n"
          ]
        }
      ],
      "source": [
        "best_dan_score, best_wan_score  = 0,0\n",
        "best_dan_emb_size, best_wan_emb_size = None, None\n",
        "\n",
        "for embedding_size in embedding_sizes:\n",
        "    \n",
        "    train_tokens_prebuilt = text_to_index_post_cleaning(df_train['Lyrics'],vocab_dict,embedding_size)\n",
        "    test_tokens_prebuilt = text_to_index_post_cleaning(df_test['Lyrics'],vocab_dict,embedding_size)\n",
        "    \n",
        "    dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix, output_layer_size = 7, max_sequence_length=embedding_size)\n",
        "    dan_sorted_history = dan_model_sorted.fit(np.array(train_tokens_prebuilt),\n",
        "                        np.array(train_labels.map(mapping)),\n",
        "                        validation_data=(np.array(test_tokens_prebuilt), np.array(test_labels.map(mapping))),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
        "                        callbacks = [es])\n",
        "    \n",
        "    \n",
        "    if max(dan_sorted_history.history['val_accuracy']) > best_dan_score:\n",
        "            best_dan_score = max(dan_sorted_history.history['val_accuracy'])\n",
        "            best_dan_emb_size = embedding_size\n",
        "            \n",
        "    wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix, output_layer_size = 7, max_sequence_length=embedding_size,\n",
        "                                   num_attention=1)\n",
        "    wan_sorted_history = wan_model_sorted.fit(np.array(train_tokens_prebuilt),\n",
        "                        np.array(train_labels.map(mapping)),\n",
        "                        validation_data=(np.array(test_tokens_prebuilt), np.array(test_labels.map(mapping))),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
        "                        callbacks = [es])\n",
        "    \n",
        "    \n",
        "    if max(wan_sorted_history.history['val_accuracy']) > best_wan_score:\n",
        "            best_wan_score = max(wan_sorted_history.history['val_accuracy'])\n",
        "            best_wan_emb_size = embedding_size\n",
        "\n",
        "print('best dan performance ', best_dan_score)\n",
        "print('best dan embedding size ', best_dan_emb_size)\n",
        "print('best wan performance ', best_wan_score)\n",
        "print('best wan embedding size ', best_wan_emb_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMF7vRI6PvDT"
      },
      "source": [
        "# 4 Custom Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilvYcJtMPvDT"
      },
      "source": [
        "Both of those models used prebuilt embeddings, what happens if we use custom ones?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl8E864kPvDT"
      },
      "outputs": [],
      "source": [
        "df_train['Lyrics_String']=df_train['Lyrics'].apply(lambda x: \" \".join(x))\n",
        "df_test['Lyrics_String']=df_test['Lyrics'].apply(lambda x: \" \".join(x))\n",
        "vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG4hX9NkPvDU",
        "outputId": "616a1394-7c32-4c2a-fdd4-dcf17d4e2ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16303    go take life dreams fire go take day time hour...\n",
              "8721     bitch one click ruin life trip yea take pic bi...\n",
              "11930    eyes like face bit different bit fucked guess ...\n",
              "7945     ugh ugh what what ugh what what ugh ugh behind...\n",
              "15504    age darkness light appears wards away ancient ...\n",
              "                               ...                        \n",
              "7303     saucey genius aztro cut put magnum bottom gloc...\n",
              "9125     i’ve loved / i’ve done months made feel young ...\n",
              "5125     another it's kel p vibes wanna give everything...\n",
              "15805    woke mornin' understand means give life one ma...\n",
              "2952     läppar döljer dina tänder och din tunga är så ...\n",
              "Name: Lyrics_String, Length: 14778, dtype: object"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['Lyrics_String']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "NktullVSPvDU",
        "outputId": "4b406783-413e-438d-dfff-d42850de6e78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer.fit(df_train['Lyrics_String'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fItq1bp4PvDU",
        "outputId": "f813335f-7de3-4a24-af98-f78a3189bf3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "96406"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYWOv3B4PvDU"
      },
      "outputs": [],
      "source": [
        "embedding_matrix_cust = np.random.random((len(vectorizer.get_feature_names()) + 1) * 300).reshape((len(vectorizer.get_feature_names()) + 1,300))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK388WVSPvDV"
      },
      "outputs": [],
      "source": [
        "embedding_matrix_cust[-1] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e2raEZ2PvDV"
      },
      "outputs": [],
      "source": [
        "mapping_dict = {}\n",
        "i = 0\n",
        "for feature_name in vectorizer.get_feature_names():\n",
        "    mapping_dict[feature_name] = i\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWOojmW7PvDV"
      },
      "outputs": [],
      "source": [
        "def get_unique_words(dataset, mapping_dict, seq_size = 1000):\n",
        "    mapped_lyrics = []\n",
        "    for song in dataset:\n",
        "        song_tokens = []\n",
        "        for word in song.split():\n",
        "            try:\n",
        "                song_tokens.append(mapping_dict[word])\n",
        "            except:\n",
        "                song_tokens.append(len(mapping_dict))\n",
        "        if len(song_tokens) > seq_size:\n",
        "            song_tokens = song_tokens[:seq_size]\n",
        "        elif len(song_tokens) < seq_size:\n",
        "            while len(song_tokens) < seq_size:\n",
        "                song_tokens.append(len(mapping_dict))\n",
        "                    \n",
        "        mapped_lyrics.append(song_tokens)\n",
        "    return np.array(mapped_lyrics)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DecTaok3PvDV"
      },
      "outputs": [],
      "source": [
        "mapped_lyrics_train = get_unique_words(df_train['Lyrics_String'], mapping_dict, seq_size = 1000)\n",
        "mapped_lyrics_test = get_unique_words(df_test['Lyrics_String'], mapping_dict, seq_size = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5ZHY-9dPvDV",
        "outputId": "2aedc804-a98c-46c3-d3b0-c55e9a493b58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Rock': 0,\n",
              " 'Indie': 1,\n",
              " 'Alternative': 2,\n",
              " 'Hip Hop': 3,\n",
              " 'Metal': 4,\n",
              " 'Pop': 5,\n",
              " 'Blues': 6}"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mapping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWBH_i1QjHy3",
        "outputId": "1736781e-45b6-4a72-e22b-159bdeb8ddbd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rock           2406\n",
              "Indie          1196\n",
              "Pop            1057\n",
              "Metal           934\n",
              "Alternative     720\n",
              "Hip Hop         675\n",
              "Blues           420\n",
              "Name: Major Genre, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vqFLf2IJPvDW"
      },
      "outputs": [],
      "source": [
        "weights = 4720/train_labels.value_counts()\n",
        "class_weights = {}\n",
        "for num in range(len(weights)):\n",
        "    class_weights[mapping[weights.index[num]]] = weights.iloc[num]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "G-GJ7Nr6PvDW",
        "outputId": "db8a33e2-f193-4380-8dd1-717dd28e9da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.9617622610141314,\n",
              " 1: 3.9464882943143813,\n",
              " 2: 6.555555555555555,\n",
              " 3: 6.992592592592593,\n",
              " 4: 5.053533190578158,\n",
              " 5: 4.465468306527909,\n",
              " 6: 11.238095238095237}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdesAc6-PvDW",
        "outputId": "2b689086-067a-4908-b20f-ee04b8203dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 23s 11ms/step - loss: 4.1546 - accuracy: 0.1897 - val_loss: 1.8286 - val_accuracy: 0.2081\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 4.0748 - accuracy: 0.1880 - val_loss: 1.8068 - val_accuracy: 0.2507\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 22s 12ms/step - loss: 4.0551 - accuracy: 0.2045 - val_loss: 1.7979 - val_accuracy: 0.3010\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 4.0499 - accuracy: 0.2053 - val_loss: 1.8205 - val_accuracy: 0.1960\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 4.0302 - accuracy: 0.2066 - val_loss: 1.7987 - val_accuracy: 0.2460\n",
            "Epoch 6/100\n",
            "1841/1848 [============================>.] - ETA: 0s - loss: 4.0375 - accuracy: 0.2070Restoring model weights from the end of the best epoch: 3.\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 4.0378 - accuracy: 0.2067 - val_loss: 1.8001 - val_accuracy: 0.1918\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ],
      "source": [
        "dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix_cust, output_layer_size = 7)\n",
        "dan_sorted_history = dan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
        "                        np.array(train_labels.map(mapping)),\n",
        "                        validation_data=(np.array(mapped_lyrics_test), np.array(test_labels.map(mapping))),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 2,\n",
        "                        callbacks = [es],\n",
        "                        class_weight = class_weights                  \n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMJiN9esPvDW",
        "outputId": "7b171551-6a8c-4a6c-c27d-6765795c1778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_26\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 1000)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 1000, 300)    28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_12 (Reshape)           (None, 1, 1000)      0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 1000)      0           ['reshape_12[0][0]']             \n",
            "                                                                                                  \n",
            " dot_8 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)            (None, 300)          0           ['dot_8[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 300)          0           ['flatten_8[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_13 (Reshape)           (None, 1, 300)       0           ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_13[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_14 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_14[0][0]']             \n",
            "                                                                                                  \n",
            " dot_9 (Dot)                    (None, 300, 1)       0           ['reshape_13[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_9 (Flatten)            (None, 300)          0           ['dot_9[0][0]']                  \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_9[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 43s 22ms/step - loss: 4.1504 - accuracy: 0.1979 - val_loss: 1.8852 - val_accuracy: 0.1112\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 39s 21ms/step - loss: 4.0717 - accuracy: 0.1995 - val_loss: 1.8245 - val_accuracy: 0.1643\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 37s 20ms/step - loss: 4.0492 - accuracy: 0.2032 - val_loss: 1.8337 - val_accuracy: 0.2143\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 40s 21ms/step - loss: 4.0230 - accuracy: 0.2130 - val_loss: 1.7862 - val_accuracy: 0.2146\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 39s 21ms/step - loss: 3.9999 - accuracy: 0.2071 - val_loss: 1.7704 - val_accuracy: 0.2329\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 40s 21ms/step - loss: 3.9771 - accuracy: 0.2194 - val_loss: 1.7833 - val_accuracy: 0.2026\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 39s 21ms/step - loss: 3.9665 - accuracy: 0.2153 - val_loss: 1.8277 - val_accuracy: 0.2143\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 45s 24ms/step - loss: 3.9475 - accuracy: 0.2208 - val_loss: 1.7653 - val_accuracy: 0.2348\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 37s 20ms/step - loss: 3.9423 - accuracy: 0.2121 - val_loss: 1.7951 - val_accuracy: 0.2367\n",
            "Epoch 10/100\n",
            "1848/1848 [==============================] - 35s 19ms/step - loss: 3.9421 - accuracy: 0.2165 - val_loss: 1.7510 - val_accuracy: 0.2445\n",
            "Epoch 11/100\n",
            "1848/1848 [==============================] - 36s 19ms/step - loss: 3.9414 - accuracy: 0.2108 - val_loss: 1.7424 - val_accuracy: 0.2929\n",
            "Epoch 12/100\n",
            "1848/1848 [==============================] - 40s 22ms/step - loss: 3.9265 - accuracy: 0.2214 - val_loss: 1.7946 - val_accuracy: 0.1817\n",
            "Epoch 13/100\n",
            "1848/1848 [==============================] - 38s 21ms/step - loss: 3.9327 - accuracy: 0.2278 - val_loss: 1.7746 - val_accuracy: 0.2282\n",
            "Epoch 14/100\n",
            "1845/1848 [============================>.] - ETA: 0s - loss: 3.9204 - accuracy: 0.2212Restoring model weights from the end of the best epoch: 11.\n",
            "1848/1848 [==============================] - 32s 17ms/step - loss: 3.9212 - accuracy: 0.2214 - val_loss: 1.7647 - val_accuracy: 0.2123\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ],
      "source": [
        "wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix_cust, output_layer_size = 7,\n",
        "                                   num_attention=1)\n",
        "wan_sorted_history = wan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
        "                        np.array(train_labels.map(mapping)),\n",
        "                        validation_data=(np.array(mapped_lyrics_test), np.array(test_labels.map(mapping))),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
        "                        callbacks = [es],\n",
        "                        class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOsYoA7_PvDW"
      },
      "source": [
        "best result .29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiwLWj6TPvDX"
      },
      "source": [
        "lets experiment with embedding size and see if we find anything interesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrt9vYEbPvDX",
        "outputId": "3648f96e-4c9a-41ca-ce55-65d8609db868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 100, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 9s 4ms/step - loss: 4.3608 - accuracy: 0.1411 - val_loss: 1.9491 - val_accuracy: 0.0632\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 4.3518 - accuracy: 0.1191 - val_loss: 1.9506 - val_accuracy: 0.1341\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 4.3519 - accuracy: 0.1181 - val_loss: 1.9436 - val_accuracy: 0.0632\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 6s 3ms/step - loss: 4.3516 - accuracy: 0.1490 - val_loss: 1.9485 - val_accuracy: 0.0632\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 4.3521 - accuracy: 0.1162 - val_loss: 1.9469 - val_accuracy: 0.1654\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 6s 3ms/step - loss: 4.3519 - accuracy: 0.1205 - val_loss: 1.9453 - val_accuracy: 0.0926\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 4.3514 - accuracy: 0.1606 - val_loss: 1.9486 - val_accuracy: 0.1054\n",
            "Epoch 8/100\n",
            "1843/1848 [============================>.] - ETA: 0s - loss: 4.3532 - accuracy: 0.1103Restoring model weights from the end of the best epoch: 5.\n",
            "1848/1848 [==============================] - 6s 3ms/step - loss: 4.3515 - accuracy: 0.1102 - val_loss: 1.9465 - val_accuracy: 0.1368\n",
            "Epoch 8: early stopping\n",
            "Model: \"model_31\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 100, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 100, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_18 (Reshape)           (None, 1, 100)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 100)       0           ['reshape_18[0][0]']             \n",
            "                                                                                                  \n",
            " dot_12 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_12 (Flatten)           (None, 300)          0           ['dot_12[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 300)          0           ['flatten_12[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_19 (Reshape)           (None, 1, 300)       0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_19[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_20 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_20[0][0]']             \n",
            "                                                                                                  \n",
            " dot_13 (Dot)                   (None, 300, 1)       0           ['reshape_19[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_13 (Flatten)           (None, 300)          0           ['dot_13[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_13[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 4.3370 - accuracy: 0.1338 - val_loss: 1.9534 - val_accuracy: 0.0790\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.3167 - accuracy: 0.1287 - val_loss: 1.9305 - val_accuracy: 0.1406\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.3069 - accuracy: 0.1216 - val_loss: 1.9343 - val_accuracy: 0.1317\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 4.3027 - accuracy: 0.1247 - val_loss: 1.9248 - val_accuracy: 0.1310\n",
            "Epoch 5/100\n",
            "1845/1848 [============================>.] - ETA: 0s - loss: 4.3003 - accuracy: 0.1251Restoring model weights from the end of the best epoch: 2.\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.3003 - accuracy: 0.1251 - val_loss: 1.9393 - val_accuracy: 0.0976\n",
            "Epoch 5: early stopping\n",
            "Model: \"model_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 200)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 200, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 9s 4ms/step - loss: 4.3041 - accuracy: 0.1433 - val_loss: 1.8937 - val_accuracy: 0.1705\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 4.2436 - accuracy: 0.1407 - val_loss: 1.9367 - val_accuracy: 0.0721\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 6s 3ms/step - loss: 4.2010 - accuracy: 0.1491 - val_loss: 1.8661 - val_accuracy: 0.1461\n",
            "Epoch 4/100\n",
            "1846/1848 [============================>.] - ETA: 0s - loss: 4.1955 - accuracy: 0.1442Restoring model weights from the end of the best epoch: 1.\n",
            "1848/1848 [==============================] - 6s 3ms/step - loss: 4.1950 - accuracy: 0.1442 - val_loss: 1.8722 - val_accuracy: 0.1395\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_33\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 200)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 200, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 200, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_21 (Reshape)           (None, 1, 200)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 200)       0           ['reshape_21[0][0]']             \n",
            "                                                                                                  \n",
            " dot_14 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_14 (Flatten)           (None, 300)          0           ['dot_14[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 300)          0           ['flatten_14[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_22 (Reshape)           (None, 1, 300)       0           ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_22[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_23 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_23[0][0]']             \n",
            "                                                                                                  \n",
            " dot_15 (Dot)                   (None, 300, 1)       0           ['reshape_22[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_15 (Flatten)           (None, 300)          0           ['dot_15[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_15[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 11s 5ms/step - loss: 4.2113 - accuracy: 0.1749 - val_loss: 1.8909 - val_accuracy: 0.1623\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.1451 - accuracy: 0.1744 - val_loss: 1.8388 - val_accuracy: 0.1879\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.1033 - accuracy: 0.1860 - val_loss: 1.8234 - val_accuracy: 0.2286\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 4.0808 - accuracy: 0.1987 - val_loss: 1.8192 - val_accuracy: 0.2294\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 4.0651 - accuracy: 0.1947 - val_loss: 1.8394 - val_accuracy: 0.1840\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 13s 7ms/step - loss: 4.0364 - accuracy: 0.1889 - val_loss: 1.7949 - val_accuracy: 0.2425\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 4.0007 - accuracy: 0.2090 - val_loss: 1.8106 - val_accuracy: 0.2015\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 3.9988 - accuracy: 0.1952 - val_loss: 1.8435 - val_accuracy: 0.1589\n",
            "Epoch 9/100\n",
            "1845/1848 [============================>.] - ETA: 0s - loss: 3.9850 - accuracy: 0.1994Restoring model weights from the end of the best epoch: 6.\n",
            "1848/1848 [==============================] - 10s 6ms/step - loss: 3.9853 - accuracy: 0.1994 - val_loss: 1.7978 - val_accuracy: 0.1933\n",
            "Epoch 9: early stopping\n",
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 300)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 300, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.1918 - accuracy: 0.1726 - val_loss: 1.8608 - val_accuracy: 0.1364\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.0883 - accuracy: 0.1878 - val_loss: 1.8453 - val_accuracy: 0.1581\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.0708 - accuracy: 0.1941 - val_loss: 1.8246 - val_accuracy: 0.2205\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 4.0624 - accuracy: 0.2037 - val_loss: 1.8473 - val_accuracy: 0.1527\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 6s 3ms/step - loss: 4.0506 - accuracy: 0.2055 - val_loss: 1.9054 - val_accuracy: 0.1461\n",
            "Epoch 6/100\n",
            "1844/1848 [============================>.] - ETA: 0s - loss: 4.0381 - accuracy: 0.1975Restoring model weights from the end of the best epoch: 3.\n",
            "1848/1848 [==============================] - 6s 3ms/step - loss: 4.0386 - accuracy: 0.1977 - val_loss: 1.8506 - val_accuracy: 0.1945\n",
            "Epoch 6: early stopping\n",
            "Model: \"model_35\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 300, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 300, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_24 (Reshape)           (None, 1, 300)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 300)       0           ['reshape_24[0][0]']             \n",
            "                                                                                                  \n",
            " dot_16 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_16 (Flatten)           (None, 300)          0           ['dot_16[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 300)          0           ['flatten_16[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_25 (Reshape)           (None, 1, 300)       0           ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_25[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_26 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_26[0][0]']             \n",
            "                                                                                                  \n",
            " dot_17 (Dot)                   (None, 300, 1)       0           ['reshape_25[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_17 (Flatten)           (None, 300)          0           ['dot_17[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_17[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 13s 6ms/step - loss: 4.1469 - accuracy: 0.1859 - val_loss: 1.8245 - val_accuracy: 0.1910\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 4.0701 - accuracy: 0.2029 - val_loss: 1.8242 - val_accuracy: 0.1852\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 13s 7ms/step - loss: 4.0397 - accuracy: 0.1976 - val_loss: 1.7839 - val_accuracy: 0.3138\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 4.0211 - accuracy: 0.2118 - val_loss: 1.7835 - val_accuracy: 0.2344\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 4.0069 - accuracy: 0.1962 - val_loss: 1.7934 - val_accuracy: 0.2092\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - ETA: 0s - loss: 3.9894 - accuracy: 0.2005Restoring model weights from the end of the best epoch: 3.\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 3.9894 - accuracy: 0.2005 - val_loss: 1.7769 - val_accuracy: 0.2561\n",
            "Epoch 6: early stopping\n",
            "Model: \"model_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 400)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 400, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 9s 4ms/step - loss: 4.1650 - accuracy: 0.1822 - val_loss: 1.8282 - val_accuracy: 0.1620\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.0791 - accuracy: 0.2056 - val_loss: 1.8347 - val_accuracy: 0.1713\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.0605 - accuracy: 0.2056 - val_loss: 1.8528 - val_accuracy: 0.1775\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.0444 - accuracy: 0.2065 - val_loss: 1.8290 - val_accuracy: 0.1806\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.0373 - accuracy: 0.2028 - val_loss: 1.7954 - val_accuracy: 0.2821\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.0354 - accuracy: 0.2173 - val_loss: 1.8115 - val_accuracy: 0.2053\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 4.0181 - accuracy: 0.2079 - val_loss: 1.8216 - val_accuracy: 0.1875\n",
            "Epoch 8/100\n",
            "1835/1848 [============================>.] - ETA: 0s - loss: 4.0329 - accuracy: 0.2213Restoring model weights from the end of the best epoch: 5.\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 4.0295 - accuracy: 0.2207 - val_loss: 1.8256 - val_accuracy: 0.1964\n",
            "Epoch 8: early stopping\n",
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 400)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 400, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 400, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_27 (Reshape)           (None, 1, 400)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 400)       0           ['reshape_27[0][0]']             \n",
            "                                                                                                  \n",
            " dot_18 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_18 (Flatten)           (None, 300)          0           ['dot_18[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 300)          0           ['flatten_18[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_28 (Reshape)           (None, 1, 300)       0           ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_28[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_29 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_29[0][0]']             \n",
            "                                                                                                  \n",
            " dot_19 (Dot)                   (None, 300, 1)       0           ['reshape_28[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " flatten_19 (Flatten)           (None, 300)          0           ['dot_19[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_19[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 26s 10ms/step - loss: 4.1638 - accuracy: 0.2056 - val_loss: 1.8574 - val_accuracy: 0.1685\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 4.0775 - accuracy: 0.2035 - val_loss: 1.8392 - val_accuracy: 0.1616\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 4.0370 - accuracy: 0.2089 - val_loss: 1.8169 - val_accuracy: 0.2069\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 4.0099 - accuracy: 0.2134 - val_loss: 1.8012 - val_accuracy: 0.1991\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 3.9792 - accuracy: 0.2084 - val_loss: 1.7589 - val_accuracy: 0.2259\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 3.9493 - accuracy: 0.2167 - val_loss: 1.7478 - val_accuracy: 0.2828\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 3.9280 - accuracy: 0.2203 - val_loss: 1.7685 - val_accuracy: 0.2220\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 3.9291 - accuracy: 0.2106 - val_loss: 1.7553 - val_accuracy: 0.2174\n",
            "Epoch 9/100\n",
            "1845/1848 [============================>.] - ETA: 0s - loss: 3.9228 - accuracy: 0.2124Restoring model weights from the end of the best epoch: 6.\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 3.9231 - accuracy: 0.2125 - val_loss: 1.7530 - val_accuracy: 0.2329\n",
            "Epoch 9: early stopping\n",
            "Model: \"model_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 500, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 13s 6ms/step - loss: 4.1690 - accuracy: 0.1772 - val_loss: 1.8609 - val_accuracy: 0.1682\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 4.1108 - accuracy: 0.1976 - val_loss: 1.8417 - val_accuracy: 0.1616\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0956 - accuracy: 0.2020 - val_loss: 1.8052 - val_accuracy: 0.2491\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 4.0748 - accuracy: 0.2033 - val_loss: 1.8191 - val_accuracy: 0.2503\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 4.0684 - accuracy: 0.2019 - val_loss: 1.8154 - val_accuracy: 0.1879\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 4.0519 - accuracy: 0.1998 - val_loss: 1.8309 - val_accuracy: 0.1775\n",
            "Epoch 7/100\n",
            "1846/1848 [============================>.] - ETA: 0s - loss: 4.0568 - accuracy: 0.1966Restoring model weights from the end of the best epoch: 4.\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 4.0562 - accuracy: 0.1966 - val_loss: 1.8271 - val_accuracy: 0.1879\n",
            "Epoch 7: early stopping\n",
            "Model: \"model_39\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 500)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 500, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 500, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_30 (Reshape)           (None, 1, 500)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 500)       0           ['reshape_30[0][0]']             \n",
            "                                                                                                  \n",
            " dot_20 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_20 (Flatten)           (None, 300)          0           ['dot_20[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 300)          0           ['flatten_20[0][0]']             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " reshape_31 (Reshape)           (None, 1, 300)       0           ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_31[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_32 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_32[0][0]']             \n",
            "                                                                                                  \n",
            " dot_21 (Dot)                   (None, 300, 1)       0           ['reshape_31[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_21 (Flatten)           (None, 300)          0           ['dot_21[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_21[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 4.1676 - accuracy: 0.1958 - val_loss: 1.8234 - val_accuracy: 0.2073\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 4.0804 - accuracy: 0.2008 - val_loss: 1.8789 - val_accuracy: 0.1891\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 4.0361 - accuracy: 0.2090 - val_loss: 1.7982 - val_accuracy: 0.2131\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 13s 7ms/step - loss: 4.0091 - accuracy: 0.2192 - val_loss: 1.7915 - val_accuracy: 0.2007\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 3.9840 - accuracy: 0.2100 - val_loss: 1.7589 - val_accuracy: 0.2635\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 14s 7ms/step - loss: 3.9723 - accuracy: 0.2187 - val_loss: 1.7740 - val_accuracy: 0.2251\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 13s 7ms/step - loss: 3.9617 - accuracy: 0.2140 - val_loss: 1.7748 - val_accuracy: 0.2170\n",
            "Epoch 8/100\n",
            "1841/1848 [============================>.] - ETA: 0s - loss: 3.9551 - accuracy: 0.2053Restoring model weights from the end of the best epoch: 5.\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 3.9543 - accuracy: 0.2053 - val_loss: 1.8101 - val_accuracy: 0.2019\n",
            "Epoch 8: early stopping\n",
            "Model: \"model_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 600)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 600, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 4.1604 - accuracy: 0.1884 - val_loss: 1.8183 - val_accuracy: 0.2247\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0789 - accuracy: 0.1998 - val_loss: 1.8068 - val_accuracy: 0.2852\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 4.0499 - accuracy: 0.2089 - val_loss: 1.8217 - val_accuracy: 0.1914\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 4.0434 - accuracy: 0.2092 - val_loss: 1.8141 - val_accuracy: 0.1883\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0300 - accuracy: 0.2132 - val_loss: 1.7866 - val_accuracy: 0.3014\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0304 - accuracy: 0.2215 - val_loss: 1.8077 - val_accuracy: 0.2069\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 8s 5ms/step - loss: 4.0343 - accuracy: 0.2084 - val_loss: 1.8188 - val_accuracy: 0.2243\n",
            "Epoch 8/100\n",
            "1838/1848 [============================>.] - ETA: 0s - loss: 4.0427 - accuracy: 0.2043Restoring model weights from the end of the best epoch: 5.\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0406 - accuracy: 0.2043 - val_loss: 1.7901 - val_accuracy: 0.2731\n",
            "Epoch 8: early stopping\n",
            "Model: \"model_41\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 600)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 600, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 600, 1)       300         ['embedding_layer[0][0]']        \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                  \n",
            " reshape_33 (Reshape)           (None, 1, 600)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 600)       0           ['reshape_33[0][0]']             \n",
            "                                                                                                  \n",
            " dot_22 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_22 (Flatten)           (None, 300)          0           ['dot_22[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 300)          0           ['flatten_22[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_34 (Reshape)           (None, 1, 300)       0           ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_34[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_35 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_35[0][0]']             \n",
            "                                                                                                  \n",
            " dot_23 (Dot)                   (None, 300, 1)       0           ['reshape_34[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_23 (Flatten)           (None, 300)          0           ['dot_23[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_23[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 18s 9ms/step - loss: 4.1882 - accuracy: 0.1905 - val_loss: 1.8579 - val_accuracy: 0.1457\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 4.0907 - accuracy: 0.2071 - val_loss: 1.8225 - val_accuracy: 0.2050\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 4.0679 - accuracy: 0.1985 - val_loss: 1.8196 - val_accuracy: 0.2294\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 4.0449 - accuracy: 0.2008 - val_loss: 1.8093 - val_accuracy: 0.2313\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 4.0074 - accuracy: 0.2086 - val_loss: 1.8301 - val_accuracy: 0.1817\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 3.9840 - accuracy: 0.2134 - val_loss: 1.8415 - val_accuracy: 0.1472\n",
            "Epoch 7/100\n",
            "1847/1848 [============================>.] - ETA: 0s - loss: 3.9820 - accuracy: 0.2024Restoring model weights from the end of the best epoch: 4.\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 3.9818 - accuracy: 0.2024 - val_loss: 1.7778 - val_accuracy: 0.2174\n",
            "Epoch 7: early stopping\n",
            "Model: \"model_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 700)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 700, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 4.1572 - accuracy: 0.1968 - val_loss: 1.8662 - val_accuracy: 0.1499\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 13s 7ms/step - loss: 4.0682 - accuracy: 0.1997 - val_loss: 1.8187 - val_accuracy: 0.2011\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0562 - accuracy: 0.1972 - val_loss: 1.7859 - val_accuracy: 0.3305\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0427 - accuracy: 0.2149 - val_loss: 1.8348 - val_accuracy: 0.1875\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0397 - accuracy: 0.2070 - val_loss: 1.8059 - val_accuracy: 0.2026\n",
            "Epoch 6/100\n",
            "1842/1848 [============================>.] - ETA: 0s - loss: 4.0351 - accuracy: 0.2122Restoring model weights from the end of the best epoch: 3.\n",
            "1848/1848 [==============================] - 9s 5ms/step - loss: 4.0338 - accuracy: 0.2121 - val_loss: 1.8128 - val_accuracy: 0.1922\n",
            "Epoch 6: early stopping\n",
            "Model: \"model_43\"\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 700)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 700, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 700, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_36 (Reshape)           (None, 1, 700)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 700)       0           ['reshape_36[0][0]']             \n",
            "                                                                                                  \n",
            " dot_24 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_24 (Flatten)           (None, 300)          0           ['dot_24[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 300)          0           ['flatten_24[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_37 (Reshape)           (None, 1, 300)       0           ['concatenate_12[0][0]']         \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_37[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_38 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_38[0][0]']             \n",
            "                                                                                                  \n",
            " dot_25 (Dot)                   (None, 300, 1)       0           ['reshape_37[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_25 (Flatten)           (None, 300)          0           ['dot_25[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_25[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 18s 9ms/step - loss: 4.1775 - accuracy: 0.1813 - val_loss: 1.8260 - val_accuracy: 0.1639\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 4.0908 - accuracy: 0.1998 - val_loss: 1.8138 - val_accuracy: 0.1840\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 4.0461 - accuracy: 0.2184 - val_loss: 1.7926 - val_accuracy: 0.2139\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 4.0234 - accuracy: 0.2080 - val_loss: 1.8448 - val_accuracy: 0.1515\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 3.9983 - accuracy: 0.2119 - val_loss: 1.7645 - val_accuracy: 0.2557\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 3.9641 - accuracy: 0.2254 - val_loss: 1.7759 - val_accuracy: 0.2174\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 3.9502 - accuracy: 0.2132 - val_loss: 1.7735 - val_accuracy: 0.1988\n",
            "Epoch 8/100\n",
            "1845/1848 [============================>.] - ETA: 0s - loss: 3.9521 - accuracy: 0.2060Restoring model weights from the end of the best epoch: 5.\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 3.9522 - accuracy: 0.2058 - val_loss: 1.7600 - val_accuracy: 0.2026\n",
            "Epoch 8: early stopping\n",
            "Model: \"model_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 800)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 800, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 20s 6ms/step - loss: 4.1472 - accuracy: 0.1928 - val_loss: 1.8160 - val_accuracy: 0.2503\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 4.0723 - accuracy: 0.2119 - val_loss: 1.8239 - val_accuracy: 0.2487\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 4.0490 - accuracy: 0.2206 - val_loss: 1.8022 - val_accuracy: 0.2414\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 10s 6ms/step - loss: 4.0429 - accuracy: 0.2201 - val_loss: 1.8118 - val_accuracy: 0.2542\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 10s 5ms/step - loss: 4.0348 - accuracy: 0.2217 - val_loss: 1.8107 - val_accuracy: 0.1856\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 4.0361 - accuracy: 0.2162 - val_loss: 1.7935 - val_accuracy: 0.2259\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 10s 6ms/step - loss: 4.0201 - accuracy: 0.2071 - val_loss: 1.7739 - val_accuracy: 0.3177\n",
            "Epoch 8/100\n",
            "1848/1848 [==============================] - 13s 7ms/step - loss: 4.0240 - accuracy: 0.2098 - val_loss: 1.8359 - val_accuracy: 0.1875\n",
            "Epoch 9/100\n",
            "1848/1848 [==============================] - 19s 10ms/step - loss: 4.0222 - accuracy: 0.2139 - val_loss: 1.8303 - val_accuracy: 0.1949\n",
            "Epoch 10/100\n",
            "1844/1848 [============================>.] - ETA: 0s - loss: 4.0211 - accuracy: 0.2110Restoring model weights from the end of the best epoch: 7.\n",
            "1848/1848 [==============================] - 15s 8ms/step - loss: 4.0202 - accuracy: 0.2111 - val_loss: 1.7876 - val_accuracy: 0.2917\n",
            "Epoch 10: early stopping\n",
            "Model: \"model_45\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 800)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 800, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 800, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_39 (Reshape)           (None, 1, 800)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 800)       0           ['reshape_39[0][0]']             \n",
            "                                                                                                  \n",
            " dot_26 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_26 (Flatten)           (None, 300)          0           ['dot_26[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 300)          0           ['flatten_26[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_40 (Reshape)           (None, 1, 300)       0           ['concatenate_13[0][0]']         \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_40[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_41 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_41[0][0]']             \n",
            "                                                                                                  \n",
            " dot_27 (Dot)                   (None, 300, 1)       0           ['reshape_40[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_27 (Flatten)           (None, 300)          0           ['dot_27[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_27[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 24s 12ms/step - loss: 4.1714 - accuracy: 0.2010 - val_loss: 1.8274 - val_accuracy: 0.1790\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 21s 11ms/step - loss: 4.0987 - accuracy: 0.2025 - val_loss: 1.9532 - val_accuracy: 0.1418\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 21s 12ms/step - loss: 4.0554 - accuracy: 0.2152 - val_loss: 1.8361 - val_accuracy: 0.1573\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 22s 12ms/step - loss: 4.0408 - accuracy: 0.2053 - val_loss: 1.7976 - val_accuracy: 0.2468\n",
            "Epoch 5/100\n",
            "1848/1848 [==============================] - 21s 12ms/step - loss: 4.0138 - accuracy: 0.2144 - val_loss: 1.7790 - val_accuracy: 0.2650\n",
            "Epoch 6/100\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 3.9990 - accuracy: 0.2192 - val_loss: 1.8105 - val_accuracy: 0.1709\n",
            "Epoch 7/100\n",
            "1848/1848 [==============================] - 21s 11ms/step - loss: 3.9796 - accuracy: 0.2063 - val_loss: 1.8558 - val_accuracy: 0.1368\n",
            "Epoch 8/100\n",
            "1846/1848 [============================>.] - ETA: 0s - loss: 3.9596 - accuracy: 0.2157Restoring model weights from the end of the best epoch: 5.\n",
            "1848/1848 [==============================] - 19s 11ms/step - loss: 3.9588 - accuracy: 0.2157 - val_loss: 1.7785 - val_accuracy: 0.2251\n",
            "Epoch 8: early stopping\n",
            "Model: \"model_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 900)]             0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 900, 300)         28922100  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 7)                 707       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,973,107\n",
            "Trainable params: 51,007\n",
            "Non-trainable params: 28,922,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 13s 6ms/step - loss: 4.1519 - accuracy: 0.1846 - val_loss: 1.8061 - val_accuracy: 0.2495\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 12s 6ms/step - loss: 4.0759 - accuracy: 0.2031 - val_loss: 1.8251 - val_accuracy: 0.2108\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 4.0573 - accuracy: 0.2055 - val_loss: 1.8157 - val_accuracy: 0.2232\n",
            "Epoch 4/100\n",
            "1842/1848 [============================>.] - ETA: 0s - loss: 4.0341 - accuracy: 0.2192Restoring model weights from the end of the best epoch: 1.\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 4.0350 - accuracy: 0.2191 - val_loss: 1.8676 - val_accuracy: 0.1678\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_47\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 900)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 900, 300)     28922100    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 900, 1)       300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_42 (Reshape)           (None, 1, 900)       0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 900)       0           ['reshape_42[0][0]']             \n",
            "                                                                                                  \n",
            " dot_28 (Dot)                   (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_28 (Flatten)           (None, 300)          0           ['dot_28[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 300)          0           ['flatten_28[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_43 (Reshape)           (None, 1, 300)       0           ['concatenate_14[0][0]']         \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_43[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_44 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_44[0][0]']             \n",
            "                                                                                                  \n",
            " dot_29 (Dot)                   (None, 300, 1)       0           ['reshape_43[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_29 (Flatten)           (None, 300)          0           ['dot_29[0][0]']                 \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_29[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 7)            707         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,973,707\n",
            "Trainable params: 51,607\n",
            "Non-trainable params: 28,922,100\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "1848/1848 [==============================] - 23s 12ms/step - loss: 4.1864 - accuracy: 0.1912 - val_loss: 1.8511 - val_accuracy: 0.1399\n",
            "Epoch 2/100\n",
            "1848/1848 [==============================] - 27s 15ms/step - loss: 4.0884 - accuracy: 0.1994 - val_loss: 1.8042 - val_accuracy: 0.2848\n",
            "Epoch 3/100\n",
            "1848/1848 [==============================] - 22s 12ms/step - loss: 4.0527 - accuracy: 0.2048 - val_loss: 1.7883 - val_accuracy: 0.2592\n",
            "Epoch 4/100\n",
            "1848/1848 [==============================] - 23s 12ms/step - loss: 4.0104 - accuracy: 0.2136 - val_loss: 1.7878 - val_accuracy: 0.2259\n",
            "Epoch 5/100\n",
            "1847/1848 [============================>.] - ETA: 0s - loss: 3.9825 - accuracy: 0.2207Restoring model weights from the end of the best epoch: 2.\n",
            "1848/1848 [==============================] - 23s 12ms/step - loss: 3.9826 - accuracy: 0.2207 - val_loss: 1.7846 - val_accuracy: 0.1980\n",
            "Epoch 5: early stopping\n",
            "best dan performance  0.3304920494556427\n",
            "best dan embedding size  700\n",
            "best wan performance  0.3138318359851837\n",
            "best wan embedding size  300\n"
          ]
        }
      ],
      "source": [
        "best_dan_score, best_wan_score  = 0,0\n",
        "best_dan_emb_size, best_wan_emb_size = None, None\n",
        "embedding_sizes_cust = [100,200,300,400,500,600,700,800,900]\n",
        "\n",
        "for embedding_size in embedding_sizes_cust:\n",
        "    \n",
        "    mapped_lyrics_train = get_unique_words(df_train['Lyrics_String'], mapping_dict, seq_size = embedding_size)\n",
        "    mapped_lyrics_test = get_unique_words(df_test['Lyrics_String'], mapping_dict, seq_size = embedding_size)\n",
        "    \n",
        "    dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix_cust, output_layer_size = 7, max_sequence_length=embedding_size)\n",
        "    dan_sorted_history = dan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
        "                        np.array(train_labels.map(mapping)),\n",
        "                        validation_data=(np.array(mapped_lyrics_test), np.array(test_labels.map(mapping))),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 2,\n",
        "                        callbacks = [es],\n",
        "                        class_weight = class_weights)\n",
        "    \n",
        "    \n",
        "    if max(dan_sorted_history.history['val_accuracy']) > best_dan_score:\n",
        "            best_dan_score = max(dan_sorted_history.history['val_accuracy'])\n",
        "            best_dan_emb_size = embedding_size\n",
        "            \n",
        "    wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix_cust, output_layer_size = 7, max_sequence_length=embedding_size,\n",
        "                                   num_attention=1)\n",
        "    wan_sorted_history = wan_model_sorted.fit(np.array(mapped_lyrics_train),\n",
        "                        np.array(train_labels.map(mapping)),\n",
        "                        validation_data=(np.array(mapped_lyrics_test), np.array(test_labels.map(mapping))),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 2,\n",
        "                        callbacks = [es],\n",
        "                        class_weight = class_weights)\n",
        "    \n",
        "    \n",
        "    if max(wan_sorted_history.history['val_accuracy']) > best_wan_score:\n",
        "            best_wan_score = max(wan_sorted_history.history['val_accuracy'])\n",
        "            best_wan_emb_size = embedding_size\n",
        "\n",
        "print('best dan performance ', best_dan_score)\n",
        "print('best dan embedding size ', best_dan_emb_size)\n",
        "print('best wan performance ', best_wan_score)\n",
        "print('best wan embedding size ', best_wan_emb_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf5yJRSqPvDX"
      },
      "source": [
        "currently:\n",
        "\n",
        "best dan performance  0.3304920494556427\n",
        "best dan embedding size  700\n",
        "best wan performance  0.3138318359851837\n",
        "best wan embedding size  300\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGZ0QdofPvDX"
      },
      "source": [
        "# 5 Audio Feature DL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNroRtuAPvDX"
      },
      "source": [
        "lets look at the audio features we have too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "rqWtnMQtPvDY",
        "outputId": "bd9f461c-ff53-4b40-efe0-fecc9bd74e38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>loudness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>valence</th>\n",
              "      <th>tempo</th>\n",
              "      <th>duration_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16303</th>\n",
              "      <td>0.083890</td>\n",
              "      <td>0.541561</td>\n",
              "      <td>0.082481</td>\n",
              "      <td>-0.663296</td>\n",
              "      <td>-0.419475</td>\n",
              "      <td>-0.421705</td>\n",
              "      <td>0.281600</td>\n",
              "      <td>-0.045805</td>\n",
              "      <td>-0.635516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8721</th>\n",
              "      <td>1.777120</td>\n",
              "      <td>0.379438</td>\n",
              "      <td>-0.018027</td>\n",
              "      <td>-0.311507</td>\n",
              "      <td>0.535964</td>\n",
              "      <td>-0.420469</td>\n",
              "      <td>0.204008</td>\n",
              "      <td>-0.455375</td>\n",
              "      <td>-1.530281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11930</th>\n",
              "      <td>0.162224</td>\n",
              "      <td>0.202576</td>\n",
              "      <td>0.573121</td>\n",
              "      <td>-0.635356</td>\n",
              "      <td>-0.672419</td>\n",
              "      <td>-0.422246</td>\n",
              "      <td>-0.485701</td>\n",
              "      <td>-0.726473</td>\n",
              "      <td>-0.476165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7945</th>\n",
              "      <td>0.867234</td>\n",
              "      <td>-0.475394</td>\n",
              "      <td>-1.048238</td>\n",
              "      <td>-0.368260</td>\n",
              "      <td>2.019137</td>\n",
              "      <td>-0.423698</td>\n",
              "      <td>-0.856420</td>\n",
              "      <td>0.194771</td>\n",
              "      <td>-0.346021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15504</th>\n",
              "      <td>-0.536761</td>\n",
              "      <td>-0.534348</td>\n",
              "      <td>0.497078</td>\n",
              "      <td>-0.535344</td>\n",
              "      <td>-0.632178</td>\n",
              "      <td>2.799775</td>\n",
              "      <td>-1.059022</td>\n",
              "      <td>0.425864</td>\n",
              "      <td>1.866022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7303</th>\n",
              "      <td>0.626205</td>\n",
              "      <td>-0.401702</td>\n",
              "      <td>-0.481556</td>\n",
              "      <td>0.156409</td>\n",
              "      <td>3.410330</td>\n",
              "      <td>-0.424316</td>\n",
              "      <td>1.363581</td>\n",
              "      <td>1.375829</td>\n",
              "      <td>-0.792824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9125</th>\n",
              "      <td>1.572245</td>\n",
              "      <td>0.615253</td>\n",
              "      <td>-1.054850</td>\n",
              "      <td>0.763627</td>\n",
              "      <td>-0.007866</td>\n",
              "      <td>-0.415252</td>\n",
              "      <td>1.962766</td>\n",
              "      <td>0.043757</td>\n",
              "      <td>0.134579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5125</th>\n",
              "      <td>1.801223</td>\n",
              "      <td>0.163273</td>\n",
              "      <td>-0.034888</td>\n",
              "      <td>0.751721</td>\n",
              "      <td>-0.057305</td>\n",
              "      <td>-0.418003</td>\n",
              "      <td>0.919581</td>\n",
              "      <td>-0.827523</td>\n",
              "      <td>-0.473074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15805</th>\n",
              "      <td>-0.386117</td>\n",
              "      <td>-1.477611</td>\n",
              "      <td>-2.291367</td>\n",
              "      <td>0.287377</td>\n",
              "      <td>-0.662071</td>\n",
              "      <td>0.707498</td>\n",
              "      <td>-0.826245</td>\n",
              "      <td>1.420558</td>\n",
              "      <td>0.838621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2952</th>\n",
              "      <td>0.252610</td>\n",
              "      <td>-0.716122</td>\n",
              "      <td>-1.335877</td>\n",
              "      <td>-0.634960</td>\n",
              "      <td>-0.490759</td>\n",
              "      <td>3.376955</td>\n",
              "      <td>-0.377934</td>\n",
              "      <td>0.776225</td>\n",
              "      <td>0.866398</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14778 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       danceability    energy  loudness  acousticness  speechiness  \\\n",
              "16303      0.083890  0.541561  0.082481     -0.663296    -0.419475   \n",
              "8721       1.777120  0.379438 -0.018027     -0.311507     0.535964   \n",
              "11930      0.162224  0.202576  0.573121     -0.635356    -0.672419   \n",
              "7945       0.867234 -0.475394 -1.048238     -0.368260     2.019137   \n",
              "15504     -0.536761 -0.534348  0.497078     -0.535344    -0.632178   \n",
              "...             ...       ...       ...           ...          ...   \n",
              "7303       0.626205 -0.401702 -0.481556      0.156409     3.410330   \n",
              "9125       1.572245  0.615253 -1.054850      0.763627    -0.007866   \n",
              "5125       1.801223  0.163273 -0.034888      0.751721    -0.057305   \n",
              "15805     -0.386117 -1.477611 -2.291367      0.287377    -0.662071   \n",
              "2952       0.252610 -0.716122 -1.335877     -0.634960    -0.490759   \n",
              "\n",
              "       instrumentalness   valence     tempo  duration_ms  \n",
              "16303         -0.421705  0.281600 -0.045805    -0.635516  \n",
              "8721          -0.420469  0.204008 -0.455375    -1.530281  \n",
              "11930         -0.422246 -0.485701 -0.726473    -0.476165  \n",
              "7945          -0.423698 -0.856420  0.194771    -0.346021  \n",
              "15504          2.799775 -1.059022  0.425864     1.866022  \n",
              "...                 ...       ...       ...          ...  \n",
              "7303          -0.424316  1.363581  1.375829    -0.792824  \n",
              "9125          -0.415252  1.962766  0.043757     0.134579  \n",
              "5125          -0.418003  0.919581 -0.827523    -0.473074  \n",
              "15805          0.707498 -0.826245  1.420558     0.838621  \n",
              "2952           3.376955 -0.377934  0.776225     0.866398  \n",
              "\n",
              "[14778 rows x 9 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# reminder, what does our data look like?\n",
        "df_train_audio_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzubBPA5PvDY",
        "outputId": "9df97fd3-735a-4900-e90d-ecb55b2803a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1848/1848 [==============================] - 15s 7ms/step - loss: 3.4483 - accuracy: 0.3587 - val_loss: 1.5358 - val_accuracy: 0.3936\n",
            "Epoch 2/10\n",
            "1848/1848 [==============================] - 14s 8ms/step - loss: 3.3353 - accuracy: 0.3781 - val_loss: 1.5839 - val_accuracy: 0.3026\n",
            "Epoch 3/10\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 3.2890 - accuracy: 0.3831 - val_loss: 1.4824 - val_accuracy: 0.4289\n",
            "Epoch 4/10\n",
            "1848/1848 [==============================] - 21s 11ms/step - loss: 3.2670 - accuracy: 0.3862 - val_loss: 1.4851 - val_accuracy: 0.4448\n",
            "Epoch 5/10\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 3.2605 - accuracy: 0.3927 - val_loss: 1.4989 - val_accuracy: 0.4150\n",
            "Epoch 6/10\n",
            "1848/1848 [==============================] - 17s 9ms/step - loss: 3.2313 - accuracy: 0.3984 - val_loss: 1.5111 - val_accuracy: 0.4188\n",
            "Epoch 7/10\n",
            "1848/1848 [==============================] - 16s 8ms/step - loss: 3.2239 - accuracy: 0.3909 - val_loss: 1.4726 - val_accuracy: 0.4277\n",
            "Epoch 8/10\n",
            "1848/1848 [==============================] - 20s 11ms/step - loss: 3.2142 - accuracy: 0.4029 - val_loss: 1.5270 - val_accuracy: 0.3801\n",
            "Epoch 9/10\n",
            "1848/1848 [==============================] - 18s 10ms/step - loss: 3.2134 - accuracy: 0.3965 - val_loss: 1.4758 - val_accuracy: 0.4386\n",
            "Epoch 10/10\n",
            "1848/1848 [==============================] - 16s 9ms/step - loss: 3.2085 - accuracy: 0.4005 - val_loss: 1.5105 - val_accuracy: 0.4165\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc8fd72aaf0>"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# audio features should help too: lets see what results we get from\n",
        "# a standard feed-forward network\n",
        "# note: audio features have been normalized\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100,activation='relu'),\n",
        "    keras.layers.Dense(100,activation='relu'),\n",
        "    keras.layers.Dense(7,activation='softmax')\n",
        "])\n",
        "\n",
        "#Compile the model, specifying loss function, optimizer, and performance metric\n",
        "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "             optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
        "             metrics=['accuracy'],\n",
        "             )\n",
        "\n",
        "model.fit(x = np.array(df_train_audio_normalized),y = train_labels.map(mapping),batch_size=8,epochs=10,\n",
        "         validation_data = (np.array(df_test_audio_normalized) ,test_labels.map(mapping)),\n",
        "         use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1, class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WIvGRlPsPvDY"
      },
      "outputs": [],
      "source": [
        "#predictions = model.predict(np.array(df_test_audio_normalized))\n",
        "#predictions = model.predict([np.array(test_term_df), np.array(df_test_audio_normalized)])\n",
        "predictions = model.predict(np.array(test_term_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "crhZxBHRPvDY"
      },
      "outputs": [],
      "source": [
        "predictions_ = [x.argmax() for x in predictions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Yc3pRpI2PvDY",
        "outputId": "2aa96df9-763c-49bf-ca81-db9ba9933343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Rock  Indie  Alternative  Hip Hop  Metal  Pop  Blues\n",
              "Rock          781      0            0        0      0    0      0\n",
              "Indie         427      0            0        0      0    0      0\n",
              "Alternative   239      0            0        0      0    0      0\n",
              "Hip Hop       272      0            0        0      0    0      0\n",
              "Metal         353      0            0        0      0    0      0\n",
              "Pop           346      0            0        0      0    0      0\n",
              "Blues         163      0            0        0      0    0      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-344268f7-5cd3-4661-b746-a7aafa3a9b62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rock</th>\n",
              "      <th>Indie</th>\n",
              "      <th>Alternative</th>\n",
              "      <th>Hip Hop</th>\n",
              "      <th>Metal</th>\n",
              "      <th>Pop</th>\n",
              "      <th>Blues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Rock</th>\n",
              "      <td>781</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Indie</th>\n",
              "      <td>427</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alternative</th>\n",
              "      <td>239</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hip Hop</th>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Metal</th>\n",
              "      <td>353</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pop</th>\n",
              "      <td>346</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Blues</th>\n",
              "      <td>163</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-344268f7-5cd3-4661-b746-a7aafa3a9b62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-344268f7-5cd3-4661-b746-a7aafa3a9b62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-344268f7-5cd3-4661-b746-a7aafa3a9b62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "conf = sklearn.metrics.confusion_matrix(test_labels.map(mapping), predictions_)\n",
        "conf = pd.DataFrame(conf, index = mapping.keys(), columns = mapping.keys())\n",
        "conf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEHE3oFxPvDZ"
      },
      "source": [
        "write up some precision/recall stuff on the final conf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8pWPtfJPvDZ"
      },
      "source": [
        "# 6. Lyrics + Audio DL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYdqLcc2PvDZ"
      },
      "outputs": [],
      "source": [
        "def create_multimodal_genre_FFN(max_sequence_length = 1000, retrain_embeddings = True, learning_rate = 0.01):\n",
        "    audio_inputs = keras.layers.Input(shape = (8,), dtype = 'float32', name = 'audio_input')\n",
        "    lyric_inputs = keras.layers.Input(shape = (1000,), dtype='int64',name='lyric_input')\n",
        "                                    \n",
        "    ffn_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                                  embedding_matrix.shape[1],\n",
        "                                  weights = [embedding_matrix],\n",
        "                                  input_length=max_sequence_length,\n",
        "                                  trainable=retrain_embeddings,\n",
        "                                   name = 'embedding_layer')\n",
        "    \n",
        "    #Input Layer, sequence of max_sequence_length tokens\n",
        "    #ffn_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
        "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
        "    ffn_embeddings = ffn_embedding_layer(lyric_inputs)\n",
        "    ffn_avg_input_embeddings = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(ffn_embeddings)\n",
        "    concat_ffn = tf.keras.layers.Concatenate()([ffn_avg_input_embeddings,audio_inputs])\n",
        "    hidden = keras.layers.Dense(100,activation='relu')(concat_ffn)\n",
        "    classification = keras.layers.Dense(7,activation='softmax')(hidden)\n",
        "    \n",
        "    ffn_model = tf.keras.models.Model(inputs=[audio_inputs,lyric_inputs], outputs=[classification])\n",
        "    ffn_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
        "                                                beta_1=0.9,\n",
        "                                                beta_2=0.999,\n",
        "                                                epsilon=1e-07,\n",
        "                                                amsgrad=False,\n",
        "                                                name='Adam'),\n",
        "                 metrics='accuracy',\n",
        "                     run_eagerly = True)\n",
        "    \n",
        "    print(ffn_model.summary())\n",
        "\n",
        "    return ffn_model\n",
        "  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s7V_vxQPvDZ"
      },
      "outputs": [],
      "source": [
        "# define two sets of inputs\n",
        "inputA = Input(shape=(1000,))\n",
        "inputB = Input(shape=(9,))\n",
        "# the first branch operates on the first input\n",
        "x = Dense(8, activation=\"relu\")(inputA)\n",
        "x = Dense(4, activation=\"relu\")(x)\n",
        "x = Model(inputs=inputA, outputs=x)\n",
        "# the second branch opreates on the second input\n",
        "y = Dense(64, activation=\"relu\")(inputB)\n",
        "y = Dense(32, activation=\"relu\")(y)\n",
        "y = Dense(4, activation=\"relu\")(y)\n",
        "y = Model(inputs=inputB, outputs=y)\n",
        "# combine the output of the two branches\n",
        "combined = concatenate([x.output, y.output])\n",
        "# apply a FC layer and then a classification prediction on the\n",
        "# combined outputs\n",
        "z = Dense(2, activation=\"relu\")(combined)\n",
        "z = Dense(7, activation=\"softmax\")(z)\n",
        "#z = Dense(1, activation=\"linear\")(z)\n",
        "# our model will accept the inputs of the two branches and\n",
        "# then output a single value\n",
        "model = Model(inputs=[x.input, y.input], outputs=z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZK0NSgAPvDZ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001,\n",
        "                                                beta_1=0.9,\n",
        "                                                beta_2=0.999,\n",
        "                                                epsilon=1e-07,\n",
        "                                                amsgrad=False,\n",
        "                                                name='Adam'),\n",
        "             metrics='accuracy',\n",
        "             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlbT23J8PvDZ",
        "outputId": "81829cd4-2b3e-4d24-bc5c-668274332438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1848/1848 [==============================] - 5s 3ms/step - loss: 2.9874 - accuracy: 0.4164 - val_loss: 1.5368 - val_accuracy: 0.4064\n",
            "Epoch 2/10\n",
            "1848/1848 [==============================] - 11s 6ms/step - loss: 2.9880 - accuracy: 0.4164 - val_loss: 1.5520 - val_accuracy: 0.4018\n",
            "Epoch 3/10\n",
            "1848/1848 [==============================] - 6s 3ms/step - loss: 2.9761 - accuracy: 0.4173 - val_loss: 1.5460 - val_accuracy: 0.3998\n",
            "Epoch 4/10\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 2.9767 - accuracy: 0.4203 - val_loss: 1.5593 - val_accuracy: 0.4099\n",
            "Epoch 5/10\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 2.9691 - accuracy: 0.4182 - val_loss: 1.5466 - val_accuracy: 0.3940\n",
            "Epoch 6/10\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 2.9636 - accuracy: 0.4251 - val_loss: 1.5589 - val_accuracy: 0.3979\n",
            "Epoch 7/10\n",
            "1848/1848 [==============================] - 5s 3ms/step - loss: 2.9572 - accuracy: 0.4195 - val_loss: 1.5729 - val_accuracy: 0.3940\n",
            "Epoch 8/10\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 2.9582 - accuracy: 0.4228 - val_loss: 1.5615 - val_accuracy: 0.3793\n",
            "Epoch 9/10\n",
            "1848/1848 [==============================] - 8s 4ms/step - loss: 2.9428 - accuracy: 0.4243 - val_loss: 1.5564 - val_accuracy: 0.3913\n",
            "Epoch 10/10\n",
            "1848/1848 [==============================] - 7s 4ms/step - loss: 2.9460 - accuracy: 0.4215 - val_loss: 1.5476 - val_accuracy: 0.3979\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc046908160>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=[np.array(train_tokens_prebuilt_new), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_tokens_prebuilt_new), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8,\n",
        "             class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zblDxEY-PvDa"
      },
      "outputs": [],
      "source": [
        "# -------------------------------Model that accepts input and creates embedding matrix-------------------------------\n",
        "#input_layer = tf.keras.layers.Input(shape=(1000,))\n",
        "lyric_input = tf.keras.layers.Input(shape=(1000,))\n",
        "audio_input = tf.keras.layers.Input(shape=(9,))\n",
        "#Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
        "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                            embedding_matrix.shape[1],\n",
        "                            weights = [embedding_matrix],\n",
        "                            input_length=1000,\n",
        "                            trainable=True,\n",
        "                            name = 'embedding_layer')\n",
        "\n",
        "embeddings = embedding_layer(lyric_input)\n",
        "embedding_model = tf.keras.Model(inputs = [lyric_input],outputs=[embeddings])\n",
        "\n",
        "\n",
        "# -----------------------------------------------------AUDIO FFN MODEL-----------------------------------------------------\n",
        "\n",
        "# AUDIO\n",
        "#audio_layer = Dense(300, activation=\"relu\")(audio_input)\n",
        "# add more layers?\n",
        "audio_model = tf.keras.Model(inputs = [audio_input],outputs=[audio_input])\n",
        "\n",
        "# -----------------------------------------------------WAN Model-----------------------------------------------------\n",
        "# LYRICS\n",
        "#Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
        "query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(embedding_model.output)\n",
        "#reshape to 1 x num_attention\n",
        "reshaped_query = tf.keras.layers.Reshape((1,1000))(query)\n",
        "#Softmax over query * key (words) to obtain weights\n",
        "weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
        "                                    name='attention_weights')(reshaped_query)\n",
        "#weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
        "#from prior layer\n",
        "wan_embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((embedding_model.output,weights)))\n",
        "wan_embedding = tf.keras.Model(inputs=[embedding_model.input],outputs=[wan_embedding])\n",
        "\n",
        "# WAN Model that uses an attention layer with a single node to learn how to combine WAN/DAN embeddings into single representation\n",
        "dual_embedding = tf.keras.layers.concatenate([audio_model.output,wan_embedding.output])\n",
        "#dual_embedding = tf.keras.layers.Reshape((2,embedding_matrix.shape[1]))(dual_embedding)\n",
        "#query = tf.keras.layers.Dense(1,activation='linear',use_bias=False)(dual_embedding)\n",
        "#reshaped_query = tf.keras.layers.Reshape((1,2))(query)\n",
        "#weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x))(reshaped_query)\n",
        "#embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((dual_embedding,weights)))\n",
        "hidden = tf.keras.layers.Dense(100,activation='relu')(dual_embedding)\n",
        "output = tf.keras.layers.Dense(7,activation='softmax')(hidden)\n",
        "final_model = tf.keras.Model(inputs=[audio_model.input, embedding_model.input],outputs=[output])\n",
        "\n",
        "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "                            metrics='accuracy') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bz8qbetPvDa",
        "outputId": "84036026-5956-4efd-f4f3-d8343cbf75b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 393/1848 [=====>........................] - ETA: 7:46 - loss: 3.5846 - accuracy: 0.3302"
          ]
        }
      ],
      "source": [
        "final_model.fit(x=[np.array(df_train_audio_normalized), np.array(train_tokens_prebuilt_new)], y=train_labels.map(mapping), validation_data=([np.array(df_test_audio_normalized), np.array(test_tokens_prebuilt_new)], test_labels.map(mapping)), epochs=10, batch_size=8,\n",
        "             class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HZA2OjXPvDa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjKNy6OYPvDa",
        "outputId": "1560b9c2-46dc-4e40-f853-b2ee61938b76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.executing_eagerly()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCXuvGlMPvDa",
        "outputId": "91410aea-6392-4291-ecb9-87034007e64b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_48\" is incompatible with the layer: expected shape=(None, 9), found shape=(None, 1000)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-5a32e48b853b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m final_model.fit(x=[np.array(train_tokens_prebuilt_new), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_tokens_prebuilt_new), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8,\n\u001b[0m\u001b[1;32m      2\u001b[0m              class_weight = class_weights)\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_48\" is incompatible with the layer: expected shape=(None, 9), found shape=(None, 1000)\n"
          ]
        }
      ],
      "source": [
        "final_model.fit(x=[np.array(train_tokens_prebuilt_new), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_tokens_prebuilt_new), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8,\n",
        "             class_weight = class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16-ThMsGPvDb",
        "outputId": "34c5aa2c-9e38-471a-b574-2a5959553da8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"reshape_4\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [], output_shape = [1, 300]\n\nCall arguments received by layer \"reshape_4\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None,), dtype=float32)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-b6bf6ee86d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# AUDIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mavg_embedding_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mavg_embedding_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_embedding_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mavg_embedding_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maudio_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mavg_embedding_audio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/layers/reshaping/reshape.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_4\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [], output_shape = [1, 300]\n\nCall arguments received by layer \"reshape_4\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None,), dtype=float32)"
          ]
        }
      ],
      "source": [
        "# -------------------------------Model that accepts input and creates embedding matrix-------------------------------\n",
        "#input_layer = tf.keras.layers.Input(shape=(1000,))\n",
        "lyric_input = tf.keras.layers.Input(shape=(1000,))\n",
        "audio_input = tf.keras.layers.Input(shape=(9,))\n",
        "#Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
        "embedding_layer = Embedding(embedding_matrix.shape[0],\n",
        "                            embedding_matrix.shape[1],\n",
        "                            weights = [embedding_matrix],\n",
        "                            input_length=1000,\n",
        "                            trainable=True,\n",
        "                            name = 'embedding_layer')\n",
        "\n",
        "audio_layer = Dense(100, activation=\"relu\")(audio_input)\n",
        "\n",
        "embeddings = embedding_layer(lyric_input)\n",
        "embedding_model = tf.keras.Model(inputs = [lyric_input],outputs=[embeddings])\n",
        "\n",
        "audio_model = tf.keras.Model(inputs = [audio_input],outputs=[audio_layer])\n",
        "\n",
        "# -----------------------------------------------------DAN MODEL-----------------------------------------------------\n",
        "# AUDIO\n",
        "avg_embedding_audio = tf.keras.layers.Lambda(lambda x:K.mean(x,axis=1))(audio_model.output)\n",
        "avg_embedding_audio = tf.keras.layers.Reshape((1,embedding_matrix.shape[1]))(avg_embedding_audio)\n",
        "avg_embedding_audio = tf.keras.Model(inputs = [audio_model.input], outputs = [avg_embedding_audio])\n",
        "\n",
        "\n",
        "# -----------------------------------------------------WAN Model-----------------------------------------------------\n",
        "# LYRICS\n",
        "#Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
        "query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(embedding_model.output)\n",
        "#reshape to 1 x num_attention\n",
        "reshaped_query = tf.keras.layers.Reshape((1,1000))(query)\n",
        "#Softmax over query * key (words) to obtain weights\n",
        "weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
        "                                    name='attention_weights')(reshaped_query)\n",
        "#weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
        "#from prior layer\n",
        "wan_embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((embedding_model.output,weights)))\n",
        "wan_embedding = tf.keras.Model(inputs=[embedding_model.input],outputs=[wan_embedding])\n",
        "\n",
        "# WAN Model that uses an attention layer with a single node to learn how to combine WAN/DAN embeddings into single representation\n",
        "dual_embedding = tf.keras.layers.concatenate([audio_reshaped.output,wan_embedding.output])\n",
        "dual_embedding = tf.keras.layers.Reshape((2,embedding_matrix_custom.shape[1]))(dual_embedding)\n",
        "query = tf.keras.layers.Dense(1,activation='linear',use_bias=False)(dual_embedding)\n",
        "reshaped_query = tf.keras.layers.Reshape((1,2))(query)\n",
        "weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x))(reshaped_query)\n",
        "embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((dual_embedding,weights)))\n",
        "hidden = tf.keras.layers.Dense(100,activation='relu')(embedding)\n",
        "output = tf.keras.layers.Dense(11,activation='softmax')(hidden)\n",
        "final_model = tf.keras.Model(inputs=[embedding_model.input],outputs=[output])\n",
        "\n",
        "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "                            metrics='accuracy') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmmtI1hYPvDc",
        "outputId": "e8ec3715-1891-4ad4-aef7-7012a6a8aa6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43982 300\n"
          ]
        }
      ],
      "source": [
        "print(embedding_matrix.shape[0], embedding_matrix.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW4GQ50-PvDc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDx2bBpkPvDc"
      },
      "source": [
        "# 7. Subgenre Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzB0krLdPvDc"
      },
      "source": [
        "once we have predicted a genre, let's see if we can predict the correct subgenres a song fits into"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bcmUFXrPvDc"
      },
      "outputs": [],
      "source": [
        "df_train['lyric_token_array'] = [np.array(song) for song in train_tokens_prebuilt_new]\n",
        "df_test['lyric_token_array'] = [np.array(song) for song in test_tokens_prebuilt_new]\n",
        "\n",
        "def run_subgenre_model(major_genre, sub_genre_label, df_train, df_test, model_type = 'dan'):\n",
        "    # create df for major genre\n",
        "    df_train_major_genre = df_train[df_train['Major Genre'] == major_genre]\n",
        "    df_test_major_genre = df_test[df_test['Major Genre'] == major_genre]\n",
        "    \n",
        "    # now get an array of the tokens\n",
        "    train_tokens_prebuilt_major_genre = df_train_major_genre['lyric_token_array'].to_numpy()\n",
        "    test_tokens_prebuilt_major_genre  = df_test_major_genre['lyric_token_array'].to_numpy()\n",
        "    \n",
        "    # convert those tokens to a tensor (not sure why i have to do this, but its the only way i can get the model to run)\n",
        "    tensor_train_major_genre = tf.convert_to_tensor(np.array([np.array(song) for song in train_tokens_prebuilt_major_genre]))\n",
        "    tensor_test_major_genre = tf.convert_to_tensor(np.array([np.array(song) for song in test_tokens_prebuilt_major_genre]))\n",
        "    \n",
        "    # run the model\n",
        "    if model_type == 'dan':\n",
        "        dan_model_sorted = create_dan_model(embedding_matrix = embedding_matrix, output_activation = 'sigmoid', output_layer_size = 2)\n",
        "        dan_sorted_history = dan_model_sorted.fit(tensor_train_major_genre,\n",
        "                        np.array(df_train_major_genre[sub_genre_label]),\n",
        "                        validation_data=(tensor_test_major_genre, np.array(df_test_major_genre[sub_genre_label])),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
        "                        callbacks = [es])\n",
        "        return(dan_model_sorted.predict(tensor_test_pop))\n",
        "        \n",
        "    elif model_type == 'wan':\n",
        "        wan_model_sorted = create_wan_model(embedding_matrix=embedding_matrix, output_layer_size = 1, output_activation = 'sigmoid',\n",
        "                                   num_attention=1, loss = tf.keras.losses.BinaryCrossentropy())\n",
        "        wan_sorted_history = wan_model_sorted.fit(tensor_train_major_genre,\n",
        "                        np.array(df_train_major_genre[sub_genre_label]),\n",
        "                        validation_data=(tensor_test_major_genre, np.array(df_test_major_genre[sub_genre_label])),\n",
        "                        batch_size=8,\n",
        "                        epochs=100,\n",
        "                        shuffle=True,\n",
        "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1,\n",
        "                        callbacks = [es])\n",
        "        return(wan_model_sorted.predict(tensor_test_pop))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "JToGkZMIPvDc",
        "outputId": "f10a34d0-1d27-4459-bcc9-fd90b4fd1133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_21\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 1000)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding)    (None, 1000, 300)    13194600    ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " attention_query1 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
            "                                                                                                  \n",
            " reshape_9 (Reshape)            (None, 1, 1000)      0           ['attention_query1[0][0]']       \n",
            "                                                                                                  \n",
            " attention_weights1 (Lambda)    (None, 1, 1000)      0           ['reshape_9[0][0]']              \n",
            "                                                                                                  \n",
            " dot_6 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
            "                                                                  'attention_weights1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 300)          0           ['dot_6[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 300)          0           ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_10 (Reshape)           (None, 1, 300)       0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 1, 1)         300         ['reshape_10[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_11 (Reshape)           (None, 1, 1)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 1)         0           ['reshape_11[0][0]']             \n",
            "                                                                                                  \n",
            " dot_7 (Dot)                    (None, 300, 1)       0           ['reshape_10[0][0]',             \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_7 (Flatten)            (None, 300)          0           ['dot_7[0][0]']                  \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 100)          30100       ['flatten_7[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " wan_classification (Dense)     (None, 1)            101         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,245,601\n",
            "Trainable params: 51,001\n",
            "Non-trainable params: 13,194,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 7s 20ms/step - loss: 0.2856 - accuracy: 0.9335 - val_loss: 0.2182 - val_accuracy: 0.9451\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 5s 19ms/step - loss: 0.2372 - accuracy: 0.9344 - val_loss: 0.2036 - val_accuracy: 0.9451\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 5s 20ms/step - loss: 0.2339 - accuracy: 0.9344 - val_loss: 0.2043 - val_accuracy: 0.9451\n",
            "Epoch 4/100\n",
            "266/267 [============================>.] - ETA: 0s - loss: 0.2301 - accuracy: 0.9342Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 6s 21ms/step - loss: 0.2297 - accuracy: 0.9344 - val_loss: 0.2127 - val_accuracy: 0.9451\n",
            "Epoch 4: early stopping\n"
          ]
        }
      ],
      "source": [
        "run_subgenre_model('Pop', 'Sub-Genre: electropop', df_train, df_test, 'wan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBbtTmrqPvDd"
      },
      "outputs": [],
      "source": [
        "pop_subgenres = ['Sub-Genre: electropop', 'Sub-Genre: new rave', 'Sub-Genre: post-teen pop', 'Sub-Genre: art pop', 'Sub-Genre: dance pop', 'Sub-Genre: pop', 'Sub-Genre: pop rap', 'Sub-Genre: pop rock', 'Sub-Genre: indie pop']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wF2ncjzPvDd",
        "outputId": "1d23310e-693e-42ed-82b6-fe68266bfedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 3s 10ms/step - loss: 0.2786 - accuracy: 0.9344 - val_loss: 0.2109 - val_accuracy: 0.9451\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.2415 - accuracy: 0.9344 - val_loss: 0.2069 - val_accuracy: 0.9451\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.2357 - accuracy: 0.9344 - val_loss: 0.2044 - val_accuracy: 0.9451\n",
            "Epoch 4/100\n",
            "267/267 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9344Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.2286 - accuracy: 0.9344 - val_loss: 0.2063 - val_accuracy: 0.9451\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 4s 11ms/step - loss: 0.0729 - accuracy: 0.9963 - val_loss: 0.0245 - val_accuracy: 0.9971\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.0255 - accuracy: 0.9972 - val_loss: 0.0223 - val_accuracy: 0.9971\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.0253 - accuracy: 0.9972 - val_loss: 0.0239 - val_accuracy: 0.9971\n",
            "Epoch 4/100\n",
            "261/267 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9971Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.0254 - accuracy: 0.9972 - val_loss: 0.0232 - val_accuracy: 0.9971\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 4s 11ms/step - loss: 0.3839 - accuracy: 0.8824 - val_loss: 0.2912 - val_accuracy: 0.9104\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 3s 10ms/step - loss: 0.3369 - accuracy: 0.8852 - val_loss: 0.2970 - val_accuracy: 0.9104\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.3318 - accuracy: 0.8852 - val_loss: 0.2944 - val_accuracy: 0.9104\n",
            "Epoch 4/100\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8854Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.3294 - accuracy: 0.8852 - val_loss: 0.3027 - val_accuracy: 0.9104\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 4s 11ms/step - loss: 0.1147 - accuracy: 0.9873 - val_loss: 0.0789 - val_accuracy: 0.9884\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.0665 - accuracy: 0.9902 - val_loss: 0.0702 - val_accuracy: 0.9884\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.0593 - accuracy: 0.9902 - val_loss: 0.0647 - val_accuracy: 0.9884\n",
            "Epoch 4/100\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9905Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 3s 9ms/step - loss: 0.0588 - accuracy: 0.9902 - val_loss: 0.0692 - val_accuracy: 0.9884\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 8s 28ms/step - loss: 0.4094 - accuracy: 0.8650 - val_loss: 0.3572 - val_accuracy: 0.8728\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.3655 - accuracy: 0.8664 - val_loss: 0.3432 - val_accuracy: 0.8728\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.3617 - accuracy: 0.8664 - val_loss: 0.3351 - val_accuracy: 0.8728\n",
            "Epoch 4/100\n",
            "264/267 [============================>.] - ETA: 0s - loss: 0.3551 - accuracy: 0.8660Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.3549 - accuracy: 0.8664 - val_loss: 0.3337 - val_accuracy: 0.8728\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 3s 10ms/step - loss: 0.5485 - accuracy: 0.7470 - val_loss: 0.4528 - val_accuracy: 0.8035\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.5160 - accuracy: 0.7470 - val_loss: 0.4466 - val_accuracy: 0.8035\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 3s 9ms/step - loss: 0.5072 - accuracy: 0.7470 - val_loss: 0.4507 - val_accuracy: 0.8035\n",
            "Epoch 4/100\n",
            "260/267 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.7462Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.5046 - accuracy: 0.7470 - val_loss: 0.4594 - val_accuracy: 0.8035\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 3s 10ms/step - loss: 0.2302 - accuracy: 0.9527 - val_loss: 0.2260 - val_accuracy: 0.9335\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.1693 - accuracy: 0.9536 - val_loss: 0.2154 - val_accuracy: 0.9335\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.1612 - accuracy: 0.9536 - val_loss: 0.2192 - val_accuracy: 0.9335\n",
            "Epoch 4/100\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9532Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.1540 - accuracy: 0.9536 - val_loss: 0.2068 - val_accuracy: 0.9335\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 3s 10ms/step - loss: 0.2748 - accuracy: 0.9391 - val_loss: 0.2175 - val_accuracy: 0.9422\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.2254 - accuracy: 0.9405 - val_loss: 0.2094 - val_accuracy: 0.9422\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.2204 - accuracy: 0.9405 - val_loss: 0.2087 - val_accuracy: 0.9422\n",
            "Epoch 4/100\n",
            "265/267 [============================>.] - ETA: 0s - loss: 0.2192 - accuracy: 0.9401Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.2183 - accuracy: 0.9405 - val_loss: 0.2085 - val_accuracy: 0.9422\n",
            "Epoch 4: early stopping\n",
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_layer (Embedding)  (None, 1000, 300)        13194600  \n",
            "                                                                 \n",
            " averaging (Lambda)          (None, 300)               0         \n",
            "                                                                 \n",
            " hidden_1 (Dense)            (None, 100)               30100     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_2 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " hidden_3 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dan_classification (Dense)  (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,245,102\n",
            "Trainable params: 50,502\n",
            "Non-trainable params: 13,194,600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "267/267 [==============================] - 3s 9ms/step - loss: 0.2196 - accuracy: 0.9555 - val_loss: 0.1973 - val_accuracy: 0.9509\n",
            "Epoch 2/100\n",
            "267/267 [==============================] - 3s 13ms/step - loss: 0.1827 - accuracy: 0.9564 - val_loss: 0.1903 - val_accuracy: 0.9509\n",
            "Epoch 3/100\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.1784 - accuracy: 0.9564 - val_loss: 0.1864 - val_accuracy: 0.9509\n",
            "Epoch 4/100\n",
            "262/267 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 0.9571Restoring model weights from the end of the best epoch: 1.\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.1731 - accuracy: 0.9564 - val_loss: 0.1873 - val_accuracy: 0.9509\n",
            "Epoch 4: early stopping\n"
          ]
        }
      ],
      "source": [
        "predicted_subgenres = []\n",
        "for sub_genre in pop_subgenres:\n",
        "    predictions = run_subgenre_model('Pop', sub_genre, df_train, df_test)\n",
        "    for pred in predictions:\n",
        "        single_pred = []\n",
        "        if pred[1] > pred[0]:\n",
        "            single_pred.append(sub_genre)\n",
        "        predicted_\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkdqpd0PPvDd",
        "outputId": "0368df2a-0285-4563-d8b3-9c5d3d73138a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 1s 44ms/step\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "predictions = dan_model_sorted.predict(tensor_test_pop)\n",
        "rounded_predictions = []\n",
        "for prediction in predictions:\n",
        "    if prediction[0] > prediction[1]:\n",
        "        rounded_predictions.append(0)\n",
        "    else:\n",
        "        rounded_predictions.append(1)\n",
        "\n",
        "print(rounded_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd6MiwjKPvDd"
      },
      "outputs": [],
      "source": [
        "subgenre_predictions = []\n",
        "for pred in rounded_predictions:\n",
        "    single_pred = []\n",
        "    if pred == 1:\n",
        "        single_pred.append('subgenre')\n",
        "    subgenre_predictions.append(single_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgqcPeXXPvDd"
      },
      "source": [
        "# 8. BERT Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "FH4FqJcDPvDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "d90c72579cb646079551103c732f0770",
            "7b9281b67f1d4847a5a12c243583a7af",
            "b74b3efd33cf4f1cb68f953ce64df4b5",
            "549bc7a2f1f34fed82be71e2ff403981",
            "fede47e020b24b33b70973f2368354a6",
            "26cfb653005a401c9873023531a3b214",
            "0ddc3de572e747b3a9af3231f97baffb",
            "bdc599fab9d84a739bf77810c816f678",
            "a19d3b02c85945bb94101dbb19f5eac3",
            "3a7cea6d31864643bb693575e802a166",
            "583e3ba45df74cb5bf80cfab7db15dff",
            "3b6c7b2fd344415389855cec0b503c50",
            "d4ff3361af4649e48b68c499df4b8ec5",
            "581ad14fabab4b828a51c34daaa5dedd",
            "79f42f28bacf4917ad260fdff4a44939",
            "6ba0ad9e0d154e9686c2df22060c6281",
            "69c0cc823f02429e96ccd9004f3c5301",
            "6fa43aff58174bacbc84b3443195d8a4",
            "546ab8aac5ad40408c33491746194b13",
            "98e89fd326604d8aa28d56d079e8fac9",
            "4e1619a6edd94b5a9f31f4f9144bcb26",
            "fd2d2a45fd654dce815110f7ce3b8c53",
            "2a7bc750c4424c32817015e5de481d4d",
            "f1dbf229fc39436b8de525a442333682",
            "656499608fd64e3f864179ca6c32d817",
            "5d8dfcab42cb4e48bcf458e1372f468d",
            "65eb48b74c104f31a6130529019543b2",
            "5364b89a3f5a4feebdb39104fe7e1908",
            "15a00f8bb5574b2aa558b7d04b9a5e2c",
            "e6c08e97aaae488dae290d9c5250cdfb",
            "aa38386ad94f45b3a654ad1f637bcf6e",
            "69f9f858699b4226a7d61257b5c0b317",
            "510844178fc4484fb215656f32b447ea"
          ]
        },
        "outputId": "d0b531ac-192a-4e14-faf6-094d5d58f12a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d90c72579cb646079551103c732f0770"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b6c7b2fd344415389855cec0b503c50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a7bc750c4424c32817015e5de481d4d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "aHlZk2VEPvDe",
        "outputId": "c7007372-94b5-4ac8-8249-574cda41ea9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Lyrics_String'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-40b672a80ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lyrics_String'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Lyrics_String'"
          ]
        }
      ],
      "source": [
        "#df_train['Lyrics_String']\n",
        "df_train['final_modified_lyrics']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lX0L2NcWPvDe"
      },
      "outputs": [],
      "source": [
        "#train_bert_ids = bert_tokenizer(list(df_train['Lyrics_String']),\n",
        " #                              max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
        "#test_bert_ids = bert_tokenizer(list(df_test['Lyrics_String']),\n",
        " #                            max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
        "\n",
        "train_bert_ids = bert_tokenizer(list(df_train['final_modified_lyrics']),\n",
        "                               max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
        "test_bert_ids = bert_tokenizer(list(df_test['final_modified_lyrics']),\n",
        "                             max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UGK29e_ZPvDe",
        "outputId": "f90cc49e-65c6-4450-dc5b-43a0eac08240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "c112913ebbc94b51a3b44e390c2a884b",
            "c5a025221c8f400ca218beee6faf65c8",
            "c5ebc5d4679e49a0992b4793a52aab7f",
            "c28b77e093324a2fbcb4174c44bec661",
            "5f1b35e982b34fc9bc2291681e3f1e19",
            "1469420a34154e9f9257458b290507d2",
            "c03d0915a8c249618a4d84af34bf0669",
            "2e79aa4e1b6f4c4a858fc41ddafd1c3a",
            "e7b6924b8a3547b7a16397663358a36d",
            "96556f35e08247898751de10d37057ed",
            "9f6f23efebff447eba4e35867df061c6"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c112913ebbc94b51a3b44e390c2a884b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GfWULamoPvDe"
      },
      "outputs": [],
      "source": [
        "def create_bert_model(train_layers=-1,\n",
        "                      embedding_dim=768,\n",
        "                      token = 'cls', # 'cls' or 'pooled' or 'avg'\n",
        "                      num_attention = 0,\n",
        "                      hidden_dim=[10,10,10],\n",
        "                      dropout_rate=0.3,\n",
        "                      hidden_layer_activation = 'relu',\n",
        "                      output_layer_size = 4,\n",
        "                      output_activation = 'softmax',\n",
        "                      learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Load BERT\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    #restrict training to the train_layers outer transformer layers (SPECIFY WHICH BERT LAYERS ARE TRAINABLE)\n",
        "    if not train_layers == -1:\n",
        "\n",
        "            retrain_layers = []\n",
        "\n",
        "            for retrain_layer_number in range(train_layers):\n",
        "\n",
        "                layer_code = '_' + str(11 - retrain_layer_number)\n",
        "                retrain_layers.append(layer_code)\n",
        "\n",
        "            for w in bert_model.weights:\n",
        "                if not any([x in w.name for x in retrain_layers]):\n",
        "                    w._trainable = False\n",
        "    \n",
        "    #Input Layer\n",
        "    input_ids = tf.keras.layers.Input(shape = (512,),dtype=tf.int64, name='input_ids_layer') \n",
        "    #Get Contextual Embeddings + Single Vector Representations of Input (CLS or Pooled)\n",
        "    bert_out = bert_model(input_ids) \n",
        "    \n",
        "    if token == 'cls':\n",
        "        token = bert_out[0][:,0] #Get CLS Tokens\n",
        "    elif token == 'pooled':\n",
        "        token = bert_out[1] #Pooled Token\n",
        "    elif token == 'avg':\n",
        "        token = tf.math.reduce_mean(bert_out[0][:,1:-1],axis=1)\n",
        "    elif token == 'word_embeddings':\n",
        "        token = bert_out[0][:,1:-1]\n",
        "    \n",
        "    # Attention to Combine CLS/Pooled Tokens into single representation in the event of chunking text for single example\n",
        "    if num_attention == 0: # Single CLS/Pooled Token\n",
        "        embedding = token\n",
        "    elif num_attention == 1:\n",
        "        #Apply Query Vector to BERT Token, returning a num_attention x 1 tensor\n",
        "        query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(token)\n",
        "        if token.shape == (None,768):\n",
        "            reshaped_query = tf.keras.layers.Reshape((1,1))(query)\n",
        "            token = tf.keras.layers.Reshape((1,token.shape[1]))(token)\n",
        "        else:\n",
        "            reshaped_query = tf.keras.layers.Reshape((1,token.shape[1]))(query)\n",
        "        #Softmax over query * key (words) to obtain weights\n",
        "        weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
        "                                            name='attention_weights')(reshaped_query)\n",
        "        #weight attention embeddings according to weights\n",
        "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((token,weights)))\n",
        "    else:\n",
        "        #Create attention based single vector representations of words according to alternative query vectors\n",
        "        attention_embeddings = []\n",
        "        for num in range(num_attention):\n",
        "            #Apply Query Vector to words in embeddings, returning a embedding_dim x 1 tensor\n",
        "            l1_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query_l' + str(num+1))(token)\n",
        "            if token.shape == (None,768):\n",
        "                l1_reshaped_query = tf.keras.layers.Reshape((1,1))(l1_query)\n",
        "                l1_token = tf.keras.layers.Reshape((1,token.shape[1]))(token)\n",
        "            else:\n",
        "                l1_reshaped_query = tf.keras.layers.Reshape((1,token.shape[1]))(l1_query)\n",
        "                l1_token = token\n",
        "                \n",
        "            #Softmax over query * key (words) to obtain weights\n",
        "            l1_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
        "                                                name='attention_weights_l' + str(num+1))(l1_reshaped_query)\n",
        "            \n",
        "            #weight attention embeddings according to weights\n",
        "            l1_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((l1_token,l1_weights)))\n",
        "            attention_embeddings.append(l1_attention)\n",
        "\n",
        "        concat_attention = tf.keras.layers.Concatenate()(attention_embeddings)\n",
        "        concat_attention = tf.keras.layers.Reshape((num_attention,embedding_dim))(concat_attention)\n",
        "        \n",
        "        #Apply Query Vector to BERT Embeddings with Various Attention-Based representations, returning a num_attention x 1 tensor\n",
        "        query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(concat_attention)\n",
        "        #reshape to 1 x num_attention\n",
        "        reshaped_query = tf.keras.layers.Reshape((1,num_attention))(query)\n",
        "        #Softmax over query * key (words) to obtain weights\n",
        "        weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
        "                                            name='attention_weights')(reshaped_query)\n",
        "        #weight attention embeddings according to weights\n",
        "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((concat_attention,weights)))\n",
        "        \n",
        "    x = embedding\n",
        "    count = 1\n",
        "    for layer in hidden_dim:\n",
        "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
        "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
        "        count = count + 1\n",
        "        x = dropout\n",
        "\n",
        "    bert_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation,name='classification_layer')(x)\n",
        "    \n",
        "    bert_model = tf.keras.Model(inputs=[input_ids], outputs=[bert_classification])\n",
        "    \n",
        "    bert_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
        "                                                beta_1=0.9,\n",
        "                                                beta_2=0.999,\n",
        "                                                epsilon=1e-07,\n",
        "                                                amsgrad=False,\n",
        "                                                name='Adam'),\n",
        "                 metrics=['accuracy'],\n",
        "                     run_eagerly=True) \n",
        "    \n",
        "    print(bert_model.summary())\n",
        "    \n",
        "    return bert_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cVfixhBPvDf",
        "outputId": "b89e73d1-4b9b-494b-d1a8-20dbd61d4c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids_layer (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  109482240   ['input_ids_layer[0][0]']        \n",
            "                                thPoolingAndCrossAt                                               \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 510, 768)    0           ['tf_bert_model_1[0][0]']        \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " attention_query_l1 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " attention_query_l2 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " attention_query_l3 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " attention_query_l4 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " attention_query_l5 (Dense)     (None, 510, 1)       768         ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 1, 510)       0           ['attention_query_l1[0][0]']     \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 1, 510)       0           ['attention_query_l2[0][0]']     \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 1, 510)       0           ['attention_query_l3[0][0]']     \n",
            "                                                                                                  \n",
            " reshape_3 (Reshape)            (None, 1, 510)       0           ['attention_query_l4[0][0]']     \n",
            "                                                                                                  \n",
            " reshape_4 (Reshape)            (None, 1, 510)       0           ['attention_query_l5[0][0]']     \n",
            "                                                                                                  \n",
            " attention_weights_l1 (Lambda)  (None, 1, 510)       0           ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " attention_weights_l2 (Lambda)  (None, 1, 510)       0           ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " attention_weights_l3 (Lambda)  (None, 1, 510)       0           ['reshape_2[0][0]']              \n",
            "                                                                                                  \n",
            " attention_weights_l4 (Lambda)  (None, 1, 510)       0           ['reshape_3[0][0]']              \n",
            "                                                                                                  \n",
            " attention_weights_l5 (Lambda)  (None, 1, 510)       0           ['reshape_4[0][0]']              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'attention_weights_l1[0][0]']  \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'attention_weights_l2[0][0]']  \n",
            "                                                                                                  \n",
            " dot_2 (Dot)                    (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'attention_weights_l3[0][0]']  \n",
            "                                                                                                  \n",
            " dot_3 (Dot)                    (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'attention_weights_l4[0][0]']  \n",
            "                                                                                                  \n",
            " dot_4 (Dot)                    (None, 768, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'attention_weights_l5[0][0]']  \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 768)          0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 768)          0           ['dot_1[0][0]']                  \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 768)          0           ['dot_2[0][0]']                  \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 768)          0           ['dot_3[0][0]']                  \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 768)          0           ['dot_4[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3840)         0           ['flatten[0][0]',                \n",
            "                                                                  'flatten_1[0][0]',              \n",
            "                                                                  'flatten_2[0][0]',              \n",
            "                                                                  'flatten_3[0][0]',              \n",
            "                                                                  'flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_5 (Reshape)            (None, 5, 768)       0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " attention_query (Dense)        (None, 5, 1)         768         ['reshape_5[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)            (None, 1, 5)         0           ['attention_query[0][0]']        \n",
            "                                                                                                  \n",
            " attention_weights (Lambda)     (None, 1, 5)         0           ['reshape_6[0][0]']              \n",
            "                                                                                                  \n",
            " dot_5 (Dot)                    (None, 768, 1)       0           ['reshape_5[0][0]',              \n",
            "                                                                  'attention_weights[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)            (None, 768)          0           ['dot_5[0][0]']                  \n",
            "                                                                                                  \n",
            " hidden_1 (Dense)               (None, 50)           38450       ['flatten_5[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 50)           0           ['hidden_1[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_2 (Dense)               (None, 50)           2550        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 50)           0           ['hidden_2[0][0]']               \n",
            "                                                                                                  \n",
            " hidden_3 (Dense)               (None, 50)           2550        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 50)           0           ['hidden_3[0][0]']               \n",
            "                                                                                                  \n",
            " classification_layer (Dense)   (None, 7)            357         ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,530,755\n",
            "Trainable params: 109,530,755\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/13 [=>............................] - ETA: 8:13 - loss: 1.8959 - accuracy: 0.2500WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/13 [===>..........................] - ETA: 7:29 - loss: 2.5921 - accuracy: 0.1250WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/13 [=====>........................] - ETA: 6:33 - loss: 2.5171 - accuracy: 0.0833WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/13 [========>.....................] - ETA: 5:48 - loss: 2.4308 - accuracy: 0.0625WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5/13 [==========>...................] - ETA: 5:04 - loss: 2.6485 - accuracy: 0.0750WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/13 [============>.................] - ETA: 4:34 - loss: 2.6062 - accuracy: 0.0833"
          ]
        }
      ],
      "source": [
        "cls_bert_model = create_bert_model(learning_rate=0.0005,output_layer_size=7,num_attention=2,token='word_embeddings')\n",
        "                        \n",
        "cls_bert_model.fit(train_bert_ids[:100], df_train['Major Genre'].map(mapping).iloc[:100], \n",
        "                   validation_data=(test_bert_ids[:100],df_test['Major Genre'].map(mapping).iloc[:100]),\n",
        "                   batch_size=8, epochs=2) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk3Z_8CkPvDf"
      },
      "source": [
        "# 9 Extra Cleaning Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLMuJyexPvDf",
        "outputId": "b8e7089f-6543-46e5-9551-0192596e59ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16303    [go, take, life, dreams, fire, go, take, day, ...\n",
              "8721     [bitch, one, click, ruin, life, trip, yea, tak...\n",
              "11930    [eyes, like, face, bit, different, bit, fucked...\n",
              "7945     [ugh, ugh, what, what, ugh, what, what, ugh, u...\n",
              "15504    [age, darkness, light, appears, wards, away, a...\n",
              "                               ...                        \n",
              "7303     [saucey, genius, aztro, cut, put, magnum, bott...\n",
              "9125     [i’ve, loved, /, i’ve, done, months, made, fee...\n",
              "5125     [another, it's, kel, p, vibes, wanna, give, ev...\n",
              "15805    [woke, mornin', understand, means, give, life,...\n",
              "2952     [läppar, döljer, dina, tänder, och, din, tunga...\n",
              "Name: Lyrics, Length: 14778, dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['Lyrics']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nML6-HQvPvDg"
      },
      "outputs": [],
      "source": [
        "def split_text_into_regions(text):\n",
        "    string = text\n",
        "   \n",
        "    #mark line breaks\n",
        "    string = string.replace('\\n','[]')\n",
        "    string = string.replace('embed','')\n",
        "    #find language indicators of song sections\n",
        "    splits = re.findall('\\[.*?\\]',string)\n",
        "    #find ad libs to remove\n",
        "    ad_libs = re.findall('\\(.*?\\)',string)\n",
        "   \n",
        "    #remove ad libs\n",
        "    if len(ad_libs) > 0:\n",
        "        for ad_lib in ad_libs:\n",
        "            string = string.replace(ad_lib,'')\n",
        "        string = string.replace('  ',' ')\n",
        "   \n",
        "    #If there is no splitting criteria, single string is entire song without any additional groupings\n",
        "    if len(splits) == 0:\n",
        "        string = [string]\n",
        "    else:\n",
        "        #replace split criteria with makers for splitting\n",
        "        for delim in splits:\n",
        "            string = string.replace(delim,'[]')\n",
        "        string = string.split('[]')\n",
        "   \n",
        "    #Identify sections of song, made up of groups of lyrics\n",
        "    sections = []\n",
        "    section = []\n",
        "    last_part = ''\n",
        "    for part in string:\n",
        "        if part == '' and last_part != '':\n",
        "            sections.append(section)\n",
        "            section = []\n",
        "        elif part != '':\n",
        "            section.append(part)\n",
        "       \n",
        "        last_part = part\n",
        "   \n",
        "    try:\n",
        "        if section != sections[-1]:\n",
        "            sections.append(section)\n",
        "    except:\n",
        "        sections.append(section)\n",
        "   \n",
        "    return sections    \n",
        "\n",
        "\n",
        "def single_text_lyrics(group_of_lyrics):\n",
        "    lyrics = ''\n",
        "    for group in group_of_lyrics:\n",
        "        lyrics = lyrics + ' ' + ' '.join(group)\n",
        "    return lyrics.strip() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-w-95itPvDg"
      },
      "source": [
        "# 10 Term Density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fBRtbybGPvDg"
      },
      "outputs": [],
      "source": [
        "term_freq = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0n9qsPvIPvDh"
      },
      "outputs": [],
      "source": [
        "df_test = pkl.load(open('genre_sub_genre_test.pkl', 'rb'))\n",
        "df_train = pkl.load(open('genre_sub_genre_train.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train[:8250]"
      ],
      "metadata": {
        "id": "DDr-t1lwaM1F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GeKSL5a7PvDh",
        "outputId": "94888364-3790-4df4-ec48-509088ec7f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Artist Name            Track Name  \\\n",
              "5                         Stevie Ray Vaughan      Life By The Drop   \n",
              "6                                   DARKSIDE          Paper Trails   \n",
              "11               Christone \"Kingfish\" Ingram  Outside Of This Town   \n",
              "28                                Jesse Cook  I Put A Spell On You   \n",
              "31               Christone \"Kingfish\" Ingram        Before I'm Old   \n",
              "...                                      ...                   ...   \n",
              "19316                             Woolbright               Tuesday   \n",
              "19321                           Runnin' Wild  How You Want It Done   \n",
              "19344                       Four Year Strong    Go Down in History   \n",
              "19355  Nathaniel Rateliff & The Night Sweats                S.O.B.   \n",
              "19356                                Muskets              17 Years   \n",
              "\n",
              "       Popularity  danceability  energy  key  loudness  mode  speechiness  \\\n",
              "5              51         0.659   0.163    6   -11.864     0       0.0388   \n",
              "6              55         0.947   0.419    8   -13.043     0       0.0578   \n",
              "11             48         0.418   0.866   11    -4.033     0       0.0513   \n",
              "28             34         0.420   0.373    1    -9.302     0       0.0320   \n",
              "31             41         0.534   0.649    2    -5.526     1       0.0410   \n",
              "...           ...           ...     ...  ...       ...   ...          ...   \n",
              "19316          23         0.514   0.819   11    -6.713     0       0.0375   \n",
              "19321          27         0.614   0.953    9    -3.539     1       0.0517   \n",
              "19344          48         0.505   0.985    5    -4.401     1       0.1190   \n",
              "19355          66         0.699   0.579    1    -6.504     1       0.0416   \n",
              "19356          31         0.446   0.935    8    -4.677     1       0.0357   \n",
              "\n",
              "       acousticness  ...  Sub-Genre: modern alternative rock  \\\n",
              "5           0.76600  ...                                   0   \n",
              "6           0.77800  ...                                   0   \n",
              "11          0.00381  ...                                   0   \n",
              "28          0.92200  ...                                   0   \n",
              "31          0.04380  ...                                   0   \n",
              "...             ...  ...                                 ...   \n",
              "19316       0.01220  ...                                   0   \n",
              "19321       0.07710  ...                                   0   \n",
              "19344       0.00006  ...                                   0   \n",
              "19355       0.26700  ...                                   0   \n",
              "19356       0.00007  ...                                   0   \n",
              "\n",
              "       Sub-Genre: southern hip hop  Sub-Genre: nu metal  \\\n",
              "5                                0                    0   \n",
              "6                                0                    0   \n",
              "11                               0                    0   \n",
              "28                               0                    0   \n",
              "31                               0                    0   \n",
              "...                            ...                  ...   \n",
              "19316                            0                    0   \n",
              "19321                            0                    0   \n",
              "19344                            0                    0   \n",
              "19355                            0                    0   \n",
              "19356                            0                    0   \n",
              "\n",
              "       Sub-Genre: israeli mediterranean Sub-Genre: thrash metal  \\\n",
              "5                                     0                       0   \n",
              "6                                     0                       0   \n",
              "11                                    0                       0   \n",
              "28                                    0                       0   \n",
              "31                                    0                       0   \n",
              "...                                 ...                     ...   \n",
              "19316                                 0                       0   \n",
              "19321                                 0                       0   \n",
              "19344                                 0                       0   \n",
              "19355                                 0                       0   \n",
              "19356                                 0                       0   \n",
              "\n",
              "      Sub-Genre: pop rock Sub-Genre: chicago blues Sub-Genre: indie pop  \\\n",
              "5                       0                        0                    0   \n",
              "6                       0                        0                    0   \n",
              "11                      0                        0                    0   \n",
              "28                      0                        0                    0   \n",
              "31                      0                        0                    0   \n",
              "...                   ...                      ...                  ...   \n",
              "19316                   0                        0                    0   \n",
              "19321                   0                        0                    0   \n",
              "19344                   0                        0                    0   \n",
              "19355                   0                        0                    0   \n",
              "19356                   0                        0                    0   \n",
              "\n",
              "       Sub-Genre: classic rock  Sub-Genre: hardcore hip hop  \n",
              "5                            1                            0  \n",
              "6                            0                            0  \n",
              "11                           0                            0  \n",
              "28                           0                            0  \n",
              "31                           0                            0  \n",
              "...                        ...                          ...  \n",
              "19316                        0                            0  \n",
              "19321                        0                            0  \n",
              "19344                        0                            0  \n",
              "19355                        0                            0  \n",
              "19356                        0                            0  \n",
              "\n",
              "[2581 rows x 72 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-740dda0c-8eff-4622-b38e-030fc1dda5f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist Name</th>\n",
              "      <th>Track Name</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>key</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>...</th>\n",
              "      <th>Sub-Genre: modern alternative rock</th>\n",
              "      <th>Sub-Genre: southern hip hop</th>\n",
              "      <th>Sub-Genre: nu metal</th>\n",
              "      <th>Sub-Genre: israeli mediterranean</th>\n",
              "      <th>Sub-Genre: thrash metal</th>\n",
              "      <th>Sub-Genre: pop rock</th>\n",
              "      <th>Sub-Genre: chicago blues</th>\n",
              "      <th>Sub-Genre: indie pop</th>\n",
              "      <th>Sub-Genre: classic rock</th>\n",
              "      <th>Sub-Genre: hardcore hip hop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Stevie Ray Vaughan</td>\n",
              "      <td>Life By The Drop</td>\n",
              "      <td>51</td>\n",
              "      <td>0.659</td>\n",
              "      <td>0.163</td>\n",
              "      <td>6</td>\n",
              "      <td>-11.864</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0388</td>\n",
              "      <td>0.76600</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DARKSIDE</td>\n",
              "      <td>Paper Trails</td>\n",
              "      <td>55</td>\n",
              "      <td>0.947</td>\n",
              "      <td>0.419</td>\n",
              "      <td>8</td>\n",
              "      <td>-13.043</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0578</td>\n",
              "      <td>0.77800</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Christone \"Kingfish\" Ingram</td>\n",
              "      <td>Outside Of This Town</td>\n",
              "      <td>48</td>\n",
              "      <td>0.418</td>\n",
              "      <td>0.866</td>\n",
              "      <td>11</td>\n",
              "      <td>-4.033</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0513</td>\n",
              "      <td>0.00381</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Jesse Cook</td>\n",
              "      <td>I Put A Spell On You</td>\n",
              "      <td>34</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.373</td>\n",
              "      <td>1</td>\n",
              "      <td>-9.302</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0320</td>\n",
              "      <td>0.92200</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Christone \"Kingfish\" Ingram</td>\n",
              "      <td>Before I'm Old</td>\n",
              "      <td>41</td>\n",
              "      <td>0.534</td>\n",
              "      <td>0.649</td>\n",
              "      <td>2</td>\n",
              "      <td>-5.526</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0410</td>\n",
              "      <td>0.04380</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19316</th>\n",
              "      <td>Woolbright</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>23</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.819</td>\n",
              "      <td>11</td>\n",
              "      <td>-6.713</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0375</td>\n",
              "      <td>0.01220</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19321</th>\n",
              "      <td>Runnin' Wild</td>\n",
              "      <td>How You Want It Done</td>\n",
              "      <td>27</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.953</td>\n",
              "      <td>9</td>\n",
              "      <td>-3.539</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0517</td>\n",
              "      <td>0.07710</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19344</th>\n",
              "      <td>Four Year Strong</td>\n",
              "      <td>Go Down in History</td>\n",
              "      <td>48</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.985</td>\n",
              "      <td>5</td>\n",
              "      <td>-4.401</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1190</td>\n",
              "      <td>0.00006</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19355</th>\n",
              "      <td>Nathaniel Rateliff &amp; The Night Sweats</td>\n",
              "      <td>S.O.B.</td>\n",
              "      <td>66</td>\n",
              "      <td>0.699</td>\n",
              "      <td>0.579</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.504</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0416</td>\n",
              "      <td>0.26700</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19356</th>\n",
              "      <td>Muskets</td>\n",
              "      <td>17 Years</td>\n",
              "      <td>31</td>\n",
              "      <td>0.446</td>\n",
              "      <td>0.935</td>\n",
              "      <td>8</td>\n",
              "      <td>-4.677</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.00007</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2581 rows × 72 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-740dda0c-8eff-4622-b38e-030fc1dda5f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-740dda0c-8eff-4622-b38e-030fc1dda5f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-740dda0c-8eff-4622-b38e-030fc1dda5f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# filter out results\n",
        "df_train.drop(df_train[df_train['Lyrics'].str.len() > 5000].index, inplace=True)\n",
        "df_train[df_train['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
        "df_train[df_train['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
        "\n",
        "df_test.drop(df_test[df_test['Lyrics'].str.len() > 5000].index, inplace=True)\n",
        "df_test[df_test['Artist Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]\n",
        "df_test[df_test['Track Name'].str.contains(\"ÂÃÄÀÁÅÆÇÈÉÊËÌÍÎÏÐÑÒÓÔÕÖØÙÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿ\") == False]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = df_train['Major Genre']\n",
        "test_labels = df_test['Major Genre']\n",
        "print(train_labels.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u9GNgFDkhDI",
        "outputId": "dfee6708-1d68-4c04-bd32-3407a8f0dd95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rock           2406\n",
            "Indie          1196\n",
            "Pop            1057\n",
            "Metal           934\n",
            "Alternative     720\n",
            "Hip Hop         675\n",
            "Blues           420\n",
            "Name: Major Genre, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff9Fne58yB2W",
        "outputId": "7a4a47cd-e1e7-4da8-e771-3ed5ef35dfe3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rock           781\n",
            "Indie          427\n",
            "Metal          353\n",
            "Pop            346\n",
            "Hip Hop        272\n",
            "Alternative    239\n",
            "Blues          163\n",
            "Name: Major Genre, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapper so we can use numeric labels in our networks\n",
        "mapping = {}\n",
        "count = 0\n",
        "for label in train_labels.unique():\n",
        "    mapping[label] = count\n",
        "    count = count + 1\n",
        "print(mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEU-dAQPmGEa",
        "outputId": "7a0d414a-4baa-41a1-bc9b-985fab9d8a07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Rock': 0, 'Indie': 1, 'Alternative': 2, 'Hip Hop': 3, 'Metal': 4, 'Pop': 5, 'Blues': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = 2406/train_labels.value_counts()\n",
        "class_weights = {}\n",
        "for num in range(len(weights)):\n",
        "    class_weights[mapping[weights.index[num]]] = weights.iloc[num]\n",
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcgqPbMQkdf-",
        "outputId": "65b70a76-82ff-48ef-c2cb-c36ac4c73e82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0,\n",
              " 1: 2.011705685618729,\n",
              " 2: 3.341666666666667,\n",
              " 3: 3.5644444444444443,\n",
              " 4: 2.576017130620985,\n",
              " 5: 2.2762535477767267,\n",
              " 6: 5.728571428571429}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j5HSpXBJPvDh",
        "outputId": "68b6c75b-9432-4c8c-d31d-fddf9691ef52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16303    Unbreakable Lyrics[Intro]\\nGo take it all\\nYou...\n",
              "8721     NOBODY LyricsTake a bitch\\nThat I have in one ...\n",
              "11930    Worth It Lyrics[Verse 1]\\nYour eyes are just l...\n",
              "7945     Bloodrush Lyrics[Intro: Denzel Curry]\\nUgh\\nUg...\n",
              "15504    Age of Man Lyrics[Intro]\\nIn an age of darknes...\n",
              "                               ...                        \n",
              "3883     Kid Milli & dress - Kitty ft. MIYEON (Romanize...\n",
              "2531     Earthless Lyrics[Verse 1]\\nDescending through ...\n",
              "1133     We Get By Lyrics[Verse 1: Mavis Staples and Be...\n",
              "14500    Fly Away LyricsI wish that I could fly\\nInto t...\n",
              "4249     Shney Yeladim Ba’olam - שני ילדים בעולם Lyrics...\n",
              "Name: Lyrics, Length: 7408, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_train['Lyrics']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_Fj94ZqSPvDh"
      },
      "outputs": [],
      "source": [
        "df_train['modified_lyrics'] = df_train['Lyrics'].apply(lambda x: ' '.join(str(x).split('Lyrics')[1:]).lower())\n",
        "df_test['modified_lyrics'] = df_test['Lyrics'].apply(lambda x: ' '.join(str(x).split('Lyrics')[1:]).lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WLmGOsaOPvDi"
      },
      "outputs": [],
      "source": [
        "df_train['modified_lyrics'] = df_train['modified_lyrics'].apply(lambda x: split_text_into_regions(x))\n",
        "df_test['modified_lyrics'] = df_test['modified_lyrics'].apply(lambda x: split_text_into_regions(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_zxyJVI9PvDi",
        "outputId": "bf4f4c5c-8f57-4888-af60-b93d1ff7d7cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16303    [[go take it all, your life, your dreams, your...\n",
              "8721     [[take a bitch, that i have in one click, ruin...\n",
              "11930    [[your eyes are just like his, but your face i...\n",
              "7945     [[ugh, ugh,  ugh,  ugh, ugh], [behind every sm...\n",
              "15504    [[in an age of darkness light appears, and it ...\n",
              "                               ...                        \n",
              "3883     [[i don't tryna be a good boy, nae saenggage, ...\n",
              "2531     [[descending through the mouth, engulfing teet...\n",
              "1133     [[we get by on love and faith, we get by with ...\n",
              "14500    [[i wish that i could fly, into the sky so ver...\n",
              "4249     [[איך הכל ממהר לי פתאום, רציתי לראות את השמיים...\n",
              "Name: modified_lyrics, Length: 7408, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df_train['modified_lyrics']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xboQsTKZPvDi"
      },
      "outputs": [],
      "source": [
        "df_train['final_modified_lyrics'] = df_train['modified_lyrics'].apply(lambda x: single_text_lyrics(x))\n",
        "df_test['final_modified_lyrics'] = df_test['modified_lyrics'].apply(lambda x: single_text_lyrics(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['final_modified_lyrics']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVcMZEe2rcLF",
        "outputId": "5e5888b5-2eff-485c-92ba-55ab96bdbafc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16303    go take it all your life, your dreams, your fi...\n",
              "8721     take a bitch that i have in one click ruin my ...\n",
              "11930    your eyes are just like his but your face is a...\n",
              "7945     ugh ugh  ugh  ugh ugh behind every smile, it b...\n",
              "15504    in an age of darkness light appears and it war...\n",
              "                               ...                        \n",
              "3883     i don't tryna be a good boy nae saenggage you ...\n",
              "2531     descending through the mouth engulfing teeth p...\n",
              "1133     we get by on love and faith we get by with a s...\n",
              "14500    i wish that i could fly into the sky so very h...\n",
              "4249     איך הכל ממהר לי פתאום רציתי לראות את השמיים שנ...\n",
              "Name: final_modified_lyrics, Length: 7408, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b64ZEK8MPvDj",
        "outputId": "086d5fbf-bf50-46d7-97da-1ae50eb7ca78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "term_freq.fit(df_train['final_modified_lyrics'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hY8j63pdPvDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f13bb0-cbdc-44bc-8bd9-cd8691cb9c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "train_term_df = pd.DataFrame(term_freq.transform(df_train['final_modified_lyrics']).todense(), columns = term_freq.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_term_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtUuUowBYxei",
        "outputId": "edba7d39-34e5-41e0-e36d-7750490fce6e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7408, 66198)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cOmLruKrPvDj"
      },
      "outputs": [],
      "source": [
        "train_term_sums = np.array(train_term_df.sum(axis = 1)).astype('float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XwE1X3olPvDj",
        "outputId": "91aa0b0d-3a09-464b-e6db-0fedcfa64540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189.0\n"
          ]
        }
      ],
      "source": [
        "print(train_term_sums[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "D7tqcp2SPvDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3bf4ed-0ab5-4026-e7eb-0e79b4b386a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "train_term_sums_reshaped = train_term_sums.repeat(len(term_freq.get_feature_names())).reshape(train_term_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BdI5o6s6PvDj"
      },
      "outputs": [],
      "source": [
        "# bigger numbers = better words for that song\n",
        "train_term_df = (train_term_df / train_term_sums_reshaped).astype('float16')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_term_df.shape\n",
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9dC2VkMbBZN",
        "outputId": "5befe411-1294-428c-aba6-d08eb47c4713"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7408, 74)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_term_df = pd.DataFrame(term_freq.transform(df_test['final_modified_lyrics']).todense(), columns = term_freq.get_feature_names())\n",
        "test_term_sums = np.array(test_term_df.sum(axis = 1)).astype('float16')\n",
        "test_term_sums_reshaped = test_term_sums.repeat(len(term_freq.get_feature_names())).reshape(test_term_df.shape)\n",
        "test_term_df = (test_term_df / test_term_sums_reshaped).astype('float16')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjiNa02Paucv",
        "outputId": "fa5dd673-30c4-4ade-ef53-1a5eb0389aa3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels.map(mapping)[0:5])\n",
        "print(train_labels[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK_4QTZGxBft",
        "outputId": "9402c41f-ccb5-4a6d-fa43-d1c594b192e0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16303    0\n",
            "8721     1\n",
            "11930    2\n",
            "7945     3\n",
            "15504    0\n",
            "Name: Major Genre, dtype: int64\n",
            "16303           Rock\n",
            "8721           Indie\n",
            "11930    Alternative\n",
            "7945         Hip Hop\n",
            "15504           Rock\n",
            "Name: Major Genre, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZKFFVR5_xziF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels.map(mapping)[0:5])\n",
        "print(test_labels[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjKrIfSFxspR",
        "outputId": "0cdb37b9-9bf9-4386-c480-43a3cd08d4d2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5     6\n",
            "6     6\n",
            "11    6\n",
            "28    6\n",
            "31    6\n",
            "Name: Major Genre, dtype: int64\n",
            "5     Blues\n",
            "6     Blues\n",
            "11    Blues\n",
            "28    Blues\n",
            "31    Blues\n",
            "Name: Major Genre, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_term_df.iloc[0].sort_values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbpI8zUY0leC",
        "outputId": "0169e95a-7c5a-4da3-8831-673b6654a30d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "00              0.000000\n",
              "thes            0.000000\n",
              "thesaurus       0.000000\n",
              "thescrivener    0.000000\n",
              "these           0.000000\n",
              "                  ...   \n",
              "how             0.027176\n",
              "that            0.032623\n",
              "living          0.043488\n",
              "the             0.054352\n",
              "it              0.054352\n",
              "Name: 0, Length: 66198, dtype: float16"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_term_df.iloc[1].sort_values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJOdkNhY1ZQr",
        "outputId": "a35f0b08-05a9-4f26-f348-064ab4e5cbc8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "00              0.000000\n",
              "thesaurus       0.000000\n",
              "thescrivener    0.000000\n",
              "these           0.000000\n",
              "thesis          0.000000\n",
              "                  ...   \n",
              "go              0.040649\n",
              "the             0.040649\n",
              "on              0.048767\n",
              "to              0.065063\n",
              "you             0.081299\n",
              "Name: 1, Length: 66198, dtype: float16"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first lets see if we can do a basic FFN with just the dfs\n",
        "# a standard feed-forward network\n",
        "# note: audio features have been normalized\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(50,activation='leaky_relu'),\n",
        "    keras.layers.Dense(50,activation='leaky_relu'),\n",
        "    keras.layers.Dense(10,activation='leaky_relu'),\n",
        "    keras.layers.Dense(7,activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "#Compile the model, specifying loss function, optimizer, and performance metric\n",
        "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "             optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
        "             metrics=['accuracy'],\n",
        "             )\n",
        "\n",
        "\n",
        "#model.fit(x = np.array(train_term_df),y = train_labels.map(mapping),batch_size=20,epochs=3,\n",
        "  #       validation_data = (np.array(test_term_df), test_labels.map(mapping)),\n",
        "   #      use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1)\n",
        "\n",
        "model.fit(x = np.array(train_term_df),y = train_labels.map(mapping),batch_size=8,epochs=10,\n",
        "         validation_data = (np.array(test_term_df) ,test_labels.map(mapping)),\n",
        "         use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1, class_weight = class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gVDV-1cbKfL",
        "outputId": "284a7201-b9c3-48c4-c6c3-d7a73ce96f54"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "926/926 [==============================] - 19s 20ms/step - loss: nan - accuracy: 0.3224 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 2/10\n",
            "926/926 [==============================] - 14s 15ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 3/10\n",
            "926/926 [==============================] - 14s 15ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 4/10\n",
            "926/926 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 5/10\n",
            "926/926 [==============================] - 15s 17ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 6/10\n",
            "926/926 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 7/10\n",
            "926/926 [==============================] - 15s 16ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 8/10\n",
            "926/926 [==============================] - 14s 16ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 9/10\n",
            "926/926 [==============================] - 14s 15ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 10/10\n",
            "926/926 [==============================] - 14s 15ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a0573b210>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S_ARbN7fxrrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RWfSElahPvDk"
      },
      "outputs": [],
      "source": [
        "# let's try with audio features too...this will be a big model\n",
        "# define two sets of inputs\n",
        "inputA = Input(shape=(66198,))\n",
        "inputB = Input(shape=(9,))\n",
        "# the first branch operates on the first input\n",
        "x = Dense(1000, activation=\"relu\")(inputA)\n",
        "x = Dense(1000, activation=\"relu\")(x)\n",
        "x = Dense(100, activation=\"relu\")(x)\n",
        "x = Model(inputs=inputA, outputs=x)\n",
        "# the second branch opreates on the second input\n",
        "y = Dense(10, activation=\"relu\")(inputB)\n",
        "y = Dense(50, activation=\"relu\")(y)\n",
        "y = Dense(100, activation=\"relu\")(y)\n",
        "y = Model(inputs=inputB, outputs=y)\n",
        "# combine the output of the two branches\n",
        "combined = concatenate([x.output, y.output])\n",
        "# apply a FC layer and then a classification prediction on the\n",
        "# combined outputs\n",
        "z = Dense(50, activation=\"relu\")(combined)\n",
        "z = Dense(20, activation=\"relu\")(z)\n",
        "z = Dense(7, activation=\"softmax\")(z)\n",
        "#z = Dense(1, activation=\"linear\")(z)\n",
        "# our model will accept the inputs of the two branches and\n",
        "# then output a single value\n",
        "model = Model(inputs=[x.input, y.input], outputs=z)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=.001,\n",
        "                                                beta_1=0.9,\n",
        "                                                beta_2=0.999,\n",
        "                                                epsilon=1e-07,\n",
        "                                                amsgrad=False,\n",
        "                                                name='Adam'),\n",
        "             metrics='accuracy',\n",
        "             )"
      ],
      "metadata": {
        "id": "7bhHoPisdoJu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(x=[np.array(train_term_df), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_term_df), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8,\n",
        " #            class_weight = class_weights)\n",
        "\n",
        "model.fit(x=[np.array(train_term_df), np.array(df_train_audio_normalized)], y=train_labels.map(mapping), validation_data=([np.array(test_term_df), np.array(df_test_audio_normalized)], test_labels.map(mapping)), epochs=10, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "aFIiI8h3d5fN",
        "outputId": "79299943-8499-48a6-9912-97b765a10934"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "926/926 [==============================] - 211s 227ms/step - loss: nan - accuracy: 0.3248 - val_loss: nan - val_accuracy: 0.3026\n",
            "Epoch 2/10\n",
            " 66/926 [=>............................] - ETA: 3:06 - loss: nan - accuracy: 0.2803"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-c97fb2182e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m  \u001b[0;31m#            class_weight = class_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_term_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_audio_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_term_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_audio_normalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate with audio features"
      ],
      "metadata": {
        "id": "quK3IY19dB4W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Genre_Prediction-Copy1.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d90c72579cb646079551103c732f0770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b9281b67f1d4847a5a12c243583a7af",
              "IPY_MODEL_b74b3efd33cf4f1cb68f953ce64df4b5",
              "IPY_MODEL_549bc7a2f1f34fed82be71e2ff403981"
            ],
            "layout": "IPY_MODEL_fede47e020b24b33b70973f2368354a6"
          }
        },
        "7b9281b67f1d4847a5a12c243583a7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26cfb653005a401c9873023531a3b214",
            "placeholder": "​",
            "style": "IPY_MODEL_0ddc3de572e747b3a9af3231f97baffb",
            "value": "Downloading: 100%"
          }
        },
        "b74b3efd33cf4f1cb68f953ce64df4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc599fab9d84a739bf77810c816f678",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a19d3b02c85945bb94101dbb19f5eac3",
            "value": 231508
          }
        },
        "549bc7a2f1f34fed82be71e2ff403981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a7cea6d31864643bb693575e802a166",
            "placeholder": "​",
            "style": "IPY_MODEL_583e3ba45df74cb5bf80cfab7db15dff",
            "value": " 226k/226k [00:00&lt;00:00, 2.48MB/s]"
          }
        },
        "fede47e020b24b33b70973f2368354a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26cfb653005a401c9873023531a3b214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ddc3de572e747b3a9af3231f97baffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdc599fab9d84a739bf77810c816f678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19d3b02c85945bb94101dbb19f5eac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a7cea6d31864643bb693575e802a166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "583e3ba45df74cb5bf80cfab7db15dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b6c7b2fd344415389855cec0b503c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4ff3361af4649e48b68c499df4b8ec5",
              "IPY_MODEL_581ad14fabab4b828a51c34daaa5dedd",
              "IPY_MODEL_79f42f28bacf4917ad260fdff4a44939"
            ],
            "layout": "IPY_MODEL_6ba0ad9e0d154e9686c2df22060c6281"
          }
        },
        "d4ff3361af4649e48b68c499df4b8ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69c0cc823f02429e96ccd9004f3c5301",
            "placeholder": "​",
            "style": "IPY_MODEL_6fa43aff58174bacbc84b3443195d8a4",
            "value": "Downloading: 100%"
          }
        },
        "581ad14fabab4b828a51c34daaa5dedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_546ab8aac5ad40408c33491746194b13",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98e89fd326604d8aa28d56d079e8fac9",
            "value": 28
          }
        },
        "79f42f28bacf4917ad260fdff4a44939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1619a6edd94b5a9f31f4f9144bcb26",
            "placeholder": "​",
            "style": "IPY_MODEL_fd2d2a45fd654dce815110f7ce3b8c53",
            "value": " 28.0/28.0 [00:00&lt;00:00, 755B/s]"
          }
        },
        "6ba0ad9e0d154e9686c2df22060c6281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c0cc823f02429e96ccd9004f3c5301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa43aff58174bacbc84b3443195d8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "546ab8aac5ad40408c33491746194b13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e89fd326604d8aa28d56d079e8fac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e1619a6edd94b5a9f31f4f9144bcb26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2d2a45fd654dce815110f7ce3b8c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a7bc750c4424c32817015e5de481d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1dbf229fc39436b8de525a442333682",
              "IPY_MODEL_656499608fd64e3f864179ca6c32d817",
              "IPY_MODEL_5d8dfcab42cb4e48bcf458e1372f468d"
            ],
            "layout": "IPY_MODEL_65eb48b74c104f31a6130529019543b2"
          }
        },
        "f1dbf229fc39436b8de525a442333682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5364b89a3f5a4feebdb39104fe7e1908",
            "placeholder": "​",
            "style": "IPY_MODEL_15a00f8bb5574b2aa558b7d04b9a5e2c",
            "value": "Downloading: 100%"
          }
        },
        "656499608fd64e3f864179ca6c32d817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c08e97aaae488dae290d9c5250cdfb",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa38386ad94f45b3a654ad1f637bcf6e",
            "value": 570
          }
        },
        "5d8dfcab42cb4e48bcf458e1372f468d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f9f858699b4226a7d61257b5c0b317",
            "placeholder": "​",
            "style": "IPY_MODEL_510844178fc4484fb215656f32b447ea",
            "value": " 570/570 [00:00&lt;00:00, 12.9kB/s]"
          }
        },
        "65eb48b74c104f31a6130529019543b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5364b89a3f5a4feebdb39104fe7e1908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a00f8bb5574b2aa558b7d04b9a5e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6c08e97aaae488dae290d9c5250cdfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa38386ad94f45b3a654ad1f637bcf6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69f9f858699b4226a7d61257b5c0b317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510844178fc4484fb215656f32b447ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c112913ebbc94b51a3b44e390c2a884b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5a025221c8f400ca218beee6faf65c8",
              "IPY_MODEL_c5ebc5d4679e49a0992b4793a52aab7f",
              "IPY_MODEL_c28b77e093324a2fbcb4174c44bec661"
            ],
            "layout": "IPY_MODEL_5f1b35e982b34fc9bc2291681e3f1e19"
          }
        },
        "c5a025221c8f400ca218beee6faf65c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1469420a34154e9f9257458b290507d2",
            "placeholder": "​",
            "style": "IPY_MODEL_c03d0915a8c249618a4d84af34bf0669",
            "value": "Downloading: 100%"
          }
        },
        "c5ebc5d4679e49a0992b4793a52aab7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e79aa4e1b6f4c4a858fc41ddafd1c3a",
            "max": 536063208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7b6924b8a3547b7a16397663358a36d",
            "value": 536063208
          }
        },
        "c28b77e093324a2fbcb4174c44bec661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96556f35e08247898751de10d37057ed",
            "placeholder": "​",
            "style": "IPY_MODEL_9f6f23efebff447eba4e35867df061c6",
            "value": " 511M/511M [00:12&lt;00:00, 44.2MB/s]"
          }
        },
        "5f1b35e982b34fc9bc2291681e3f1e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1469420a34154e9f9257458b290507d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03d0915a8c249618a4d84af34bf0669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e79aa4e1b6f4c4a858fc41ddafd1c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b6924b8a3547b7a16397663358a36d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96556f35e08247898751de10d37057ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6f23efebff447eba4e35867df061c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}