{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7BzBd-N9mS1"
   },
   "source": [
    "# Assignment 2: Text Classification with Various Neural Networks\n",
    "\n",
    "**Description:** This assignment covers various neural network architectures and components, largely used in the context of classification. You will compare Deep Averaging Networks, Deep Weighted Averaging Networks using Attention, and BERT-based models. You should also be able to develop an intuition for:\n",
    "\n",
    "\n",
    "*   The effects of fine-tuning word vectors or starting with random word vectors\n",
    "*   How various networks behave when the training set size changes\n",
    "* The effect of shuffling your training data\n",
    "*   The benefits of Attention calculations\n",
    "* Working with BERT\n",
    "\n",
    "\n",
    "The assignment notebook closely follows the lesson notebooks. We will use the IMDB dataset and will leverage some of the models, or part of the code, for our current investigation.\n",
    "\n",
    "The initial part of the notebook is purely setup. We will then evaluate how Attention can make Deep Averaging networks better. \n",
    "\n",
    "Do not try to run this entire notebook on your GCP instance as the training of models requires a GPU to work in a timely fashion. This notebook should be run on a Google Colab leveraging a GPU. By default, when you open the notebook in Colab it will try to use a GPU. Total runtime of the entire notebook (with solutions and a Colab GPU) should be about 1h.\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datasci-w266/2022-summer-main/blob/master/assignment/a2/Text_classification.ipynb)\n",
    "\n",
    "The overall assignment structure is as follows:\n",
    "\n",
    "1. Setup\n",
    "  \n",
    "  1.1 Libraries, Embeddings,  & Helper Functions\n",
    "\n",
    "  1.2 Data Acquisition\n",
    "\n",
    "  1.3. Data Preparation\n",
    "\n",
    "      1.3.1 Training/Test Sets using Word2Vec \n",
    "\n",
    "      1.3.2 Training/Test Sets for BERT-based models\n",
    "\n",
    "2. Classification with various Word2Vec-based Models\n",
    "\n",
    "  2.1 The Role of Shuffling of the Training Set\n",
    "\n",
    "  2.2 DAN vs Weighted Averaging Models using Attention\n",
    "\n",
    "    2.2.1 Warm-Up\n",
    "    \n",
    "    2.2.2 The WAN Model\n",
    "    \n",
    "  2.3 Approaches for Training of Embeddings \n",
    "\n",
    "3. Classification with BERT\n",
    "\n",
    "  3.1. BERT Basics\n",
    "\n",
    "  3.2 CLS-Token-based Classification \n",
    "\n",
    "  3.3 Averaging of BERT Outputs\n",
    "\n",
    "  3.4. Adding a CNN on top of BERT\n",
    "\n",
    "\n",
    "\n",
    "**INSTRUCTIONS:**: \n",
    "\n",
    "* Questions are always indicated as **QUESTION**, so you can search for this string to make sure you answered all of the questions. You are expected to fill out, run, and submit this notebook, as well as to answer the questions in the **answers** file as you did in a1.\n",
    "* **### YOUR CODE HERE** indicates that you are supposed to write code.\n",
    "\n",
    "* If you want to, you can run all of the cells in section 1 in bulk. This is setup work and no questions are in there. At the end of section 1 we will state all of the relevant variables that were defined and created in section 1.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so-yur1S9mS4"
   },
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1. Libraries and Helper Functions\n",
    "\n",
    "This notebook requires the TensorFlow dataset and other prerequisites that you must download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uQnMctL9mS5",
    "outputId": "7cf0dc4d-cbef-4612-ef2a-d0672cd4965f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 24.2 MB 67.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 34.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 30.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 53.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 86 kB 6.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 596 kB 58.8 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#@title Imports\n",
    "\n",
    "!pip install pydot --quiet\n",
    "!pip install gensim==3.8.3 --quiet\n",
    "!pip install tensorflow-datasets --quiet\n",
    "!pip install -U tensorflow-text==2.8.2 --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install pydot --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFFBvPMR9mS8"
   },
   "source": [
    "Now we are ready to do the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q8b9aykE9mS8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 23:03:22.463391: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#@title Imports\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.data import find\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "#This continues to work with gensim 3.8.3.  It doesn't yet work with 4.x.  \n",
    "#Make sure your pip install command specifies gensim==3.8.3\n",
    "import gensim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESElm33U9mS9"
   },
   "source": [
    "Below is a helper function to plot histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YKWj6pPM9mS-"
   },
   "outputs": [],
   "source": [
    "#@title Plotting Function\n",
    "\n",
    "# 4-window plot. Small modification from matplotlib examples.\n",
    "\n",
    "def make_plot(axs, history1, \n",
    "              history2, \n",
    "              y_lim_loss_lower=0.4, \n",
    "              y_lim_loss_upper=0.6,\n",
    "              y_lim_accuracy_lower=0.7, \n",
    "              y_lim_accuracy_upper=0.8,\n",
    "              model_1_name='model 1',\n",
    "              model_2_name='model 2',\n",
    "              \n",
    "             ):\n",
    "    box = dict(facecolor='yellow', pad=5, alpha=0.2)\n",
    "\n",
    "    ax1 = axs[0, 0]\n",
    "    ax1.plot(history1.history['loss'])\n",
    "    ax1.plot(history1.history['val_loss'])\n",
    "    ax1.set_title('loss - ' + model_1_name)\n",
    "    ax1.set_ylabel('loss', bbox=box)\n",
    "    ax1.set_ylim(y_lim_loss_lower, y_lim_loss_upper)\n",
    "\n",
    "    ax3 = axs[1, 0]\n",
    "    ax3.set_title('accuracy - ' + model_1_name)\n",
    "    ax3.plot(history1.history['accuracy'])\n",
    "    ax3.plot(history1.history['val_accuracy'])\n",
    "    ax3.set_ylabel('accuracy', bbox=box)\n",
    "    ax3.set_ylim(y_lim_accuracy_lower, y_lim_accuracy_upper)\n",
    "\n",
    "\n",
    "    ax2 = axs[0, 1]\n",
    "    ax2.set_title('loss - ' + model_2_name)\n",
    "    ax2.plot(history2.history['loss'])\n",
    "    ax2.plot(history2.history['val_loss'])\n",
    "    ax2.set_ylim(y_lim_loss_lower, y_lim_loss_upper)\n",
    "\n",
    "    ax4 = axs[1, 1]\n",
    "    ax4.set_title('accuracy - ' + model_2_name)\n",
    "\n",
    "    # small adjustment to account for the 2 accuracy measures in the Weighted Averging Model with Attention\n",
    "    if 'classification_accuracy' in history2.history.keys():\n",
    "        ax4.plot(history2.history['classification_accuracy'])\n",
    "    else:\n",
    "        ax4.plot(history2.history['accuracy'])\n",
    "    \n",
    "    if 'val_classification_accuracy' in history2.history.keys():\n",
    "        ax4.plot(history2.history['val_classification_accuracy'])\n",
    "    else:\n",
    "        ax4.plot(history2.history['val_accuracy'])\n",
    "    ax4.set_ylim(y_lim_accuracy_lower, y_lim_accuracy_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QDi-Kg49mS-"
   },
   "source": [
    "Next, we get the word2vec model from nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49X1T6an9mS_",
    "outputId": "b490a7dd-4bd2-4e95-96e5-a20d87246c64"
   },
   "outputs": [],
   "source": [
    "#@title NLTK & Word2Vec\n",
    "\n",
    "#nltk.download('word2vec_sample')\n",
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_rdVE3z9mTA"
   },
   "source": [
    "Now here we have the embedding **model** defined, let's see how many words are in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoL6l_q89mTA",
    "outputId": "7455b744-7252-4423-d1cb-71a294ed9ad8"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py:735\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvocab\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 735\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse KeyedVector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    739\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    740\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3Q0zOkJ9mTB"
   },
   "source": [
    "How do the word vectors look like? As expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyAGMYGK9mTB",
    "outputId": "8a81c71e-6e15-49e4-ca10-746f38d17fe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0306035 ,  0.0886877 , -0.0121269 ,  0.0761965 ,  0.0566269 ,\n",
       "       -0.0424702 ,  0.0410129 , -0.0497567 , -0.00364328,  0.0632889 ,\n",
       "       -0.0142608 , -0.0791111 ,  0.0174877 , -0.0383064 ,  0.00926433,\n",
       "        0.0295626 ,  0.0770293 ,  0.0949334 , -0.0428866 , -0.0295626 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['great'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BMraFZS9mTB"
   },
   "source": [
    "We can now build the embedding matrix and a vocabulary dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lOTIN3G39mTB"
   },
   "outputs": [],
   "source": [
    "#@title Embedding Matrix Creation\n",
    "\n",
    "EMBEDDING_DIM = len(model['university'])      # we know... it's 300\n",
    "\n",
    "# initialize embedding matrix and word-to-id map:\n",
    "embedding_matrix = np.zeros((len(model.vocab.keys()) + 1, EMBEDDING_DIM))       \n",
    "vocab_dict = {}\n",
    "\n",
    "# build the embedding matrix and the word-to-id map:\n",
    "for i, word in enumerate(model.vocab.keys()):\n",
    "    embedding_vector = model[word]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        vocab_dict[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGYcZu0N9mTC",
    "outputId": "fa2ab298-bf0b-4187-879e-f34268c5b3ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0891758 ,  0.121832  , -0.0671959 , ..., -0.0480419 ,\n",
       "        -0.0277889 ,  0.0872918 ],\n",
       "       [ 0.0526281 ,  0.013157  , -0.010104  , ...,  0.0209349 ,\n",
       "        -0.0537912 ,  0.0654217 ],\n",
       "       [ 0.0786419 ,  0.0373911 , -0.0131472 , ..., -0.00832253,\n",
       "        -0.00398034, -0.0825016 ],\n",
       "       ...,\n",
       "       [ 0.0887422 ,  0.0537124 ,  0.0467064 , ..., -0.0794009 ,\n",
       "         0.0945805 , -0.0361975 ],\n",
       "       [-0.011512  ,  0.0173624 , -0.0364862 , ..., -0.0425253 ,\n",
       "         0.0231499 , -0.014217  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIL1eUtV9mTC"
   },
   "source": [
    "The last row consists of all zeros. We will use that for the UNK token, the placeholder token for unknown words.\n",
    "\n",
    "### 1.2 Data Acquisition\n",
    "\n",
    "\n",
    "We will use the IMDB dataset delivered as part of the TensorFlow-datasets library, and split into training and test sets. For expedience, we will limit ourselves in terms of train and test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336,
     "referenced_widgets": [
      "1d86e234c89c4bce9f0ce10449c525f3",
      "234d8b28ec234d9e8fc29a3f892b52c4",
      "235372224872455484ea50119e39ccd4",
      "69f90ff024884cae821935bfc1e19dbe",
      "b1a4baa215a94fd4a06c33ebb0e6b2af",
      "d049e6c6c7e14fd1a8394fb5bcf6c9f7",
      "66b75f419dcc4ecc84f1e6a5961b59e8",
      "112aca87c7f94ae39b4f6fe48c0101e4",
      "78525e466f564fd8a7ee19027e8ea16c",
      "c9b7e19041a2460fa1124671511dfe04",
      "40a6b1d03cc645eaa0a1cbd28ce1ebcf",
      "0440b27acb404724bc95661c3cfbdd09",
      "72fcadb1def142b2878e146d898cba9d",
      "17abd9820ba74c6887fa9530e1dd8bc9",
      "7b192c8e3d66454bac86daee9cfdb12e",
      "2e4c20c5c8904b54b412606fae7fdd90",
      "57b0323081d24d729fa6e729b11970c8",
      "c490630518d24d23a90c557e07f9b495",
      "92400f6e453a45c298545591fee09f72",
      "3e4e60f7f4d94d0581a6751f21d44223",
      "5c054a6d31f042d7b373f09e502de39f",
      "ea6cdb2c229645f2aeb160ec392afccf",
      "f9f3e057246a4e9695003e9d760518e3",
      "9d0e8cdfc2c54745ac45f024326cb4ed",
      "a7770a1aebfb4f63bccc309035521062",
      "0dbc717464b24e74b6154e376d9e0e79",
      "db6da51343e24f0ea6b5ec75050f35e2",
      "16facf7463154189bf3785b3cb386d13",
      "fd2f01cb75bd4ad4b5486cf814495c9c",
      "4fb7a85bd2ed419db8bb3e20aa72a3b6",
      "fde32be8c8ef4a2083fb29b231a7a305",
      "68f8688090294e148e7e0dd17faa91bd",
      "3c2ae3ac6c9a4ba0bb16b8433fe58592",
      "27aba27f275e47f783a24a044fef9eb2",
      "7c2ff71374304fb4bc7338e6e04379b3",
      "d75f3f5f623947c3b94adf7c0b620749",
      "b651a0ba32d34fdaa9eb7190af079153",
      "deb17f25c270401abe5e19147c34e86b",
      "218d7afe88544f1588a9ce9c01806435",
      "b5334652607742d6b3026c2ea0e80cfd",
      "282815bf757e4fc38dd794dcb21bb9a3",
      "3bf35beee76b4c7fbc56f919bbffcf4d",
      "8791c57025344273b85b14d1f2d57505",
      "b33144df5c654b5e82d96a02020158c2",
      "ac85956278c54552950c599836a0fa4f",
      "ea318c6575c14653a993d1cf5bc9edad",
      "c3d31e5017b74c859de03307ef1782aa",
      "cf6e832c46a14701a58383390fd3ae09",
      "c44baf26c12f437b8130a71b4dfbb238",
      "47ab703b5a3841ddb28ca52f75beceac",
      "e55415461aa3422fabb4ff1c57cfa2a8",
      "4fc2b69233804167872ac964f7d2499d",
      "b69a54005e824389b9bc8f88f9a65fcc",
      "4214e272e9d448948abd4501eed8bc7c",
      "3f0efc22de7f4d79b57d807650e55d08",
      "ad9e90bda32c40fca68568bb07b03da3",
      "bc9d9dce1ee44c90b632ef2acbce3760",
      "38ebe4e97a234ec8a59324f52e8b53a4",
      "8e3719d7a0104e85842dc19211b6eb4e",
      "173e584116f7443cb0cc05db823e6c04",
      "7a2ce0de2bb84570a3f4962ec07cd38b",
      "7017efbbc7a7464ab11bdf5eea90fe7d",
      "8154388e04674d949f184df66691f9df",
      "6a0a0b1232cf411aa3a8ee2b041f7fa3",
      "5ebd682d19f74017a59e8a343d692948",
      "d227933dfb134366ab81966a88fae3e4",
      "d6e5899ccf7047b9a4fe9c0b11a16cb3",
      "dd5dda6404e54ca188942e1005b635cb",
      "18e31d0847534b75a72468ff1fb79ac4",
      "560dce48969347399e7ad85180854b61",
      "757abcaa9bb64247846ea60c1e9ab797",
      "dd7665db249a4d5783320f0e6bf9d82d",
      "b236a756ffc64912ab4c0be4d62b6197",
      "10d1daf04d9e4a52ad9f958bf1716bed",
      "e07ba778a6894206a38dd84e2c3cb4db",
      "947ebe6319ee44d69db1f296b2c00ba4",
      "bb19279c0d384456bc05e21e3b0b3eaf",
      "40d390466ce4400691b1fe3d793a2bda",
      "a684b963675b481a9674b70319de9abe",
      "de24a80ce5b849b192ea749fd25c21bf",
      "096909a5390645c3a9b31a882160841f",
      "94a63f1ca2e04f748ba33e41b328404e",
      "bb2fb4eefe324d97b5bceb889d4102e2",
      "91268b617a1c44b5b48d70b148c9968f",
      "84f2a802b467410396d9bcb290805962",
      "f3bc7527a816461fa765bc1bf72d4f97",
      "e31cea2d788a4cdeb3b5107d6ccd782d",
      "feb1dda844434382bb56ab62f6e50c31"
     ]
    },
    "id": "uwOF0qYb9mTC",
    "outputId": "ca98aa41-93b9-489d-f2b2-32c9dba50073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d86e234c89c4bce9f0ce10449c525f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0440b27acb404724bc95661c3cfbdd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f3e057246a4e9695003e9d760518e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteB83702/imdb_reviews-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27aba27f275e47f783a24a044fef9eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac85956278c54552950c599836a0fa4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteB83702/imdb_reviews-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9e90bda32c40fca68568bb07b03da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e5899ccf7047b9a4fe9c0b11a16cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteB83702/imdb_reviews-unsupervised.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d390466ce4400691b1fe3d793a2bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:80%]', 'test[80%:]'),\n",
    "    as_supervised=True)\n",
    "\n",
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(30000)))\n",
    "test_examples_batch, test_labels_batch = next(iter(test_data.batch(5000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPHFtgGkHNOQ"
   },
   "source": [
    "It is always highly recommended to look at the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvmWKdVQ9mTC",
    "outputId": "7d11a1aa-9c0a-4099-931b-7a9e101875c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
       "array([b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.',\n",
       "       b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_batch[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzEnCspD9mTD",
    "outputId": "295fbcca-63bb-46a8-c06f-f609b4eca997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_batch[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CplHsqSDMKCa"
   },
   "source": [
    "For convenience, in this assignment we will define a maximum length and only keep the examples that are longer than that length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Zxu9U3qXMKTW"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bHwj4vu9mTD"
   },
   "source": [
    "For simplicity, we will also limit ourselves to examples that actually have at least MAX_SEQUENCE_LENGTH tokens.\n",
    "\n",
    "\n",
    "## 1.3. Data Preparation\n",
    "\n",
    "### 1.3.1. Training/Test Sets for Word2Vec-based Models\n",
    "\n",
    "First, we tokenize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ToVTmC8V9mTD"
   },
   "outputs": [],
   "source": [
    "tokenizer = tf_text.WhitespaceTokenizer()\n",
    "train_tokens = tokenizer.tokenize(train_examples_batch)\n",
    "test_tokens = tokenizer.tokenize(test_examples_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXauPwil9mTD"
   },
   "source": [
    "Does this look right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZ22GGb-9mTD",
    "outputId": "26986891-a830-4d7a-add8-5219afed5ffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(116,), dtype=string, numpy=\n",
       "array([b'This', b'was', b'an', b'absolutely', b'terrible', b'movie.',\n",
       "       b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher', b'Walken',\n",
       "       b'or', b'Michael', b'Ironside.', b'Both', b'are', b'great',\n",
       "       b'actors,', b'but', b'this', b'must', b'simply', b'be', b'their',\n",
       "       b'worst', b'role', b'in', b'history.', b'Even', b'their', b'great',\n",
       "       b'acting', b'could', b'not', b'redeem', b'this', b\"movie's\",\n",
       "       b'ridiculous', b'storyline.', b'This', b'movie', b'is', b'an',\n",
       "       b'early', b'nineties', b'US', b'propaganda', b'piece.', b'The',\n",
       "       b'most', b'pathetic', b'scenes', b'were', b'those', b'when',\n",
       "       b'the', b'Columbian', b'rebels', b'were', b'making', b'their',\n",
       "       b'cases', b'for', b'revolutions.', b'Maria', b'Conchita',\n",
       "       b'Alonso', b'appeared', b'phony,', b'and', b'her', b'pseudo-love',\n",
       "       b'affair', b'with', b'Walken', b'was', b'nothing', b'but', b'a',\n",
       "       b'pathetic', b'emotional', b'plug', b'in', b'a', b'movie', b'that',\n",
       "       b'was', b'devoid', b'of', b'any', b'real', b'meaning.', b'I',\n",
       "       b'am', b'disappointed', b'that', b'there', b'are', b'movies',\n",
       "       b'like', b'this,', b'ruining', b\"actor's\", b'like', b'Christopher',\n",
       "       b\"Walken's\", b'good', b'name.', b'I', b'could', b'barely', b'sit',\n",
       "       b'through', b'it.'], dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9D9nqdg9mTE"
   },
   "source": [
    "Yup... looks right. Of course we will need to take care of the encoding later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiqFULXx9mTE"
   },
   "source": [
    "Next, we define a simple function that converts the tokens above into the appropriate word2vec index values.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "id": "5GpZh2Eh9mTE"
   },
   "outputs": [],
   "source": [
    "#@title Definition of sents_to_ids function\n",
    "\n",
    "def sents_to_ids(token_list_list, label_list, num_examples=100000000):\n",
    "    \"\"\"\n",
    "    converting a list of strings to a list of lists of word ids\n",
    "    \"\"\"\n",
    "    text_ids = []\n",
    "    text_labels = []\n",
    "    valid_example_list = []\n",
    "    example_count = 0\n",
    "    use_token_list_list = token_list_list[:num_examples]\n",
    "    for i, token_list in enumerate(use_token_list_list):\n",
    "        if i < num_examples:\n",
    "            try:\n",
    "                example = []\n",
    "                for token in list(token_list.numpy()):\n",
    "                    decoded = token.decode('utf-8').replace('.','').replace(',','').replace('!','')\n",
    "                    try:\n",
    "                        example.append(vocab_dict[decoded])\n",
    "                        \n",
    "                    except:\n",
    "                        example.append(43981)\n",
    "                if len(example) >= MAX_SEQUENCE_LENGTH:\n",
    "                    text_ids.append(example[:MAX_SEQUENCE_LENGTH])\n",
    "                    text_labels.append(label_list[i])\n",
    "                    if example_count % 5000 == 0:\n",
    "                        print('Examples processed: ', example_count)\n",
    "                    valid_example_list.append(i) \n",
    "                    example_count += 1\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    \n",
    "    print('Number of examples retained: ', example_count) \n",
    "    return (np.array(text_ids),   np.array(text_labels), valid_example_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv_elC2m9mTE"
   },
   "source": [
    "Now we can create training and test data that can be fed into the models of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3yIVIvo9mTF",
    "outputId": "8244d189-8f34-4f2e-ea8e-124349494a62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples processed:  0\n",
      "Examples processed:  5000\n",
      "Examples processed:  10000\n",
      "Examples processed:  15000\n",
      "Number of examples retained:  17418\n",
      "Examples processed:  0\n",
      "Number of examples retained:  4329\n"
     ]
    }
   ],
   "source": [
    "train_input_ids, train_input_labels, train_valid_example_list = sents_to_ids(train_tokens, train_labels_batch)\n",
    "test_input_ids, test_input_labels, test_valid_example_list = sents_to_ids(test_tokens, test_labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nnk0ldo45Zjr"
   },
   "source": [
    "The variable 'train_valid_example_list' contains the list of chosen examples that we can use later for the construction of the BERT training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alaUe82y5XeI",
    "outputId": "330b5512-c46b-4cd7-e4cd-b3d8db41e02e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 5, 6]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_example_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEIFFNbQN-Sa"
   },
   "source": [
    "Examples 3 and 4 were apparently shorten than our target length. \n",
    "\n",
    "We will also create a reduced training dataset with only 1000 examples to study the effect of the dataset size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NyztyBWpN-fJ"
   },
   "outputs": [],
   "source": [
    "REDUCED_TRAINING_SIZE = 1000\n",
    "\n",
    "train_input_ids_reduced = train_input_ids[:REDUCED_TRAINING_SIZE]\n",
    "train_input_labels_reduced = train_input_labels[:REDUCED_TRAINING_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dP2KY7U9mTF"
   },
   "source": [
    "Let's convince ourselves that the data looks correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FtU56wVR9mTF",
    "outputId": "ccfb99d0-7eee-49bd-f8b5-b8558914595f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21531, 25272, 12291,  7427, 37254, 34710,  6891, 12917, 38232,\n",
       "        16915, 12929, 16182, 43981, 20526, 23487, 38195, 23807, 42958,\n",
       "        35058, 34177, 19123, 35029, 41270, 29275, 12917, 32597, 20659,\n",
       "          638, 16915, 26144,   174, 32597, 35058, 39971,  2326,  3636,\n",
       "        22434, 35029, 43981, 33922, 29168, 21531, 34710, 16908, 12291,\n",
       "        36880, 28137,  5376, 28038, 38341, 15402, 29155, 18063, 24951,\n",
       "        17433, 17595,  8856, 14193, 43981, 43248, 17433,  6290, 32597,\n",
       "         9001, 11511,  9337, 21807, 39168, 43981, 16856, 28070, 43981,\n",
       "        23245, 43981,  8889,  1331, 43981, 25272, 31976, 19123, 43981,\n",
       "        18063, 36309, 24099, 16915, 43981, 34710, 36633, 25272, 20413,\n",
       "        43981, 33458, 14926, 34194, 12139, 12289, 39617, 36633,  9483,\n",
       "        42958],\n",
       "       [12139,  7841, 19666, 31757, 43981, 17853, 25745, 15445, 33741,\n",
       "        19123, 35029, 16908, 21113, 21068, 43981, 43981,  5668, 43981,\n",
       "        33456,  4942, 34554, 33013,  1200, 27498, 43981, 18802, 20514,\n",
       "        14193, 43981, 43981, 23955, 14042, 15400, 43981, 25973, 32334,\n",
       "        20514, 35029,  7870, 12139, 17108, 25745, 43830, 14193, 28743,\n",
       "        25272, 24081, 15402, 17006,   222, 25272,  7490, 43981, 33994,\n",
       "        43981, 21583, 42659, 12375, 43981, 25574, 19123,  1331, 19870,\n",
       "         7816, 43981, 31696, 25272, 23801, 13877, 20526, 39028, 12139,\n",
       "        27101, 12139, 37939,  7841, 24998, 29109, 43981, 14193, 28743,\n",
       "        19123, 16266,  8017, 14193, 43099, 43981, 16909, 43981, 30811,\n",
       "        14042, 12375, 43981, 25574, 43981, 34511, 21851, 14087,  9370,\n",
       "        33458]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_ids[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5svfigoOgaE"
   },
   "source": [
    "### 1.3.2. Training/Test Sets for BERT-based models\n",
    "\n",
    "We already imported the BERT model and the Tokenizer libraries. Now, we create the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "68e2245c1411414f8a8405435c6218c6",
      "7068847694ec446c995130890360c7eb",
      "5c118d3009544b1095319a4894dc2fe7",
      "c26db7edd2bb4883825aab90bec42f0e",
      "0482e29810cb49abafd5bf5120c2bbc9",
      "551e6693d6fd49198180c6e6820867e7",
      "7edad2c52c764ec98b65008a504dbc39",
      "f27f02acc974492788ffd95c5f6aff63",
      "c95bd32cef864ba786a7ffe315c4f3df",
      "6630c0ab222b461683c7a4163dd5d9ef",
      "33a18d0700924a34b8e554cb0be96b25",
      "66b1714165f345cd9522e122bdc4eb0d",
      "5eb453e3438b4d9ba884ea5590de772e",
      "767e3b3a023f405185dabe36e4453236",
      "baeb315d04f045c4b696a52350959748",
      "ed06df9ef7844988b41833214cc2aa19",
      "7a853514f59d4a6eb809b89f59f50658",
      "783d1065b90d4d558c5cf53f0a6b6fc8",
      "25871e2fffe84230aba0313f505315d7",
      "22cbd846c29442438768210f569890c0",
      "9b2d659ee8ce4d18953e24af1726c1c5",
      "5c16a9bd423346718bf0033ad6ba1eb9",
      "0e045ca357c0489b8a40287b23f0dabc",
      "bc128e39c0a24fa7b858a9062660c4c6",
      "08086d80f9ea45c3a7ba55027ee2b321",
      "7417f3fe61084c7ca345925950afa8cb",
      "e68a117da4bf4d75bbdfcd88265b2418",
      "212d50d7af324623b1c2dad598f33c4e",
      "ae5712f7d3294b54a8673c15bbba7435",
      "73d6236ab0b340b5b2a7f70eb77168d6",
      "66373a85c9314304aaf383a1de5d5ead",
      "10c7ffdcd8e94a4989da0282137a6109",
      "6f37801567e84334aa69c78723916567"
     ]
    },
    "id": "LEyBUFlT53zk",
    "outputId": "2702e0ac-2141-44bd-d509-cd5e4b9baa7f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e2245c1411414f8a8405435c6218c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b1714165f345cd9522e122bdc4eb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e045ca357c0489b8a40287b23f0dabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYyzQ0Wi9Mdw"
   },
   "source": [
    "Since the Tokenizer of BERT is not a whitespace tokenizer, each sentence will almost certainly result in more BERT tokens than whitespace tokens. Since we don't want to cheat by showing BERT more examples than other models we should restrict ourselves to the data that will also be seen by the other models:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "qM1qYCxz6z3a"
   },
   "outputs": [],
   "source": [
    "#@title Limit BERT data to the set used with word2vec \n",
    "all_train_examples = [x.decode('utf-8') for x in train_examples_batch.numpy()]\n",
    "all_test_examples = [x.decode('utf-8') for x in test_examples_batch.numpy()]\n",
    "\n",
    "bert_valid_train_examples_text = []\n",
    "bert_valid_train_examples_labels = []\n",
    "\n",
    "bert_valid_test_examples_text = []\n",
    "bert_valid_test_examples_labels = []\n",
    "\n",
    "for valid_example in train_valid_example_list:\n",
    "    bert_valid_train_examples_text.append(all_train_examples[valid_example])\n",
    "    bert_valid_train_examples_labels.append(train_labels_batch[valid_example])\n",
    "\n",
    "for valid_example in test_valid_example_list:\n",
    "    bert_valid_test_examples_text.append(all_test_examples[valid_example])\n",
    "    bert_valid_test_examples_labels.append(test_labels_batch[valid_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuBp01dtAZ4e"
   },
   "source": [
    "Next, we will create our training and test sets for BERT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cpSk9zvw532w"
   },
   "outputs": [],
   "source": [
    "#@title BERT Tokenization of training and test data\n",
    "\n",
    "num_train_examples = 2500000\n",
    "num_test_examples = 500000\n",
    "\n",
    "max_length = MAX_SEQUENCE_LENGTH\n",
    "\n",
    "\n",
    "x_train = bert_tokenizer(bert_valid_train_examples_text[:num_train_examples], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_train = bert_valid_train_examples_labels[:num_train_examples]\n",
    "\n",
    "x_test = bert_tokenizer(bert_valid_test_examples_text[:num_test_examples], \n",
    "              max_length=max_length,\n",
    "              truncation=True,\n",
    "              padding='max_length', \n",
    "              return_tensors='tf')\n",
    "y_test = bert_valid_test_examples_labels[:num_test_examples]\n",
    "\n",
    "\n",
    "def select_min_length_examples(x_data, y_data):\n",
    "    x_input_ids = []\n",
    "    y_labels = []\n",
    "\n",
    "    for ((input_ids, masks), label) in zip(zip(x_data['input_ids'], x_data['attention_mask']), y_data):\n",
    "        if masks[-1] == 1:\n",
    "            x_input_ids.append(input_ids)\n",
    "            y_labels.append(label)\n",
    "\n",
    "    return np.array(x_input_ids), np.array(y_labels) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-fm4hnNBijx"
   },
   "source": [
    "Next, we will simplify our lives for the purpose of the bulk of the assignment. We know that 1) all inputs  have at least MAX_SEQUENCE_LENGTH tokens, and 2) the input has one section not 2. Therefore, BERT will produce consistent results if we only use the 'input_ids'.\n",
    "\n",
    "Let us create the corresponding data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "x6DHGOdP53_v"
   },
   "outputs": [],
   "source": [
    "bert_train_input_ids, bert_train_labels = select_min_length_examples(x_train, y_train)\n",
    "bert_test_input_ids, bert_test_labels = select_min_length_examples(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jj-EjMh2CjFj"
   },
   "source": [
    "How many training examples do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xc6Vu06qCjR8",
    "outputId": "a2e47bf6-759f-4834-9b85-552f708ae564"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17418, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train_input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6x4ZOOcCDsl"
   },
   "source": [
    "Great. Looks like the same size training set that we used for the word2vec-based models.\n",
    "\n",
    "We also want to create again a reduced set of size REDUCED_TRAINING_SIZE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gRsH34yV54HB"
   },
   "outputs": [],
   "source": [
    "bert_train_input_ids_reduced = bert_train_input_ids[:REDUCED_TRAINING_SIZE]\n",
    "bert_train_labels_reduced = bert_train_labels[:REDUCED_TRAINING_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myNK4ZhQDQBL"
   },
   "source": [
    "Overall, here are the key variables and sets that we created, and that may be used moving forward. If the variable naming does not make it obvious, we also state the purpose:\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* MAX_SEQUENCE_LENGTH (100)\n",
    "* REDUCED_TRAINING_SIZE (1000)\n",
    "\n",
    "Word2vec-based models:\n",
    "\n",
    "*   train(/test)_input_ids: input ids for the training(/test) sets for word2vec models\n",
    "* train(/test)_input_labels: the corresponding labels\n",
    "*   train(/test)_input_ids_reduced: input ids for the reduced training(/test) sets for word2vec models\n",
    "* train(/test)_input_labels_reduced: the corresponding labels for the reduced set\n",
    "\n",
    "BERT:\n",
    "\n",
    "\n",
    "*   bert_train(/test)_input_ids: input ids for the training(/test) sets for BERT models\n",
    "* bert_train(/test)_labels: the corresponding labels for BERT\n",
    "*   bert_train(/test)_input_ids_reduced : input ids for the reduced training(/test) sets for BERT models\n",
    "* bert_train(/test)_labels: the corresponding labels for the reduced set for BERT\n",
    "\n",
    "**NOTE:** We recommend to inspect these variables if you have not gone through the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzbPHBf3GP2O"
   },
   "source": [
    "## 2. Classification with various Word2Vec-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7yp2gI-AtCl"
   },
   "source": [
    "**QUESTION:**\n",
    "\n",
    "2.a. Revisit the dataset. Is it balanced? Find the ratio of positive examples for the training sets.\n",
    "\n",
    "2.b. Find the ratio of positive examples for both the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6EAE6cjA9jM",
    "outputId": "967175a5-2452-4ddf-feea-8fa78971dc39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49351245837639224"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_input_labels)/len(train_input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2K_8eBTHArme",
    "outputId": "b84ebf2c-bfad-481d-c91f-b2a2bccb5432"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4968814968814969"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test_input_labels)/len(test_input_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JY6X0wL3BQKD"
   },
   "source": [
    "### 2.1 The Role of Shuffling of the Training Set\n",
    "\n",
    "\n",
    "We will first revisit the DAN model. \n",
    "\n",
    "2. Reuse the code from the class notebook to build a DAN network with one hidden layer of dimension 100. The optimizer should be Adam. Wrap the model creation in a function according to this API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vk-4mCgyBO9S"
   },
   "outputs": [],
   "source": [
    "def create_dan_model(retrain_embeddings=False, \n",
    "                     max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "                     hidden_dim=100,\n",
    "                     dropout=0.3,\n",
    "                     embedding_initializer='word2vec', \n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Construct the DAN model including the compilation and return it. Parametrize it using the arguments.\n",
    "    :param retrain_embeddings: boolean, indicating whether  the word embeddings are trainable\n",
    "    :param hidden_dim: dimension of the hidden layer\n",
    "    :param dropout: dropout applied to the hidden layer\n",
    "\n",
    "    :returns: the compiled model\n",
    "    \"\"\"\n",
    "\n",
    "    if embedding_initializer == 'word2vec':\n",
    "        embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix)\n",
    "    else:\n",
    "        embeddings_initializer='uniform'\n",
    "\n",
    "\n",
    "    dan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  embeddings_initializer=embeddings_initializer,\n",
    "                                  input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                  trainable=retrain_embeddings)\n",
    "\n",
    "    dan_input_layer = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
    "    dan_embeddings = dan_embedding_layer(dan_input_layer)\n",
    "    dan_avg_input_embeddings = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(dan_embeddings)\n",
    "    dan_hidden_out_1 = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_1')(dan_avg_input_embeddings)\n",
    "    dan_hidden_out_1 = tf.keras.layers.Dropout(dropout)(dan_hidden_out_1)\n",
    "    dan_classification = tf.keras.layers.Dense(1, activation='sigmoid', name='dan_classification')(dan_hidden_out_1)\n",
    "    dan_model = tf.keras.models.Model(inputs=dan_input_layer, outputs=[dan_classification])\n",
    "    dan_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics='accuracy')\n",
    "\n",
    "    # start by creating the dan_embedding_layer. Use the embeddings_initializer. variable defined above.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return dan_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb4LOJkFlYwF"
   },
   "source": [
    "Let us create a sorted dataset to run our simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZX2hWslCflw1"
   },
   "outputs": [],
   "source": [
    "sorted_train_input_data = [(x, y) for (x, y) in zip(list(train_input_ids), list(train_input_labels))]\n",
    "sorted_train_input_data.sort(key = lambda x: x[1])\n",
    "sorted_training_input_ids = np.array([x[0] for x in sorted_train_input_data])\n",
    "sorted_training_labels = np.array([x[1] for x in sorted_train_input_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riQ59wcQmtzs"
   },
   "source": [
    "Next, try to create your DAN model using the default parameters and train it by:\n",
    "\n",
    "1.  Using the sorted dataset\n",
    "2.  Using 'shuffle=False' as one of the model.fit parameters.\n",
    "\n",
    "Make sure you store the history (name it 'dan_sorted_history') as we did in the lesson notebooks. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIgwDUfpi7nu"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "dan_model_sorted = create_dan_model()\n",
    "dan_sorted_history = dan_model_sorted.fit(sorted_training_input_ids,\n",
    "                        sorted_training_labels,\n",
    "                        validation_data=(test_input_ids, test_input_labels),\n",
    "                        batch_size=32,\n",
    "                        epochs=20,\n",
    "                        shuffle=False)\n",
    "\n",
    "#use dan_sorted_history = ... below\n",
    "### END YOUR CODE                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4zFifGHMS1S"
   },
   "source": [
    "**QUESTION:**\n",
    "\n",
    "2.1.a Which number (in percent) is closest to the highest validation accuracy that you observed?\n",
    "\n",
    "  - 35\n",
    "  - 50\n",
    "  - 65\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUNYdZ8rnaNX"
   },
   "source": [
    "Next, recreate the same model and train with **'shuffle=True'**. (Note that this is also the default.). Use 'dan_suffled_history' for the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEsrjV2QkCo_"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "dan_model_shuffled = create_dan_model()  \n",
    "dan_shuffled_history = dan_model_shuffled.fit(sorted_training_input_ids,\n",
    "                        sorted_training_labels,\n",
    "                        validation_data=(test_input_ids, test_input_labels),\n",
    "                        batch_size=32,\n",
    "                        epochs=20,\n",
    "                        shuffle=True\n",
    "             )                                                    \n",
    "\n",
    "#use dan_suffled_history = ... below\n",
    "\n",
    "### END YOUR CODE                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXs6UX44ko7P"
   },
   "source": [
    "**QUESTION:**\n",
    "\n",
    "2.1.b Which number (in percent) is closest to the highest validation accuracy that you observed for the shuffled run?\n",
    "\n",
    "  - 65\n",
    "  - 75\n",
    "  - 80\n",
    "  - 85 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYCwHBzyoY0_"
   },
   "source": [
    "Compare the 2 histories in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAlGkoidkun-"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.subplots_adjust(left=0.2, wspace=0.6)\n",
    "make_plot(axs, \n",
    "          dan_sorted_history,\n",
    "          dan_shuffled_history, \n",
    "          model_1_name='sorted',\n",
    "         model_2_name='shuffled',\n",
    "         y_lim_accuracy_lower=0.40,\n",
    "         y_lim_accuracy_upper=0.82)\n",
    "\n",
    "fig.align_ylabels(axs[:, 1])\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRWLsg0WNdcE"
   },
   "source": [
    "### 2.2 DAN vs Weighted Averaging Models using Attention \n",
    "\n",
    "#### 2.2.1. Warm-Up: Manual Attention Calculation\n",
    "\n",
    "QUESTION: \n",
    "\n",
    "2.2.1.a Calculate the context vector for the following query and key/value vectors. You can do this manually, or you can use \n",
    "\n",
    "\n",
    "```\n",
    "tf.keras.layers.Attention()\n",
    "```\n",
    "\n",
    "2.2.1.b What are the weights for the key/value vectors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpLZyRImNdz5"
   },
   "outputs": [],
   "source": [
    "q = [1, 2., 1]\n",
    "\n",
    "k1 = v1 = [-1, -1, 3.]\n",
    "k2 = v2 = [1, 2, -5.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSbKYfjEOmlh"
   },
   "outputs": [],
   "source": [
    "weights = [np.dot(q,k1),np.dot(q,k2)]\n",
    "weights = np.exp(weights)/np.sum(np.exp(weights))\n",
    "print(weights)\n",
    "context = np.dot(weights[0],v1) + np.dot(weights[1],v2)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68YFNDesI0Cv"
   },
   "source": [
    "#### 2.2.2 The 'WAN' Model\n",
    "\n",
    "\n",
    "Next, we would like to improve our DAN by attempting to train a neural net that learns to put more weight on some words than others. How could we do that? **Attention** is the answer!\n",
    "\n",
    "Here, we will build a model that you can call \"Weighted Averaging Models using Attention\". You should construct a network that uses attention to weigh the input tokens for a given example.\n",
    "\n",
    "The core structure is the same as for the DAN network, but there are obviously some critical changes:\n",
    "\n",
    "1) How do I create a learnable query vector for the attention calculation, that is supposed to generate the suitable token probabilities? And what is its size?\n",
    "\n",
    "2) What are the key vectors for the attention calculation?\n",
    "\n",
    "3) How does the averaging change? \n",
    "\n",
    "\n",
    "First, the key vectors should be the incoming word vectors.\n",
    "\n",
    "The query vector needs to have the size of the word vectors, as it needs to attend to them. A good way to create the query vector is to generate an embedding for it that you then make trainable:\n",
    "\n",
    "\n",
    "```\n",
    "wan_query_embedding_layer = Embedding(1,  \n",
    "                                      embedding_matrix.shape[1], \n",
    "                                      input_length=1,  \n",
    "                                      trainable=True)\n",
    "```\n",
    "\n",
    "would create an embedding of the proper size for 1 vector.\n",
    "\n",
    "That sounds great... but how do I use this embedding to have a vector available in my calculation? And... make this vector available to all examples in the batch?\n",
    "\n",
    "What you can use is a 'fake input-like layer' that creates for each incoming batch example a '0', that then the query embedding layer can get applied to.\n",
    "Assuming that the input layer for your network is **wan_input_layer**, this could be done with\n",
    "\n",
    "```\n",
    "wan_zero_input = tf.cast((wan_input_layer[:, :1] < -1), 'int64') \n",
    "```\n",
    "\n",
    "You could then have the query vector available for each example through:\n",
    "\n",
    "```\n",
    "wan_query_vector = wan_query_embedding_layer(wan_zero_input)\n",
    "```\n",
    "\n",
    "You will see that this structure is essentially  the same as what we did for word vectors, except that we had to replace the input layer with our fake layer, as there is no actual input. We will also have **2 outputs** (discussed in a bit.)\n",
    "\n",
    "How does the averaging change? You should use:\n",
    "\n",
    "```\n",
    "tf.keras.layers.Attention()\n",
    "```\n",
    "\n",
    "and make sure you consider the proper inputs and outputs for that calculation.\n",
    "\n",
    "So why 2 outputs, and how do we do that? First off, we need the output that makes the classification, as always. What is the second output? We also would like our model to provide us with the attention weights it calculated. This will tell us which words were considered how much for the context creation.\n",
    "\n",
    "We can we implement 2 outputs? You need to have a list of the two outputs. But note that you may also want to have a a list of 2 cost function and 2 metrics. You can use 'None' both times to account for our new second output, and you can ignore the corresponding values that the model report. (In general, the total loss will be a sum of the individual losses. So one would rather construct a loss that always returns zero for the second loss, but as it is very small we can ignore this here.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_9F8zY4WG3Mg"
   },
   "outputs": [],
   "source": [
    "def create_wan_model(retrain_embeddings=False, \n",
    "                     max_sequence_length=100,\n",
    "                     hidden_dim=100,\n",
    "                     dropout=0.3,\n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Construct the DAN model including the compilation and return it. Parametrize it using the arguments.\n",
    "    :param retrain_embeddings: boolean, indicating whether  the word embeddings are trainable\n",
    "    :param hidden_dim: dimension of the hidden layer\n",
    "    :param dropout: dropout applied to the hidden layer\n",
    "\n",
    "    :returns: the compiled model\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    #Embedding Layer\n",
    "    wan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings)\n",
    "\n",
    "    #input layer\n",
    "    wan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64')\n",
    "\n",
    "    #Embed each token\n",
    "    wan_embeddings = wan_embedding_layer(wan_input_layer)\n",
    "\n",
    "    #Alternate Attention Calculation: words*query = unscaled weights -> softmax = weights\n",
    "    apply_query = tf.keras.layers.Dense(1,activation='linear',name='attention_calc1')(wan_embeddings)\n",
    "    #Use softmax to transform unscaled weights into weights indicating word importance\n",
    "    attention_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x)/K.sum(tf.keras.activations.exponential(x)))(apply_query)\n",
    "\n",
    "    #Weighted Avg according to Attention Calculation\n",
    "    reshape_embeddings = tf.keras.layers.Reshape((embedding_matrix.shape[1],max_sequence_length))(wan_embeddings)\n",
    "    weighted_avg_embeddings = tf.keras.layers.Dot(axes=(1,2),name='weighted_average')((attention_weights,reshape_embeddings))\n",
    "    weighted_avg_embeddings = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='eliminate_extra_dim')(weighted_avg_embeddings)\n",
    "\n",
    "    #pass into single layer feed forward network\n",
    "    wan_hidden_out_1 = tf.keras.layers.Dense(hidden_dim, activation='relu', name='hidden_1')(weighted_avg_embeddings)\n",
    "    wan_hidden_out_1 = tf.keras.layers.Dropout(dropout)(wan_hidden_out_1)\n",
    "    wan_classification = tf.keras.layers.Dense(1, activation='sigmoid', name='wan_classification')(wan_hidden_out_1)\n",
    "    wan_model = tf.keras.models.Model(inputs=wan_input_layer, outputs=[wan_classification,attention_weights])\n",
    "    wan_model.compile(loss=['binary_crossentropy',None],\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics=['accuracy',None])\n",
    "\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    print(wan_model.summary())\n",
    "    return wan_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5gnW7j8QHUo"
   },
   "source": [
    "Now run the model for the same dataset as we did for the DAN model and save it in its history 'wan_history':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "A3WYcv0CNMGC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m----> 3\u001b[0m wan_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_wan_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretrain_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0002\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_wan_classification_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m wan_shuffled_history \u001b[38;5;241m=\u001b[39m wan_model\u001b[38;5;241m.\u001b[39mfit(sorted_training_input_ids,\n\u001b[1;32m      7\u001b[0m                         sorted_training_labels,\n\u001b[1;32m      8\u001b[0m                         validation_data\u001b[38;5;241m=\u001b[39m(test_input_ids, test_input_labels),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m                         callbacks\u001b[38;5;241m=\u001b[39m[es]\n\u001b[1;32m     13\u001b[0m              )\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mcreate_wan_model\u001b[0;34m(retrain_embeddings, max_sequence_length, hidden_dim, dropout, learning_rate)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mConstruct the DAN model including the compilation and return it. Parametrize it using the arguments.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m:param retrain_embeddings: boolean, indicating whether  the word embeddings are trainable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m:returns: the compiled model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#Embedding Layer\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m wan_embedding_layer \u001b[38;5;241m=\u001b[39m Embedding(\u001b[43membedding_matrix\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     18\u001b[0m                               embedding_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     19\u001b[0m                               embeddings_initializer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39minitializers\u001b[38;5;241m.\u001b[39mConstant(embedding_matrix),\n\u001b[1;32m     20\u001b[0m                               input_length\u001b[38;5;241m=\u001b[39mmax_sequence_length,\n\u001b[1;32m     21\u001b[0m                               trainable\u001b[38;5;241m=\u001b[39mretrain_embeddings)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#input layer\u001b[39;00m\n\u001b[1;32m     24\u001b[0m wan_input_layer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(max_sequence_length,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "wan_model = create_wan_model(retrain_embeddings=True,learning_rate=0.0002)\n",
    "es = EarlyStopping(monitor='val_wan_classification_accuracy', mode='max', patience=2)\n",
    "\n",
    "wan_shuffled_history = wan_model.fit(sorted_training_input_ids,\n",
    "                        sorted_training_labels,\n",
    "                        validation_data=(test_input_ids, test_input_labels),\n",
    "                        batch_size=32,\n",
    "                        epochs=20,\n",
    "                        shuffle=True,\n",
    "                        callbacks=[es]\n",
    "             )  \n",
    "\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P0r4zH4k59o"
   },
   "source": [
    "**QUESTION:**\n",
    "\n",
    "2.2.2.a Which number (in percent) is closest to the highest validation accuracy that you observed for the wan training?\n",
    "\n",
    " * 78\n",
    "\n",
    " * 81 \n",
    "\n",
    " * 84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAgsZiy8Nx1U"
   },
   "source": [
    "Now compare the results of the initial dan_model training and the wan_model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-MMBGCWLwe1"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.subplots_adjust(left=0.2, wspace=0.6)\n",
    "make_plot(axs, \n",
    "          dan_shuffled_history,\n",
    "          wan_shuffled_history, \n",
    "          model_1_name='dan',\n",
    "         model_2_name='wan',\n",
    "         y_lim_accuracy_lower=0.70,\n",
    "         y_lim_accuracy_upper=0.82)\n",
    "\n",
    "fig.align_ylabels(axs[:, 1])\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILMLcnuZOWoT"
   },
   "source": [
    "Next, let us see for the wan_model which words did matter for the classification and which ones did less so. How can we tell? We can look at the attention weights!\n",
    "\n",
    "Consider the first training example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53pdy0pwU91Z"
   },
   "outputs": [],
   "source": [
    "train_examples_batch[0].numpy().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6CFujCuX37x"
   },
   "source": [
    "The corresponding input ids that are suitable formatted, i.e. with max length 100, are these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5U6X-fcVD88"
   },
   "outputs": [],
   "source": [
    "probe_input_ids = train_input_ids[0]\n",
    "probe_input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWNRYYmUYw-D"
   },
   "source": [
    "and the first 10 corresponding tokens are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1h1vScxYxMw"
   },
   "outputs": [],
   "source": [
    "probe_tokens = [x.decode('utf-8') for x in train_tokens[0].numpy()][:100]\n",
    "probe_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_9R85S7YOXF"
   },
   "source": [
    "Identify the 5 words with the highest impact and the 5 words with the lowest impact on the score, i.e., identify the 5 words with the largest and  smallest weights, respectively. (Not that multiple occurances of the same word count separately for the exercise).\n",
    "\n",
    "HINT: You should create a list of (word/weight) pairs, and then sort by the second argument. Python's '.sort()' function may come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UBhi3G0S0v8"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# 'pairs' should be the variable that holds the  token/weight pairs.\n",
    " \n",
    "a,b = wan_model.predict(probe_input_ids.reshape(1,100))\n",
    "pairs = list(sorted(zip(b.flatten(),probe_tokens)))\n",
    "\n",
    "print('most important tokens:')\n",
    "print('\\t', pairs[-5:])\n",
    "print('\\nleast important tokens:')\n",
    "print('\\t', pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UURhPvLWRBNd"
   },
   "source": [
    " **QUESTION:**\n",
    "\n",
    " 2.2.2.b List the 5 most important words, with the most important first. (Again, if a word appears twice, note it twice.)\n",
    "\n",
    " 2.2.2.c List the 5 least important words, with the most important of those first. (Again, if a word appears twice, note it twice.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IYOH-QfSj22"
   },
   "source": [
    "### 2.3 Approaches for Training of Embeddings\n",
    "\n",
    "Rerun the DAN Model in 3 configurations:\n",
    "\n",
    "\n",
    "1.   embedding_initializer = 'word2vec' and retrain_embeddings=False\n",
    "2.   embedding_initializer = 'word2vec' and retrain_embeddings=True\n",
    "3.   embedding_initializer = 'uniform' and retrain_embeddings=True\n",
    "\n",
    "\n",
    "**NOTE:** Train the models with static embeddings for 10 epochs and the ones with trainable embeddings for 3 epochs. \n",
    "\n",
    "What do you observe?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6Pxm-2xU1aw"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "dan_model_shuffled = create_dan_model(embedding_initializer='word2vec',retrain_embeddings=False)  \n",
    "dan_shuffled_history = dan_model_shuffled.fit(sorted_training_input_ids,\n",
    "                        sorted_training_labels,\n",
    "                        validation_data=(test_input_ids, test_input_labels),\n",
    "                        batch_size=32,\n",
    "                        epochs=10,\n",
    "                        shuffle=True\n",
    "             )      \n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0jwQ6ailUm4"
   },
   "source": [
    "**QUESTION:**\n",
    "\n",
    "2.3.a Which number (in percent) is closest to the highest validation accuracy that you observed for the static model?\n",
    "\n",
    " * 70\n",
    "\n",
    " * 73 \n",
    "\n",
    " * 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qwlDqMTxVwbQ"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "dan_model_shuffled = create_dan_model(embedding_initializer='word2vec',retrain_embeddings=True)  \n",
    "dan_shuffled_history = dan_model_shuffled.fit(sorted_training_input_ids,\n",
    "                        sorted_training_labels,\n",
    "                        validation_data=(test_input_ids, test_input_labels),\n",
    "                        batch_size=32,\n",
    "                        epochs=3,\n",
    "                        shuffle=True\n",
    "             ) \n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZXr9UY7lfHE"
   },
   "source": [
    "**QUESTION:**\n",
    "\n",
    "\n",
    "2.3.b Which number (in percent) is closest to the highest validation accuracy that you observed for the model where you initialized with word2vec vectors but allow them to retrain?\n",
    "\n",
    " * 77\n",
    "\n",
    " * 81 \n",
    "\n",
    " * 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0rMPTAOVw70"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "dan_model_shuffled = create_dan_model(embedding_initializer='uniform',retrain_embeddings=True)  \n",
    "dan_shuffled_history = dan_model_shuffled.fit(sorted_training_input_ids,\n",
    "                        sorted_training_labels,\n",
    "                        validation_data=(test_input_ids, test_input_labels),\n",
    "                        batch_size=32,\n",
    "                        epochs=3,\n",
    "                        shuffle=True\n",
    "             ) \n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hO791d-oYOgg"
   },
   "source": [
    "**QUESTION:**\n",
    "\n",
    "2.3.c Which number (in percent) is closest to the highest validation accuracy that you observed for the model where you initialized randomly and then trained?\n",
    "\n",
    " * 75\n",
    "\n",
    " * 78\n",
    "\n",
    " * 80 \n",
    "\n",
    " * 83\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BGRT1g6a0T6"
   },
   "source": [
    "\n",
    "##3. BERT-based Classification Models\n",
    "\n",
    "Now we turn to classification with BERT. We will perform classifications with various models that are based on pre-trained BERT models.\n",
    "\n",
    "\n",
    "### 3.1. Basics\n",
    "\n",
    "Let us first explore some basics of BERT. \n",
    "\n",
    "You first need to define the tokenizer and the model for the pre-trained configuration you need.\n",
    "\n",
    "We already got the tokenizer during setup with:\n",
    "\n",
    "```\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "```\n",
    "\n",
    "Now, we also need to get the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "44e85a78fb284f1fa1ab7d70c0349677",
      "284caca07c64413bb84fa28881bc4020",
      "8879fc1d70b54ea5bbe549c03ccd9ae1",
      "27fa3424fb7b499792f8d13a350b06c7",
      "064d053b71154523988fdebae0439ccb",
      "46da6a565955493689a071d5c7f574ad",
      "7f966d439fe044b4a5ca1fbfbb425021",
      "1e72c2ec96004c1396b254b24a0c4c6f",
      "619bc1a795b54682984d2bd10c66102f",
      "e9b54ff81f1043f3bee11db2ba1ba66a",
      "dc609f6174214bba8c63267cfe86b307"
     ]
    },
    "id": "tnCeDGfFgPlL",
    "outputId": "60a5e2dc-c5a5-47ae-d6e0-8a46ce506443"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e85a78fb284f1fa1ab7d70c0349677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pz_i57Qsa9Vl"
   },
   "source": [
    "(Ignore the warnings.)\n",
    "\n",
    "Next, consider this input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aM3UggLagPn4"
   },
   "outputs": [],
   "source": [
    "test_input = ['this bank is closed on Sunday', 'the steepest bank of the river is dangerous']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWaNDy5UbmGU"
   },
   "source": [
    "Now apply the tokenizer to tokenize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmoptRz0bq1o",
    "outputId": "0bbc2879-dfe1-4488-cd49-75bbd6d374b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 12), dtype=int32, numpy=\n",
       "array([[ 101, 1142, 3085, 1110, 1804, 1113, 3625,  102,    0,    0,    0,\n",
       "           0],\n",
       "       [ 101, 1103, 9458, 2556, 3085, 1104, 1103, 2186, 1110, 4249,  102,\n",
       "           0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(2, 12), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 12), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = bert_tokenizer(test_input, \n",
    "                                 max_length=12,\n",
    "                                 truncation=True,\n",
    "                                 padding='max_length', \n",
    "                                 return_tensors='tf')\n",
    "\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8WYd810dQwh"
   },
   "source": [
    " QUESTION: \n",
    " \n",
    " 3.1.a  Why do the attention_masks have 4 and 1 zeros, respectively?\n",
    "\n",
    "  * For the first example the last four tokens belong to a different segment. For the second one it is only the last token.\n",
    "\n",
    "  *  For the first example 5 positions are padded while for the second one it is only one.\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "Next, let us look at the BERT outputs for these 2 sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hpNQPvBehMc",
    "outputId": "71239190-3ce5-4e7d-b325-5eb9ce6c4479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(2, 12, 768), dtype=float32, numpy=\n",
      "array([[[ 0.3945215 ,  0.04198515,  0.06480412, ...,  0.05045468,\n",
      "          0.2235888 ,  0.24238206],\n",
      "        [-0.09458941,  0.06673873, -0.03607529, ...,  0.21925794,\n",
      "         -0.06967171,  0.7444843 ],\n",
      "        [ 0.00561046,  0.31316507, -0.17982745, ...,  0.19563255,\n",
      "         -0.10614748,  0.477736  ],\n",
      "        ...,\n",
      "        [ 0.22268727, -0.115586  ,  0.15854388, ...,  0.3002531 ,\n",
      "          0.01634064,  0.5133399 ],\n",
      "        [ 0.31638375, -0.10986965,  0.23661818, ...,  0.10924109,\n",
      "         -0.14340335,  0.32835382],\n",
      "        [ 0.34834027, -0.10076497,  0.26903206, ...,  0.127076  ,\n",
      "         -0.1843014 ,  0.26176214]],\n",
      "\n",
      "       [[ 0.44506386,  0.22265004, -0.09972464, ..., -0.23736243,\n",
      "          0.12722528,  0.07778173],\n",
      "        [ 0.07407638, -0.3180583 , -0.1192466 , ..., -0.0668015 ,\n",
      "         -0.3061705 ,  0.46923533],\n",
      "        [ 0.3145813 ,  0.62658817,  0.00606306, ..., -0.03697472,\n",
      "         -0.08461309,  0.7268304 ],\n",
      "        ...,\n",
      "        [ 0.69994617, -0.11628406,  0.01613361, ..., -0.47437245,\n",
      "          0.05725142,  0.21830113],\n",
      "        [ 0.5602969 ,  0.08535822, -0.91923475, ..., -0.3102014 ,\n",
      "         -0.09382506,  0.34911028],\n",
      "        [-0.26863506,  0.11328826,  0.07555693, ...,  0.37382194,\n",
      "          0.00740089,  0.16682105]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
      "array([[-0.6653193 ,  0.47329736,  0.9998541 , ...,  0.99994165,\n",
      "        -0.73006696,  0.97826153],\n",
      "       [-0.62586117,  0.44416317,  0.99979794, ...,  0.99991226,\n",
      "        -0.7422423 ,  0.9725732 ]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "bert_output = bert_model(tokenized_input)\n",
    "print(len(bert_output))\n",
    "print(bert_output)\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7lkLvadwDce"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVNsqd6QRepy"
   },
   "source": [
    " QUESTION: \n",
    " \n",
    " 3.1.b How many outputs are there?\n",
    "\n",
    " 3.1.c Which output do we need to use to get token-level embeddings?\n",
    "\n",
    " * the first\n",
    " \n",
    " * the second \n",
    "\n",
    " 3.1.d Which token number corresponds to 'bank' in the first sentence? ('bert_tokenizer.tokenize()' may come in handy.. and don't forget the CLS token! )\n",
    "\n",
    " 3.1.e Which token number corresponds to 'bank' in the second sentence?\n",
    "\n",
    " 3.1.f What is the cosine similarity between the BERT outputs for the two occurances of 'bank' in the two sentences?\n",
    "\n",
    " 3.1.g How does this relate to the cosine similarity of 'this' (sentence 1) and 'the' (sentence 2). Compute the cosine similarity.\n",
    "\n",
    " Enter your code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAfOnO9zov-y",
    "outputId": "f3e5bfaf-ef2d-4eb4-a6e5-b43f1ea5f25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'bank', 'is', 'closed', 'on', 'Sunday']\n",
      "tf.Tensor([ 101 1142 3085 1110 1804 1113 3625  102    0    0    0    0], shape=(12,), dtype=int32)\n",
      "['the', 'steep', '##est', 'bank', 'of', 'the', 'river', 'is', 'dangerous']\n",
      "tf.Tensor([ 101 1103 9458 2556 3085 1104 1103 2186 1110 4249  102    0], shape=(12,), dtype=int32)\n",
      "0.74783057\n",
      "0.81102693\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "#1. -> print it out\n",
    "\n",
    "\n",
    "#2. -> answer in answer file\n",
    "\n",
    "#3. -> Look at tokenization\n",
    "#['this bank is closed on Sunday', 'the steepest bank of the river is dangerous']\n",
    "print(bert_tokenizer.tokenize('this bank is closed on Sunday'))\n",
    "print(tokenized_input['input_ids'][0])\n",
    "#4. -> Look at tokenization\n",
    "print(bert_tokenizer.tokenize('the steepest bank of the river is dangerous'))\n",
    "print(tokenized_input['input_ids'][1])\n",
    "#5.  -> get the vectors and calclate cosine similarity\n",
    "\n",
    "bank_1 = bert_output[0][0][2].numpy()\n",
    "bank_2 = bert_output[0][1][4].numpy()\n",
    "cos_sim_1 = np.dot(bank_1,bank_2)/(np.linalg.norm(bank_1)*np.linalg.norm(bank_2))\n",
    "print(cos_sim_1)\n",
    "\n",
    "#6.  -> get the vectors and calculate cosine similarity\n",
    "this_1 = bert_output[0][0][1].numpy()\n",
    "the_1 = bert_output[0][1][1].numpy()\n",
    "cos_sim_2 = np.dot(this_1,the_1)/(np.linalg.norm(this_1)*np.linalg.norm(the_1))\n",
    "print(cos_sim_2)\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBOvsTBwm_Vi"
   },
   "source": [
    "### 3.2 CLS-Token-based Classification \n",
    "\n",
    "In the live session we discussed classification with BERT using the pooled token. We now will do the same but extract the [CLS] token output for each example and use that for classification purposes.\n",
    "\n",
    "Consult the model from the live session and change accordingly.\n",
    "\n",
    "**HINT:**\n",
    "You will want to extract the output of the [CLS] token from the BERT output similarly to what we did above to get the output for 'bank', etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "V1OAGPTNgPr6"
   },
   "outputs": [],
   "source": [
    "def create_cls_model(train_layers=-1,\n",
    "                          hidden_size = 100, \n",
    "                          dropout=0.3,\n",
    "                          learning_rate=0.00005):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Use the Pooled Ouutput for classification purposes\n",
    "    \"\"\"\n",
    "\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') \n",
    "\n",
    "    bert_out = bert_model(input_ids) \n",
    "\n",
    "    cls_token = bert_out[0][:,0]\n",
    "\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n",
    "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "    \n",
    "    classification_model = tf.keras.Model(inputs=[input_ids], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "                            metrics='accuracy') \n",
    "    \n",
    "    print(classification_model.summary())\n",
    "    \n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcK2PyPNoNc2"
   },
   "source": [
    "Now create the model and run for 2 epochs. Use batch size 8 and the appropriate validation/test set. (We don't make a distinction here.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIXDr8OdiSyv",
    "outputId": "37362166-e199-4784-dfae-cc04511186ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_ids_layer (InputLayer  [(None, 100)]            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf_bert_model_3 (TFBertMode  TFBaseModelOutputWithPoo  108310272\n",
      " l)                          lingAndCrossAttentions(l            \n",
      "                             ast_hidden_state=(None,             \n",
      "                             100, 768),                          \n",
      "                              pooler_output=(None, 76            \n",
      "                             8),                                 \n",
      "                              past_key_values=None, h            \n",
      "                             idden_states=None, atten            \n",
      "                             tions=None, cross_attent            \n",
      "                             ions=None)                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem_2   (None, 768)              0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 100)               76900     \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " classification_layer (Dense  (None, 1)                101       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,387,273\n",
      "Trainable params: 108,387,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2178/2178 [==============================] - 485s 216ms/step - loss: 0.4597 - accuracy: 0.7871 - val_loss: 0.3842 - val_accuracy: 0.8263\n",
      "Epoch 2/2\n",
      "2178/2178 [==============================] - 458s 210ms/step - loss: 0.3001 - accuracy: 0.8747 - val_loss: 0.4040 - val_accuracy: 0.8261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3aacb3b50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "cls_bert_model = create_cls_model(learning_rate=0.00005)\n",
    "                        \n",
    "cls_bert_model.fit(bert_train_input_ids, bert_train_labels, \n",
    "                   validation_data=(bert_test_input_ids,bert_test_labels),\n",
    "                   batch_size=8, epochs=2)  \n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLjgxylMnC0x"
   },
   "source": [
    " QUESTION: \n",
    " \n",
    " 3.2.a Which number (in percent) is closest to the highest validation accuracy that you observed for the [CLS]-classification model?\n",
    "\n",
    " * 78\n",
    "\n",
    " * 80\n",
    "\n",
    " * 82 \n",
    "\n",
    " * 84\n",
    "\n",
    " * 86\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cMVEBuxro4j"
   },
   "source": [
    "### 3.3 Classification by Averaging the BERT outputs\n",
    "\n",
    "Instead of using the [CLS] token, we will now average all of the output tokens that correspond to actual tokens. I.e., ignore the [CLS] and [SEP] tokens. Where are they? First and last for us.\n",
    "\n",
    "\n",
    "**HINT:**\n",
    "You will want to extract all of the relevant tokens and then apply an average across the tokens. You may want to use:\n",
    "\n",
    "\n",
    "```\n",
    "tf.math.reduce_mean()\n",
    "```\n",
    "but you can also do it in other ways.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "sB2WKwLTk4LY"
   },
   "outputs": [],
   "source": [
    "def create_avg_bert_model(train_layers=-1,\n",
    "                          hidden_size = 100, \n",
    "                          dropout=0.3,\n",
    "                          learning_rate=0.00005):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT. Use the Pooled Ouutput for classification purposes\n",
    "    \"\"\"\n",
    "\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') \n",
    "\n",
    "    bert_out = bert_model(input_ids) \n",
    "    word_embeddings = bert_out[0][:,1:-1]\n",
    "    avg_token = tf.math.reduce_mean(word_embeddings,axis=1)\n",
    "\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(avg_token)\n",
    "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "    \n",
    "    classification_model = tf.keras.Model(inputs=[input_ids], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "                            metrics='accuracy') \n",
    "    \n",
    "    print(classification_model.summary())\n",
    "    \n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcLrgI49tBde"
   },
   "source": [
    "Now create the model and run for 2 epochs. Use batch size 8 and the appropriate validation/test set. (We don't make a distinction here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtS29uRbk4Os",
    "outputId": "47a290fa-1b60-499b-9c57-bb01a8da039e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_ids_layer (InputLayer  [(None, 100)]            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf_bert_model_6 (TFBertMode  TFBaseModelOutputWithPoo  108310272\n",
      " l)                          lingAndCrossAttentions(l            \n",
      "                             ast_hidden_state=(None,             \n",
      "                             100, 768),                          \n",
      "                              pooler_output=(None, 76            \n",
      "                             8),                                 \n",
      "                              past_key_values=None, h            \n",
      "                             idden_states=None, atten            \n",
      "                             tions=None, cross_attent            \n",
      "                             ions=None)                          \n",
      "                                                                 \n",
      " tf.__operators__.getitem_5   (None, 98, 768)          0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " tf.math.reduce_mean (TFOpLa  (None, 768)              0         \n",
      " mbda)                                                           \n",
      "                                                                 \n",
      " hidden_layer (Dense)        (None, 100)               76900     \n",
      "                                                                 \n",
      " dropout_264 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " classification_layer (Dense  (None, 1)                101       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,387,273\n",
      "Trainable params: 108,387,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2178/2178 [==============================] - 476s 212ms/step - loss: 0.4416 - accuracy: 0.7937 - val_loss: 0.4467 - val_accuracy: 0.8025\n",
      "Epoch 2/2\n",
      "2178/2178 [==============================] - 457s 210ms/step - loss: 0.2898 - accuracy: 0.8789 - val_loss: 0.3893 - val_accuracy: 0.8316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd295443290>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "avg_bert_model = create_avg_bert_model()\n",
    "                        \n",
    "avg_bert_model.fit(bert_train_input_ids, bert_train_labels, \n",
    "                   validation_data=(bert_test_input_ids,bert_test_labels),\n",
    "                   batch_size=8, epochs=2)  \n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiWb3y9anNlG"
   },
   "source": [
    " QUESTION: \n",
    " \n",
    " 3.3.a Which number (in percent) is closest to the highest validation accuracy that you observed for the BERT-averaging-classification model?\n",
    "\n",
    " * 78\n",
    "\n",
    " * 80\n",
    "\n",
    " * 82 \n",
    "\n",
    " * 84\n",
    "\n",
    " * 86\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpVZXfOAt0UC"
   },
   "source": [
    "### 3.4 Adding a CNN on top of BERT\n",
    "\n",
    "Can we also combine advanced architectures? Why not! I the end we deal with tensors and it does not matter whether they are coming from static word embeddings or context-based embeddings coming from BERT. (Whether we want to is another question, but let's try it here.)\n",
    "\n",
    "\n",
    "**HINT:**\n",
    "You should appropriately stitch together the BERT-based components and the CNN components from the lesson notebook. Keep the same parameters, but set dropout to 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "6IJoPmcHk4UO"
   },
   "outputs": [],
   "source": [
    "def create_bert_cnn_model(hidden_size = 100, \n",
    "                                learning_rate=0.00005,\n",
    "                                num_filters = [100, 100, 50, 25],\n",
    "                                kernel_sizes = [3, 5, 10, 20],\n",
    "                                dense_layer_dims = [100],\n",
    "                                dropout = 0.3):\n",
    "    \"\"\"\n",
    "    Build a  classification model with BERT, where you apply CNN layers  to the BERT output\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
    "    #Get BERT Output For Each Example\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') \n",
    "    bert_out = bert_model(input_ids) \n",
    "    #Get Contextual Embeddings For each Example\n",
    "    word_embeddings = bert_out[0][:,1:-1]\n",
    "    \n",
    "    conv_layers_for_all_kernel_sizes = []\n",
    "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
    "      conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(word_embeddings)\n",
    "      conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "      conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
    "    \n",
    "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
    "    h = keras.layers.Dropout(rate=dropout)(h)\n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(h)\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "                            metrics='accuracy') \n",
    "    \n",
    "    print(classification_model.summary())\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KVHhxxIhkqS"
   },
   "source": [
    "Run this model for 2 epochs as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gobUGAVFk4XG",
    "outputId": "92f43d90-55ce-4b01-9492-b5cbf082a425"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids_layer (InputLayer)   [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_8 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids_layer[0][0]']        \n",
      "                                thPoolingAndCrossAt                                               \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 100,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, 98, 768)     0           ['tf_bert_model_8[0][0]']        \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 96, 100)      230500      ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 94, 100)      384100      ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 89, 50)       384050      ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 79, 25)       384025      ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " global_max_pooling1d_4 (Global  (None, 100)         0           ['conv1d_4[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_5 (Global  (None, 100)         0           ['conv1d_5[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_6 (Global  (None, 50)          0           ['conv1d_6[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_7 (Global  (None, 25)          0           ['conv1d_7[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 275)          0           ['global_max_pooling1d_4[0][0]', \n",
      "                                                                  'global_max_pooling1d_5[0][0]', \n",
      "                                                                  'global_max_pooling1d_6[0][0]', \n",
      "                                                                  'global_max_pooling1d_7[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_341 (Dropout)          (None, 275)          0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 100)          27600       ['dropout_341[0][0]']            \n",
      "                                                                                                  \n",
      " classification_layer (Dense)   (None, 1)            101         ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,720,648\n",
      "Trainable params: 109,720,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2178/2178 [==============================] - 492s 219ms/step - loss: 0.4630 - accuracy: 0.7804 - val_loss: 0.3802 - val_accuracy: 0.8300\n",
      "Epoch 2/2\n",
      "2178/2178 [==============================] - 474s 217ms/step - loss: 0.3088 - accuracy: 0.8723 - val_loss: 0.4594 - val_accuracy: 0.8069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd38773b410>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "bert_cnn = create_bert_cnn_model()\n",
    "                        \n",
    "bert_cnn.fit(bert_train_input_ids, bert_train_labels, \n",
    "                   validation_data=(bert_test_input_ids,bert_test_labels),\n",
    "                   batch_size=8, epochs=2)  \n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19zjdjc0nTn8"
   },
   "source": [
    " QUESTION: \n",
    " \n",
    "3.4.a Which number (in percent) is closest to the highest validation accuracy that you observed for the BERT-CNN-classification model?\n",
    "\n",
    "78\n",
    "\n",
    "80\n",
    "\n",
    "82\n",
    "\n",
    "84\n",
    "\n",
    "86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Y3e9X8bvhZf"
   },
   "source": [
    "# That's It! Congratulations... You are Done! We hope you learned a ton!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Text_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0440b27acb404724bc95661c3cfbdd09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72fcadb1def142b2878e146d898cba9d",
       "IPY_MODEL_17abd9820ba74c6887fa9530e1dd8bc9",
       "IPY_MODEL_7b192c8e3d66454bac86daee9cfdb12e"
      ],
      "layout": "IPY_MODEL_2e4c20c5c8904b54b412606fae7fdd90"
     }
    },
    "0482e29810cb49abafd5bf5120c2bbc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "064d053b71154523988fdebae0439ccb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08086d80f9ea45c3a7ba55027ee2b321": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73d6236ab0b340b5b2a7f70eb77168d6",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66373a85c9314304aaf383a1de5d5ead",
      "value": 570
     }
    },
    "096909a5390645c3a9b31a882160841f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e31cea2d788a4cdeb3b5107d6ccd782d",
      "placeholder": "​",
      "style": "IPY_MODEL_feb1dda844434382bb56ab62f6e50c31",
      "value": " 49999/50000 [00:00&lt;00:00, 140358.77 examples/s]"
     }
    },
    "0dbc717464b24e74b6154e376d9e0e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68f8688090294e148e7e0dd17faa91bd",
      "placeholder": "​",
      "style": "IPY_MODEL_3c2ae3ac6c9a4ba0bb16b8433fe58592",
      "value": " 24718/0 [00:09&lt;00:00, 3628.97 examples/s]"
     }
    },
    "0e045ca357c0489b8a40287b23f0dabc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc128e39c0a24fa7b858a9062660c4c6",
       "IPY_MODEL_08086d80f9ea45c3a7ba55027ee2b321",
       "IPY_MODEL_7417f3fe61084c7ca345925950afa8cb"
      ],
      "layout": "IPY_MODEL_e68a117da4bf4d75bbdfcd88265b2418"
     }
    },
    "10c7ffdcd8e94a4989da0282137a6109": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10d1daf04d9e4a52ad9f958bf1716bed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "112aca87c7f94ae39b4f6fe48c0101e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "16facf7463154189bf3785b3cb386d13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "173e584116f7443cb0cc05db823e6c04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17abd9820ba74c6887fa9530e1dd8bc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92400f6e453a45c298545591fee09f72",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e4e60f7f4d94d0581a6751f21d44223",
      "value": 1
     }
    },
    "18e31d0847534b75a72468ff1fb79ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10d1daf04d9e4a52ad9f958bf1716bed",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e07ba778a6894206a38dd84e2c3cb4db",
      "value": 1
     }
    },
    "1d86e234c89c4bce9f0ce10449c525f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_234d8b28ec234d9e8fc29a3f892b52c4",
       "IPY_MODEL_235372224872455484ea50119e39ccd4",
       "IPY_MODEL_69f90ff024884cae821935bfc1e19dbe"
      ],
      "layout": "IPY_MODEL_b1a4baa215a94fd4a06c33ebb0e6b2af"
     }
    },
    "1e72c2ec96004c1396b254b24a0c4c6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "212d50d7af324623b1c2dad598f33c4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "218d7afe88544f1588a9ce9c01806435": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22cbd846c29442438768210f569890c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "234d8b28ec234d9e8fc29a3f892b52c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d049e6c6c7e14fd1a8394fb5bcf6c9f7",
      "placeholder": "​",
      "style": "IPY_MODEL_66b75f419dcc4ecc84f1e6a5961b59e8",
      "value": "Dl Completed...: 100%"
     }
    },
    "235372224872455484ea50119e39ccd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_112aca87c7f94ae39b4f6fe48c0101e4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_78525e466f564fd8a7ee19027e8ea16c",
      "value": 1
     }
    },
    "25871e2fffe84230aba0313f505315d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27aba27f275e47f783a24a044fef9eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c2ff71374304fb4bc7338e6e04379b3",
       "IPY_MODEL_d75f3f5f623947c3b94adf7c0b620749",
       "IPY_MODEL_b651a0ba32d34fdaa9eb7190af079153"
      ],
      "layout": "IPY_MODEL_deb17f25c270401abe5e19147c34e86b"
     }
    },
    "27fa3424fb7b499792f8d13a350b06c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9b54ff81f1043f3bee11db2ba1ba66a",
      "placeholder": "​",
      "style": "IPY_MODEL_dc609f6174214bba8c63267cfe86b307",
      "value": " 502M/502M [00:10&lt;00:00, 52.4MB/s]"
     }
    },
    "282815bf757e4fc38dd794dcb21bb9a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "284caca07c64413bb84fa28881bc4020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46da6a565955493689a071d5c7f574ad",
      "placeholder": "​",
      "style": "IPY_MODEL_7f966d439fe044b4a5ca1fbfbb425021",
      "value": "Downloading: 100%"
     }
    },
    "2e4c20c5c8904b54b412606fae7fdd90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33a18d0700924a34b8e554cb0be96b25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38ebe4e97a234ec8a59324f52e8b53a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8154388e04674d949f184df66691f9df",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a0a0b1232cf411aa3a8ee2b041f7fa3",
      "value": 24999
     }
    },
    "3bf35beee76b4c7fbc56f919bbffcf4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3c2ae3ac6c9a4ba0bb16b8433fe58592": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e4e60f7f4d94d0581a6751f21d44223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f0efc22de7f4d79b57d807650e55d08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40a6b1d03cc645eaa0a1cbd28ce1ebcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40d390466ce4400691b1fe3d793a2bda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a684b963675b481a9674b70319de9abe",
       "IPY_MODEL_de24a80ce5b849b192ea749fd25c21bf",
       "IPY_MODEL_096909a5390645c3a9b31a882160841f"
      ],
      "layout": "IPY_MODEL_94a63f1ca2e04f748ba33e41b328404e"
     }
    },
    "4214e272e9d448948abd4501eed8bc7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44e85a78fb284f1fa1ab7d70c0349677": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_284caca07c64413bb84fa28881bc4020",
       "IPY_MODEL_8879fc1d70b54ea5bbe549c03ccd9ae1",
       "IPY_MODEL_27fa3424fb7b499792f8d13a350b06c7"
      ],
      "layout": "IPY_MODEL_064d053b71154523988fdebae0439ccb"
     }
    },
    "46da6a565955493689a071d5c7f574ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47ab703b5a3841ddb28ca52f75beceac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fb7a85bd2ed419db8bb3e20aa72a3b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "4fc2b69233804167872ac964f7d2499d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "551e6693d6fd49198180c6e6820867e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "560dce48969347399e7ad85180854b61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_947ebe6319ee44d69db1f296b2c00ba4",
      "placeholder": "​",
      "style": "IPY_MODEL_bb19279c0d384456bc05e21e3b0b3eaf",
      "value": " 49696/0 [00:19&lt;00:00, 3597.72 examples/s]"
     }
    },
    "57b0323081d24d729fa6e729b11970c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c054a6d31f042d7b373f09e502de39f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c118d3009544b1095319a4894dc2fe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f27f02acc974492788ffd95c5f6aff63",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c95bd32cef864ba786a7ffe315c4f3df",
      "value": 213450
     }
    },
    "5c16a9bd423346718bf0033ad6ba1eb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5eb453e3438b4d9ba884ea5590de772e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a853514f59d4a6eb809b89f59f50658",
      "placeholder": "​",
      "style": "IPY_MODEL_783d1065b90d4d558c5cf53f0a6b6fc8",
      "value": "Downloading: 100%"
     }
    },
    "5ebd682d19f74017a59e8a343d692948": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "619bc1a795b54682984d2bd10c66102f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6630c0ab222b461683c7a4163dd5d9ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66373a85c9314304aaf383a1de5d5ead": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "66b1714165f345cd9522e122bdc4eb0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5eb453e3438b4d9ba884ea5590de772e",
       "IPY_MODEL_767e3b3a023f405185dabe36e4453236",
       "IPY_MODEL_baeb315d04f045c4b696a52350959748"
      ],
      "layout": "IPY_MODEL_ed06df9ef7844988b41833214cc2aa19"
     }
    },
    "66b75f419dcc4ecc84f1e6a5961b59e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68e2245c1411414f8a8405435c6218c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7068847694ec446c995130890360c7eb",
       "IPY_MODEL_5c118d3009544b1095319a4894dc2fe7",
       "IPY_MODEL_c26db7edd2bb4883825aab90bec42f0e"
      ],
      "layout": "IPY_MODEL_0482e29810cb49abafd5bf5120c2bbc9"
     }
    },
    "68f8688090294e148e7e0dd17faa91bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69f90ff024884cae821935bfc1e19dbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9b7e19041a2460fa1124671511dfe04",
      "placeholder": "​",
      "style": "IPY_MODEL_40a6b1d03cc645eaa0a1cbd28ce1ebcf",
      "value": " 1/1 [00:04&lt;00:00,  4.43s/ url]"
     }
    },
    "6a0a0b1232cf411aa3a8ee2b041f7fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6f37801567e84334aa69c78723916567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7017efbbc7a7464ab11bdf5eea90fe7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7068847694ec446c995130890360c7eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_551e6693d6fd49198180c6e6820867e7",
      "placeholder": "​",
      "style": "IPY_MODEL_7edad2c52c764ec98b65008a504dbc39",
      "value": "Downloading: 100%"
     }
    },
    "72fcadb1def142b2878e146d898cba9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57b0323081d24d729fa6e729b11970c8",
      "placeholder": "​",
      "style": "IPY_MODEL_c490630518d24d23a90c557e07f9b495",
      "value": "Dl Size...: 100%"
     }
    },
    "73d6236ab0b340b5b2a7f70eb77168d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7417f3fe61084c7ca345925950afa8cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10c7ffdcd8e94a4989da0282137a6109",
      "placeholder": "​",
      "style": "IPY_MODEL_6f37801567e84334aa69c78723916567",
      "value": " 570/570 [00:00&lt;00:00, 5.27kB/s]"
     }
    },
    "757abcaa9bb64247846ea60c1e9ab797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "767e3b3a023f405185dabe36e4453236": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25871e2fffe84230aba0313f505315d7",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_22cbd846c29442438768210f569890c0",
      "value": 29
     }
    },
    "783d1065b90d4d558c5cf53f0a6b6fc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78525e466f564fd8a7ee19027e8ea16c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a2ce0de2bb84570a3f4962ec07cd38b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a853514f59d4a6eb809b89f59f50658": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b192c8e3d66454bac86daee9cfdb12e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c054a6d31f042d7b373f09e502de39f",
      "placeholder": "​",
      "style": "IPY_MODEL_ea6cdb2c229645f2aeb160ec392afccf",
      "value": " 80/80 [00:04&lt;00:00, 38.00 MiB/s]"
     }
    },
    "7c2ff71374304fb4bc7338e6e04379b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_218d7afe88544f1588a9ce9c01806435",
      "placeholder": "​",
      "style": "IPY_MODEL_b5334652607742d6b3026c2ea0e80cfd",
      "value": "100%"
     }
    },
    "7edad2c52c764ec98b65008a504dbc39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f966d439fe044b4a5ca1fbfbb425021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8154388e04674d949f184df66691f9df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84f2a802b467410396d9bcb290805962": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8791c57025344273b85b14d1f2d57505": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8879fc1d70b54ea5bbe549c03ccd9ae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e72c2ec96004c1396b254b24a0c4c6f",
      "max": 526681800,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_619bc1a795b54682984d2bd10c66102f",
      "value": 526681800
     }
    },
    "8e3719d7a0104e85842dc19211b6eb4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ebd682d19f74017a59e8a343d692948",
      "placeholder": "​",
      "style": "IPY_MODEL_d227933dfb134366ab81966a88fae3e4",
      "value": " 24999/25000 [00:00&lt;00:00, 97078.06 examples/s]"
     }
    },
    "91268b617a1c44b5b48d70b148c9968f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92400f6e453a45c298545591fee09f72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "947ebe6319ee44d69db1f296b2c00ba4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94a63f1ca2e04f748ba33e41b328404e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b2d659ee8ce4d18953e24af1726c1c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d0e8cdfc2c54745ac45f024326cb4ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16facf7463154189bf3785b3cb386d13",
      "placeholder": "​",
      "style": "IPY_MODEL_fd2f01cb75bd4ad4b5486cf814495c9c",
      "value": ""
     }
    },
    "a684b963675b481a9674b70319de9abe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb2fb4eefe324d97b5bceb889d4102e2",
      "placeholder": "​",
      "style": "IPY_MODEL_91268b617a1c44b5b48d70b148c9968f",
      "value": "100%"
     }
    },
    "a7770a1aebfb4f63bccc309035521062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fb7a85bd2ed419db8bb3e20aa72a3b6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fde32be8c8ef4a2083fb29b231a7a305",
      "value": 1
     }
    },
    "ac85956278c54552950c599836a0fa4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea318c6575c14653a993d1cf5bc9edad",
       "IPY_MODEL_c3d31e5017b74c859de03307ef1782aa",
       "IPY_MODEL_cf6e832c46a14701a58383390fd3ae09"
      ],
      "layout": "IPY_MODEL_c44baf26c12f437b8130a71b4dfbb238"
     }
    },
    "ad9e90bda32c40fca68568bb07b03da3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc9d9dce1ee44c90b632ef2acbce3760",
       "IPY_MODEL_38ebe4e97a234ec8a59324f52e8b53a4",
       "IPY_MODEL_8e3719d7a0104e85842dc19211b6eb4e"
      ],
      "layout": "IPY_MODEL_173e584116f7443cb0cc05db823e6c04"
     }
    },
    "ae5712f7d3294b54a8673c15bbba7435": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b1a4baa215a94fd4a06c33ebb0e6b2af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b236a756ffc64912ab4c0be4d62b6197": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b33144df5c654b5e82d96a02020158c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5334652607742d6b3026c2ea0e80cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b651a0ba32d34fdaa9eb7190af079153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8791c57025344273b85b14d1f2d57505",
      "placeholder": "​",
      "style": "IPY_MODEL_b33144df5c654b5e82d96a02020158c2",
      "value": " 24999/25000 [00:00&lt;00:00, 105357.79 examples/s]"
     }
    },
    "b69a54005e824389b9bc8f88f9a65fcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "baeb315d04f045c4b696a52350959748": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b2d659ee8ce4d18953e24af1726c1c5",
      "placeholder": "​",
      "style": "IPY_MODEL_5c16a9bd423346718bf0033ad6ba1eb9",
      "value": " 29.0/29.0 [00:00&lt;00:00, 242B/s]"
     }
    },
    "bb19279c0d384456bc05e21e3b0b3eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb2fb4eefe324d97b5bceb889d4102e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc128e39c0a24fa7b858a9062660c4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_212d50d7af324623b1c2dad598f33c4e",
      "placeholder": "​",
      "style": "IPY_MODEL_ae5712f7d3294b54a8673c15bbba7435",
      "value": "Downloading: 100%"
     }
    },
    "bc9d9dce1ee44c90b632ef2acbce3760": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a2ce0de2bb84570a3f4962ec07cd38b",
      "placeholder": "​",
      "style": "IPY_MODEL_7017efbbc7a7464ab11bdf5eea90fe7d",
      "value": "100%"
     }
    },
    "c26db7edd2bb4883825aab90bec42f0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6630c0ab222b461683c7a4163dd5d9ef",
      "placeholder": "​",
      "style": "IPY_MODEL_33a18d0700924a34b8e554cb0be96b25",
      "value": " 208k/208k [00:00&lt;00:00, 2.89MB/s]"
     }
    },
    "c3d31e5017b74c859de03307ef1782aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fc2b69233804167872ac964f7d2499d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b69a54005e824389b9bc8f88f9a65fcc",
      "value": 1
     }
    },
    "c44baf26c12f437b8130a71b4dfbb238": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c490630518d24d23a90c557e07f9b495": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c95bd32cef864ba786a7ffe315c4f3df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c9b7e19041a2460fa1124671511dfe04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf6e832c46a14701a58383390fd3ae09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4214e272e9d448948abd4501eed8bc7c",
      "placeholder": "​",
      "style": "IPY_MODEL_3f0efc22de7f4d79b57d807650e55d08",
      "value": " 24706/0 [00:07&lt;00:00, 2450.47 examples/s]"
     }
    },
    "d049e6c6c7e14fd1a8394fb5bcf6c9f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d227933dfb134366ab81966a88fae3e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6e5899ccf7047b9a4fe9c0b11a16cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd5dda6404e54ca188942e1005b635cb",
       "IPY_MODEL_18e31d0847534b75a72468ff1fb79ac4",
       "IPY_MODEL_560dce48969347399e7ad85180854b61"
      ],
      "layout": "IPY_MODEL_757abcaa9bb64247846ea60c1e9ab797"
     }
    },
    "d75f3f5f623947c3b94adf7c0b620749": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_282815bf757e4fc38dd794dcb21bb9a3",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3bf35beee76b4c7fbc56f919bbffcf4d",
      "value": 24999
     }
    },
    "db6da51343e24f0ea6b5ec75050f35e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc609f6174214bba8c63267cfe86b307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd5dda6404e54ca188942e1005b635cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd7665db249a4d5783320f0e6bf9d82d",
      "placeholder": "​",
      "style": "IPY_MODEL_b236a756ffc64912ab4c0be4d62b6197",
      "value": ""
     }
    },
    "dd7665db249a4d5783320f0e6bf9d82d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de24a80ce5b849b192ea749fd25c21bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84f2a802b467410396d9bcb290805962",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3bc7527a816461fa765bc1bf72d4f97",
      "value": 49999
     }
    },
    "deb17f25c270401abe5e19147c34e86b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e07ba778a6894206a38dd84e2c3cb4db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e31cea2d788a4cdeb3b5107d6ccd782d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e55415461aa3422fabb4ff1c57cfa2a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e68a117da4bf4d75bbdfcd88265b2418": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9b54ff81f1043f3bee11db2ba1ba66a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea318c6575c14653a993d1cf5bc9edad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47ab703b5a3841ddb28ca52f75beceac",
      "placeholder": "​",
      "style": "IPY_MODEL_e55415461aa3422fabb4ff1c57cfa2a8",
      "value": ""
     }
    },
    "ea6cdb2c229645f2aeb160ec392afccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed06df9ef7844988b41833214cc2aa19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f27f02acc974492788ffd95c5f6aff63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3bc7527a816461fa765bc1bf72d4f97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f9f3e057246a4e9695003e9d760518e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d0e8cdfc2c54745ac45f024326cb4ed",
       "IPY_MODEL_a7770a1aebfb4f63bccc309035521062",
       "IPY_MODEL_0dbc717464b24e74b6154e376d9e0e79"
      ],
      "layout": "IPY_MODEL_db6da51343e24f0ea6b5ec75050f35e2"
     }
    },
    "fd2f01cb75bd4ad4b5486cf814495c9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fde32be8c8ef4a2083fb29b231a7a305": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "feb1dda844434382bb56ab62f6e50c31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
