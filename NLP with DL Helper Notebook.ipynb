{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c884b687",
   "metadata": {},
   "source": [
    "# 1. Import Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6620b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 18:39:31.823600: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "import keras.backend as K\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import pickle\n",
    "import random\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3e8350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 2.9.1\n",
      "sklearn 0.24.2\n",
      "xgboost 1.6.1\n",
      "nltk 3.7\n",
      "pd 1.3.4\n",
      "np 1.20.3\n",
      "shap 0.41.0\n",
      "mpl 3.4.3\n",
      "scipy 1.7.1\n",
      "gensim 4.2.0\n"
     ]
    }
   ],
   "source": [
    "print('tf ' + tf.__version__)\n",
    "print('sklearn ' + sklearn.__version__)\n",
    "print('xgboost ' + xgboost.__version__)\n",
    "print('nltk ' + nltk.__version__)\n",
    "print('pd ' + pd.__version__)\n",
    "print('np ' + np.__version__)\n",
    "print('shap ' + shap.__version__)\n",
    "print('mpl ' + matplotlib.__version__)\n",
    "print('scipy ' + scipy.__version__)\n",
    "print('gensim ' + gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376cb027",
   "metadata": {},
   "source": [
    "# 2. Read in Dataset + Create Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdecafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts in Train Set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Spanish        2412\n",
       "Portuguese     2405\n",
       "English        2371\n",
       "Kinyarwanda    1332\n",
       "Italian        1156\n",
       "French          968\n",
       "German          700\n",
       "Other           509\n",
       "Finnish         114\n",
       "Swedish          97\n",
       "Romanian         74\n",
       "Name: language label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_dataset = pd.read_csv('Language_Detection/Train_Test_Data/train.csv')[['Lyric','language label']]\n",
    "test_dataset = pd.read_csv('Language_Detection/Train_Test_Data/test.csv')[['Lyric','language label']]\n",
    "print('Label Counts in Train Set')\n",
    "display(sample_dataset['language label'].value_counts())\n",
    "train_set = sample_dataset\n",
    "val_set = test_dataset.iloc[:1418]\n",
    "test_set = test_dataset.iloc[1418:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a66d3a",
   "metadata": {},
   "source": [
    "# 3. Resample (Oversample on Minority Classes) Training Set to Deal with Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9265cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Varf&amp;oumlr ska det vara så seri&amp;oumlst f&amp;oumlr...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intro:\\n(What a group of kids we sent out into...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Vem är Gud? (Vad är Gud?) \"\\n\"Det är en svår ...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vi sover på dagen,\\nvi saknar tidsuppfattning,...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honey, honey, underbara, aha, honey honey\\nHon...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26527</th>\n",
       "      <td>Trece timpul si inteleg ca trece\\nDragostea da...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26528</th>\n",
       "      <td>Astazi pe la 5 ma vad cu ea\\nNu stiu ce m-aste...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26529</th>\n",
       "      <td>can you give me ,can you give me\\n\\nAstazi pe ...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26530</th>\n",
       "      <td>I:\\nLasa-ma sa-ti spun :\\n'viata mea fara tine...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26531</th>\n",
       "      <td>Asculta si ia aminte !\\nAsculta ! Asculta ! As...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Lyric language label\n",
       "0      Varf&oumlr ska det vara så seri&oumlst f&oumlr...        Swedish\n",
       "1      Intro:\\n(What a group of kids we sent out into...        Swedish\n",
       "2      \"Vem är Gud? (Vad är Gud?) \"\\n\"Det är en svår ...        Swedish\n",
       "3      vi sover på dagen,\\nvi saknar tidsuppfattning,...        Swedish\n",
       "4      Honey, honey, underbara, aha, honey honey\\nHon...        Swedish\n",
       "...                                                  ...            ...\n",
       "26527  Trece timpul si inteleg ca trece\\nDragostea da...       Romanian\n",
       "26528  Astazi pe la 5 ma vad cu ea\\nNu stiu ce m-aste...       Romanian\n",
       "26529  can you give me ,can you give me\\n\\nAstazi pe ...       Romanian\n",
       "26530  I:\\nLasa-ma sa-ti spun :\\n'viata mea fara tine...       Romanian\n",
       "26531  Asculta si ia aminte !\\nAsculta ! Asculta ! As...       Romanian\n",
       "\n",
       "[26532 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(50)\n",
    "max_class_counts = train_set['language label'].value_counts().iloc[0]\n",
    "resampled_train_set = pd.DataFrame()\n",
    "for lang in train_set['language label'].unique():\n",
    "    subset = train_set[train_set['language label'] == lang].copy()\n",
    "    if len(subset) == max_class_counts:\n",
    "        resampled_train_set = pd.concat([resampled_train_set,subset],ignore_index=True)\n",
    "    else:\n",
    "        added_subset = subset.iloc[random.choices(np.arange(0,len(subset)),k=max_class_counts - len(subset))]\n",
    "        resampled_train_set = pd.concat([resampled_train_set,subset,added_subset],ignore_index=True)\n",
    "        \n",
    "display(resampled_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50a1c1b",
   "metadata": {},
   "source": [
    "# 4. Term Density Transformation of Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8471c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swedish        2412\n",
       "French         2412\n",
       "Kinyarwanda    2412\n",
       "Spanish        2412\n",
       "German         2412\n",
       "Portuguese     2412\n",
       "Italian        2412\n",
       "Finnish        2412\n",
       "English        2412\n",
       "Other          2412\n",
       "Romanian       2412\n",
       "Name: language label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_train_set['language label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d2e10a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('  ',' ')\n",
    "    return text\n",
    "\n",
    "vectorizer = CountVectorizer(preprocessor=preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c6ec1",
   "metadata": {},
   "source": [
    "#### Vectorize According to Terms in Non-Other Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253f8677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(preprocessor=<function preprocess_text at 0x7fb8888b60d0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(resampled_train_set[resampled_train_set['language label'] != 'Other']['Lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab6c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize Train Lyrics\n",
    "train_lyrics = vectorizer.transform(resampled_train_set['Lyric'])\n",
    "train_lyrics = pd.DataFrame(train_lyrics.todense(),columns = vectorizer.get_feature_names())\n",
    "train_lyrics_token_count = train_lyrics.sum(axis=1)\n",
    "train_lyrics = train_lyrics/np.array(train_lyrics_token_count.repeat(len(train_lyrics.columns))).reshape(train_lyrics.shape)\n",
    "\n",
    "#Vectorize Val Lyrics\n",
    "val_lyrics = vectorizer.transform(val_set['Lyric'])\n",
    "val_lyrics = pd.DataFrame(val_lyrics.todense(),columns = vectorizer.get_feature_names(),index=val_set.index)\n",
    "val_lyrics_token_count = val_lyrics.sum(axis=1)\n",
    "val_lyrics = val_lyrics/np.array(val_lyrics_token_count.repeat(len(val_lyrics.columns))).reshape(val_lyrics.shape)\n",
    "\n",
    "#Vectorize Test Lyrics\n",
    "test_lyrics = vectorizer.transform(test_set['Lyric'])\n",
    "test_lyrics = pd.DataFrame(test_lyrics.todense(),columns = vectorizer.get_feature_names(),index=test_set.index)\n",
    "test_lyrics_token_count = test_lyrics.sum(axis=1)\n",
    "test_lyrics = test_lyrics/np.array(test_lyrics_token_count.repeat(len(test_lyrics.columns))).reshape(test_lyrics.shape)\n",
    "\n",
    "train_labels = resampled_train_set['language label']\n",
    "val_labels = val_set['language label']\n",
    "test_labels = test_set['language label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd634a",
   "metadata": {},
   "source": [
    "#### Convert to float 32 and drop observations that failed to featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5905370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lyrics = train_lyrics.astype('float32')\n",
    "val_lyrics = val_lyrics.astype('float32')\n",
    "test_lyrics = test_lyrics.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f97154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lyrics.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a4c41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.loc[train_lyrics.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1a9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lyrics.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1803865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = val_labels.loc[val_lyrics.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "105e0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lyrics.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e4d2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_labels.loc[test_lyrics.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b153d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26484\n",
      "1415\n",
      "1616\n"
     ]
    }
   ],
   "source": [
    "print(len(train_lyrics))\n",
    "print(len(val_lyrics))\n",
    "print(len(test_lyrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16613fa",
   "metadata": {},
   "source": [
    "#### Mapping to map text labels to numeric labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e55bcd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "count = 0\n",
    "for label in train_labels.unique():\n",
    "    mapping[label] = count\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf04f9c",
   "metadata": {},
   "source": [
    "# 5. Quick Evaluation of Classical ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a907256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_model_id(xtrain,xval,xtest,ytrain,yval,ytest,estimator,param_grid,metric='accuracy'):\n",
    "    \n",
    "    #Concatenate training and validation data\n",
    "    train_val_feats = pd.concat([xtrain,xval],ignore_index=True)\n",
    "    train_val_labels = pd.concat([ytrain,yval],ignore_index=True)\n",
    "    #Instantiate Grid Search with model and param grid to ID which hyperparameter combo enables the model to generalize\n",
    "    #best on the validation set\n",
    "    grid = GridSearchCV(estimator = estimator, param_grid= param_grid,\n",
    "                        scoring=metric,cv=[(np.arange(0,len(xtrain)),np.arange(len(xtrain),len(train_val_feats)))])\n",
    "    \n",
    "    display(train_val_feats)\n",
    "    display(train_val_labels.map(mapping))\n",
    "    grid.fit(train_val_feats,train_val_labels.map(mapping))\n",
    "    \n",
    "    #Store Best Performing Model Output\n",
    "    best_estimator = grid.best_estimator_\n",
    "    best_val_score = grid.best_score_\n",
    "    \n",
    "    #Predictions on test set with optimal model\n",
    "    test_preds = best_estimator.predict(xtest)\n",
    "    #performance on test set\n",
    "    oos_score = accuracy_score(ytest.map(mapping),test_preds)\n",
    "    label_options = list(ytest.unique())\n",
    "    \n",
    "    #Confustion matrix of true for predicted values on the test set\n",
    "    confuse = pd.DataFrame(confusion_matrix(ytest.map(mapping),test_preds),index = label_options,columns = label_options)\n",
    "    \n",
    "    #return optimal model results\n",
    "    return {'best_estimator':best_estimator,\n",
    "           'best_val_score':best_val_score,\n",
    "           'best_test_score':oos_score,\n",
    "           'metric':metric,\n",
    "           'test_set_confusion_matrix':confuse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e1abd",
   "metadata": {},
   "source": [
    "#### KNN Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54f5df",
   "metadata": {},
   "source": [
    "test = optimal_model_id(train_lyrics,val_lyrics,test_lyrics,train_labels,val_labels,test_labels,\n",
    "                KNeighborsClassifier(),{'n_neighbors':[1,3,5,7,9]},'accuracy')\n",
    "display(test)\n",
    "display(test['test_set_confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dd09a",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf0bd3",
   "metadata": {},
   "source": [
    "test = optimal_model_id(train_lyrics,val_lyrics,test_lyrics,train_labels,val_labels,test_labels,\n",
    "                XGBClassifier(),{'max_depth':[2,3,4],'max_features':['auto'],'n_estimators':[10]},'accuracy')\n",
    "display(test)\n",
    "display(test['test_set_confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a6e43",
   "metadata": {},
   "source": [
    "# 6. Basic Feedforward NN w/ Keras Sequential API and Term Density Representation of Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38d94d",
   "metadata": {},
   "source": [
    "#### Input goes sequentially from one hidden layer to the next \"left to right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09acd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3311/3311 [==============================] - 116s 35ms/step - loss: 0.1023 - accuracy: 0.9702 - val_loss: 0.1623 - val_accuracy: 0.9795\n",
      "Epoch 2/2\n",
      "3311/3311 [==============================] - 115s 35ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.2776 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb8d9831a00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define Model Architecture Sequentially\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dense(11,activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the model, specifying loss function, optimizer, and performance metric\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
    "             metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "#Fit model and validate on val set between epochs, set multiprocessing\n",
    "model.fit(x = np.array(train_lyrics),y = train_labels.map(mapping),batch_size=8,epochs=2,\n",
    "         validation_data=(np.array(val_lyrics),val_labels.map(mapping)),\n",
    "         use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b12742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(np.array(test_lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fbd0556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814356435643564"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels.map(mapping),[x.argmax() for x in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cce6a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               12132000  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 11)                1111      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,143,211\n",
      "Trainable params: 12,143,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7684b",
   "metadata": {},
   "source": [
    "# 7. Word Embedding Based Models That Build Vector Representation of Input, Captures General Meaning Before Pass into Feed Forward NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce16e54",
   "metadata": {},
   "source": [
    "#### Build Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "393c4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)\n",
    "\n",
    "#construct embedding matrix w/ prebuilt embedding\n",
    "vocab_dict = model.key_to_index.copy()\n",
    "embedding_matrix = np.zeros((43982,300))\n",
    "for word,index in model.key_to_index.items():\n",
    "    embedding_matrix[index] = model[word]\n",
    "\n",
    "#Construct custom embedding matrix for this task\n",
    "vocab_dict_custom = {}\n",
    "count = 0\n",
    "for word in vectorizer.get_feature_names():\n",
    "    vocab_dict_custom[word] = count\n",
    "    count = count + 1\n",
    "embedding_matrix_custom = np.random.random((len(vectorizer.get_feature_names()) + 1,300))\n",
    "embedding_matrix_custom[-1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db348b6",
   "metadata": {},
   "source": [
    "#### Map tokens in train, val, test set to row in embedding matrices for both word2vec and custom embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebc0cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_index(text_data,mapping,max_size):\n",
    "    return_data = []\n",
    "    for text in text_data:\n",
    "        new_text = text.lower()\n",
    "        new_text = text.replace('\\n',' ')\n",
    "        new_text = text.replace('  ',' ')\n",
    "        new_text = new_text.split()\n",
    "        mapped_text = []\n",
    "        for token in new_text:\n",
    "            try:\n",
    "                mapped_text.append(mapping[token])\n",
    "            except:\n",
    "                mapped_text.append(len(mapping))\n",
    "        \n",
    "        if len(mapped_text) > max_size:\n",
    "            mapped_text = mapped_text[:max_size]\n",
    "        else:\n",
    "            while len(mapped_text) < max_size:\n",
    "                mapped_text.append(len(mapping))\n",
    "                \n",
    "        return_data.append(mapped_text)\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3745a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_prebuilt = text_to_index(resampled_train_set['Lyric'].loc[train_lyrics.index],vocab_dict,1000)\n",
    "train_tokens_custom = text_to_index(resampled_train_set['Lyric'].loc[train_lyrics.index],vocab_dict_custom,1000)\n",
    "\n",
    "val_tokens_prebuilt = text_to_index(val_set['Lyric'].loc[val_lyrics.index],vocab_dict,1000)\n",
    "val_tokens_custom = text_to_index(val_set['Lyric'].loc[val_lyrics.index],vocab_dict_custom,1000)\n",
    "\n",
    "test_tokens_prebuilt = text_to_index(test_set['Lyric'].loc[test_lyrics.index],vocab_dict,1000)\n",
    "test_tokens_custom = text_to_index(test_set['Lyric'].loc[test_lyrics.index],vocab_dict_custom,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71758bd0",
   "metadata": {},
   "source": [
    "### Deep Averaging Network (DAN) w/ Functional Keras API and Custom Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7a137fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dan_model(retrain_embeddings=False, \n",
    "                     max_sequence_length=1000,\n",
    "                     embedding_matrix=embedding_matrix_custom, \n",
    "                     hidden_dim=[100,100,100],\n",
    "                     dropout_rate=0.3,\n",
    "                     hidden_layer_activation = 'relu',\n",
    "                     output_layer_size = 4,\n",
    "                     output_activation = 'softmax',\n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Construct the DAN model including the compilation and return it. Parametrize it using the arguments.\n",
    "    retrain_embeddings: bool, indicates whether embeddings are retrainable\n",
    "    max_sequence_length: Number of token IDs to expect in a given input\n",
    "    embedding_matrix: initialize embedding layer with embedding matrix, specifying weights\n",
    "    hidden_dim = number of neurons in hidden layers\n",
    "    dropout = dropout rate\n",
    "    output_layer_size = # of neurons in output layer corresponding to # of classes, each neuron predicts P(class K | x)\n",
    "    output_activation = activation function for output layer\n",
    "    learning_rate = learning rate for gradient descent for finding model params to optimize loss\n",
    "    \"\"\"\n",
    "    \n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    dan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  weights = [embedding_matrix],\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings,\n",
    "                                   name = 'embedding_layer')\n",
    "    \n",
    "    \n",
    "    #Input Layer, sequence of max_sequence_length tokens\n",
    "    dan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
    "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
    "    dan_embeddings = dan_embedding_layer(dan_input_layer)\n",
    "    #Embeddings are averaged, forming single vector represenation of size embedding matrix\n",
    "    dan_avg_input_embeddings = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(dan_embeddings)\n",
    "    \n",
    "    #input into hidden layers\n",
    "    x = dan_avg_input_embeddings #hidden layer initial input\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "        \n",
    "    dan_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation, name='classification')(x)\n",
    "    dan_model = tf.keras.models.Model(inputs=dan_input_layer, outputs=[dan_classification])\n",
    "    dan_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics='accuracy')\n",
    "    \n",
    "    print(dan_model.summary())\n",
    "\n",
    "    return dan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a669f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding_layer (Embedding)  (None, 1000, 300)        36396000  \n",
      "                                                                 \n",
      " averaging (Lambda)          (None, 300)               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " hidden_3 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " classification (Dense)      (None, 11)                1111      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,447,411\n",
      "Trainable params: 36,447,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dan_model_sorted = create_dan_model(retrain_embeddings=True,embedding_matrix=embedding_matrix_custom,\n",
    "                                   output_layer_size=11)\n",
    "# dan_sorted_history = dan_model_sorted.fit(np.array(train_tokens_custom),\n",
    "#                         np.array(train_labels.map(mapping)),\n",
    "#                         validation_data=(np.array(val_tokens_custom), np.array(val_labels.map(mapping))),\n",
    "#                         batch_size=8,\n",
    "#                         epochs=2,\n",
    "#                         shuffle=True,\n",
    "#                         use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a526c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels.map(mapping),[x.argmax() for x in dan_model_sorted.predict(test_tokens_custom)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dan_model_sorted.weights[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8ff30",
   "metadata": {},
   "source": [
    "### Weighted Attention Network (WAN) with Custom Embeddings, allows for computation of multiple attention based representations of input before a final attention layer learns how to balance attention vectors from prior layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5029548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wan_model(retrain_embeddings=False, \n",
    "                     max_sequence_length=1000,\n",
    "                     embedding_matrix=embedding_matrix,\n",
    "                     num_attention = 1,\n",
    "                     hidden_dim=[100,100,100],\n",
    "                     dropout_rate=0.3,\n",
    "                     hidden_layer_activation = 'relu',\n",
    "                     output_layer_size = 4,\n",
    "                     output_activation = 'softmax',\n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Construct the WAN model including the compilation and return it. Parametrize it using the arguments.\n",
    "    retrain_embeddings: bool, indicates whether embeddings are retrainable\n",
    "    max_sequence_length: Number of token IDs to expect in a given input\n",
    "    embedding_matrix: initialize embedding layer with embedding matrix, specifying weights\n",
    "    num_attention = number of parallel attention computations that learn how to balance embeddings into a single\n",
    "    vector representation, final attention layer weights prior attention based representations\n",
    "    hidden_dim = number of neurons in hidden layers\n",
    "    dropout = dropout rate\n",
    "    output_layer_size = # of neurons in output layer corresponding to # of classes, each neuron predicts P(class K | x)\n",
    "    output_activation = activation function for output layer\n",
    "    learning_rate = learning rate for gradient descent for finding model params to optimize loss\n",
    "    \"\"\"\n",
    "    \n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    wan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  weights = [embedding_matrix],\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings,\n",
    "                                   name = 'embedding_layer')\n",
    "    \n",
    "    \n",
    "    #Input Layer, sequence of max_sequence_length tokens\n",
    "    wan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
    "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
    "    wan_embeddings = wan_embedding_layer(wan_input_layer)\n",
    "    \n",
    "    if num_attention > 0: #If attention is applied to embeddings to learn how to weight into single representation\n",
    "        if num_attention > 1:\n",
    "            #Create attention based single vector representations of words according to alternative query vectors\n",
    "            attention_embeddings = []\n",
    "            for num in range(num_attention):\n",
    "                #Apply Query Vector to words in embeddings, returning a max_sequence_length x 1 tensor\n",
    "                l1_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query' + str(num+1))(wan_embeddings)\n",
    "                #reshape to 1 x max_sequence_length\n",
    "                l1_reshape_query = tf.keras.layers.Reshape((1,max_sequence_length))(l1_query)\n",
    "                #Softmax over query * key (words) to obtain weights\n",
    "                l1_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                                    name='attention_weights' + str(num+1))(l1_reshape_query)\n",
    "                #weight embeddings according to weights\n",
    "                l1_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((wan_embeddings,l1_weights)))\n",
    "                attention_embeddings.append(l1_attention)\n",
    "\n",
    "            concat_attention = tf.keras.layers.Concatenate()(attention_embeddings)\n",
    "            concat_attention = tf.keras.layers.Reshape((num_attention,embedding_matrix.shape[1]))(concat_attention)\n",
    "        else:\n",
    "            concat_attention = wan_embeddings\n",
    "            num_attention = max_sequence_length\n",
    "    \n",
    "        #Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "        wan_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(concat_attention)\n",
    "        #reshape to 1 x num_attention\n",
    "        reshaped_query = tf.keras.layers.Reshape((1,num_attention))(wan_query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        wan_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights')(reshaped_query)\n",
    "        #weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "        #from prior layer\n",
    "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((concat_attention,wan_weights)))\n",
    "    else: #Default to DAN Treatment of Embeddings if num_attention = 0\n",
    "        embedding = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(wan_embeddings)\n",
    "    \n",
    "    #input into hidden layers\n",
    "    x = embedding #hidden layer initial input\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "        \n",
    "    wan_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation, name='classification')(x)\n",
    "    wan_model = tf.keras.models.Model(inputs=wan_input_layer, outputs=[wan_classification])\n",
    "    wan_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics=['accuracy'],\n",
    "                     run_eagerly=True)\n",
    "    \n",
    "    print(wan_model.summary())\n",
    "\n",
    "    return wan_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6eb57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 1000, 300)    36396000    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " attention_query2 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1000)      0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1000)      0           ['attention_query2[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 1000)      0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " attention_weights2 (Lambda)    (None, 1, 1000)      0           ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights2[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 300)          0           ['dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 300)          0           ['dot_2[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 600)          0           ['flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 2, 300)       0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 2, 1)         300         ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 2)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 2)         0           ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                    (None, 300, 1)       0           ['reshape_3[0][0]',              \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 300)          0           ['dot_3[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 11)           1111        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,448,311\n",
      "Trainable params: 52,311\n",
      "Non-trainable params: 36,396,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "wan_model_sorted = create_wan_model(retrain_embeddings=False,embedding_matrix=embedding_matrix_custom,\n",
    "                                   num_attention=2,output_layer_size=11)\n",
    "# wan_sorted_history = wan_model_sorted.fit(np.array(train_tokens_custom),\n",
    "#                         np.array(train_labels.map(mapping)),\n",
    "#                         validation_data=(np.array(val_tokens_custom), np.array(val_labels.map(mapping))),\n",
    "#                         batch_size=8,\n",
    "#                         epochs=2,\n",
    "#                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b870a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels.map(mapping),[x.argmax() for x in wan_model_sorted.predict(test_tokens_custom)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2786f9",
   "metadata": {},
   "source": [
    "# 8. BERT Based Models to Develop Contextual Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f5397",
   "metadata": {},
   "source": [
    "#### Pretrained Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3bbda8",
   "metadata": {},
   "source": [
    "#### Tokenize Text and Extract Input IDs For Each Token in Each Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert_ids = bert_tokenizer(list(train_set['Lyric']),\n",
    "                               max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
    "val_bert_ids = bert_tokenizer(list(val_set['Lyric']),\n",
    "                             max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
    "test_bert_ids = bert_tokenizer(list(test_set['Lyric']),\n",
    "                              max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a475331",
   "metadata": {},
   "source": [
    "#### BERT Model to Generate Contextual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05a2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b9c29",
   "metadata": {},
   "source": [
    "#### CLS Token Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8668e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model(train_bert_ids[:1])[0][:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34515c6",
   "metadata": {},
   "source": [
    "#### Pooled Token Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ccf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model(train_bert_ids[:1])[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_model(train_layers=-1,\n",
    "                      embedding_dim=768,\n",
    "                      token = 'cls', # 'cls' or 'pooled' or 'avg'\n",
    "                      num_attention = 0,\n",
    "                      hidden_dim=[100,100,100],\n",
    "                      dropout_rate=0.3,\n",
    "                      hidden_layer_activation = 'relu',\n",
    "                      output_layer_size = 4,\n",
    "                      output_activation = 'softmax',\n",
    "                      learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load BERT\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers (SPECIFY WHICH BERT LAYERS ARE TRAINABLE)\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "    \n",
    "    #Input Layer\n",
    "    input_ids = tf.keras.layers.Input(shape = (512,),dtype=tf.int64, name='input_ids_layer') \n",
    "    #Get Contextual Embeddings + Single Vector Representations of Input (CLS or Pooled)\n",
    "    bert_out = bert_model(input_ids) \n",
    "    \n",
    "    if token == 'cls':\n",
    "        token = bert_out[0][:,0] #Get CLS Tokens\n",
    "    elif token == 'pooled':\n",
    "        token = bert_out[1] #Pooled Token\n",
    "    elif token == 'avg':\n",
    "        token = tf.math.reduce_mean(bert_out[0][:,1:-1],axis=1)\n",
    "    elif token == 'word_embeddings':\n",
    "        token = bert_out[0][:,1:-1]\n",
    "    \n",
    "    # Attention to Combine CLS/Pooled Tokens into single representation in the event of chunking text for single example\n",
    "    if num_attention == 0: # Single CLS/Pooled Token\n",
    "        embedding = token\n",
    "    elif num_attention == 1:\n",
    "        #Apply Query Vector to BERT Token, returning a num_attention x 1 tensor\n",
    "        query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(token)\n",
    "        if token.shape == (None,768):\n",
    "            reshaped_query = tf.keras.layers.Reshape((1,1))(query)\n",
    "            token = tf.keras.layers.Reshape((1,token.shape[1]))(token)\n",
    "        else:\n",
    "            reshaped_query = tf.keras.layers.Reshape((1,token.shape[1]))(query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights')(reshaped_query)\n",
    "        #weight attention embeddings according to weights\n",
    "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((token,weights)))\n",
    "    else:\n",
    "        #Create attention based single vector representations of words according to alternative query vectors\n",
    "        attention_embeddings = []\n",
    "        for num in range(num_attention):\n",
    "            #Apply Query Vector to words in embeddings, returning a embedding_dim x 1 tensor\n",
    "            l1_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query_l' + str(num+1))(token)\n",
    "            if token.shape == (None,768):\n",
    "                l1_reshaped_query = tf.keras.layers.Reshape((1,1))(l1_query)\n",
    "                l1_token = tf.keras.layers.Reshape((1,token.shape[1]))(token)\n",
    "            else:\n",
    "                l1_reshaped_query = tf.keras.layers.Reshape((1,token.shape[1]))(l1_query)\n",
    "                l1_token = token\n",
    "                \n",
    "            #Softmax over query * key (words) to obtain weights\n",
    "            l1_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                                name='attention_weights_l' + str(num+1))(l1_reshaped_query)\n",
    "            \n",
    "            #weight attention embeddings according to weights\n",
    "            l1_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((l1_token,l1_weights)))\n",
    "            attention_embeddings.append(l1_attention)\n",
    "\n",
    "        concat_attention = tf.keras.layers.Concatenate()(attention_embeddings)\n",
    "        concat_attention = tf.keras.layers.Reshape((num_attention,embedding_dim))(concat_attention)\n",
    "        \n",
    "        #Apply Query Vector to BERT Embeddings with Various Attention-Based representations, returning a num_attention x 1 tensor\n",
    "        query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(concat_attention)\n",
    "        #reshape to 1 x num_attention\n",
    "        reshaped_query = tf.keras.layers.Reshape((1,num_attention))(query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights')(reshaped_query)\n",
    "        #weight attention embeddings according to weights\n",
    "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((concat_attention,weights)))\n",
    "        \n",
    "    x = embedding\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "\n",
    "    bert_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation,name='classification_layer')(x)\n",
    "    \n",
    "    bert_model = tf.keras.Model(inputs=[input_ids], outputs=[bert_classification])\n",
    "    \n",
    "    bert_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics=['accuracy'],\n",
    "                     run_eagerly=True) \n",
    "    \n",
    "    print(bert_model.summary())\n",
    "    \n",
    "    return bert_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee37fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_bert_model = create_bert_model(learning_rate=0.0005,output_layer_size=11,num_attention=5,token='word_embeddings')\n",
    "                        \n",
    "cls_bert_model.fit(train_bert_ids[:100], train_set['language label'].map(mapping).iloc[:100], \n",
    "                   validation_data=(val_bert_ids[:100],val_set['language label'].map(mapping).iloc[:100]),\n",
    "                   batch_size=8, epochs=2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4effc892",
   "metadata": {},
   "source": [
    "# 9. CNN Based Embeddings that Develop Feature Map Based Representations of Embeddings that Retain Word Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2cb822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(num_filters = [100, 100, 50, 25],\n",
    "                     kernel_sizes = [3, 5, 10, 20], \n",
    "                     retrain_embeddings=False, \n",
    "                     max_sequence_length=1000,\n",
    "                     embedding_matrix=embedding_matrix,\n",
    "                     hidden_dim=[100,100,100],\n",
    "                     dropout_rate=0.3,\n",
    "                     hidden_layer_activation = 'relu',\n",
    "                     output_layer_size = 4,\n",
    "                     output_activation = 'softmax',\n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build a  classification model that applies Conv layers to word embeddings to generate feature maps of word embeddings\n",
    "    in order to construct a order conscious, meaning based representation\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  weights = [embedding_matrix],\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings,\n",
    "                                   name = 'embedding_layer')\n",
    "    \n",
    "    #Input Layer\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='input_ids_layer') \n",
    "    \n",
    "    #Get Word Embeddings for Input\n",
    "    word_embeddings = embedding_layer(input_ids)\n",
    "    \n",
    "    conv_layers_for_all_kernel_sizes = []\n",
    "    for kernel_size, filters in zip(kernel_sizes, num_filters):\n",
    "        conv_layer = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu')(word_embeddings)\n",
    "        conv_layer = keras.layers.GlobalMaxPooling1D()(conv_layer)\n",
    "        conv_layers_for_all_kernel_sizes.append(conv_layer)\n",
    "    \n",
    "    h = keras.layers.concatenate(conv_layers_for_all_kernel_sizes, axis=1)\n",
    "    h = keras.layers.Dropout(rate=dropout)(h)\n",
    "    \n",
    "    x = h\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "        \n",
    "    classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation,name='classification_layer')(x)\n",
    "    classification_model = tf.keras.Model(inputs=[input_ids], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                            metrics='accuracy') \n",
    "    \n",
    "    print(classification_model.summary())\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35257410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 1000, 300)    36396000    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1000)      0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 1000)      0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 300)          0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 11)           1111        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,447,711\n",
      "Trainable params: 51,711\n",
      "Non-trainable params: 36,396,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "3311/3311 [==============================] - 114s 35ms/step - loss: 2.0535 - accuracy: 0.2488 - val_loss: 0.9959 - val_accuracy: 0.6799\n",
      "Epoch 2/2\n",
      "3311/3311 [==============================] - 103s 31ms/step - loss: 1.2400 - accuracy: 0.5893 - val_loss: 0.6724 - val_accuracy: 0.8177\n"
     ]
    }
   ],
   "source": [
    "cnn_model = create_wan_model(retrain_embeddings=False,embedding_matrix=embedding_matrix_custom,\n",
    "                             output_layer_size=11)\n",
    "\n",
    "cnn_model_history = cnn_model.fit(np.array(train_tokens_custom),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(val_tokens_custom), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=2,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f193d6",
   "metadata": {},
   "source": [
    "# 10. Chaining Model's Together - Applicable for Multi-Input / Multi-Output Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6de56ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------Model that accepts input and creates embedding matrix-------------------------------\n",
    "input_layer = tf.keras.layers.Input(shape=(1000,))\n",
    "#Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "embedding_layer = Embedding(embedding_matrix_custom.shape[0],\n",
    "                            embedding_matrix_custom.shape[1],\n",
    "                            weights = [embedding_matrix_custom],\n",
    "                            input_length=1000,\n",
    "                            trainable=True,\n",
    "                            name = 'embedding_layer')\n",
    "embeddings = embedding_layer(input_layer)\n",
    "embedding_model = tf.keras.Model(inputs = [input_layer],outputs=[embeddings])\n",
    "\n",
    "# -----------------------------------------------------DAN MODEL-----------------------------------------------------\n",
    "avg_embedding = tf.keras.layers.Lambda(lambda x:K.mean(x,axis=1))(embedding_model.output)\n",
    "avg_embedding = tf.keras.Model(inputs = [embedding_model.input], outputs = [avg_embedding])\n",
    "\n",
    "# -----------------------------------------------------WAN Model-----------------------------------------------------\n",
    "#Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(embedding_model.output)\n",
    "#reshape to 1 x num_attention\n",
    "reshaped_query = tf.keras.layers.Reshape((1,1000))(query)\n",
    "#Softmax over query * key (words) to obtain weights\n",
    "weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                    name='attention_weights')(reshaped_query)\n",
    "#weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "#from prior layer\n",
    "wan_embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((embedding_model.output,weights)))\n",
    "wan_embedding = tf.keras.Model(inputs=[embedding_model.input],outputs=[wan_embedding])\n",
    "\n",
    "# WAN Model that uses an attention layer with a single node to learn how to combine WAN/DAN embeddings into single representation\n",
    "dual_embedding = tf.keras.layers.concatenate([avg_embedding.output,wan_embedding.output])\n",
    "dual_embedding = tf.keras.layers.Reshape((2,embedding_matrix_custom.shape[1]))(dual_embedding)\n",
    "query = tf.keras.layers.Dense(1,activation='linear',use_bias=False)(dual_embedding)\n",
    "reshaped_query = tf.keras.layers.Reshape((1,2))(query)\n",
    "weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x))(reshaped_query)\n",
    "embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((dual_embedding,weights)))\n",
    "hidden = tf.keras.layers.Dense(100,activation='relu')(embedding)\n",
    "output = tf.keras.layers.Dense(11,activation='softmax')(hidden)\n",
    "final_model = tf.keras.Model(inputs=[embedding_model.input],outputs=[output])\n",
    "\n",
    "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                            loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                            metrics='accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52a09d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3311/3311 [==============================] - 817s 247ms/step - loss: 0.3181 - accuracy: 0.9071 - val_loss: 0.1337 - val_accuracy: 0.9689\n",
      "Epoch 2/2\n",
      "3311/3311 [==============================] - 872s 264ms/step - loss: 0.0568 - accuracy: 0.9844 - val_loss: 0.1450 - val_accuracy: 0.9654\n"
     ]
    }
   ],
   "source": [
    "final_model_history = final_model.fit(np.array(train_tokens_custom),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(val_tokens_custom), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=2,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae25863f",
   "metadata": {},
   "source": [
    "### Example Skeleton Code for Multiinput Model from https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "inputA = Input(shape=(32,))  \n",
    "inputB = Input(shape=(128,))\n",
    "#### the first branch operates on the first input\n",
    "x = Dense(8, activation=\"relu\")(inputA)  \n",
    "x = Dense(4, activation=\"relu\")(x)  \n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "#### the second branch opreates on the second input\n",
    "y = Dense(64, activation=\"relu\")(inputB)  \n",
    "y = Dense(32, activation=\"relu\")(y)  \n",
    "y = Dense(4, activation=\"relu\")(y)  \n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "#### combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "#### apply a FC layer and then a regression prediction on the combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)  \n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "#### our model will accept the inputs of the two branches and then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c134c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
