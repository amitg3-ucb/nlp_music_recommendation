{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c884b687",
   "metadata": {},
   "source": [
    "# 1. Import Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6620b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "import keras.backend as K\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.data import find\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import pickle\n",
    "import random\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d3e8350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 2.9.1\n",
      "sklearn 0.24.2\n",
      "xgboost 1.6.1\n",
      "nltk 3.7\n",
      "pd 1.3.4\n",
      "np 1.20.3\n",
      "shap 0.41.0\n",
      "mpl 3.4.3\n",
      "scipy 1.7.1\n",
      "gensim 4.2.0\n"
     ]
    }
   ],
   "source": [
    "print('tf ' + tf.__version__)\n",
    "print('sklearn ' + sklearn.__version__)\n",
    "print('xgboost ' + xgboost.__version__)\n",
    "print('nltk ' + nltk.__version__)\n",
    "print('pd ' + pd.__version__)\n",
    "print('np ' + np.__version__)\n",
    "print('shap ' + shap.__version__)\n",
    "print('mpl ' + matplotlib.__version__)\n",
    "print('scipy ' + scipy.__version__)\n",
    "print('gensim ' + gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376cb027",
   "metadata": {},
   "source": [
    "# 2. Read in Dataset + Create Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebdecafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts in Train Set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Spanish        2412\n",
       "Portuguese     2405\n",
       "English        2371\n",
       "Kinyarwanda    1332\n",
       "Italian        1156\n",
       "French          968\n",
       "German          700\n",
       "Other           509\n",
       "Finnish         114\n",
       "Swedish          97\n",
       "Romanian         74\n",
       "Name: language label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_dataset = pd.read_csv('Language_Detection/Train_Test_Data/train.csv')[['Lyric','language label']]\n",
    "test_dataset = pd.read_csv('Language_Detection/Train_Test_Data/test.csv')[['Lyric','language label']]\n",
    "print('Label Counts in Train Set')\n",
    "display(sample_dataset['language label'].value_counts())\n",
    "train_set = sample_dataset\n",
    "val_set = test_dataset.iloc[:1418]\n",
    "test_set = test_dataset.iloc[1418:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a66d3a",
   "metadata": {},
   "source": [
    "# 3. Resample (Oversample on Minority Classes) Training Set to Deal with Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9265cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyric</th>\n",
       "      <th>language label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Varf&amp;oumlr ska det vara så seri&amp;oumlst f&amp;oumlr...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intro:\\n(What a group of kids we sent out into...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Vem är Gud? (Vad är Gud?) \"\\n\"Det är en svår ...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vi sover på dagen,\\nvi saknar tidsuppfattning,...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honey, honey, underbara, aha, honey honey\\nHon...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26527</th>\n",
       "      <td>Trece timpul si inteleg ca trece\\nDragostea da...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26528</th>\n",
       "      <td>Astazi pe la 5 ma vad cu ea\\nNu stiu ce m-aste...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26529</th>\n",
       "      <td>can you give me ,can you give me\\n\\nAstazi pe ...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26530</th>\n",
       "      <td>I:\\nLasa-ma sa-ti spun :\\n'viata mea fara tine...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26531</th>\n",
       "      <td>Asculta si ia aminte !\\nAsculta ! Asculta ! As...</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Lyric language label\n",
       "0      Varf&oumlr ska det vara så seri&oumlst f&oumlr...        Swedish\n",
       "1      Intro:\\n(What a group of kids we sent out into...        Swedish\n",
       "2      \"Vem är Gud? (Vad är Gud?) \"\\n\"Det är en svår ...        Swedish\n",
       "3      vi sover på dagen,\\nvi saknar tidsuppfattning,...        Swedish\n",
       "4      Honey, honey, underbara, aha, honey honey\\nHon...        Swedish\n",
       "...                                                  ...            ...\n",
       "26527  Trece timpul si inteleg ca trece\\nDragostea da...       Romanian\n",
       "26528  Astazi pe la 5 ma vad cu ea\\nNu stiu ce m-aste...       Romanian\n",
       "26529  can you give me ,can you give me\\n\\nAstazi pe ...       Romanian\n",
       "26530  I:\\nLasa-ma sa-ti spun :\\n'viata mea fara tine...       Romanian\n",
       "26531  Asculta si ia aminte !\\nAsculta ! Asculta ! As...       Romanian\n",
       "\n",
       "[26532 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(50)\n",
    "max_class_counts = train_set['language label'].value_counts().iloc[0]\n",
    "resampled_train_set = pd.DataFrame()\n",
    "for lang in train_set['language label'].unique():\n",
    "    subset = train_set[train_set['language label'] == lang].copy()\n",
    "    if len(subset) == max_class_counts:\n",
    "        resampled_train_set = pd.concat([resampled_train_set,subset],ignore_index=True)\n",
    "    else:\n",
    "        added_subset = subset.iloc[random.choices(np.arange(0,len(subset)),k=max_class_counts - len(subset))]\n",
    "        resampled_train_set = pd.concat([resampled_train_set,subset,added_subset],ignore_index=True)\n",
    "        \n",
    "display(resampled_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50a1c1b",
   "metadata": {},
   "source": [
    "# 4. Term Density Transformation of Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe8471c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Swedish        2412\n",
       "French         2412\n",
       "Kinyarwanda    2412\n",
       "Spanish        2412\n",
       "German         2412\n",
       "Portuguese     2412\n",
       "Italian        2412\n",
       "Finnish        2412\n",
       "English        2412\n",
       "Other          2412\n",
       "Romanian       2412\n",
       "Name: language label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_train_set['language label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d2e10a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('  ',' ')\n",
    "    return text\n",
    "\n",
    "vectorizer = CountVectorizer(preprocessor=preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c6ec1",
   "metadata": {},
   "source": [
    "#### Vectorize According to Terms in Non-Other Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "253f8677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(preprocessor=<function preprocess_text at 0x7fc3bd46d5e0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(resampled_train_set[resampled_train_set['language label'] != 'Other']['Lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e954a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize Train Lyrics\n",
    "train_lyrics = vectorizer.transform(resampled_train_set['Lyric'])\n",
    "train_lyrics = pd.DataFrame(train_lyrics.todense(),columns = vectorizer.get_feature_names())\n",
    "train_lyrics_token_count = train_lyrics.sum(axis=1)\n",
    "train_lyrics = train_lyrics/np.array(train_lyrics_token_count.repeat(len(train_lyrics.columns))).reshape(train_lyrics.shape)\n",
    "\n",
    "#Vectorize Val Lyrics\n",
    "val_lyrics = vectorizer.transform(val_set['Lyric'])\n",
    "val_lyrics = pd.DataFrame(val_lyrics.todense(),columns = vectorizer.get_feature_names(),index=val_set.index)\n",
    "val_lyrics_token_count = val_lyrics.sum(axis=1)\n",
    "val_lyrics = val_lyrics/np.array(val_lyrics_token_count.repeat(len(val_lyrics.columns))).reshape(val_lyrics.shape)\n",
    "\n",
    "#Vectorize Test Lyrics\n",
    "test_lyrics = vectorizer.transform(test_set['Lyric'])\n",
    "test_lyrics = pd.DataFrame(test_lyrics.todense(),columns = vectorizer.get_feature_names(),index=test_set.index)\n",
    "test_lyrics_token_count = test_lyrics.sum(axis=1)\n",
    "test_lyrics = test_lyrics/np.array(test_lyrics_token_count.repeat(len(test_lyrics.columns))).reshape(test_lyrics.shape)\n",
    "\n",
    "train_labels = resampled_train_set['language label']\n",
    "val_labels = val_set['language label']\n",
    "test_labels = test_set['language label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd634a",
   "metadata": {},
   "source": [
    "#### Convert to float 32 and drop observations that failed to featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5905370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lyrics = train_lyrics.astype('float32')\n",
    "val_lyrics = val_lyrics.astype('float32')\n",
    "test_lyrics = test_lyrics.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f97154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lyrics.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a4c41b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_labels\u001b[49m\u001b[38;5;241m.\u001b[39mloc[train_lyrics\u001b[38;5;241m.\u001b[39mindex]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
     ]
    }
   ],
   "source": [
    "train_labels = train_labels.loc[train_lyrics.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1a9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lyrics.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1803865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = val_labels.loc[val_lyrics.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "105e0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lyrics.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e4d2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_labels.loc[test_lyrics.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b153d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26484\n",
      "1415\n",
      "1616\n"
     ]
    }
   ],
   "source": [
    "print(len(train_lyrics))\n",
    "print(len(val_lyrics))\n",
    "print(len(test_lyrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16613fa",
   "metadata": {},
   "source": [
    "#### Mapping to map text labels to numeric labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e55bcd7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_labels\u001b[49m\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m      4\u001b[0m     mapping[label] \u001b[38;5;241m=\u001b[39m count\n\u001b[1;32m      5\u001b[0m     count \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "count = 0\n",
    "for label in train_labels.unique():\n",
    "    mapping[label] = count\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf04f9c",
   "metadata": {},
   "source": [
    "# 5. Quick Evaluation of Classical ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a907256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_model_id(xtrain,xval,xtest,ytrain,yval,ytest,estimator,param_grid,metric='accuracy'):\n",
    "    \n",
    "    #Concatenate training and validation data\n",
    "    train_val_feats = pd.concat([xtrain,xval],ignore_index=True)\n",
    "    train_val_labels = pd.concat([ytrain,yval],ignore_index=True)\n",
    "    #Instantiate Grid Search with model and param grid to ID which hyperparameter combo enables the model to generalize\n",
    "    #best on the validation set\n",
    "    grid = GridSearchCV(estimator = estimator, param_grid= param_grid,\n",
    "                        scoring=metric,cv=[(np.arange(0,len(xtrain)),np.arange(len(xtrain),len(train_val_feats)))])\n",
    "    \n",
    "    display(train_val_feats)\n",
    "    display(train_val_labels.map(mapping))\n",
    "    grid.fit(train_val_feats,train_val_labels.map(mapping))\n",
    "    \n",
    "    #Store Best Performing Model Output\n",
    "    best_estimator = grid.best_estimator_\n",
    "    best_val_score = grid.best_score_\n",
    "    \n",
    "    #Predictions on test set with optimal model\n",
    "    test_preds = best_estimator.predict(xtest)\n",
    "    #performance on test set\n",
    "    oos_score = accuracy_score(ytest.map(mapping),test_preds)\n",
    "    label_options = list(ytest.unique())\n",
    "    \n",
    "    #Confustion matrix of true for predicted values on the test set\n",
    "    confuse = pd.DataFrame(confusion_matrix(ytest.map(mapping),test_preds),index = label_options,columns = label_options)\n",
    "    \n",
    "    #return optimal model results\n",
    "    return {'best_estimator':best_estimator,\n",
    "           'best_val_score':best_val_score,\n",
    "           'best_test_score':oos_score,\n",
    "           'metric':metric,\n",
    "           'test_set_confusion_matrix':confuse}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e1abd",
   "metadata": {},
   "source": [
    "#### KNN Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = optimal_model_id(train_lyrics,val_lyrics,test_lyrics,train_labels,val_labels,test_labels,\n",
    "                KNeighborsClassifier(),{'n_neighbors':[1,3,5,7,9]},'accuracy')\n",
    "display(test)\n",
    "display(test['test_set_confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30dd09a",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = optimal_model_id(train_lyrics,val_lyrics,test_lyrics,train_labels,val_labels,test_labels,\n",
    "                XGBClassifier(),{'max_depth':[2,3,4],'max_features':['auto'],'n_estimators':[10]},'accuracy')\n",
    "display(test)\n",
    "display(test['test_set_confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a6e43",
   "metadata": {},
   "source": [
    "# 6. Basic Feedforward NN w/ Keras Sequential API and Term Density Representation of Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38d94d",
   "metadata": {},
   "source": [
    "#### Input goes sequentially from one hidden layer to the next \"left to right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09acd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3311/3311 [==============================] - 141s 42ms/step - loss: 0.0998 - accuracy: 0.9716 - val_loss: 0.1404 - val_accuracy: 0.9781\n",
      "Epoch 2/2\n",
      "3311/3311 [==============================] - 131s 40ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.3540 - val_accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89890abcd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define Model Architecture Sequentially\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dense(100,activation='relu'),\n",
    "    keras.layers.Dense(11,activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the model, specifying loss function, optimizer, and performance metric\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "             optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
    "             metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "#Fit model and validate on val set between epochs, set multiprocessing\n",
    "model.fit(x = np.array(train_lyrics),y = train_labels.map(mapping),batch_size=8,epochs=2,\n",
    "         validation_data=(np.array(val_lyrics),val_labels.map(mapping)),\n",
    "         use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b12742c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(np.array(test_lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fbd0556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9789603960396039"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels.map(mapping),[x.argmax() for x in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cce6a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               12132000  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 11)                1111      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,143,211\n",
      "Trainable params: 12,143,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a7684b",
   "metadata": {},
   "source": [
    "# 7. Word Embedding Based Models That Build Vector Representation of Input, Captures General Meaning Before Pass into Feed Forward NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce16e54",
   "metadata": {},
   "source": [
    "#### Build Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "393c4a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)\n",
    "\n",
    "#construct embedding matrix w/ prebuilt embedding\n",
    "vocab_dict = model.key_to_index.copy()\n",
    "embedding_matrix = np.zeros((43982,300))\n",
    "for word,index in model.key_to_index.items():\n",
    "    embedding_matrix[index] = model[word]\n",
    "\n",
    "#Construct custom embedding matrix for this task\n",
    "vocab_dict_custom = {}\n",
    "count = 0\n",
    "for word in vectorizer.get_feature_names():\n",
    "    vocab_dict_custom[word] = count\n",
    "    count = count + 1\n",
    "embedding_matrix_custom = np.random.random((len(vectorizer.get_feature_names()) + 1,300))\n",
    "embedding_matrix_custom[-1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db348b6",
   "metadata": {},
   "source": [
    "#### Map tokens in train, val, test set to row in embedding matrices for both word2vec and custom embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_index(text_data,mapping,max_size):\n",
    "    return_data = []\n",
    "    for text in text_data:\n",
    "        new_text = text.lower()\n",
    "        new_text = text.replace('\\n',' ')\n",
    "        new_text = text.replace('  ',' ')\n",
    "        new_text = new_text.split()\n",
    "        mapped_text = []\n",
    "        for token in new_text:\n",
    "            try:\n",
    "                mapped_text.append(mapping[token])\n",
    "            except:\n",
    "                mapped_text.append(len(mapping))\n",
    "        \n",
    "        if len(mapped_text) > max_size:\n",
    "            mapped_text = mapped_text[:max_size]\n",
    "        else:\n",
    "            while len(mapped_text) < max_size:\n",
    "                mapped_text.append(len(mapping))\n",
    "                \n",
    "        return_data.append(mapped_text)\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3745a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens_prebuilt = text_to_index(resampled_train_set['Lyric'].loc[train_lyrics.index],vocab_dict,1000)\n",
    "train_tokens_custom = text_to_index(resampled_train_set['Lyric'].loc[train_lyrics.index],vocab_dict_custom,1000)\n",
    "\n",
    "val_tokens_prebuilt = text_to_index(val_set['Lyric'].loc[val_lyrics.index],vocab_dict,1000)\n",
    "val_tokens_custom = text_to_index(val_set['Lyric'].loc[val_lyrics.index],vocab_dict_custom,1000)\n",
    "\n",
    "test_tokens_prebuilt = text_to_index(test_set['Lyric'].loc[test_lyrics.index],vocab_dict,1000)\n",
    "test_tokens_custom = text_to_index(test_set['Lyric'].loc[test_lyrics.index],vocab_dict_custom,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71758bd0",
   "metadata": {},
   "source": [
    "### Deep Averaging Network (DAN) w/ Functional Keras API and Custom Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7a137fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dan_model(retrain_embeddings=False, \n",
    "                     max_sequence_length=1000,\n",
    "                     embedding_matrix=embedding_matrix_custom, \n",
    "                     hidden_dim=[100,100,100],\n",
    "                     dropout_rate=0.3,\n",
    "                     hidden_layer_activation = 'relu',\n",
    "                     output_layer_size = 4,\n",
    "                     output_activation = 'softmax',\n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Construct the DAN model including the compilation and return it. Parametrize it using the arguments.\n",
    "    retrain_embeddings: bool, indicates whether embeddings are retrainable\n",
    "    max_sequence_length: Number of token IDs to expect in a given input\n",
    "    embedding_matrix: initialize embedding layer with embedding matrix, specifying weights\n",
    "    hidden_dim = number of neurons in hidden layers\n",
    "    dropout = dropout rate\n",
    "    output_layer_size = # of neurons in output layer corresponding to # of classes, each neuron predicts P(class K | x)\n",
    "    output_activation = activation function for output layer\n",
    "    learning_rate = learning rate for gradient descent for finding model params to optimize loss\n",
    "    \"\"\"\n",
    "    \n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    dan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  weights = [embedding_matrix],\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings,\n",
    "                                   name = 'embedding_layer')\n",
    "    \n",
    "    \n",
    "    #Input Layer, sequence of max_sequence_length tokens\n",
    "    dan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
    "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
    "    dan_embeddings = dan_embedding_layer(dan_input_layer)\n",
    "    #Embeddings are averaged, forming single vector represenation of size embedding matrix\n",
    "    dan_avg_input_embeddings = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(dan_embeddings)\n",
    "    \n",
    "    #input into hidden layers\n",
    "    x = dan_avg_input_embeddings #hidden layer initial input\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "        \n",
    "    dan_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation, name='classification')(x)\n",
    "    dan_model = tf.keras.models.Model(inputs=dan_input_layer, outputs=[dan_classification])\n",
    "    dan_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics='accuracy')\n",
    "    \n",
    "    print(dan_model.summary())\n",
    "\n",
    "    return dan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb09e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dan_model_sorted = create_dan_model(retrain_embeddings=True,embedding_matrix=embedding_matrix_custom,\n",
    "                                   output_layer_size=11)\n",
    "dan_sorted_history = dan_model_sorted.fit(np.array(train_tokens_custom),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(val_tokens_custom), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=2,\n",
    "                        shuffle=True,\n",
    "                        use_multiprocessing=True,workers=multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a526c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels.map(mapping),[x.argmax() for x in dan_model_sorted.predict(test_tokens_custom)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dan_model_sorted.weights[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8ff30",
   "metadata": {},
   "source": [
    "### Weighted Attention Network (WAN) with Custom Embeddings, allows for computation of multiple attention based representations of input before a final attention layer learns how to balance attention vectors from prior layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d5029548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wan_model(retrain_embeddings=False, \n",
    "                     max_sequence_length=1000,\n",
    "                     embedding_matrix=embedding_matrix,\n",
    "                     num_attention = 1,\n",
    "                     hidden_dim=[100,100,100],\n",
    "                     dropout_rate=0.3,\n",
    "                     hidden_layer_activation = 'relu',\n",
    "                     output_layer_size = 4,\n",
    "                     output_activation = 'softmax',\n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Construct the WAN model including the compilation and return it. Parametrize it using the arguments.\n",
    "    retrain_embeddings: bool, indicates whether embeddings are retrainable\n",
    "    max_sequence_length: Number of token IDs to expect in a given input\n",
    "    embedding_matrix: initialize embedding layer with embedding matrix, specifying weights\n",
    "    num_attention = number of parallel attention computations that learn how to balance embeddings into a single\n",
    "    vector representation, final attention layer weights prior attention based representations\n",
    "    hidden_dim = number of neurons in hidden layers\n",
    "    dropout = dropout rate\n",
    "    output_layer_size = # of neurons in output layer corresponding to # of classes, each neuron predicts P(class K | x)\n",
    "    output_activation = activation function for output layer\n",
    "    learning_rate = learning rate for gradient descent for finding model params to optimize loss\n",
    "    \"\"\"\n",
    "    \n",
    "    #Specify Embedding Layer, including shape, intialize with weights, expected input length, and whether it is trainable\n",
    "    wan_embedding_layer = Embedding(embedding_matrix.shape[0],\n",
    "                                  embedding_matrix.shape[1],\n",
    "                                  weights = [embedding_matrix],\n",
    "                                  input_length=max_sequence_length,\n",
    "                                  trainable=retrain_embeddings,\n",
    "                                   name = 'embedding_layer')\n",
    "    \n",
    "    \n",
    "    #Input Layer, sequence of max_sequence_length tokens\n",
    "    wan_input_layer = tf.keras.layers.Input(shape=(max_sequence_length,), dtype='int64',name='input')\n",
    "    #Inputs go into embedding layer, form max_sequence_length x embedding dim matrix\n",
    "    wan_embeddings = wan_embedding_layer(wan_input_layer)\n",
    "    \n",
    "    if num_attention > 0: #If attention is applied to embeddings to learn how to weight into single representation\n",
    "        if num_attention > 1:\n",
    "            #Create attention based single vector representations of words according to alternative query vectors\n",
    "            attention_embeddings = []\n",
    "            for num in range(num_attention):\n",
    "                #Apply Query Vector to words in embeddings, returning a max_sequence_length x 1 tensor\n",
    "                l1_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query' + str(num+1))(wan_embeddings)\n",
    "                #reshape to 1 x max_sequence_length\n",
    "                l1_reshape_query = tf.keras.layers.Reshape((1,max_sequence_length))(l1_query)\n",
    "                #Softmax over query * key (words) to obtain weights\n",
    "                l1_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                                    name='attention_weights' + str(num+1))(l1_reshape_query)\n",
    "                #weight embeddings according to weights\n",
    "                l1_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((wan_embeddings,l1_weights)))\n",
    "                attention_embeddings.append(l1_attention)\n",
    "\n",
    "            concat_attention = tf.keras.layers.Concatenate()(attention_embeddings)\n",
    "            concat_attention = tf.keras.layers.Reshape((num_attention,embedding_matrix.shape[1]))(concat_attention)\n",
    "        else:\n",
    "            concat_attention = wan_embeddings\n",
    "            num_attention = max_sequence_length\n",
    "    \n",
    "        #Apply Query Vector to attention based representations, returning a num_attention x 1 tensor\n",
    "        wan_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(concat_attention)\n",
    "        #reshape to 1 x num_attention\n",
    "        reshaped_query = tf.keras.layers.Reshape((1,num_attention))(wan_query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        wan_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights')(reshaped_query)\n",
    "        #weight attention embeddings according to weights, learning how to balance attention based vector representations \n",
    "        #from prior layer\n",
    "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((concat_attention,wan_weights)))\n",
    "    else: #Default to DAN Treatment of Embeddings if num_attention = 0\n",
    "        embedding = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=1), name='averaging')(wan_embeddings)\n",
    "    \n",
    "    #input into hidden layers\n",
    "    x = embedding #hidden layer initial input\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "        \n",
    "    wan_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation, name='classification')(x)\n",
    "    wan_model = tf.keras.models.Model(inputs=wan_input_layer, outputs=[wan_classification])\n",
    "    wan_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics=['accuracy'],\n",
    "                     run_eagerly=True)\n",
    "    \n",
    "    print(wan_model.summary())\n",
    "\n",
    "    return wan_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c6eb57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_layer (Embedding)    (None, 1000, 300)    36396000    ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " attention_query1 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " attention_query2 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " attention_query3 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " attention_query4 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " attention_query5 (Dense)       (None, 1000, 1)      300         ['embedding_layer[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1000)      0           ['attention_query1[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 1000)      0           ['attention_query2[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1000)      0           ['attention_query3[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1000)      0           ['attention_query4[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 1000)      0           ['attention_query5[0][0]']       \n",
      "                                                                                                  \n",
      " attention_weights1 (Lambda)    (None, 1, 1000)      0           ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " attention_weights2 (Lambda)    (None, 1, 1000)      0           ['reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " attention_weights3 (Lambda)    (None, 1, 1000)      0           ['reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " attention_weights4 (Lambda)    (None, 1, 1000)      0           ['reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " attention_weights5 (Lambda)    (None, 1, 1000)      0           ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights1[0][0]']     \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights2[0][0]']     \n",
      "                                                                                                  \n",
      " dot_2 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights3[0][0]']     \n",
      "                                                                                                  \n",
      " dot_3 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights4[0][0]']     \n",
      "                                                                                                  \n",
      " dot_4 (Dot)                    (None, 300, 1)       0           ['embedding_layer[0][0]',        \n",
      "                                                                  'attention_weights5[0][0]']     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 300)          0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 300)          0           ['dot_1[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 300)          0           ['dot_2[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 300)          0           ['dot_3[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 300)          0           ['dot_4[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1500)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 5, 300)       0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " attention_query (Dense)        (None, 5, 1)         300         ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1, 5)         0           ['attention_query[0][0]']        \n",
      "                                                                                                  \n",
      " attention_weights (Lambda)     (None, 1, 5)         0           ['reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " dot_5 (Dot)                    (None, 300, 1)       0           ['reshape_7[0][0]',              \n",
      "                                                                  'attention_weights[0][0]']      \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 300)          0           ['dot_5[0][0]']                  \n",
      "                                                                                                  \n",
      " hidden_1 (Dense)               (None, 100)          30100       ['flatten_5[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_1 (Dropout)            (None, 100)          0           ['hidden_1[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_2 (Dense)               (None, 100)          10100       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 100)          0           ['hidden_2[0][0]']               \n",
      "                                                                                                  \n",
      " hidden_3 (Dense)               (None, 100)          10100       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['hidden_3[0][0]']               \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 11)           1111        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,449,211\n",
      "Trainable params: 53,211\n",
      "Non-trainable params: 36,396,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_tokens_custom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m wan_model_sorted \u001b[38;5;241m=\u001b[39m create_wan_model(retrain_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,embedding_matrix\u001b[38;5;241m=\u001b[39membedding_matrix_custom,\n\u001b[1;32m      2\u001b[0m                                    num_attention\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,output_layer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m wan_sorted_history \u001b[38;5;241m=\u001b[39m wan_model_sorted\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtrain_tokens_custom\u001b[49m),\n\u001b[1;32m      4\u001b[0m                         np\u001b[38;5;241m.\u001b[39marray(train_labels\u001b[38;5;241m.\u001b[39mmap(mapping)),\n\u001b[1;32m      5\u001b[0m                         validation_data\u001b[38;5;241m=\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(val_tokens_custom), np\u001b[38;5;241m.\u001b[39marray(val_labels\u001b[38;5;241m.\u001b[39mmap(mapping))),\n\u001b[1;32m      6\u001b[0m                         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m      7\u001b[0m                         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m                         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_tokens_custom' is not defined"
     ]
    }
   ],
   "source": [
    "wan_model_sorted = create_wan_model(retrain_embeddings=False,embedding_matrix=embedding_matrix_custom,\n",
    "                                   num_attention=5,output_layer_size=11)\n",
    "wan_sorted_history = wan_model_sorted.fit(np.array(train_tokens_custom),\n",
    "                        np.array(train_labels.map(mapping)),\n",
    "                        validation_data=(np.array(val_tokens_custom), np.array(val_labels.map(mapping))),\n",
    "                        batch_size=8,\n",
    "                        epochs=2,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b870a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_labels.map(mapping),[x.argmax() for x in wan_model_sorted.predict(test_tokens_custom)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2786f9",
   "metadata": {},
   "source": [
    "# 8. BERT Based Models to Develop Contextual Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f5397",
   "metadata": {},
   "source": [
    "#### Pretrained Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb3521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3bbda8",
   "metadata": {},
   "source": [
    "#### Tokenize Text and Extract Input IDs For Each Token in Each Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c880f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert_ids = bert_tokenizer(list(train_set['Lyric']),\n",
    "                               max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
    "val_bert_ids = bert_tokenizer(list(val_set['Lyric']),\n",
    "                             max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']\n",
    "test_bert_ids = bert_tokenizer(list(test_set['Lyric']),\n",
    "                              max_length=512,truncation=True,padding='max_length', return_tensors='tf')['input_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f0e1c4",
   "metadata": {},
   "source": [
    "#### BERT Model to Generate Contextual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05a2531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f4bfca",
   "metadata": {},
   "source": [
    "#### CLS Token Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "587f098b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model(train_bert_ids[:1])[0][:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e4143",
   "metadata": {},
   "source": [
    "#### Pooled Token Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "785ccf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model(train_bert_ids[:1])[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5976e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_model(train_layers=-1,\n",
    "                      embedding_dim=768,\n",
    "                      token = 'cls', # 'cls' or 'pooled' or 'avg'\n",
    "                      num_attention = 0,\n",
    "                      hidden_dim=[100,100,100],\n",
    "                      dropout_rate=0.3,\n",
    "                      hidden_layer_activation = 'relu',\n",
    "                      output_layer_size = 4,\n",
    "                      output_activation = 'softmax',\n",
    "                      learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build a simple classification model with BERT.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load BERT\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    #restrict training to the train_layers outer transformer layers (SPECIFY WHICH BERT LAYERS ARE TRAINABLE)\n",
    "    if not train_layers == -1:\n",
    "\n",
    "            retrain_layers = []\n",
    "\n",
    "            for retrain_layer_number in range(train_layers):\n",
    "\n",
    "                layer_code = '_' + str(11 - retrain_layer_number)\n",
    "                retrain_layers.append(layer_code)\n",
    "\n",
    "            for w in bert_model.weights:\n",
    "                if not any([x in w.name for x in retrain_layers]):\n",
    "                    w._trainable = False\n",
    "    \n",
    "    #Input Layer\n",
    "    input_ids = tf.keras.layers.Input(shape = (512,),dtype=tf.int64, name='input_ids_layer') \n",
    "    #Get Contextual Embeddings + Single Vector Representations of Input (CLS or Pooled)\n",
    "    bert_out = bert_model(input_ids) \n",
    "    \n",
    "    if token == 'cls':\n",
    "        token = bert_out[0][:,0] #Get CLS Tokens\n",
    "    elif token == 'pooled':\n",
    "        token = bert_out[1] #Pooled Token\n",
    "    elif token == 'avg':\n",
    "        token = tf.math.reduce_mean(bert_out[0][:,1:-1],axis-1)\n",
    "    \n",
    "    # Attention to Combine CLS/Pooled Tokens into single representation in the event of chunking text for single example\n",
    "    if num_attention == 0: # Single CLS/Pooled Token\n",
    "        embedding = token\n",
    "    elif num_attention == 1:\n",
    "        #Apply Query Vector to BERT Token, returning a num_attention x 1 tensor\n",
    "        query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(token)\n",
    "        #reshape to 1 x num_attention\n",
    "        reshaped_query = tf.keras.layers.Reshape((1,token.shape[0]))(query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights')(reshaped_query)\n",
    "        #weight attention embeddings according to weights\n",
    "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((token,weights)))\n",
    "    else:\n",
    "        #Create attention based single vector representations of words according to alternative query vectors\n",
    "        attention_embeddings = []\n",
    "        for num in range(num_attention):\n",
    "            #Apply Query Vector to words in embeddings, returning a embedding_dim x 1 tensor\n",
    "            l1_query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query' + str(num+1))(token)\n",
    "            #reshape to 1 x embedding_dim\n",
    "            l1_reshape_query = tf.keras.layers.Reshape((1,token.shape[0]))(l1_query)\n",
    "            #Softmax over query * key (words) to obtain weights\n",
    "            l1_weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                                name='attention_weights' + str(num+1))(l1_reshape_query)\n",
    "            #weight embeddings according to weights\n",
    "            l1_attention = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((token,l1_weights)))\n",
    "            attention_embeddings.append(l1_attention)\n",
    "\n",
    "        concat_attention = tf.keras.layers.Concatenate()(attention_embeddings)\n",
    "        concat_attention = tf.keras.layers.Reshape((num_attention,embedding_dim))(concat_attention)\n",
    "        \n",
    "        #Apply Query Vector to BERT Token, returning a num_attention x 1 tensor\n",
    "        query = tf.keras.layers.Dense(1,activation='linear',use_bias=False,name='attention_query')(concat_attention)\n",
    "        #reshape to 1 x num_attention\n",
    "        reshaped_query = tf.keras.layers.Reshape((1,token.shape[0]))(query)\n",
    "        #Softmax over query * key (words) to obtain weights\n",
    "        weights = tf.keras.layers.Lambda(lambda x:tf.keras.activations.softmax(x),\n",
    "                                            name='attention_weights')(reshaped_query)\n",
    "        #weight attention embeddings according to weights\n",
    "        embedding = tf.keras.layers.Flatten()(tf.keras.layers.Dot((1,2))((concat_attention,weights)))\n",
    "        \n",
    "    x = embedding\n",
    "    count = 1\n",
    "    for layer in hidden_dim:\n",
    "        hidden = tf.keras.layers.Dense(layer,activation = hidden_layer_activation,name='hidden_' + str(count))(x)\n",
    "        dropout = tf.keras.layers.Dropout(dropout_rate,name='dropout_' + str(count))(hidden)\n",
    "        count = count + 1\n",
    "        x = dropout\n",
    "\n",
    "    bert_classification = tf.keras.layers.Dense(output_layer_size, activation=output_activation,name='classification_layer')(x)\n",
    "    \n",
    "    bert_model = tf.keras.Model(inputs=[input_ids], outputs=[bert_classification])\n",
    "    \n",
    "    bert_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                                beta_1=0.9,\n",
    "                                                beta_2=0.999,\n",
    "                                                epsilon=1e-07,\n",
    "                                                amsgrad=False,\n",
    "                                                name='Adam'),\n",
    "                 metrics=['accuracy'],\n",
    "                     run_eagerly=True) \n",
    "    \n",
    "    print(bert_model.summary())\n",
    "    \n",
    "    return bert_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b0cb472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_9\" (type Reshape).\n\nTried to convert 'shape' to a tensor and failed. Error: None values not supported.\n\nCall arguments received by layer \"reshape_9\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cls_bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_bert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutput_layer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_attention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m cls_bert_model\u001b[38;5;241m.\u001b[39mfit(train_bert_ids[:\u001b[38;5;241m100\u001b[39m], train_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(mapping)\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m100\u001b[39m], \n\u001b[1;32m      4\u001b[0m                    validation_data\u001b[38;5;241m=\u001b[39m(val_bert_ids[:\u001b[38;5;241m100\u001b[39m],val_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(mapping)\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m100\u001b[39m]),\n\u001b[1;32m      5\u001b[0m                    batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[0;32mIn [103]\u001b[0m, in \u001b[0;36mcreate_bert_model\u001b[0;34m(train_layers, embedding_dim, token, num_attention, hidden_dim, dropout_rate, hidden_layer_activation, output_layer_size, output_activation, learning_rate)\u001b[0m\n\u001b[1;32m     62\u001b[0m l1_query \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m,use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_query\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(num\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))(token)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#reshape to 1 x embedding_dim\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m l1_reshape_query \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml1_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#Softmax over query * key (words) to obtain weights\u001b[39;00m\n\u001b[1;32m     66\u001b[0m l1_weights \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x:tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mactivations\u001b[38;5;241m.\u001b[39msoftmax(x),\n\u001b[1;32m     67\u001b[0m                                     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_weights\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(num\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))(l1_reshape_query)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:573\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    570\u001b[0m   observed \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    571\u001b[0m       values, as_ref\u001b[38;5;241m=\u001b[39minput_arg\u001b[38;5;241m.\u001b[39mis_ref)\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 573\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to convert \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to a tensor and failed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m prefix \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Op has type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m that does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    577\u001b[0m           (input_name, op_type_name, observed))\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_arg\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m types_pb2\u001b[38;5;241m.\u001b[39mDT_INVALID:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_9\" (type Reshape).\n\nTried to convert 'shape' to a tensor and failed. Error: None values not supported.\n\nCall arguments received by layer \"reshape_9\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "cls_bert_model = create_bert_model(learning_rate=0.00005,output_layer_size=11,num_attention=5)\n",
    "                        \n",
    "cls_bert_model.fit(train_bert_ids[:100], train_set['language label'].map(mapping).iloc[:100], \n",
    "                   validation_data=(val_bert_ids[:100],val_set['language label'].map(mapping).iloc[:100]),\n",
    "                   batch_size=8, epochs=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3599440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
